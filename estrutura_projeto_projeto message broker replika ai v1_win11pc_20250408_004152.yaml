.:
  .env.example:
    caminho_completo: .\.env.example
    numero_de_linhas: 32
    tamanho: 0.00 MB
  .flake8:
    caminho_completo: .\.flake8
    numero_de_linhas: 51
    tamanho: 0.00 MB
  .gitignore:
    caminho_completo: .\.gitignore
    numero_de_linhas: 60
    tamanho: 0.00 MB
  .pre-commit-config.yaml:
    caminho_completo: .\.pre-commit-config.yaml
    numero_de_linhas: 79
    tamanho: 0.00 MB
    yaml_info:
      numero_de_linhas: 79
      tamanho: 0.00 MB
  ARQUITETURA.md:
    caminho_completo: .\ARQUITETURA.md
    numero_de_linhas: 102
    tamanho: 0.00 MB
  CHANGELOG.md:
    caminho_completo: .\CHANGELOG.md
    numero_de_linhas: 93
    tamanho: 0.00 MB
  CONTRIBUTING.md:
    caminho_completo: .\CONTRIBUTING.md
    numero_de_linhas: 147
    tamanho: 0.00 MB
  DOCUMENTACAO-PROJETO.md:
    caminho_completo: .\DOCUMENTACAO-PROJETO.md
    numero_de_linhas: 61
    tamanho: 0.00 MB
  DOCUMENTACAO-PROJETO1.md:
    caminho_completo: .\DOCUMENTACAO-PROJETO1.md
    numero_de_linhas: 156
    tamanho: 0.01 MB
  LICENSE:
    caminho_completo: .\LICENSE
    numero_de_linhas: 21
    tamanho: 0.00 MB
  NOTAS.md:
    caminho_completo: .\NOTAS.md
    numero_de_linhas: 135
    tamanho: 0.00 MB
  README.md:
    caminho_completo: .\README.md
    numero_de_linhas: 95
    tamanho: 0.00 MB
  coleta-mensagem-v1.py:
    caminho_completo: .\coleta-mensagem-v1.py
    classes: []
    functions:
    - docstring: Cria o diretório de saída se não existir.
      end_lineno: 42
      lineno: 34
      name: setup_output_directory
    - docstring: Gera um nome de arquivo JSON único.
      end_lineno: 49
      lineno: 44
      name: generate_output_filename
    - docstring: Salva os dados coletados em um arquivo JSON.
      end_lineno: 62
      lineno: 51
      name: save_data_to_json
    - docstring: Função chamada ao receber sinal de parada (como Ctrl+C).
      end_lineno: 70
      lineno: 64
      name: handle_shutdown
    - docstring: Faz login usando a sessão para obter um token e configura na sessão.
      end_lineno: 99
      lineno: 72
      name: get_access_token
    - docstring: Verifica se a fila alvo existe.
      end_lineno: 121
      lineno: 101
      name: check_queue_exists
    - docstring: Tenta consumir uma mensagem e, se bem-sucedido, faz o ACK.
      end_lineno: 200
      lineno: 123
      name: consume_and_ack_message
    imports:
    - asname: null
      name: requests
    - asname: null
      name: json
    - asname: null
      name: warnings
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: datetime
    - asname: null
      name: os
    - asname: null
      name: hashlib
    - asname: null
      name: signal
    numero_de_linhas: 303
    source_code: "# -*- coding: utf-8 -*-\nimport requests\nimport json\nimport warnings\n\
      import sys\nimport time\nimport datetime\nimport os\nimport hashlib\nimport\
      \ signal # Para lidar com Ctrl+C de forma mais explícita se necessário\n\n\n\
      \n# --- Configurações ---\nBASE_URL = \"https://localhost:8777\"\nQUEUE_NAME\
      \ = \"minha-fila-teste-stress\" # <<< IMPORTANTE: Use a mesma fila do teste\
      \ de stress\nUSERNAME = \"admin\"\nPASSWORD = \"admin\"\nOUTPUT_DIR = \"test-json-data-collector-validation\"\
      \ # Pasta para salvar os JSONs\nEMPTY_QUEUE_DELAY_SECONDS = 0.5 # Tempo de espera\
      \ se a fila estiver vazia\nREQUEST_TIMEOUT = 10 # Timeout para requisições API\n\
      # --- Fim das Configurações ---\n\n# Ignorar avisos sobre certificados SSL autoassinados\n\
      warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n\n\
      # --- Globais ---\ncollected_message_contents = [] # Lista para armazenar o\
      \ conteúdo das mensagens\nsession = requests.Session() # Usar sessão para reutilizar\
      \ conexões\nsession.verify = False # Ignora verificação SSL para toda a sessão\n\
      keep_running = True # Flag para controlar o loop principal\n# --- Fim Globais\
      \ ---\n\ndef setup_output_directory():\n    \"\"\"Cria o diretório de saída\
      \ se não existir.\"\"\"\n    try:\n        os.makedirs(OUTPUT_DIR, exist_ok=True)\n\
      \        print(f\"\U0001F4C2 Diretório de saída '{OUTPUT_DIR}' verificado/criado.\"\
      )\n        return True\n    except OSError as e:\n        print(f\"❌ Erro crítico:\
      \ Não foi possível criar o diretório de saída '{OUTPUT_DIR}': {e}\")\n     \
      \   return False\n\ndef generate_output_filename() -> str:\n    \"\"\"Gera um\
      \ nome de arquivo JSON único.\"\"\"\n    timestamp = datetime.datetime.now().strftime(\"\
      %Y%m%d_%H%M%S\")\n    unique_hash = hashlib.sha1(str(os.getpid()).encode() +\
      \ str(time.time()).encode()).hexdigest()[:8]\n    filename = f\"collected_data_{QUEUE_NAME}_{timestamp}_{unique_hash}.json\"\
      \n    return os.path.join(OUTPUT_DIR, filename)\n\ndef save_data_to_json(filename:\
      \ str):\n    \"\"\"Salva os dados coletados em um arquivo JSON.\"\"\"\n    global\
      \ collected_message_contents\n    print(f\"\\n\U0001F4BE Salvando {len(collected_message_contents)}\
      \ mensagens coletadas em '{filename}'...\")\n    try:\n        with open(filename,\
      \ 'w', encoding='utf-8') as f:\n            json.dump(collected_message_contents,\
      \ f, indent=2, ensure_ascii=False)\n        print(f\"✅ Dados salvos com sucesso.\"\
      )\n    except IOError as e:\n        print(f\"❌ Erro ao salvar dados no arquivo\
      \ '{filename}': {e}\")\n    except Exception as e:\n        print(f\"\U0001F4A5\
      \ Erro inesperado ao salvar JSON: {e}\")\n\ndef handle_shutdown(signum=None,\
      \ frame=None):\n    \"\"\"Função chamada ao receber sinal de parada (como Ctrl+C).\"\
      \"\"\n    global keep_running\n    if not keep_running: # Evita chamadas múltiplas\n\
      \        return\n    print(\"\\n\U0001F6A6 Recebido sinal de parada. Iniciando\
      \ desligamento gracioso...\")\n    keep_running = False # Sinaliza para o loop\
      \ principal parar\n\ndef get_access_token(base_url, username, password):\n \
      \   \"\"\"Faz login usando a sessão para obter um token e configura na sessão.\"\
      \"\"\n    login_url = f\"{base_url}/login\"\n    try:\n        print(f\"\U0001F511\
      \ Tentando fazer login como '{username}'...\")\n        response = session.post(\n\
      \            login_url,\n            data={\"username\": username, \"password\"\
      : password},\n            timeout=REQUEST_TIMEOUT\n        )\n        response.raise_for_status()\n\
      \        token_data = response.json()\n        access_token = token_data.get(\"\
      access_token\")\n        if not access_token:\n            print(\"❌ Token não\
      \ encontrado na resposta do login.\")\n            return False\n        session.headers.update({\"\
      Authorization\": f\"Bearer {access_token}\"})\n        print(\"✅ Login bem-sucedido\
      \ e token configurado na sessão.\")\n        return True\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"❌ Erro de conexão ou HTTP ao tentar fazer login: {e}\"\
      )\n        if hasattr(e, 'response') and e.response is not None:\n         \
      \    try: print(f\"   Detalhe API: {e.response.json()}\")\n             except\
      \ json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:200]}...\")\n\
      \        return False\n    except json.JSONDecodeError:\n        print(f\"❌\
      \ Erro ao decodificar a resposta JSON do login.\")\n        return False\n\n\
      def check_queue_exists(base_url, queue_name):\n    \"\"\"Verifica se a fila\
      \ alvo existe.\"\"\"\n    get_queue_url = f\"{base_url}/queues/{queue_name}\"\
      \n    try:\n        print(f\"ℹ️  Verificando se a fila '{queue_name}' existe...\"\
      )\n        response_get = session.get(get_queue_url, timeout=REQUEST_TIMEOUT)\n\
      \        if response_get.status_code == 200:\n            print(f\"\U0001F44D\
      \ Fila '{queue_name}' encontrada.\")\n            return True\n        elif\
      \ response_get.status_code == 404:\n            print(f\"❌ Erro Crítico: Fila\
      \ '{queue_name}' não encontrada. Verifique o nome.\")\n            return False\n\
      \        else:\n            response_get.raise_for_status() # Lança erro para\
      \ outros status\n            return False # Não deve chegar aqui\n    except\
      \ requests.exceptions.RequestException as e:\n        print(f\"❌ Erro ao verificar\
      \ a fila '{queue_name}': {e}\")\n        if hasattr(e, 'response') and e.response\
      \ is not None:\n             try: print(f\"   Detalhe API: {e.response.json()}\"\
      )\n             except json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:200]}...\"\
      )\n        return False\n\ndef consume_and_ack_message(base_url, queue_name):\n\
      \    \"\"\"Tenta consumir uma mensagem e, se bem-sucedido, faz o ACK.\"\"\"\n\
      \    global collected_message_contents\n    consume_url = f\"{base_url}/queues/{queue_name}/messages/consume\"\
      \n    message_data = None\n\n    # 1. Tentar Consumir\n    try:\n        response_consume\
      \ = session.get(consume_url, timeout=REQUEST_TIMEOUT)\n\n        if response_consume.status_code\
      \ == 200:\n            message_data = response_consume.json()\n            if\
      \ message_data is None:\n                # Fila vazia, não é um erro, apenas\
      \ informativo\n                # print(\"E\", end=\"\", flush=True) # 'E' para\
      \ Empty\n                return \"empty\" # Sinaliza que a fila está vazia\n\
      \            # Temos uma mensagem!\n            message_id = message_data.get('message_id')\n\
      \            content = message_data.get('content')\n            if message_id\
      \ is None or content is None:\n                print(f\"\\n❗️ Resposta de consumo\
      \ inválida recebida: {message_data}\")\n                return \"error\" # Erro\
      \ inesperado no formato da resposta\n\n        elif response_consume.status_code\
      \ == 404: # Fila não existe mais?\n             print(f\"\\n❌ Erro: Fila '{queue_name}'\
      \ não encontrada durante consumo. Foi deletada?\")\n             return \"fatal_error\"\
      \ # Erro que deve parar o consumidor\n        else:\n             response_consume.raise_for_status()\
      \ # Levanta erro para outros status HTTP\n\n    except requests.exceptions.Timeout:\n\
      \        print(\"T\", end=\"\", flush=True) # Timeout\n        return \"error\"\
      \n    except requests.exceptions.RequestException as e:\n        print(f\"\\\
      n❌ Erro de rede/HTTP ao consumir: {e}\")\n        if hasattr(e, 'response')\
      \ and e.response is not None:\n             try: print(f\"   Detalhe API: {e.response.json()}\"\
      )\n             except json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:100]}...\"\
      )\n        return \"error\"\n    except json.JSONDecodeError:\n        print(f\"\
      \\n❌ Erro ao decodificar JSON da resposta de consumo.\")\n        return \"\
      error\"\n    except Exception as e:\n        print(f\"\\n\U0001F4A5 Erro inesperado\
      \ durante consumo: {e}\")\n        return \"error\"\n\n    # 2. Tentar Acknowledger\
      \ (ACK) - Somente se consumimos com sucesso\n    if message_data and message_id:\n\
      \        ack_url = f\"{base_url}/messages/{message_id}/ack\"\n        try:\n\
      \            response_ack = session.post(ack_url, timeout=REQUEST_TIMEOUT)\n\
      \            response_ack.raise_for_status() # Levanta erro para 4xx/5xx no\
      \ ACK\n\n            # ACK bem-sucedido!\n            collected_message_contents.append(content)\
      \ # Salva o conteúdo na lista\n            print(\".\", end=\"\", flush=True)\
      \ # \".\" para sucesso\n            return \"success\"\n\n        except requests.exceptions.Timeout:\n\
      \            print(\"A\", end=\"\", flush=True) # Ack Timeout\n            #\
      \ O que fazer aqui? A mensagem foi consumida mas não ack'd.\n            # Poderia\
      \ tentar NACK ou apenas logar por enquanto.\n            print(f\"\\n⚠️ Timeout\
      \ ao tentar ACK msg {message_id}. Mensagem pode ser reprocessada por outro consumidor.\"\
      )\n            return \"ack_error\"\n        except requests.exceptions.RequestException\
      \ as e:\n            status_code = getattr(e.response, 'status_code', 'N/A')\n\
      \            print(\"F\", end=\"\", flush=True) # Failed Ack\n            print(f\"\
      \\n❌ Falha ({status_code}) ao tentar ACK msg {message_id}: {e}\")\n        \
      \    if hasattr(e, 'response') and e.response is not None:\n               \
      \ try: print(f\"   Detalhe API: {e.response.json()}\")\n                except\
      \ json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:100]}...\")\n\
      \            # Mensagem foi consumida mas não ack'd.\n            return \"\
      ack_error\"\n        except Exception as e:\n            print(f\"\\n\U0001F4A5\
      \ Erro inesperado durante ACK da msg {message_id}: {e}\")\n            return\
      \ \"ack_error\"\n\n    # Se chegamos aqui, algo deu errado antes do ACK\n  \
      \  return \"error\"\n\n# --- Execução Principal ---\nif __name__ == \"__main__\"\
      :\n    print(\"--- Consumidor e Coletor de Dados da Fila ---\")\n    print(f\"\
      Alvo: {BASE_URL}\")\n    print(f\"Fila: {QUEUE_NAME}\")\n    print(f\"Pasta\
      \ de Saída: {OUTPUT_DIR}\")\n\n    # Configura manipulador de sinal para Ctrl+C\n\
      \    signal.signal(signal.SIGINT, handle_shutdown)\n    signal.signal(signal.SIGTERM,\
      \ handle_shutdown)\n\n    if not setup_output_directory():\n        sys.exit(1)\n\
      \n    # 1. Autenticar\n    if not get_access_token(BASE_URL, USERNAME, PASSWORD):\n\
      \        print(\"\\n--- Falha no Login. Abortando. ---\")\n        session.close()\n\
      \        sys.exit(1)\n\n    # 2. Verificar se a fila existe\n    if not check_queue_exists(BASE_URL,\
      \ QUEUE_NAME):\n        print(f\"\\n--- Fila '{QUEUE_NAME}' não existe ou inacessível.\
      \ Abortando. ---\")\n        session.close()\n        sys.exit(1)\n\n    print(f\"\
      \\n--- Iniciando consumo da fila '{QUEUE_NAME}' ---\")\n    print(\"Pressione\
      \ Ctrl+C para parar e salvar os dados.\")\n    print(\"Legenda: [.] Sucesso\
      \ | [E] Fila Vazia (pausando) | [T] Timeout Consumo | [A] Timeout ACK | [F]\
      \ Falha ACK | [X] Erro\")\n\n    processed_count = 0\n    error_count = 0\n\
      \    start_time = time.time()\n\n    try:\n        while keep_running:\n   \
      \         result = consume_and_ack_message(BASE_URL, QUEUE_NAME)\n\n       \
      \     if result == \"success\":\n                processed_count += 1\n    \
      \            # Adiciona nova linha a cada 50 sucessos para melhor visualização\n\
      \                if processed_count % 50 == 0:\n                    elapsed\
      \ = time.time() - start_time\n                    rate = processed_count / elapsed\
      \ if elapsed > 0 else 0\n                    print(f\" | {processed_count} msgs\
      \ processadas ({rate:.1f} msg/s)\")\n\n            elif result == \"empty\"\
      :\n                print(\"E\", end=\"\", flush=True)\n                # Pausa\
      \ antes de tentar novamente se a fila estiver vazia\n                # Usa wait\
      \ do Event se estiver usando threading, ou sleep simples\n                try:\n\
      \                   time.sleep(EMPTY_QUEUE_DELAY_SECONDS)\n                except\
      \ InterruptedError: # Pode acontecer se Ctrl+C for pressionado durante o sleep\n\
      \                   handle_shutdown()\n                   break # Sai do loop\
      \ se interrompido\n\n            elif result == \"ack_error\":\n           \
      \     error_count += 1\n                # Pausa curta após erro de ACK para\
      \ evitar spam\n                time.sleep(0.2)\n\n            elif result ==\
      \ \"error\":\n                print(\"X\", end=\"\", flush=True)\n         \
      \       error_count += 1\n                # Pausa um pouco maior após erro genérico\
      \ ou de rede\n                time.sleep(1.0)\n\n            elif result ==\
      \ \"fatal_error\":\n                print(\"\\n⛔ Erro fatal detectado. Parando\
      \ o consumidor.\")\n                keep_running = False # Para o loop\n   \
      \             break\n\n            # Verificação adicional para o caso de handle_shutdown\
      \ ter sido chamado por um sinal\n            if not keep_running:\n        \
      \        break\n\n    # except KeyboardInterrupt: # Redundante se o signal handler\
      \ funcionar bem\n    #     handle_shutdown()\n\n    finally:\n        # Esta\
      \ parte será executada quando o loop terminar (normalmente ou por sinal)\n \
      \       print(\"\\n--- Finalizando ---\")\n        output_filename = generate_output_filename()\n\
      \        save_data_to_json(output_filename)\n\n        # Imprimir estatísticas\
      \ finais\n        end_time = time.time()\n        total_time = end_time - start_time\n\
      \        print(\"\\n--- Resumo da Coleta ---\")\n        print(f\"Tempo total\
      \ de execução: {total_time:.2f} segundos\")\n        print(f\"Total de mensagens\
      \ processadas e salvas: {processed_count}\")\n        print(f\"Total de erros\
      \ (consumo/ack/outros): {error_count}\")\n        if total_time > 0 and processed_count\
      \ > 0:\n            average_rate = processed_count / total_time\n          \
      \  print(f\"Taxa média de processamento: {average_rate:.2f} mensagens/segundo\"\
      )\n        print(f\"Dados salvos em: {output_filename}\")\n        print(\"\
      --------------------------\")\n\n        # Fecha a sessão de requests\n    \
      \    session.close()\n        print(\"\U0001F50C Sessão HTTP fechada.\")\n \
      \       sys.exit(0)"
    tamanho: 0.01 MB
  coleta-mensagem-v3-batch-lote.py:
    caminho_completo: .\coleta-mensagem-v3-batch-lote.py
    classes: []
    functions:
    - docstring: null
      end_lineno: 37
      lineno: 30
      name: setup_output_directory
    - docstring: Gera um nome de arquivo JSON único para um lote.
      end_lineno: 44
      lineno: 39
      name: generate_batch_filename
    - docstring: Salva um lote de dados coletados em um arquivo JSON.
      end_lineno: 63
      lineno: 46
      name: save_batch_to_json
    - docstring: null
      end_lineno: 70
      lineno: 65
      name: handle_shutdown
    - docstring: null
      end_lineno: 98
      lineno: 72
      name: get_access_token
    - docstring: null
      end_lineno: 119
      lineno: 100
      name: check_queue_exists
    - docstring: null
      end_lineno: 204
      lineno: 121
      name: consume_and_ack_message
    imports:
    - asname: null
      name: requests
    - asname: null
      name: json
    - asname: null
      name: warnings
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: datetime
    - asname: null
      name: os
    - asname: null
      name: hashlib
    - asname: null
      name: signal
    numero_de_linhas: 319
    source_code: "import requests\nimport json\nimport warnings\nimport sys\nimport\
      \ time\nimport datetime\nimport os\nimport hashlib\nimport signal\n\n# --- Configurações\
      \ ---\nBASE_URL = \"https://localhost:8777\"\nQUEUE_NAME = \"minha-fila-teste-stress\"\
      \nUSERNAME = \"admin\"\nPASSWORD = \"admin\"\nOUTPUT_DIR = \"test-json-data-collector-validation_batched\"\
      \ # Nome de diretório sugerido para lotes\nEMPTY_QUEUE_DELAY_SECONDS = 0.5\n\
      REQUEST_TIMEOUT = 10\nSAVE_BATCH_SIZE = 10  # <<< NOVO: Salvar a cada X mensagens\n\
      \nwarnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n\
      \n# --- Globais ---\ncurrent_batch = [] # <<< ALTERADO: Armazena o lote atual\n\
      total_saved_count = 0 # <<< NOVO: Contagem total de mensagens salvas em todos\
      \ os lotes\nsession = requests.Session()\nsession.verify = False\nkeep_running\
      \ = True\n\ndef setup_output_directory():\n    try:\n        os.makedirs(OUTPUT_DIR,\
      \ exist_ok=True)\n        print(f\"\U0001F4C2 Diretório de saída '{OUTPUT_DIR}'\
      \ verificado/criado.\")\n        return True\n    except OSError as e:\n   \
      \     print(f\"❌ Erro crítico: Não foi possível criar o diretório de saída '{OUTPUT_DIR}':\
      \ {e}\")\n        return False\n\ndef generate_batch_filename() -> str: # Renomeado\
      \ para clareza\n    \"\"\"Gera um nome de arquivo JSON único para um lote.\"\
      \"\"\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\"\
      ) # Adiciona microsegundos para maior unicidade\n    unique_hash = hashlib.sha1(str(os.getpid()).encode()\
      \ + str(time.time_ns()).encode()).hexdigest()[:8]\n    filename = f\"collected_batch_{QUEUE_NAME}_{timestamp}_{unique_hash}.json\"\
      \n    return os.path.join(OUTPUT_DIR, filename)\n\ndef save_batch_to_json(filename:\
      \ str, batch_data: list): # Modificado para aceitar dados\n    \"\"\"Salva um\
      \ lote de dados coletados em um arquivo JSON.\"\"\"\n    global total_saved_count\n\
      \    batch_size = len(batch_data)\n    if batch_size == 0:\n        print(\"\
      \\n⚠️ Tentativa de salvar lote vazio. Ignorando.\")\n        return\n\n    print(f\"\
      \\n\U0001F4BE Salvando lote de {batch_size} mensagens em '{filename}'...\")\n\
      \    try:\n        with open(filename, 'w', encoding='utf-8') as f:\n      \
      \      json.dump(batch_data, f, indent=2, ensure_ascii=False)\n        total_saved_count\
      \ += batch_size # Incrementa contador global\n        print(f\"✅ Lote salvo\
      \ com sucesso. Total salvo até agora: {total_saved_count}\")\n    except IOError\
      \ as e:\n        print(f\"❌ Erro ao salvar lote no arquivo '{filename}': {e}\"\
      )\n    except Exception as e:\n        print(f\"\U0001F4A5 Erro inesperado ao\
      \ salvar lote JSON: {e}\")\n\ndef handle_shutdown(signum=None, frame=None):\n\
      \    global keep_running\n    if not keep_running:\n        return\n    print(\"\
      \\n\U0001F6A6 Recebido sinal de parada. Processando último lote e finalizando...\"\
      )\n    keep_running = False\n\ndef get_access_token(base_url, username, password):\n\
      \    login_url = f\"{base_url}/login\"\n    try:\n        print(f\"\U0001F511\
      \ Tentando fazer login como '{username}'...\")\n        response = session.post(\n\
      \            login_url,\n            data={\"username\": username, \"password\"\
      : password},\n            timeout=REQUEST_TIMEOUT\n        )\n        response.raise_for_status()\n\
      \        token_data = response.json()\n        access_token = token_data.get(\"\
      access_token\")\n        if not access_token:\n            print(\"❌ Token não\
      \ encontrado na resposta do login.\")\n            return False\n        session.headers.update({\"\
      Authorization\": f\"Bearer {access_token}\"})\n        print(\"✅ Login bem-sucedido\
      \ e token configurado na sessão.\")\n        return True\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"❌ Erro de conexão ou HTTP ao tentar fazer login: {e}\"\
      )\n        if hasattr(e, 'response') and e.response is not None:\n         \
      \    try: print(f\"   Detalhe API: {e.response.json()}\")\n             except\
      \ json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:200]}...\")\n\
      \        return False\n    except json.JSONDecodeError:\n        print(f\"❌\
      \ Erro ao decodificar a resposta JSON do login.\")\n        return False\n\n\
      def check_queue_exists(base_url, queue_name):\n    get_queue_url = f\"{base_url}/queues/{queue_name}\"\
      \n    try:\n        print(f\"ℹ️  Verificando se a fila '{queue_name}' existe...\"\
      )\n        response_get = session.get(get_queue_url, timeout=REQUEST_TIMEOUT)\n\
      \        if response_get.status_code == 200:\n            print(f\"\U0001F44D\
      \ Fila '{queue_name}' encontrada.\")\n            return True\n        elif\
      \ response_get.status_code == 404:\n            print(f\"❌ Erro Crítico: Fila\
      \ '{queue_name}' não encontrada. Verifique o nome.\")\n            return False\n\
      \        else:\n            response_get.raise_for_status()\n            return\
      \ False\n    except requests.exceptions.RequestException as e:\n        print(f\"\
      ❌ Erro ao verificar a fila '{queue_name}': {e}\")\n        if hasattr(e, 'response')\
      \ and e.response is not None:\n             try: print(f\"   Detalhe API: {e.response.json()}\"\
      )\n             except json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:200]}...\"\
      )\n        return False\n\ndef consume_and_ack_message(base_url, queue_name):\n\
      \    global current_batch # Modificado para usar current_batch\n    consume_url\
      \ = f\"{base_url}/queues/{queue_name}/messages/consume\"\n    message_data =\
      \ None\n    message_id = None\n\n    try:\n        response_consume = session.get(consume_url,\
      \ timeout=REQUEST_TIMEOUT)\n\n        if response_consume.status_code == 200:\n\
      \            message_data = response_consume.json()\n            if message_data\
      \ is None:\n                return \"empty\"\n\n            message_id = message_data.get('id')\n\
      \            content = message_data.get('content')\n\n            if message_id\
      \ is None or content is None:\n                print(f\"\\n❗️ Resposta de consumo\
      \ inválida (faltando 'id' ou 'content'): {message_data}\")\n               \
      \ return \"error\"\n\n        elif response_consume.status_code == 204:\n  \
      \           # Fila vazia, não imprime 'E' aqui, será tratado no loop principal\n\
      \             return \"empty\"\n\n        elif response_consume.status_code\
      \ == 404:\n             print(f\"\\n❌ Erro: Fila '{queue_name}' não encontrada\
      \ durante consumo. Foi deletada?\")\n             return \"fatal_error\"\n \
      \       else:\n             response_consume.raise_for_status()\n\n    except\
      \ requests.exceptions.Timeout:\n        print(\"T\", end=\"\", flush=True)\n\
      \        return \"error\"\n    except requests.exceptions.RequestException as\
      \ e:\n        print(f\"\\n❌ Erro de rede/HTTP ao consumir: {e}\")\n        if\
      \ hasattr(e, 'response') and e.response is not None:\n             try:\n  \
      \               print(f\"   Detalhe API: {e.response.json()}\")\n          \
      \   except json.JSONDecodeError:\n                 print(f\"   Resposta: {e.response.text[:100]}...\"\
      )\n        return \"error\"\n    except json.JSONDecodeError:\n        status_code_info\
      \ = getattr(response_consume, 'status_code', 'N/A')\n        body_info = getattr(response_consume,\
      \ 'text', '')[:100]\n        print(f\"\\n❌ Erro ao decodificar JSON da resposta\
      \ de consumo (Status {status_code_info}). Corpo: {body_info}...\")\n       \
      \ return \"error\"\n    except Exception as e:\n        print(f\"\\n\U0001F4A5\
      \ Erro inesperado durante consumo: {type(e).__name__} - {e}\")\n        return\
      \ \"error\"\n\n    # ACK só acontece se o consumo foi bem-sucedido (message_id\
      \ e message_data existem)\n    if message_id and message_data:\n        ack_url\
      \ = f\"{base_url}/messages/{message_id}/ack\"\n        try:\n            response_ack\
      \ = session.post(ack_url, timeout=REQUEST_TIMEOUT)\n            response_ack.raise_for_status()\n\
      \n            # ACK OK - Adiciona ao lote atual\n            content = message_data.get('content')\n\
      \            current_batch.append(content) # Adiciona ao lote\n            print(\"\
      .\", end=\"\", flush=True)\n            return \"success\" # Retorna sucesso\
      \ para o loop principal\n\n        except requests.exceptions.Timeout:\n   \
      \         print(\"A\", end=\"\", flush=True)\n            print(f\"\\n⚠️ Timeout\
      \ ao tentar ACK msg {message_id}. Mensagem pode ser reprocessada.\")\n     \
      \       return \"ack_error\"\n        except requests.exceptions.RequestException\
      \ as e:\n            status_code = getattr(e.response, 'status_code', 'N/A')\n\
      \            print(\"F\", end=\"\", flush=True)\n            print(f\"\\n❌ Falha\
      \ ({status_code}) ao tentar ACK msg {message_id}: {e}\")\n            if hasattr(e,\
      \ 'response') and e.response is not None:\n                try:\n          \
      \          print(f\"   Detalhe API: {e.response.json()}\")\n               \
      \ except json.JSONDecodeError:\n                    print(f\"   Resposta: {e.response.text[:100]}...\"\
      )\n            return \"ack_error\"\n        except Exception as e:\n      \
      \      print(f\"\\n\U0001F4A5 Erro inesperado durante ACK da msg {message_id}:\
      \ {type(e).__name__} - {e}\")\n            return \"ack_error\"\n\n    # Se\
      \ chegou aqui, algo deu errado antes do ACK (fila vazia, erro de consumo, resposta\
      \ inválida)\n    return \"error\"\n\n# --- Execução Principal ---\nif __name__\
      \ == \"__main__\":\n    print(\"--- Consumidor e Coletor de Dados da Fila (Salvando\
      \ em Lotes) ---\")\n    print(f\"Alvo: {BASE_URL}\")\n    print(f\"Fila: {QUEUE_NAME}\"\
      )\n    print(f\"Pasta de Saída: {OUTPUT_DIR}\")\n    print(f\"Tamanho do Lote\
      \ para Salvar: {SAVE_BATCH_SIZE}\")\n\n    signal.signal(signal.SIGINT, handle_shutdown)\n\
      \    signal.signal(signal.SIGTERM, handle_shutdown)\n\n    if not setup_output_directory():\n\
      \        sys.exit(1)\n\n    if not get_access_token(BASE_URL, USERNAME, PASSWORD):\n\
      \        print(\"\\n--- Falha no Login. Abortando. ---\")\n        session.close()\n\
      \        sys.exit(1)\n\n    if not check_queue_exists(BASE_URL, QUEUE_NAME):\n\
      \        print(f\"\\n--- Fila '{QUEUE_NAME}' não existe ou inacessível. Abortando.\
      \ ---\")\n        session.close()\n        sys.exit(1)\n\n    print(f\"\\n---\
      \ Iniciando consumo da fila '{QUEUE_NAME}' ---\")\n    print(\"Pressione Ctrl+C\
      \ para parar e salvar os dados restantes.\")\n    print(\"Legenda: [.] Sucesso\
      \ | [E] Fila Vazia | [S] Lote Salvo | [T] Timeout Consumo | [A] Timeout ACK\
      \ | [F] Falha ACK | [X] Erro\")\n\n    processed_in_run = 0 # Conta mensagens\
      \ processadas nesta execução\n    error_count = 0\n    start_time = time.time()\n\
      \    last_empty_print_time = 0\n\n    try:\n        while keep_running:\n  \
      \          result = consume_and_ack_message(BASE_URL, QUEUE_NAME)\n\n      \
      \      if result == \"success\":\n                processed_in_run += 1\n  \
      \              # Verifica se o lote está cheio para salvar\n               \
      \ if len(current_batch) >= SAVE_BATCH_SIZE:\n                    batch_filename\
      \ = generate_batch_filename()\n                    save_batch_to_json(batch_filename,\
      \ current_batch)\n                    current_batch = [] # Limpa o lote para\
      \ o próximo\n                    print(\"S\", end=\"\", flush=True) # Indica\
      \ que um lote foi salvo\n\n                # Opcional: Imprimir taxa a cada\
      \ X mensagens, independente do lote\n                if processed_in_run % 100\
      \ == 0: # Ex: a cada 100 mensagens\n                     elapsed = time.time()\
      \ - start_time\n                     rate = processed_in_run / elapsed if elapsed\
      \ > 0 else 0\n                     print(f\" | {processed_in_run} msgs processadas\
      \ nesta execução ({rate:.1f} msg/s)\")\n\n\n            elif result == \"empty\"\
      :\n                 # Imprime 'E' apenas uma vez a cada segundo para não poluir\n\
      \                 current_time = time.time()\n                 if current_time\
      \ - last_empty_print_time >= 1.0:\n                      print(\"E\", end=\"\
      \", flush=True)\n                      last_empty_print_time = current_time\n\
      \                 try:\n                    time.sleep(EMPTY_QUEUE_DELAY_SECONDS)\n\
      \                 except InterruptedError:\n                    handle_shutdown()\n\
      \                    break\n\n            elif result == \"ack_error\":\n  \
      \              error_count += 1\n                # Considerar não pausar ou\
      \ pausar muito pouco após erro de ACK,\n                # pois a mensagem pode\
      \ ser reprocessada rapidamente por outro consumidor.\n                # time.sleep(0.1)\n\
      \n            elif result == \"error\":\n                print(\"X\", end=\"\
      \", flush=True)\n                error_count += 1\n                time.sleep(0.5)\
      \ # Pausa menor após erro genérico\n\n            elif result == \"fatal_error\"\
      :\n                print(\"\\n⛔ Erro fatal detectado. Parando o consumidor.\"\
      )\n                keep_running = False # Sinaliza para parar\n            \
      \    break # Sai do loop imediatamente\n\n            # Verificação explícita\
      \ caso o handle_shutdown tenha sido chamado\n            if not keep_running:\n\
      \                break\n\n    finally:\n        print(\"\\n--- Finalizando ---\"\
      )\n        # Salva qualquer mensagem restante no lote atual\n        if current_batch:\n\
      \            print(f\"\\nSalvando lote final com {len(current_batch)} mensagens...\"\
      )\n            final_batch_filename = generate_batch_filename()\n          \
      \  save_batch_to_json(final_batch_filename, current_batch)\n        else:\n\
      \            print(\"\\nNenhuma mensagem pendente no lote final para salvar.\"\
      )\n\n        end_time = time.time()\n        total_time = end_time - start_time\n\
      \        print(\"\\n--- Resumo da Execução ---\")\n        print(f\"Tempo total\
      \ de execução: {total_time:.2f} segundos\")\n        print(f\"Total de mensagens\
      \ processadas nesta execução: {processed_in_run}\")\n        print(f\"Total\
      \ de mensagens salvas (acumulado): {total_saved_count}\")\n        print(f\"\
      Total de erros (consumo/ack/outros): {error_count}\")\n        if total_time\
      \ > 0 and processed_in_run > 0:\n            average_rate = processed_in_run\
      \ / total_time\n            print(f\"Taxa média de processamento: {average_rate:.2f}\
      \ mensagens/segundo\")\n        print(f\"Dados salvos em lotes no diretório:\
      \ {OUTPUT_DIR}\")\n        print(\"--------------------------\")\n\n       \
      \ session.close()\n        print(\"\U0001F50C Sessão HTTP fechada.\")\n    \
      \    # Sai com código 0 indicando sucesso (mesmo que erros tenham ocorrido durante\
      \ a execução)\n        # ou 1 se houve erro fatal ou interrupção não graciosa.\n\
      \        exit_code = 0 if keep_running else 1 # Se keep_running for False por\
      \ sinal, saída graciosa (0). Se por erro fatal, também é False. Ajustar se necessário.\n\
      \        sys.exit(exit_code)"
    tamanho: 0.01 MB
  coleta-mensagem-v3.py:
    caminho_completo: .\coleta-mensagem-v3.py
    classes: []
    functions:
    - docstring: null
      end_lineno: 33
      lineno: 26
      name: setup_output_directory
    - docstring: null
      end_lineno: 39
      lineno: 35
      name: generate_output_filename
    - docstring: null
      end_lineno: 51
      lineno: 41
      name: save_data_to_json
    - docstring: null
      end_lineno: 58
      lineno: 53
      name: handle_shutdown
    - docstring: null
      end_lineno: 86
      lineno: 60
      name: get_access_token
    - docstring: null
      end_lineno: 107
      lineno: 88
      name: check_queue_exists
    - docstring: null
      end_lineno: 189
      lineno: 109
      name: consume_and_ack_message
    imports:
    - asname: null
      name: requests
    - asname: null
      name: json
    - asname: null
      name: warnings
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: datetime
    - asname: null
      name: os
    - asname: null
      name: hashlib
    - asname: null
      name: signal
    numero_de_linhas: 280
    source_code: "import requests\nimport json\nimport warnings\nimport sys\nimport\
      \ time\nimport datetime\nimport os\nimport hashlib\nimport signal\n\nBASE_URL\
      \ = \"https://localhost:8777\"\nQUEUE_NAME = \"minha-fila-teste-stress\"\nUSERNAME\
      \ = \"admin\"\nPASSWORD = \"admin\"\nOUTPUT_DIR = \"test-json-data-collector-validation\"\
      \nEMPTY_QUEUE_DELAY_SECONDS = 0.5\nREQUEST_TIMEOUT = 10\n\nwarnings.filterwarnings(\"\
      ignore\", message=\"Unverified HTTPS request\")\n\ncollected_message_contents\
      \ = []\nsession = requests.Session()\nsession.verify = False\nkeep_running =\
      \ True\n\ndef setup_output_directory():\n    try:\n        os.makedirs(OUTPUT_DIR,\
      \ exist_ok=True)\n        print(f\"\U0001F4C2 Diretório de saída '{OUTPUT_DIR}'\
      \ verificado/criado.\")\n        return True\n    except OSError as e:\n   \
      \     print(f\"❌ Erro crítico: Não foi possível criar o diretório de saída '{OUTPUT_DIR}':\
      \ {e}\")\n        return False\n\ndef generate_output_filename() -> str:\n \
      \   timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    unique_hash\
      \ = hashlib.sha1(str(os.getpid()).encode() + str(time.time()).encode()).hexdigest()[:8]\n\
      \    filename = f\"collected_data_{QUEUE_NAME}_{timestamp}_{unique_hash}.json\"\
      \n    return os.path.join(OUTPUT_DIR, filename)\n\ndef save_data_to_json(filename:\
      \ str):\n    global collected_message_contents\n    print(f\"\\n\U0001F4BE Salvando\
      \ {len(collected_message_contents)} mensagens coletadas em '{filename}'...\"\
      )\n    try:\n        with open(filename, 'w', encoding='utf-8') as f:\n    \
      \        json.dump(collected_message_contents, f, indent=2, ensure_ascii=False)\n\
      \        print(f\"✅ Dados salvos com sucesso.\")\n    except IOError as e:\n\
      \        print(f\"❌ Erro ao salvar dados no arquivo '{filename}': {e}\")\n \
      \   except Exception as e:\n        print(f\"\U0001F4A5 Erro inesperado ao salvar\
      \ JSON: {e}\")\n\ndef handle_shutdown(signum=None, frame=None):\n    global\
      \ keep_running\n    if not keep_running:\n        return\n    print(\"\\n\U0001F6A6\
      \ Recebido sinal de parada. Iniciando desligamento gracioso...\")\n    keep_running\
      \ = False\n\ndef get_access_token(base_url, username, password):\n    login_url\
      \ = f\"{base_url}/login\"\n    try:\n        print(f\"\U0001F511 Tentando fazer\
      \ login como '{username}'...\")\n        response = session.post(\n        \
      \    login_url,\n            data={\"username\": username, \"password\": password},\n\
      \            timeout=REQUEST_TIMEOUT\n        )\n        response.raise_for_status()\n\
      \        token_data = response.json()\n        access_token = token_data.get(\"\
      access_token\")\n        if not access_token:\n            print(\"❌ Token não\
      \ encontrado na resposta do login.\")\n            return False\n        session.headers.update({\"\
      Authorization\": f\"Bearer {access_token}\"})\n        print(\"✅ Login bem-sucedido\
      \ e token configurado na sessão.\")\n        return True\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"❌ Erro de conexão ou HTTP ao tentar fazer login: {e}\"\
      )\n        if hasattr(e, 'response') and e.response is not None:\n         \
      \    try: print(f\"   Detalhe API: {e.response.json()}\")\n             except\
      \ json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:200]}...\")\n\
      \        return False\n    except json.JSONDecodeError:\n        print(f\"❌\
      \ Erro ao decodificar a resposta JSON do login.\")\n        return False\n\n\
      def check_queue_exists(base_url, queue_name):\n    get_queue_url = f\"{base_url}/queues/{queue_name}\"\
      \n    try:\n        print(f\"ℹ️  Verificando se a fila '{queue_name}' existe...\"\
      )\n        response_get = session.get(get_queue_url, timeout=REQUEST_TIMEOUT)\n\
      \        if response_get.status_code == 200:\n            print(f\"\U0001F44D\
      \ Fila '{queue_name}' encontrada.\")\n            return True\n        elif\
      \ response_get.status_code == 404:\n            print(f\"❌ Erro Crítico: Fila\
      \ '{queue_name}' não encontrada. Verifique o nome.\")\n            return False\n\
      \        else:\n            response_get.raise_for_status()\n            return\
      \ False\n    except requests.exceptions.RequestException as e:\n        print(f\"\
      ❌ Erro ao verificar a fila '{queue_name}': {e}\")\n        if hasattr(e, 'response')\
      \ and e.response is not None:\n             try: print(f\"   Detalhe API: {e.response.json()}\"\
      )\n             except json.JSONDecodeError: print(f\"   Resposta: {e.response.text[:200]}...\"\
      )\n        return False\n\ndef consume_and_ack_message(base_url, queue_name):\n\
      \    global collected_message_contents\n    consume_url = f\"{base_url}/queues/{queue_name}/messages/consume\"\
      \n    message_data = None\n    message_id = None\n\n    try:\n        response_consume\
      \ = session.get(consume_url, timeout=REQUEST_TIMEOUT)\n\n        if response_consume.status_code\
      \ == 200:\n            message_data = response_consume.json()\n            if\
      \ message_data is None:\n                return \"empty\"\n\n            message_id\
      \ = message_data.get('id') # CORRIGIDO: Buscar 'id'\n            content = message_data.get('content')\n\
      \n            if message_id is None or content is None: # Verifica se 'id' foi\
      \ encontrado\n                print(f\"\\n❗️ Resposta de consumo inválida (faltando\
      \ 'id' ou 'content'): {message_data}\")\n                return \"error\"\n\n\
      \        elif response_consume.status_code == 204:\n             print(\"E\"\
      , end=\"\", flush=True)\n             return \"empty\"\n\n        elif response_consume.status_code\
      \ == 404:\n             print(f\"\\n❌ Erro: Fila '{queue_name}' não encontrada\
      \ durante consumo. Foi deletada?\")\n             return \"fatal_error\"\n \
      \       else:\n             response_consume.raise_for_status()\n\n    except\
      \ requests.exceptions.Timeout:\n        print(\"T\", end=\"\", flush=True)\n\
      \        return \"error\"\n    except requests.exceptions.RequestException as\
      \ e:\n        print(f\"\\n❌ Erro de rede/HTTP ao consumir: {e}\")\n        if\
      \ hasattr(e, 'response') and e.response is not None:\n             try:\n  \
      \               print(f\"   Detalhe API: {e.response.json()}\")\n          \
      \   except json.JSONDecodeError:\n                 print(f\"   Resposta: {e.response.text[:100]}...\"\
      )\n        return \"error\"\n    except json.JSONDecodeError:\n        status_code_info\
      \ = getattr(response_consume, 'status_code', 'N/A')\n        body_info = getattr(response_consume,\
      \ 'text', '')[:100]\n        print(f\"\\n❌ Erro ao decodificar JSON da resposta\
      \ de consumo (Status {status_code_info}). Corpo: {body_info}...\")\n       \
      \ return \"error\"\n    except Exception as e:\n        print(f\"\\n\U0001F4A5\
      \ Erro inesperado durante consumo: {type(e).__name__} - {e}\")\n        return\
      \ \"error\"\n\n    if message_id and message_data:\n        ack_url = f\"{base_url}/messages/{message_id}/ack\"\
      \n        try:\n            response_ack = session.post(ack_url, timeout=REQUEST_TIMEOUT)\n\
      \            response_ack.raise_for_status()\n\n            content = message_data.get('content')\n\
      \            collected_message_contents.append(content)\n            print(\"\
      .\", end=\"\", flush=True)\n            return \"success\"\n\n        except\
      \ requests.exceptions.Timeout:\n            print(\"A\", end=\"\", flush=True)\n\
      \            print(f\"\\n⚠️ Timeout ao tentar ACK msg {message_id}. Mensagem\
      \ pode ser reprocessada.\")\n            return \"ack_error\"\n        except\
      \ requests.exceptions.RequestException as e:\n            status_code = getattr(e.response,\
      \ 'status_code', 'N/A')\n            print(\"F\", end=\"\", flush=True)\n  \
      \          print(f\"\\n❌ Falha ({status_code}) ao tentar ACK msg {message_id}:\
      \ {e}\")\n            if hasattr(e, 'response') and e.response is not None:\n\
      \                try:\n                    print(f\"   Detalhe API: {e.response.json()}\"\
      )\n                except json.JSONDecodeError:\n                    print(f\"\
      \   Resposta: {e.response.text[:100]}...\")\n            return \"ack_error\"\
      \n        except Exception as e:\n            print(f\"\\n\U0001F4A5 Erro inesperado\
      \ durante ACK da msg {message_id}: {type(e).__name__} - {e}\")\n           \
      \ return \"ack_error\"\n\n    return \"error\"\n\nif __name__ == \"__main__\"\
      :\n    print(\"--- Consumidor e Coletor de Dados da Fila ---\")\n    print(f\"\
      Alvo: {BASE_URL}\")\n    print(f\"Fila: {QUEUE_NAME}\")\n    print(f\"Pasta\
      \ de Saída: {OUTPUT_DIR}\")\n\n    signal.signal(signal.SIGINT, handle_shutdown)\n\
      \    signal.signal(signal.SIGTERM, handle_shutdown)\n\n    if not setup_output_directory():\n\
      \        sys.exit(1)\n\n    if not get_access_token(BASE_URL, USERNAME, PASSWORD):\n\
      \        print(\"\\n--- Falha no Login. Abortando. ---\")\n        session.close()\n\
      \        sys.exit(1)\n\n    if not check_queue_exists(BASE_URL, QUEUE_NAME):\n\
      \        print(f\"\\n--- Fila '{QUEUE_NAME}' não existe ou inacessível. Abortando.\
      \ ---\")\n        session.close()\n        sys.exit(1)\n\n    print(f\"\\n---\
      \ Iniciando consumo da fila '{QUEUE_NAME}' ---\")\n    print(\"Pressione Ctrl+C\
      \ para parar e salvar os dados.\")\n    print(\"Legenda: [.] Sucesso | [E] Fila\
      \ Vazia (pausando) | [T] Timeout Consumo | [A] Timeout ACK | [F] Falha ACK |\
      \ [X] Erro\")\n\n    processed_count = 0\n    error_count = 0\n    start_time\
      \ = time.time()\n\n    try:\n        while keep_running:\n            result\
      \ = consume_and_ack_message(BASE_URL, QUEUE_NAME)\n\n            if result ==\
      \ \"success\":\n                processed_count += 1\n                if processed_count\
      \ % 50 == 0:\n                    elapsed = time.time() - start_time\n     \
      \               rate = processed_count / elapsed if elapsed > 0 else 0\n   \
      \                 print(f\" | {processed_count} msgs processadas ({rate:.1f}\
      \ msg/s)\")\n\n            elif result == \"empty\":\n                print(\"\
      E\", end=\"\", flush=True)\n                try:\n                   # Pequena\
      \ pausa antes de verificar novamente para não sobrecarregar\n              \
      \     time.sleep(EMPTY_QUEUE_DELAY_SECONDS)\n                   # Adiciona nova\
      \ linha a cada ~10 segundos de espera (20 * 0.5s)\n                   if int(time.time()\
      \ * (1/EMPTY_QUEUE_DELAY_SECONDS)) % 20 == 0:\n                       print(\"\
      E\", end=\"\\n\", flush=True)\n                except InterruptedError:\n  \
      \                 handle_shutdown()\n                   break\n\n          \
      \  elif result == \"ack_error\":\n                error_count += 1\n       \
      \         time.sleep(0.2)\n\n            elif result == \"error\":\n       \
      \         print(\"X\", end=\"\", flush=True)\n                error_count +=\
      \ 1\n                time.sleep(1.0)\n\n            elif result == \"fatal_error\"\
      :\n                print(\"\\n⛔ Erro fatal detectado. Parando o consumidor.\"\
      )\n                keep_running = False\n                break\n\n         \
      \   if not keep_running:\n                break\n\n    finally:\n        print(\"\
      \\n--- Finalizando ---\")\n        output_filename = generate_output_filename()\n\
      \        save_data_to_json(output_filename)\n\n        end_time = time.time()\n\
      \        total_time = end_time - start_time\n        print(\"\\n--- Resumo da\
      \ Coleta ---\")\n        print(f\"Tempo total de execução: {total_time:.2f}\
      \ segundos\")\n        print(f\"Total de mensagens processadas e salvas: {processed_count}\"\
      )\n        print(f\"Total de erros (consumo/ack/outros): {error_count}\")\n\
      \        if total_time > 0 and processed_count > 0:\n            average_rate\
      \ = processed_count / total_time\n            print(f\"Taxa média de processamento:\
      \ {average_rate:.2f} mensagens/segundo\")\n        print(f\"Dados salvos em:\
      \ {output_filename}\")\n        print(\"--------------------------\")\n\n  \
      \      session.close()\n        print(\"\U0001F50C Sessão HTTP fechada.\")\n\
      \        sys.exit(0)"
    tamanho: 0.01 MB
  coletamensagemv1.py:
    caminho_completo: .\coletamensagemv1.py
    classes: []
    functions:
    - docstring: Faz login usando a sessão para obter um token.
      end_lineno: 58
      lineno: 28
      name: get_access_token
    - docstring: Envia um ACK para o servidor para confirmar o processamento.
      end_lineno: 97
      lineno: 60
      name: acknowledge_message
    - docstring: Tenta consumir uma mensagem e envia ACK se bem-sucedido.
      end_lineno: 188
      lineno: 99
      name: consume_and_ack_message
    imports:
    - asname: null
      name: requests
    - asname: null
      name: json
    - asname: null
      name: warnings
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: datetime
    numero_de_linhas: 260
    source_code: "# -*- coding: utf-8 -*-\nimport requests\nimport json\nimport warnings\n\
      import sys\nimport time\nimport datetime\n\n# --- Configurações ---\nBASE_URL\
      \ = \"https://localhost:8777\"\nQUEUE_NAME = \"minha-fila-teste-stress\" # <<<\
      \ A MESMA FILA USADA NO SCRIPT DE ENVIO >>>\nUSERNAME = \"admin\"\nPASSWORD\
      \ = \"admin\"\nPOLL_INTERVAL = 1 # Segundos para esperar se a fila estiver vazia\
      \ (reduzido para testes)\nREQUEST_TIMEOUT = 15 # Timeout para requisições GET/POST\n\
      # --- Fim das Configurações ---\n\n# Ignorar avisos sobre certificados SSL autoassinados\n\
      warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n\n\
      # --- Globais ---\nmessages_processed = 0\nconsume_attempts = 0\nack_failures\
      \ = 0\nlast_message_time = None\n# --- Fim Globais ---\n\ndef get_access_token(session,\
      \ base_url, username, password):\n    \"\"\"Faz login usando a sessão para obter\
      \ um token.\"\"\"\n    login_url = f\"{base_url}/login\"\n    try:\n       \
      \ print(f\"\U0001F511 Tentando fazer login como '{username}' em {login_url}...\"\
      )\n        response = session.post(\n            login_url,\n            data={\"\
      username\": username, \"password\": password},\n            verify=False,\n\
      \            timeout=20 # Timeout maior para login\n        )\n        response.raise_for_status()\n\
      \        token_data = response.json()\n        print(\"✅ Login bem-sucedido!\"\
      )\n        access_token = token_data.get(\"access_token\")\n        if access_token:\n\
      \            session.headers.update({\"Authorization\": f\"Bearer {access_token}\"\
      })\n            print(\"\U0001F511 Token de acesso configurado na sessão.\"\
      )\n            return access_token\n        else:\n             print(\"❌ Token\
      \ não encontrado na resposta do login.\")\n             return None\n    except\
      \ requests.exceptions.RequestException as e:\n        print(f\"❌ Erro de conexão\
      \ ou HTTP ao tentar fazer login: {e}\")\n        if hasattr(e, 'response') and\
      \ e.response is not None:\n            try: print(f\"   Detalhe da API: {e.response.status_code}\
      \ {e.response.reason} - {e.response.json()}\")\n            except json.JSONDecodeError:\
      \ print(f\"   Resposta (não JSON): {e.response.status_code} {e.response.reason}\
      \ - {e.response.text[:200]}...\")\n        return None\n    except json.JSONDecodeError:\n\
      \        print(f\"❌ Erro ao decodificar a resposta JSON do login.\")\n     \
      \   return None\n\ndef acknowledge_message(session, base_url, message_id):\n\
      \    \"\"\"Envia um ACK para o servidor para confirmar o processamento.\"\"\"\
      \n    global ack_failures\n    ack_url = f\"{base_url}/messages/{message_id}/ack\"\
      \n    try:\n        # print(f\"  -> Enviando ACK para {ack_url}...\") # Debug\
      \ verboso\n        response_ack = session.post(\n            ack_url,\n    \
      \        verify=False,\n            timeout=REQUEST_TIMEOUT\n        )\n\n \
      \       if response_ack.status_code == 200:\n            # print(f\"  ✅ ACK\
      \ bem-sucedido para mensagem {message_id}.\") # Debug verboso\n            return\
      \ True\n        elif response_ack.status_code == 404:\n             print(f\"\
      \  ⚠️ ACK falhou (404): Mensagem {message_id} não encontrada (provavelmente\
      \ já processada/deletada).\")\n             # Consideramos sucesso pois a mensagem\
      \ não está mais pendente para nós\n             return True\n        elif response_ack.status_code\
      \ == 409:\n             print(f\"  ⚠️ ACK falhou (409): Mensagem {message_id}\
      \ não estava no estado 'processing'. Status: {response_ack.json().get('detail',\
      \ '')}\")\n             ack_failures += 1\n             return False # Falha\
      \ real, a mensagem pode ter sido NACK'd ou ainda está pendente\n        else:\n\
      \            response_ack.raise_for_status() # Levanta erro para outros status\
      \ inesperados\n\n    except requests.exceptions.Timeout:\n        print(f\"\
      \  ⏳ Timeout ao enviar ACK para mensagem {message_id}.\")\n        ack_failures\
      \ += 1\n        return False\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"  ❌ Erro ao enviar ACK para mensagem {message_id}:\
      \ {e}\")\n        ack_failures += 1\n        if hasattr(e, 'response') and e.response\
      \ is not None:\n             try: print(f\"     Detalhe da API: {e.response.status_code}\
      \ {e.response.reason} - {e.response.json()}\")\n             except json.JSONDecodeError:\
      \ print(f\"     Resposta (não JSON): {e.response.status_code} {e.response.reason}\
      \ - {e.response.text[:200]}...\")\n        return False\n    return False #\
      \ Se chegou aqui por algum motivo\n\ndef consume_and_ack_message(session, base_url,\
      \ queue_name):\n    \"\"\"Tenta consumir uma mensagem e envia ACK se bem-sucedido.\"\
      \"\"\n    global messages_processed, last_message_time, consume_attempts\n \
      \   consume_url = f\"{base_url}/queues/{queue_name}/messages/consume\" # <<<\
      \ URL CORRIGIDA >>>\n    message_data = None\n    message_id = None\n    consume_attempts\
      \ += 1\n\n    # 1. Tentar obter (consumir) uma mensagem\n    try:\n        #\
      \ print(f\" Tentando consumir de {consume_url}...\") # Debug verboso\n     \
      \   response_get = session.get(\n            consume_url,\n            verify=False,\n\
      \            timeout=REQUEST_TIMEOUT\n        )\n\n        # --- Tratamento\
      \ da Resposta do Consumo ---\n        if response_get.status_code == 200:\n\
      \            # Tenta decodificar o JSON. Se o corpo for 'null', json() pode\
      \ retornar None ou dar erro\n            try:\n                message_data\
      \ = response_get.json()\n            except json.JSONDecodeError:\n        \
      \         # Isso pode acontecer se a resposta for 'null' literal ou outro texto\
      \ não-JSON\n                 if response_get.text == 'null':\n             \
      \        message_data = None # Tratar 'null' como fila vazia\n             \
      \    else:\n                    print(f\"❌ Erro ao decodificar JSON da resposta\
      \ de consumo (não era 'null'): {response_get.text[:100]}...\")\n           \
      \         return False # Falha inesperada\n\n            # --- Checa se a mensagem\
      \ foi recebida (message_data não é None) ---\n            if message_data:\n\
      \                message_id = message_data.get(\"message_id\") # <<< NOME DO\
      \ CAMPO CORRIGIDO >>>\n                content = message_data.get(\"content\"\
      , \"*Conteúdo não encontrado*\")\n                status = message_data.get(\"\
      status\", \"*Status não encontrado*\")\n                queue_recv = message_data.get(\"\
      queue\", queue_name) # Usa o nome da fila retornado se disponível\n\n      \
      \          if not message_id:\n                     print(f\"❌ Resposta de consumo\
      \ recebida, mas sem 'message_id'. Dados: {message_data}\")\n               \
      \      return False # Algo deu errado na API\n\n                print(f\"\U0001F4E9\
      \ [{datetime.datetime.now().strftime('%H:%M:%S')}] Msg Recebida (ID: {message_id},\
      \ Fila: {queue_recv}, Status: {status}): '{content[:80]}{'...' if len(content)>80\
      \ else ''}'\")\n\n                # --- 2. Enviar ACK imediatamente (após receber\
      \ a mensagem) ---\n                # Em uma aplicação real, o processamento\
      \ do 'content' iria aqui\n                ack_successful = acknowledge_message(session,\
      \ base_url, message_id)\n\n                if ack_successful:\n            \
      \        messages_processed += 1\n                    last_message_time = time.time()\n\
      \                    return True # Consumo E ACK bem-sucedidos\n           \
      \     else:\n                    # O ACK falhou. A mensagem permanecerá como\
      \ 'processing' no servidor.\n                    # Poderíamos tentar um NACK\
      \ aqui, mas por simplicidade vamos apenas registrar\n                    print(f\"\
      ‼️ Falha ao enviar ACK para msg {message_id} após consumo bem-sucedido.\")\n\
      \                    return False # Processamento completo falhou devido ao\
      \ ACK\n\n            else:\n                # Status 200 mas message_data é\
      \ None (corpo 'null'), significa fila vazia\n                # print(f\" Fila\
      \ '{queue_name}' vazia (200 OK com null).\") # Debug verboso\n             \
      \   return False # Indica que não havia mensagem\n\n        elif response_get.status_code\
      \ == 404:\n            # Este 404 geralmente significa que a *fila* em si não\
      \ foi encontrada\n            print(f\"❓ Fila '{queue_name}' não encontrada\
      \ no servidor (Erro 404 no GET .../consume). Verifique o nome da fila.\")\n\
      \            # Espera um pouco mais se a fila não for encontrada para não spammar\
      \ logs\n            time.sleep(POLL_INTERVAL * 5)\n            return False\
      \ # Indica que a fila não existe\n\n        else:\n            # Outros erros\
      \ HTTP inesperados\n            print(f\"‼️ Erro HTTP inesperado ao consumir\
      \ de '{queue_name}': {response_get.status_code} {response_get.reason}\")\n \
      \           response_get.raise_for_status() # Levanta erro para análise detalhada\n\
      \n    except requests.exceptions.Timeout:\n        print(f\"⏳ Timeout ao tentar\
      \ consumir mensagem da fila '{queue_name}'.\")\n        return False # Falha\
      \ temporária, tentar novamente depois\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"❌ Erro de requisição ao consumir mensagem da fila\
      \ '{queue_name}': {e}\")\n        if hasattr(e, 'response') and e.response is\
      \ not None:\n             try: print(f\"   Detalhe da API: {e.response.status_code}\
      \ {e.response.reason} - {e.response.json()}\")\n             except json.JSONDecodeError:\
      \ print(f\"   Resposta (não JSON): {e.response.status_code} {e.response.reason}\
      \ - {e.response.text[:200]}...\")\n        return False # Falha, tentar novamente\
      \ depois\n    except Exception as e:\n         print(f\"\U0001F4A5 Erro inesperado\
      \ na função consume_and_ack_message: {type(e).__name__}: {e}\")\n         #\
      \ Considerar logar traceback aqui para depuração\n         return False\n\n\
      \    # Retorno padrão caso nenhum caminho anterior retorne\n    return False\n\
      \n\n# --- Execução Principal ---\nif __name__ == \"__main__\":\n    print(f\"\
      --- Consumidor de Mensagens (com ACK) da Fila '{QUEUE_NAME}' ---\")\n    print(f\"\
      Alvo: {BASE_URL}\")\n    print(f\"Intervalo de polling (fila vazia): {POLL_INTERVAL}s\"\
      )\n\n    session = requests.Session()\n    session.verify = False # Ignora verificação\
      \ SSL para toda a sessão\n\n    # 1. Obter token de acesso e configurar na sessão\n\
      \    token = get_access_token(session, BASE_URL, USERNAME, PASSWORD)\n    if\
      \ not token:\n        print(\"\\n--- Falha no Login. Abortando. ---\")\n   \
      \     sys.exit(1)\n\n    print(f\"\\n--- Iniciando consumo da fila '{QUEUE_NAME}'\
      \ ---\")\n    print(\"Pressione Ctrl+C para parar...\")\n\n    start_time =\
      \ time.time()\n    running = True\n\n    try:\n        while running:\n    \
      \        try:\n                # Tenta consumir E fazer o ACK\n            \
      \    message_processed_successfully = consume_and_ack_message(session, BASE_URL,\
      \ QUEUE_NAME)\n\n                if not message_processed_successfully:\n  \
      \                  # Se não processou mensagem (fila vazia, erro, falha no ACK),\
      \ esperar\n                    # print(\".\", end=\"\", flush=True) # Indicador\
      \ visual de polling\n                    time.sleep(POLL_INTERVAL)\n       \
      \         # else:\n                    # Se consumiu e ACK foi OK, tenta ler\
      \ a próxima imediatamente (sem sleep)\n                    # Pequeno sleep opcional\
      \ para não sobrecarregar CPU em loop muito rápido\n                    # time.sleep(0.01)\n\
      \                    pass # Tenta consumir a próxima imediatamente\n\n     \
      \       except Exception as e:\n                # Captura exceções inesperadas\
      \ no loop principal\n                print(f\"\\n\U0001F4A5 Erro inesperado\
      \ no loop principal: {e}\")\n                print(\"Aguardando antes de tentar\
      \ novamente...\")\n                time.sleep(POLL_INTERVAL * 2) # Espera um\
      \ pouco mais após um erro grave\n\n    except KeyboardInterrupt:\n        print(\"\
      \\n\\n\U0001F6D1 Interrupção pelo usuário recebida. Parando o consumidor...\"\
      )\n        running = False\n\n    finally:\n        # Fecha a sessão de requests\
      \ para liberar conexões\n        print(\"Fechando a sessão HTTP...\")\n    \
      \    session.close()\n\n        # Imprimir estatísticas finais\n        end_time\
      \ = time.time()\n        total_time = end_time - start_time\n\n        print(\"\
      \\n--- Resumo Final do Consumo ---\")\n        print(f\"Tempo total de execução:\
      \ {total_time:.2f} segundos\")\n        print(f\"Tentativas de consumo: {consume_attempts}\"\
      )\n        print(f\"Mensagens processadas (consumo + ACK OK): {messages_processed}\"\
      )\n        print(f\"Falhas no ACK (após consumo OK): {ack_failures}\")\n   \
      \     if messages_processed > 0 and total_time > 0:\n            average_rate\
      \ = messages_processed / total_time\n            print(f\"Taxa média de consumo\
      \ efetivo: {average_rate:.2f} mensagens/segundo\")\n        if last_message_time:\n\
      \             print(f\"Última mensagem processada com sucesso em: {datetime.datetime.fromtimestamp(last_message_time).strftime('%Y-%m-%d\
      \ %H:%M:%S')}\")\n        else:\n             print(\"Nenhuma mensagem foi processada\
      \ com sucesso durante esta execução.\")\n        print(\"---------------------------------\"\
      )\n        sys.exit(0)"
    tamanho: 0.01 MB
  dbfixv1.py:
    caminho_completo: .\dbfixv1.py
    classes: []
    functions:
    - docstring: Conecta diretamente ao SQLite e adiciona a coluna 'updated_at'.
      end_lineno: 75
      lineno: 12
      name: add_updated_at_column_direct
    imports:
    - asname: null
      name: sqlite3
    - asname: null
      name: os
    - asname: null
      name: sys
    numero_de_linhas: 91
    source_code: "# -*- coding: utf-8 -*-\nimport sqlite3\nimport os\nimport sys\n\
      \n# --- Configurações (Ajuste se necessário) ---\nDB_DIR = 'databases'\nDB_FILENAME\
      \ = 'message_broker_v3.db'\nDB_PATH = os.path.abspath(os.path.join(DB_DIR, DB_FILENAME))\n\
      # --- Fim das Configurações ---\n\ndef add_updated_at_column_direct():\n   \
      \ \"\"\"Conecta diretamente ao SQLite e adiciona a coluna 'updated_at'.\"\"\"\
      \n\n    print(f\"--- Iniciando Script de Correção Direta (sqlite3): Adicionar\
      \ Coluna 'updated_at' ---\")\n    print(f\"Banco de dados alvo: {DB_PATH}\"\
      )\n\n    if not os.path.exists(DB_PATH):\n        print(f\"❌ Erro: Arquivo de\
      \ banco de dados não encontrado em '{DB_PATH}'.\")\n        print(\"   O script\
      \ da API precisa ser executado pelo menos uma vez para criar o DB inicial.\"\
      )\n        sys.exit(1)\n\n    # Comando SQL para adicionar a coluna (SQLite)\n\
      \    # Adicionamos como NULLABLE para não dar erro em linhas existentes\n  \
      \  # e IF NOT EXISTS para segurança, embora a verificação de erro seja mais\
      \ robusta\n    sql_command = \"ALTER TABLE queues ADD COLUMN updated_at DATETIME\
      \ NULL;\"\n    # SQL para verificar se a coluna já existe (específico do SQLite)\n\
      \    sql_check_column = \"SELECT COUNT(*) FROM pragma_table_info('queues') WHERE\
      \ name='updated_at';\"\n\n\n    conn = None # Inicializa a conexão fora do try\
      \ para poder usar no finally\n    try:\n        print(\"\U0001F50C Conectando\
      \ diretamente ao banco de dados SQLite...\")\n        conn = sqlite3.connect(DB_PATH)\n\
      \        cursor = conn.cursor()\n        print(\"   Conectado.\")\n\n      \
      \  # 1. Verificar se a coluna já existe\n        print(\"\U0001F50D Verificando\
      \ se a coluna 'updated_at' já existe...\")\n        cursor.execute(sql_check_column)\n\
      \        result = cursor.fetchone()\n        column_exists = result[0] > 0\n\
      \n        if column_exists:\n            print(\"✅ A coluna 'updated_at' já\
      \ existe na tabela 'queues'. Nenhuma alteração necessária.\")\n        else:\n\
      \            # 2. Se não existe, tentar adicionar\n            print(\" कॉलम\
      \ 'updated_at' não encontrada. Tentando adicionar...\") # (Coluna em Hindi,\
      \ mantido por consistência se foi erro de digitação)\n            print(f\"\U0001F680\
      \ Executando comando SQL: {sql_command}\")\n            cursor.execute(sql_command)\n\
      \            # Commit é necessário para ALTER TABLE no sqlite3\n           \
      \ conn.commit()\n            print(\"✅ Sucesso! Coluna 'updated_at' adicionada\
      \ à tabela 'queues'.\")\n\n    except sqlite3.Error as e:\n        # O erro\
      \ \"duplicate column name\" pode ocorrer se a verificação falhar por algum motivo\n\
      \        if \"duplicate column name: updated_at\" in str(e).lower():\n     \
      \        print(f\"ℹ️  Aviso: A coluna 'updated_at' já existe (detectado via\
      \ erro). Nenhuma alteração feita.\")\n        else:\n            print(f\"❌\
      \ Erro do SQLite ao tentar modificar a tabela:\")\n            print(f\"   Tipo\
      \ de Erro: {type(e).__name__}\")\n            print(f\"   Mensagem: {e}\")\n\
      \            print(\"   Verifique se a tabela 'queues' existe e se o comando\
      \ SQL está correto.\")\n            # Rollback pode ser útil se outras operações\
      \ estivessem na transação\n            if conn:\n                conn.rollback()\n\
      \    except Exception as e:\n        print(f\"❌ Ocorreu um erro inesperado:\"\
      )\n        print(e)\n    finally:\n        if conn:\n            print(\"\U0001F512\
      \ Fechando a conexão com o banco de dados SQLite...\")\n            conn.close()\n\
      \            print(\"   Conexão fechada.\")\n        print(\"--- Script de Correção\
      \ Direta Concluído ---\")\n\n# Executa a função\nif __name__ == \"__main__\"\
      :\n    print(\"*********************************************************************\"\
      )\n    print(\"* IMPORTANTE:                                               \
      \        *\")\n    print(\"* 1. PARE o servidor da API ANTES de executar este\
      \ script.          *\")\n    print(\"* 2. FAÇA UM BACKUP do arquivo .db como\
      \ precaução.                  *\")\n    print(\"*    Arquivo: databases/message_broker_v3.db\
      \                        *\")\n    print(\"*********************************************************************\"\
      )\n    try:\n      input(\"Pressione Enter para continuar ou Ctrl+C para cancelar...\"\
      )\n    except KeyboardInterrupt:\n        print(\"\\nOperação cancelada pelo\
      \ usuário.\")\n        sys.exit(0)\n\n    add_updated_at_column_direct()"
    tamanho: 0.00 MB
  dbfixv2.py:
    caminho_completo: .\dbfixv2.py
    classes: []
    functions:
    - docstring: Conecta diretamente ao SQLite e aplica as correções de esquema necessárias.
      end_lineno: 95
      lineno: 20
      name: apply_schema_corrections
    imports:
    - asname: null
      name: sqlite3
    - asname: null
      name: os
    - asname: null
      name: sys
    numero_de_linhas: 112
    source_code: "# -*- coding: utf-8 -*-\nimport sqlite3\nimport os\nimport sys\n\
      \n# --- Configurações (Ajuste se necessário) ---\nDB_DIR = 'databases'\nDB_FILENAME\
      \ = 'message_broker_v3.db'\nDB_PATH = os.path.abspath(os.path.join(DB_DIR, DB_FILENAME))\n\
      # --- Fim das Configurações ---\n\n# Lista de correções a serem aplicadas: (table_name,\
      \ column_name, column_type_sql)\ncorrections = [\n    ('queues',   'updated_at',\
      \ 'DATETIME NULL'),\n    ('messages', 'updated_at', 'DATETIME NULL'),\n    #\
      \ Adicione outras correções aqui se necessário no futuro\n    # Ex: ('messages',\
      \ 'retry_count', 'INTEGER DEFAULT 0')\n]\n\ndef apply_schema_corrections():\n\
      \    \"\"\"Conecta diretamente ao SQLite e aplica as correções de esquema necessárias.\"\
      \"\"\n\n    print(f\"--- Iniciando Script de Correção de Esquema (sqlite3) ---\"\
      )\n    print(f\"Banco de dados alvo: {DB_PATH}\")\n\n    if not os.path.exists(DB_PATH):\n\
      \        print(f\"❌ Erro: Arquivo de banco de dados não encontrado em '{DB_PATH}'.\"\
      )\n        print(\"   Execute o script da API principal primeiro para criar\
      \ o DB.\")\n        sys.exit(1)\n\n    conn = None\n    all_successful = True\
      \ # Flag para rastrear o sucesso geral\n\n    try:\n        print(\"\U0001F50C\
      \ Conectando diretamente ao banco de dados SQLite...\")\n        conn = sqlite3.connect(DB_PATH)\n\
      \        cursor = conn.cursor()\n        print(\"   Conectado.\")\n\n      \
      \  print(\"\\n--- Verificando e Aplicando Correções ---\")\n        for table_name,\
      \ column_name, column_type in corrections:\n            print(f\"\\n -> Verificando\
      \ Tabela: '{table_name}', Coluna: '{column_name}'\")\n\n            # SQL para\
      \ verificar se a coluna já existe\n            sql_check_column = f\"SELECT\
      \ COUNT(*) FROM pragma_table_info('{table_name}') WHERE name='{column_name}';\"\
      \n            # Comando SQL para adicionar a coluna\n            sql_add_column\
      \ = f\"ALTER TABLE {table_name} ADD COLUMN {column_name} {column_type};\"\n\n\
      \            try:\n                cursor.execute(sql_check_column)\n      \
      \          result = cursor.fetchone()\n                column_exists = result[0]\
      \ > 0\n\n                if column_exists:\n                    print(f\"  \
      \  ✅ Coluna '{column_name}' já existe em '{table_name}'.\")\n              \
      \  else:\n                    print(f\"    ⚠️ Coluna '{column_name}' não encontrada\
      \ em '{table_name}'. Tentando adicionar...\")\n                    print(f\"\
      \       Executando: {sql_add_column}\")\n                    cursor.execute(sql_add_column)\n\
      \                    # Commit APÓS CADA ALTER TABLE bem-sucedido é mais seguro\n\
      \                    conn.commit()\n                    print(f\"    ✅ Sucesso!\
      \ Coluna '{column_name}' adicionada a '{table_name}'.\")\n\n            except\
      \ sqlite3.Error as e_inner:\n                 # Verifica erro específico de\
      \ coluna duplicada\n                if f\"duplicate column name: {column_name}\"\
      \ in str(e_inner).lower():\n                     print(f\"    ℹ️ Aviso: Coluna\
      \ '{column_name}' já existe em '{table_name}' (detectado via erro).\")\n   \
      \             else:\n                    print(f\"    ❌ Erro do SQLite ao processar\
      \ '{table_name}'.'{column_name}':\")\n                    print(f\"       {type(e_inner).__name__}:\
      \ {e_inner}\")\n                    all_successful = False\n               \
      \     # Interrompe em caso de erro inesperado para esta correção específica\n\
      \                    break\n\n    except sqlite3.Error as e_outer:\n       \
      \ print(f\"\\n❌ Erro Crítico do SQLite durante a conexão ou operação geral:\"\
      )\n        print(f\"   {type(e_outer).__name__}: {e_outer}\")\n        all_successful\
      \ = False\n        if conn:\n            conn.rollback() # Desfaz qualquer alteração\
      \ pendente na transação atual\n    except Exception as e_generic:\n        print(f\"\
      \\n❌ Ocorreu um erro inesperado:\")\n        print(e_generic)\n        all_successful\
      \ = False\n    finally:\n        if conn:\n            print(\"\\n\U0001F512\
      \ Fechando a conexão com o banco de dados SQLite...\")\n            conn.close()\n\
      \            print(\"   Conexão fechada.\")\n\n        print(\"\\n--- Script\
      \ de Correção de Esquema Concluído ---\")\n        if all_successful:\n    \
      \        print(\"\U0001F389 Todas as verificações/correções foram concluídas\
      \ (ou não foram necessárias).\")\n        else:\n            print(\"\U0001F6D1\
      \ Ocorreram erros durante o processo. Verifique os logs acima.\")\n\n\n# Executa\
      \ a função\nif __name__ == \"__main__\":\n    print(\"*********************************************************************\"\
      )\n    print(\"* IMPORTANTE:                                               \
      \        *\")\n    print(\"* 1. PARE o servidor da API ANTES de executar este\
      \ script.          *\")\n    print(\"* 2. FAÇA UM BACKUP do arquivo .db como\
      \ precaução.                  *\")\n    print(\"*    Arquivo: databases/message_broker_v3.db\
      \                        *\")\n    print(\"*********************************************************************\"\
      )\n    try:\n      input(\"Pressione Enter para continuar ou Ctrl+C para cancelar...\"\
      )\n    except KeyboardInterrupt:\n        print(\"\\nOperação cancelada pelo\
      \ usuário.\")\n        sys.exit(0)\n\n    apply_schema_corrections()"
    tamanho: 0.00 MB
  doc-estatisticas.md:
    caminho_completo: .\doc-estatisticas.md
    numero_de_linhas: 167
    tamanho: 0.01 MB
  doc-footer-cleaner.py:
    caminho_completo: .\doc-footer-cleaner.py
    classes: []
    functions:
    - docstring: 'Lê um arquivo HTML, procura pelo bloco de footer específico,

        remove-o se encontrado e salva o arquivo. Retorna True se modificado, False
        caso contrário.'
      end_lineno: 84
      lineno: 10
      name: remove_footer_from_html
    - docstring: null
      end_lineno: 113
      lineno: 86
      name: main
    imports:
    - asname: null
      name: os
    - asname: null
      name: sys
    numero_de_linhas: 116
    source_code: "import os\nimport sys\n\n# Define os marcadores de início e fim\
      \ do bloco do footer a ser removido\n# O marcador inicial é o comentário que\
      \ você especificou.\nSTART_MARKER = \"<!-- Footer Adicionado pelo Script -->\"\
      \n# O marcador final é a tag de fechamento do footer.\nEND_MARKER = \"</footer>\"\
      \n\ndef remove_footer_from_html(filepath):\n    \"\"\"\n    Lê um arquivo HTML,\
      \ procura pelo bloco de footer específico,\n    remove-o se encontrado e salva\
      \ o arquivo. Retorna True se modificado, False caso contrário.\n    \"\"\"\n\
      \    filename = os.path.basename(filepath)\n    try:\n        # Tenta ler o\
      \ arquivo com encoding UTF-8 (mais comum na web)\n        with open(filepath,\
      \ 'r', encoding='utf-8') as f:\n            content = f.read()\n           \
      \ original_encoding = 'utf-8'\n    except UnicodeDecodeError:\n        try:\n\
      \            # Se falhar, tenta com Latin-1 (comum no Windows)\n           \
      \ with open(filepath, 'r', encoding='cp1252') as f:\n                content\
      \ = f.read()\n                original_encoding = 'cp1252'\n        except Exception\
      \ as e:\n            print(f\"Erro ao ler '{filename}': Não foi possível decodificar\
      \ o arquivo ({e}). Pulando.\")\n            return False\n    except IOError\
      \ as e:\n        print(f\"Erro de I/O ao ler '{filename}': {e}. Pulando.\")\n\
      \        return False\n\n    original_content = content\n    modified = False\n\
      \n    # Procura pelo bloco repetidamente (caso haja mais de um, embora improvável)\n\
      \    while True:\n        start_index = content.find(START_MARKER)\n\n     \
      \   # Se não encontrar o marcador inicial, para a busca neste arquivo\n    \
      \    if start_index == -1:\n            break\n\n        # Se encontrou o marcador\
      \ inicial, procura o marcador final *depois* dele\n        end_index = content.find(END_MARKER,\
      \ start_index)\n\n        # Se não encontrar o marcador final correspondente,\
      \ é um problema.\n        # Imprime um aviso e para de modificar este arquivo\
      \ para segurança.\n        if end_index == -1:\n            print(f\"AVISO:\
      \ Marcador inicial encontrado, mas tag '{END_MARKER}' não encontrada depois\
      \ dele em '{filename}'. Nenhuma remoção feita a partir deste ponto no arquivo.\"\
      )\n            break\n\n        # Calcula a posição exata do fim do bloco (incluindo\
      \ a tag END_MARKER)\n        end_pos = end_index + len(END_MARKER)\n\n     \
      \   # Remove o bloco inteiro (do início do comentário até o fim do footer)\n\
      \        # Mantém o que veio ANTES do marcador inicial e o que veio DEPOIS do\
      \ marcador final.\n        content = content[:start_index] + content[end_pos:]\n\
      \        modified = True\n        # Continua o loop para o caso de haver mais\
      \ blocos *idênticos* a serem removidos\n\n    # Se o conteúdo foi modificado,\
      \ salva o arquivo\n    if modified:\n        try:\n            # Salva o arquivo\
      \ com o mesmo encoding que foi lido, se possível,\n            # ou UTF-8 como\
      \ padrão ao escrever. UTF-8 é geralmente seguro.\n            write_encoding\
      \ = original_encoding if original_encoding else 'utf-8'\n            with open(filepath,\
      \ 'w', encoding=write_encoding) as f:\n                f.write(content)\n  \
      \          print(f\"Footer removido com sucesso de: '{filename}'\")\n      \
      \      return True\n        except IOError as e:\n            print(f\"Erro\
      \ de I/O ao salvar alterações em '{filename}': {e}\")\n            # Opcional:\
      \ Poderia tentar reverter para o conteúdo original aqui,\n            # mas\
      \ pode ser complexo. Melhor apenas reportar o erro.\n            return False\n\
      \        except Exception as e:\n            print(f\"Erro inesperado ao salvar\
      \ alterações em '{filename}': {e}\")\n            return False\n    else:\n\
      \        # Informa que o footer não foi encontrado (ou já tinha sido removido)\n\
      \        # print(f\"Nenhum bloco de footer correspondente encontrado em: '{filename}'\"\
      )\n        return False # Retorna False pois não houve modificação\n\ndef main():\n\
      \    # Obtém o diretório onde o script está sendo executado\n    # Assume-se\
      \ que os arquivos HTML estão neste mesmo diretório (\"raiz\")\n    current_dir\
      \ = os.getcwd()\n    print(f\"Procurando arquivos HTML em: {current_dir}\")\n\
      \    print(\"-\" * 30)\n\n    processed_files = 0\n    modified_files = 0\n\n\
      \    # Lista todos os arquivos no diretório atual\n    for filename in os.listdir(current_dir):\n\
      \        # Verifica se é um arquivo HTML\n        if filename.lower().endswith(('.html',\
      \ '.htm')):\n            processed_files += 1\n            filepath = os.path.join(current_dir,\
      \ filename)\n            # Chama a função para processar o arquivo\n       \
      \     if remove_footer_from_html(filepath):\n                modified_files\
      \ += 1\n\n    print(\"-\" * 30)\n    if processed_files == 0:\n        print(\"\
      Nenhum arquivo .html ou .htm encontrado no diretório.\")\n    else:\n      \
      \  print(f\"Processamento concluído.\")\n        print(f\"Total de arquivos\
      \ HTML/HTM encontrados: {processed_files}\")\n        print(f\"Arquivos modificados:\
      \ {modified_files}\")\n        print(f\"Arquivos não modificados (footer não\
      \ encontrado ou erro): {processed_files - modified_files}\")\n\nif __name__\
      \ == \"__main__\":\n    main()"
    tamanho: 0.00 MB
  doc-web-diagram-20250404-204005-1bf71190.html:
    caminho_completo: .\doc-web-diagram-20250404-204005-1bf71190.html
    numero_de_linhas: 378
    tamanho: 0.02 MB
  doc-web-diagram-20250407-223027-ea133238.html:
    caminho_completo: .\doc-web-diagram-20250407-223027-ea133238.html
    numero_de_linhas: 394
    tamanho: 0.02 MB
  doc-web-diagram-20250408-004137-c1fa35d6.html:
    caminho_completo: .\doc-web-diagram-20250408-004137-c1fa35d6.html
    numero_de_linhas: 364
    tamanho: 0.02 MB
  docgenv2.py:
    caminho_completo: .\docgenv2.py
    classes: []
    functions:
    - docstring: null
      end_lineno: 36
      lineno: 32
      name: get_file_size
    - docstring: null
      end_lineno: 44
      lineno: 39
      name: count_lines
    - docstring: null
      end_lineno: 53
      lineno: 47
      name: read_file_content
    - docstring: null
      end_lineno: 102
      lineno: 56
      name: analyze_python_code
    - docstring: null
      end_lineno: 130
      lineno: 105
      name: get_sqlite_info
    - docstring: null
      end_lineno: 142
      lineno: 133
      name: get_python_info
    - docstring: null
      end_lineno: 151
      lineno: 145
      name: get_json_info
    - docstring: null
      end_lineno: 160
      lineno: 154
      name: get_yaml_info
    - docstring: null
      end_lineno: 166
      lineno: 164
      name: format_size
    - docstring: null
      end_lineno: 170
      lineno: 169
      name: stylize_header
    - docstring: null
      end_lineno: 186
      lineno: 179
      name: configurar_geracao
    - docstring: null
      end_lineno: 197
      lineno: 189
      name: enviar_mensagem
    - docstring: null
      end_lineno: 238
      lineno: 200
      name: scan_directory
    - docstring: null
      end_lineno: 358
      lineno: 241
      name: gerar_relatorio_ia
    - docstring: null
      end_lineno: 377
      lineno: 361
      name: main
    imports:
    - asname: null
      name: os
    - asname: null
      name: platform
    - asname: null
      name: sqlite3
    - asname: null
      name: json
    - asname: null
      name: yaml
    - asname: null
      name: time
    - module: datetime
      names:
      - datetime
    - asname: genai
      name: google.generativeai
    - module: colorama
      names:
      - Fore
      - Style
      - init
    - asname: null
      name: ast
    numero_de_linhas: 386
    source_code: "import os\nimport platform\nimport sqlite3\nimport json\nimport\
      \ yaml\nimport time\nfrom datetime import datetime\nimport google.generativeai\
      \ as genai\nfrom colorama import Fore, Style, init\nimport ast\n\n# Inicializa\
      \ o Colorama para colorir os logs\ninit(autoreset=True)\n\n# Configuração da\
      \ API de IA\nAPI_KEY = 'AIzaSyC7dAwSyLKaVO2E-PA6UaacLZ4aLGtrXbY'  # Chave da\
      \ API fornecida\ngenai.configure(api_key=API_KEY)\nNOME_MODELO = \"gemini-2.0-flash\"\
      \  # Modelo atualizado\n\n# Arquivos e diretórios a serem ignorados\nIGNORE_LIST\
      \ = [\n    \"docgenv1.py\",  # Ignora o próprio script\n    \".git\",  # Ignora\
      \ diretórios .git\n    \".venv\",  # Ignora ambientes virtuais\n    \"venv\"\
      ,  # Ignora ambientes virtuais\n    \"__pycache__\", # Ignora diretórios de\
      \ cache\n    \"node_modules\",  # Ignora diretórios node_modules\n    \".md\"\
      \ # Ignora arquivos Markdown\n]\n\n# Função para calcular o tamanho de um arquivo\n\
      def get_file_size(file_path):\n    try:\n        return os.path.getsize(file_path)\n\
      \    except OSError:\n        return -1  # Retorna -1 se o arquivo não existir\
      \ ou ocorrer um erro\n\n# Função para calcular o número de linhas em um arquivo\
      \ de texto\ndef count_lines(file_path):\n    try:\n        with open(file_path,\
      \ 'r', encoding='utf-8') as f:\n            return sum(1 for _ in f)\n    except\
      \ Exception:\n        return -1\n\n# Função para ler o conteúdo de um arquivo\
      \ de texto (com limite)\ndef read_file_content(file_path, max_lines=500): #\
      \ Aumentei o limite de linhas\n    try:\n        with open(file_path, 'r', encoding='utf-8')\
      \ as f:\n            lines = [next(f) for _ in range(max_lines)]  # Lê até max_lines\
      \ linhas\n            return \"\".join(lines)\n    except Exception:\n     \
      \   return None\n\n# Função para analisar o código Python e extrair informações\
      \ relevantes\ndef analyze_python_code(file_path):\n    try:\n        with open(file_path,\
      \ 'r', encoding='utf-8') as f:\n            source_code = f.read()\n       \
      \ \n        tree = ast.parse(source_code)\n        \n        functions = []\n\
      \        classes = []\n        imports = []\n\n        for node in ast.walk(tree):\n\
      \            if isinstance(node, ast.FunctionDef):\n                functions.append({\n\
      \                    \"name\": node.name,\n                    \"docstring\"\
      : ast.get_docstring(node),\n                    \"lineno\": node.lineno,\n \
      \                   \"end_lineno\": node.end_lineno if hasattr(node, 'end_lineno')\
      \ else None\n                })\n            elif isinstance(node, ast.ClassDef):\n\
      \                classes.append({\n                    \"name\": node.name,\n\
      \                    \"docstring\": ast.get_docstring(node),\n             \
      \       \"lineno\": node.lineno,\n                    \"end_lineno\": node.end_lineno\
      \ if hasattr(node, 'end_lineno') else None\n                })\n           \
      \ elif isinstance(node, ast.Import):\n                for alias in node.names:\n\
      \                    imports.append({\n                        \"name\": alias.name,\n\
      \                        \"asname\": alias.asname\n                    })\n\
      \            elif isinstance(node, ast.ImportFrom):\n                imports.append({\n\
      \                    \"module\": node.module,\n                    \"names\"\
      : [alias.name for alias in node.names]\n                })\n        \n     \
      \   return {\n            \"functions\": functions,\n            \"classes\"\
      : classes,\n            \"imports\": imports,\n            \"source_code\":\
      \ source_code # Mantém o código fonte completo\n        }\n\n    except Exception\
      \ as e:\n        return {\"error\": str(e)}\n\n# Função para obter informações\
      \ de um arquivo .db (SQLite)\ndef get_sqlite_info(file_path, max_rows=5): #\
      \ Aumentei o número de exemplos\n    try:\n        conn = sqlite3.connect(file_path)\n\
      \        cursor = conn.cursor()\n\n        cursor.execute(\"SELECT name FROM\
      \ sqlite_master WHERE type='table';\")\n        tables = [row[0] for row in\
      \ cursor.fetchall()]\n        \n        table_data = {}\n        for table in\
      \ tables:\n            cursor.execute(f\"PRAGMA table_info('{table}');\")\n\
      \            columns = [(row[1], row[2]) for row in cursor.fetchall()] # (nome,\
      \ tipo)\n            \n            try:\n                cursor.execute(f\"\
      SELECT * FROM '{table}' LIMIT {max_rows};\")\n                rows = cursor.fetchall()\n\
      \            except sqlite3.OperationalError as e:\n                print(f\"\
      {Fore.YELLOW}Aviso: Não foi possível selecionar dados da tabela '{table}': {e}{Style.RESET_ALL}\"\
      )\n                rows = []  # Define rows como uma lista vazia em caso de\
      \ erro\n\n            table_data[table] = {\"columns\": columns, \"rows\": rows}\n\
      \        \n        conn.close()\n        return table_data\n    except Exception\
      \ as e:\n        return {\"error\": str(e)}\n\n# Função para obter informações\
      \ de um arquivo .py\ndef get_python_info(file_path):\n    try:\n        with\
      \ open(file_path, 'r', encoding='utf-8') as f:\n            source_code = f.read()\n\
      \        analysis_result = analyze_python_code(file_path)\n        # Garante\
      \ que o código fonte seja armazenado corretamente\n        analysis_result['source_code']\
      \ = source_code\n        return analysis_result\n    except Exception as e:\n\
      \        return {\"error\": str(e)}\n\n# Função para obter informações de um\
      \ arquivo .json\ndef get_json_info(file_path):\n     try:\n        file_size\
      \ = get_file_size(file_path)\n        line_count = count_lines(file_path)\n\
      \        return {\"tamanho\": format_size(file_size), \"numero_de_linhas\":\
      \ line_count}\n     except Exception as e:\n        return {\"error\": str(e)}\n\
      \n# Função para obter informações de um arquivo .yaml\ndef get_yaml_info(file_path):\n\
      \    try:\n        file_size = get_file_size(file_path)\n        line_count\
      \ = count_lines(file_path)\n        return {\"tamanho\": format_size(file_size),\
      \ \"numero_de_linhas\": line_count}\n    except Exception as e:\n        return\
      \ {\"error\": str(e)}\n\n\n# Função para formatar o tamanho em MB\ndef format_size(size_in_bytes):\n\
      \    size_mb = size_in_bytes / (1024 * 1024)\n    return f\"{size_mb:.2f} MB\"\
      \n\n# Função para estilizar o cabeçalho de cada unidade\ndef stylize_header(header):\n\
      \    return f\"\U0001F4C1 --- {header} --- \U0001F4C1\\n\"\n\n# Configurações\
      \ de geração da IA (movido para o escopo global para facilitar a modificação)\n\
      AI_TEMPERATURE = 0.9  # Aumentei para respostas mais criativas e variadas\n\
      AI_TOP_P = 0.99       # Aumentei para considerar um conjunto maior de palavras\
      \ possíveis\nAI_TOP_K = 80         # Aumentei para uma amostragem mais ampla\n\
      AI_MAX_TOKENS = 32768  # Aumentei consideravelmente o limite máximo de tokens\n\
      \n# Função para gerar o payload da IA para relatório Markdown\ndef configurar_geracao(temperatura=AI_TEMPERATURE,\
      \ top_p=AI_TOP_P, top_k=AI_TOP_K, max_tokens=AI_MAX_TOKENS):\n    return {\n\
      \        \"temperature\": temperatura,\n        \"top_p\": top_p,\n        \"\
      top_k\": top_k,\n        \"max_output_tokens\": max_tokens,\n        \"response_mime_type\"\
      : \"text/plain\",\n    }\n\n# Função para enviar mensagens para a IA com logging\
      \ aprimorado\ndef enviar_mensagem(sessao, mensagem):\n    try:\n        print(f\"\
      {Fore.YELLOW}\U0001F9E0 Enviando mensagem para a IA...\")  # Log colorido\n\
      \        resposta = sessao.send_message([mensagem])\n        print(f\"{Fore.GREEN}✅\
      \ Resposta recebida!\")  # Sucesso\n        return resposta.text\n    except\
      \ Exception as e:\n        print(f\"{Fore.RED}❗Erro ao enviar mensagem para\
      \ o modelo: {e}\")\n        return \"\"\n\n# Função para varrer diretórios e\
      \ arquivos\ndef scan_directory(root_path=\".\"):\n    report = {}\n    for root,\
      \ dirs, files in os.walk(root_path):\n        # Ignora diretórios da lista de\
      \ ignorados\n        dirs[:] = [d for d in dirs if d not in IGNORE_LIST]\n\n\
      \        root_report = {}\n        for file in files:\n            if file in\
      \ IGNORE_LIST:\n                continue\n            \n            file_path\
      \ = os.path.join(root, file)\n            file_size = get_file_size(file_path)\n\
      \            line_count = count_lines(file_path)\n\n            file_info =\
      \ {\n                \"tamanho\": format_size(file_size),\n                \"\
      numero_de_linhas\": line_count,\n                \"caminho_completo\": file_path\
      \ # Adicionado caminho completo\n            }\n\n            if file.endswith(\"\
      .py\"):\n                python_info = get_python_info(file_path)\n        \
      \        if python_info:\n                    file_info.update(python_info)\n\
      \            elif file.endswith(\".db\"):\n                sqlite_info = get_sqlite_info(file_path)\n\
      \                file_info[\"sqlite_info\"] = sqlite_info\n            elif\
      \ file.endswith(\".json\"):\n                json_info = get_json_info(file_path)\n\
      \                file_info[\"json_info\"] = json_info\n            elif file.endswith(\"\
      .yaml\") or file.endswith(\".yml\"):\n                yaml_info = get_yaml_info(file_path)\n\
      \                file_info[\"yaml_info\"] = yaml_info\n            \n      \
      \      root_report[file] = file_info\n\n        report[root] = root_report\n\
      \    return report\n\n# Função para gerar relatório em YAML e enviar para IA\n\
      def gerar_relatorio_ia(data, project_name):\n    try:\n        sessao_chat =\
      \ genai.GenerativeModel(\n            model_name=NOME_MODELO,\n            generation_config=configurar_geracao(),\n\
      \        ).start_chat(history=[])\n    except Exception as e:\n        print(f\"\
      {Fore.RED}❗Erro ao iniciar sessão de chat: {e}\")\n        return\n\n    prompt\
      \ = f\"\"\"\n    nao repita dados dos bancos, foque mais em descrever o projeto,\
      \ o que faz, como faz, etc quem faz, etc, o projeto no espectro amplo é o objetivo\n\
      \    documente o projeto bem comercial e executivo\n    nao precisa cobrir cada\
      \ arquivo cada coisa, documente no amplo, foque no pareto 80 - 20  - foque no\
      \ 20 relevante dos 80 irrrelevante ignore\n    \n    naoseja minuciosoo, abranja\
      \ tudo de forma geral, o projeto como todo, foque no que é relevante\n    NUNCA\
      \ GERE CODIGO NA SUA RESPOSTA, NAO ANALISE O CODIGO A PONTO DE REPETIR, NUNCA\
      \ CRIE SNIPPETS E CODIGO FONTE NA RESPOSTA\n    seu objeitov nao é criar nem\
      \ ficar citando ocdoigo, mas sim documentar o projeto, documente como produto\
      \ e projeto\n    sempre criado por elias andrade - replika ia solutions- sempre\
      \ documente o projeto em si, nao fique repetindo codigo\n    respondoa mais\
      \ longo, detlahado, aprofundado, use muitos icones, emojis, documente o projeto,\
      \ o que faz, como faz, o que faz o que, etc.\n    \n    Você é um especialista\
      \ sênior em documentação de projetos de software e agora também um arquiteto\
      \ de sistemas.\n    Sua missão é analisar a estrutura e o conteúdo de um projeto\
      \ e gerar um README.md completo e detalhado.\n    Você deve fornecer uma visão\
      \ geral abrangente do projeto para facilitar a compreensão e manutenção futura.\n\
      \n    Com base nos dados fornecidos, gere um README.md completo e detalhado\
      \ para o projeto. Use Markdown para formatar o README.md.\n\n    O README.md\
      \ deve incluir as seguintes seções (use títulos e subtítulos apropriados):\n\
      \n    1.  **Título do Projeto:** {project_name} (Utilize emojis relacionados\
      \ ao nome, se aplicável)\n\n    2.  **Descrição Geral:**\n        *   Forneça\
      \ uma descrição concisa e de alto nível do projeto, incluindo seu propósito\
      \ principal e funcionalidades.\n        *   Identifique os principais componentes\
      \ e tecnologias utilizadas.\n        *   Resuma o problema que o projeto resolve\
      \ ou a necessidade que atende.\n\n    3.  **Estrutura do Projeto (com muitos\
      \ emojis):**\n        *   Apresente uma lista detalhada de todos os diretórios\
      \ e arquivos.\n        *   Para cada diretório, descreva seu papel e responsabilidades\
      \ dentro do projeto.\n        *   Para cada arquivo, inclua:\n            *\
      \   Nome do arquivo (com emoji indicando o tipo, ex: \U0001F40D para .py, ⚙️\
      \ para config)\n            *   Caminho completo (importante para localização)\n\
      \            *   Tamanho do arquivo\n            *   Número de linhas\n    \
      \        *   Descrição da função do arquivo (inferida do nome, comentários no\
      \ código, etc.)\n\n    4.  **Detalhes Técnicos e Arquiteturais:**\n        *\
      \   **Código Fonte (Python):**\n            *   Apresente o código fonte completo\
      \ de cada arquivo Python.\n            *   Analise o código e destaque os principais\
      \ componentes:\n                *   Funções (nome, docstring, linhas de início\
      \ e fim)\n                *   Classes (nome, docstring, linhas de início e fim)\n\
      \                *   Imports (módulos importados, aliases)\n            *  \
      \ Explique a lógica por trás dos principais algoritmos e estruturas de dados.\n\
      \            *   Comente sobre padrões de design utilizados (se houver).\n \
      \            *  Formate o código de forma legível, removendo quebras de linha\
      \ desnecessárias e garantindo a codificação UTF-8 correta.\n        *   **Bancos\
      \ de Dados (SQLite):**\n            *   Diagrama ER (se possível, descreva a\
      \ estrutura em texto se não for possível gerar o diagrama).\n            * \
      \  Lista de tabelas com descrições claras.\n            *   Esquema de cada\
      \ tabela (nome das colunas, tipos de dados, chaves primárias/estrangeiras).\n\
      \            *   Exemplos de consultas SQL importantes.\n            *   Dados\
      \ de exemplo (até 5 linhas por tabela, com formatação de tabela Markdown).\n\
      \            *   Observações sobre otimizações de queries (se aplicável).\n\
      \        *   **Configurações (JSON/YAML):**\n            *   Descreva o propósito\
      \ de cada arquivo de configuração.\n            *   Liste as principais chaves\
      \ de configuração e seus significados.\n            *   (Não inclua o conteúdo\
      \ completo, apenas resumos e exemplos se necessários)\n            *   Caminho\
      \ completo (para facilidade de acesso)\n            *    Tamanho do arquivo\
      \ e número de linhas.\n\n    5.  **Como Executar e Configurar o Projeto:**\n\
      \        *   Instruções passo a passo para configurar o ambiente (ex: instalar\
      \ Python, dependências).\n        *   Exemplo de como executar o projeto (ex:\
      \ `python main.py`).\n        *   Explique como configurar o projeto (ex: editar\
      \ arquivos de configuração).\n        *   Liste as dependências externas e como\
      \ instalá-las (use `pip install -r requirements.txt` se aplicável).\n      \
      \  *   Explique como executar os testes (se houver testes automatizados).\n\n\
      \    6.  **Considerações Adicionais:**\n        *   **Arquitetura do Projeto:**\
      \ Discuta a arquitetura geral do projeto (ex: MVC, microserviços, etc.).\n \
      \       *   **Padrões de Codificação:** Mencione se o projeto segue algum padrão\
      \ de codificação específico (ex: PEP 8).\n        *   **Licença:** Informe a\
      \ licença sob a qual o projeto é distribuído.\n        *   **Contribuições:**\
      \ Explique como outros desenvolvedores podem contribuir para o projeto.\n  \
      \      *   **Próximos Passos:** Liste os próximos passos para o desenvolvimento\
      \ do projeto.\n        *   **Notas:** Inclua quaisquer notas adicionais que\
      \ sejam relevantes para o projeto.\n\n    7.  **Informações sobre o ambiente\
      \ que o gerou:**\n        *   Sistema Operacional\n        *   Data e Hora da\
      \ geração\n        *   Nome do computador\n\n    Formate o README.md de forma\
      \ clara, concisa e profissional. Use formatação Markdown (títulos, subtítulos,\
      \ listas, tabelas, blocos de código, links, imagens) para facilitar a leitura\
      \ e a compreensão. Inclua emojis relevantes para tornar o documento mais visualmente\
      \ atraente.\n\n    Seja extremamente detalhista e procure inferir o máximo de\
      \ informações possível sobre o projeto com base nos dados fornecidos.\n    O\
      \ objetivo é criar um README.md que seja útil tanto para desenvolvedores que\
      \ já conhecem o projeto quanto para aqueles que estão chegando agora.\n\n  \
      \  Aqui estão os dados do projeto em formato YAML:\n\n    ```yaml\n    {yaml.dump(data,\
      \ allow_unicode=True)}\n    ```\n    \n    nunca crie snippet de codigo, nunca\
      \ traga na sua resposta pedaços do codigo por que isso é redundante, nao é permitido\
      \ ter codigo fonte nas respostas\n    --\n    a documentacao é itnerna rpa mim,\
      \ pra replika ai, entao nao crie como se fosse um repo publico, é documento\
      \ interno - use muitos icones e emojis, cubra o projeto e fale altaemnte tecnico\n\
      \    entenda uqe nivel o projeto est,a parou, etc, o que ja funciona, oq ue\
      \ nao funciona ainda, o que ja foi criado, entenda nesse aspecto, muito icone\
      \ e emoji estilizado pro notion\n    documente o projeto a propriedade intelectual\
      \ e que nivel esta o projeto, etc, \n    \n    \"\"\"\n\n    resposta = enviar_mensagem(sessao_chat,\
      \ prompt)\n\n    if resposta:\n        markdown_filename = \"DOCUMENTACAO-PROJETO.md\"\
      \  # Nome fixo do arquivo README\n        with open(markdown_filename, 'w',\
      \ encoding='utf-8') as markdown_file:\n            markdown_file.write(resposta)\n\
      \        print(f\"{Fore.GREEN}\U0001F4C4 {markdown_filename} salvo com sucesso!\"\
      )\n    else:\n        print(f\"{Fore.RED}❗Erro ao gerar relatório com a IA.\"\
      )\n\n# Função principal para unir tudo\ndef main():\n    project_path = \".\"\
      \ # Diretório atual\n    project_name = os.path.basename(os.getcwd()) # Nome\
      \ do diretório atual\n    print(f\"{Fore.YELLOW}\U0001F504 Iniciando varredura\
      \ do projeto '{project_name}' em '{project_path}'...\")\n    project_data =\
      \ scan_directory(project_path)\n\n    if project_data:\n        # Salva o YAML\
      \ em arquivo para fins de backup\n        yaml_filename = f\"estrutura_projeto_{project_name}_{platform.node()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yaml\"\
      \n        with open(yaml_filename, 'w', encoding='utf-8') as yaml_file:\n  \
      \          yaml.dump(project_data, yaml_file, allow_unicode=True)\n        print(f\"\
      {Fore.GREEN}\U0001F4C2 Estrutura do projeto salva em: {yaml_filename}\")\n\n\
      \        # Envia os dados para a IA para gerar relatório final\n        gerar_relatorio_ia(project_data,\
      \ project_name)\n    else:\n        print(f\"{Fore.RED}\U0001F6AB Nenhum arquivo\
      \ ou diretório encontrado.\")\n\n# Execução do programa\nif __name__ == \"__main__\"\
      :\n    try:\n        main()\n    except KeyboardInterrupt:\n        print(f\"\
      {Fore.RED}❗Processo interrompido pelo usuário.\")\n    except Exception as e:\n\
      \        print(f\"{Fore.RED}❗Erro inesperado: {e}\")"
    tamanho: 0.02 MB
  docgenv4.py:
    caminho_completo: .\docgenv4.py
    classes: []
    functions:
    - docstring: Retorna o tamanho do arquivo em bytes ou -1 em caso de erro.
      end_lineno: 87
      lineno: 81
      name: get_file_size
    - docstring: "Conta as linhas de um arquivo, tentando várias codificações.\nRetorna:\n\
        \    >= 0: número de linhas\n    -1: Erro de IO/Permissão\n    -2: Erro de\
        \ decodificação com codificações comuns"
      end_lineno: 110
      lineno: 89
      name: count_lines
    - docstring: Lê as primeiras `max_lines` de um arquivo, tentando várias codificações.
      end_lineno: 139
      lineno: 112
      name: read_file_content
    - docstring: Analisa um arquivo Python usando AST para extrair funções, classes
        e imports.
      end_lineno: 204
      lineno: 141
      name: get_python_info
    - docstring: Extrai esquema e amostra de dados de um banco de dados SQLite.
      end_lineno: 276
      lineno: 206
      name: get_sqlite_info
    - docstring: Obtém informações básicas sobre um arquivo JSON.
      end_lineno: 323
      lineno: 278
      name: get_json_info
    - docstring: Obtém informações básicas sobre um arquivo YAML.
      end_lineno: 346
      lineno: 325
      name: get_yaml_info
    - docstring: Formata o tamanho em bytes para KB, MB, GB.
      end_lineno: 355
      lineno: 348
      name: format_size
    - docstring: Cria o objeto de configuração de geração para a IA.
      end_lineno: 376
      lineno: 363
      name: configurar_geracao
    - docstring: Envia uma mensagem para a sessão de chat da IA com retentativas.
      end_lineno: 445
      lineno: 379
      name: enviar_mensagem
    - docstring: Varre o diretório raiz, analisa arquivos e retorna um dicionário
        com a estrutura.
      end_lineno: 564
      lineno: 448
      name: scan_directory
    - docstring: 'Gera relatórios: Markdown (descrição do projeto) e HTML (diagrama
        de arquitetura do projeto).

        O HTML é gerado pela IA baseando-se nos dados do projeto e usando um template
        como guia de estilo.'
      end_lineno: 1540
      lineno: 1246
      name: gerar_relatorio_ia
    - docstring: Função principal que orquestra a varredura e geração dos relatórios.
      end_lineno: 1605
      lineno: 1543
      name: main
    imports:
    - asname: null
      name: os
    - asname: null
      name: platform
    - asname: null
      name: sqlite3
    - asname: null
      name: json
    - asname: null
      name: yaml
    - asname: null
      name: time
    - module: datetime
      names:
      - datetime
    - asname: genai
      name: google.generativeai
    - module: colorama
      names:
      - Fore
      - Style
      - init
    - asname: null
      name: ast
    - asname: null
      name: re
    - module: typing
      names:
      - List
      - Dict
      - Any
      - Optional
      - Tuple
      - Union
    - asname: null
      name: traceback
    - asname: null
      name: traceback
    numero_de_linhas: 1619
    source_code: "# -*- coding: utf-8 -*-\nimport os\nimport platform\nimport sqlite3\n\
      import json\nimport yaml\nimport time\nfrom datetime import datetime\nimport\
      \ google.generativeai as genai\nfrom colorama import Fore, Style, init\nimport\
      \ ast\nimport re # Importa o módulo de expressões regulares\nfrom typing import\
      \ List, Dict, Any, Optional, Tuple, Union # Para type hints\n\n# Inicializa\
      \ o Colorama para colorir os logs\ninit(autoreset=True)\n\n# --- ATENÇÃO: Chave\
      \ de API ---\n# NUNCA coloque chaves de API diretamente no código em produção.\n\
      # Use variáveis de ambiente ou um sistema de gerenciamento de segredos.\nAPI_KEY\
      \ = os.getenv(\"GEMINI_API_KEY\") # Tenta pegar da env\nif not API_KEY:\n  \
      \  # Use uma chave placeholder SOMENTE para desenvolvimento local e NUNCA com\
      \ dados sensíveis.\n    # Substitua 'SUA_CHAVE_PLACEHOLDER_AQUI' por uma chave\
      \ real ou remova esta linha em produção.\n    API_KEY = 'AIzaSyC7dAwSyLKaVO2E-PA6UaacLZ4aLGtrXbY'\
      \ # CHAVE PLACEHOLDER - RISCO!\n    print(f\"{Fore.RED}{'#'*66}\")\n    print(f\"\
      ### {Fore.YELLOW}ALERTA:{Style.RESET_ALL}{Fore.RED} USANDO CHAVE DE API PADRÃO/PLACEHOLDER!\
      \                 ###\")\n    print(f\"### Defina a variável de ambiente 'GEMINI_API_KEY'\
      \ com sua chave ###\")\n    print(f\"### real para segurança e funcionamento\
      \ adequado em produção.    ###\")\n    print(f\"### {Style.BRIGHT}NÃO USE ESTA\
      \ CHAVE EM AMBIENTES PÚBLICOS OU COM DADOS REAIS.{Style.NORMAL} ###\")\n   \
      \ print(f\"{'#'*66}{Style.RESET_ALL}\")\n    # Considerar adicionar exit(1)\
      \ aqui se a chave for absolutamente essencial e não houver fallback funcional.\n\
      \    # Ex: descomente a linha abaixo se o script NÃO DEVE rodar sem uma chave\
      \ real:\n    # exit(1)\n\ntry:\n    genai.configure(api_key=API_KEY)\n    print(f\"\
      {Fore.GREEN}\U0001F511 Configuração da API do Gemini bem-sucedida.\")\nexcept\
      \ Exception as e:\n    print(f\"{Fore.RED}ERRO FATAL: Falha ao configurar a\
      \ API do Gemini.\")\n    print(f\"{Fore.RED}   Erro: {e}\")\n    print(f\"{Fore.RED}\
      \   Verifique se a chave de API ('{API_KEY[:4]}...{API_KEY[-4:] if API_KEY else\
      \ ''}') é válida e se há conectividade.\")\n    exit(1) # Para a execução se\
      \ não puder configurar a API\n\n# Modelo da IA - Verifique a disponibilidade\
      \ e adequação do modelo\n# Modelos comuns: gemini-1.5-flash-latest, gemini-1.5-pro-latest,\
      \ gemini-1.0-pro\n# NOME_MODELO = \"gemini-1.5-pro-latest\" # Usar o modelo\
      \ mais capaz se necessário\nNOME_MODELO = \"gemini-2.0-flash\" # Modelo mais\
      \ rápido e geralmente suficiente\nprint(f\"{Fore.BLUE}ℹ️ Usando modelo de IA:\
      \ {NOME_MODELO}\")\n\n# Arquivos e diretórios a serem ignorados\n# Adicione\
      \ padrões conforme necessário\nIGNORE_LIST = [\n    os.path.basename(__file__),\
      \ # Ignora o próprio script dinamicamente\n    \".git\",\n    \".venv\",\n \
      \   \"venv\",\n    \"__pycache__\",\n    \"node_modules\",\n    \".md\", # Ignora\
      \ arquivos Markdown existentes\n    \".html\", # Ignora arquivos HTML existentes\
      \ (incluindo o gerado)\n    \".yaml\", # Ignora arquivos YAML de estrutura gerados\
      \ anteriormente\n    \"requirements.txt\",\n    \"LICENSE\",\n    \"build\"\
      , # Diretório comum de build\n    \"dist\",  # Diretório comum de distribuição\n\
      \    \"*.log\", # Arquivos de log (padrão de exemplo)\n    \".idea\", # Configurações\
      \ do IntelliJ/Android Studio\n    \".vscode\",# Configurações do VS Code\n \
      \   \"target\", # Diretório comum de build Java/Rust\n    \"docs\",   # Diretório\
      \ comum de documentação\n    \"tests\",  # Diretório comum de testes (pode querer\
      \ analisar)\n    \"test\",   # Diretório comum de testes (pode querer analisar)\n\
      \    \".pytest_cache\",\n    \".mypy_cache\",\n    \"site\",   # Diretório comum\
      \ do MkDocs/Sphinx\n]\n\n# --- Funções de Análise de Arquivos ---\n\ndef get_file_size(file_path:\
      \ str) -> int:\n    \"\"\"Retorna o tamanho do arquivo em bytes ou -1 em caso\
      \ de erro.\"\"\"\n    try:\n        return os.path.getsize(file_path)\n    except\
      \ OSError as e:\n        # print(f\"{Fore.YELLOW}Aviso: Não foi possível obter\
      \ o tamanho de '{file_path}': {e}{Style.RESET_ALL}\")\n        return -1\n\n\
      def count_lines(file_path: str) -> int:\n    \"\"\"Conta as linhas de um arquivo,\
      \ tentando várias codificações.\n    Retorna:\n        >= 0: número de linhas\n\
      \        -1: Erro de IO/Permissão\n        -2: Erro de decodificação com codificações\
      \ comuns\n    \"\"\"\n    encodings_to_try = ['utf-8', 'latin-1', 'cp1252']\n\
      \    for enc in encodings_to_try:\n        try:\n            with open(file_path,\
      \ 'r', encoding=enc) as f:\n                return sum(1 for _ in f)\n     \
      \   except UnicodeDecodeError:\n            continue\n        except (OSError,\
      \ IOError) as e:\n            # print(f\"{Fore.YELLOW}Aviso: Erro ao abrir/ler\
      \ '{file_path}' para contagem de linhas: {e}{Style.RESET_ALL}\")\n         \
      \   return -1\n        except Exception as e: # Captura genérica para outros\
      \ erros inesperados\n            # print(f\"{Fore.YELLOW}Aviso: Erro inesperado\
      \ ao contar linhas de '{file_path}': {e}{Style.RESET_ALL}\")\n            return\
      \ -1\n    # print(f\"{Fore.YELLOW}Aviso: Não foi possível decodificar '{file_path}'\
      \ para contar linhas com {encodings_to_try}.{Style.RESET_ALL}\")\n    return\
      \ -2\n\ndef read_file_content(file_path: str, max_lines: int = 50) -> Optional[str]:\n\
      \    \"\"\"Lê as primeiras `max_lines` de um arquivo, tentando várias codificações.\"\
      \"\"\n    encodings_to_try = ['utf-8', 'latin-1', 'cp1252']\n    content = None\n\
      \    for enc in encodings_to_try:\n        try:\n            with open(file_path,\
      \ 'r', encoding=enc) as f:\n                lines = [next(f) for _ in range(max_lines)]\n\
      \                content = \"\".join(lines)\n            return content # Retorna\
      \ assim que conseguir ler\n        except UnicodeDecodeError:\n            continue\n\
      \        except StopIteration: # Arquivo tem menos que max_lines\n         \
      \   try:\n                 with open(file_path, 'r', encoding=enc) as f:\n \
      \                    content = f.read()\n                 return content # Retorna\
      \ o conteúdo completo\n            except Exception: # Erro na segunda tentativa\
      \ de leitura completa\n                continue\n        except (OSError, IOError):\n\
      \             # Não loga erro aqui, pois é comum tentar e falhar com encodings\n\
      \             return None # Erro de IO impede leitura\n        except Exception:\n\
      \             # Log genérico pode ser útil aqui se necessário\n            \
      \ return None # Outro erro impede leitura\n\n    # print(f\"{Fore.YELLOW}Aviso:\
      \ Não foi possível ler o conteúdo de '{file_path}' com codificações comuns.{Style.RESET_ALL}\"\
      )\n    return None # Retorna None se todas as tentativas falharem\n\ndef get_python_info(file_path:\
      \ str) -> Dict[str, Any]:\n    \"\"\"Analisa um arquivo Python usando AST para\
      \ extrair funções, classes e imports.\"\"\"\n    source_code: Optional[str]\
      \ = None\n    read_error: Optional[str] = None\n    encodings_to_try = ['utf-8',\
      \ 'latin-1', 'cp1252']\n\n    for enc in encodings_to_try:\n        try:\n \
      \           with open(file_path, 'r', encoding=enc) as f:\n                source_code\
      \ = f.read()\n            break # Sucesso na leitura\n        except UnicodeDecodeError:\n\
      \            continue\n        except (OSError, IOError) as e:\n           \
      \ read_error = f\"Erro de IO ao ler o arquivo com {enc}: {e}\"\n           \
      \ break # Erro de IO provavelmente não será resolvido com outro encoding\n \
      \       except Exception as e:\n            read_error = f\"Erro inesperado\
      \ ao ler o arquivo com {enc}: {e}\"\n            # Continuar tentando outros\
      \ encodings pode ser útil em casos raros\n\n    if source_code is None:\n  \
      \      err_msg = read_error if read_error else f\"Não foi possível decodificar\
      \ o arquivo '{os.path.basename(file_path)}' com as codificações testadas.\"\n\
      \        return {\"error\": err_msg, \"analysis_status\": \"failed_read\"}\n\
      \n    try:\n        tree = ast.parse(source_code)\n        functions: List[Dict[str,\
      \ Any]] = []\n        classes: List[Dict[str, Any]] = []\n        imports: List[Dict[str,\
      \ Any]] = []\n\n        for node in ast.walk(tree):\n            if isinstance(node,\
      \ ast.FunctionDef):\n                # Usa getattr para end_lineno que pode\
      \ não estar presente em todas as versões/nós\n                functions.append({\n\
      \                    \"name\": node.name,\n                    \"docstring\"\
      : ast.get_docstring(node) or \"\", # Garante string vazia se não houver docstring\n\
      \                    \"lineno\": node.lineno,\n                    \"end_lineno\"\
      : getattr(node, 'end_lineno', None)\n                })\n            elif isinstance(node,\
      \ ast.ClassDef):\n                classes.append({\n                    \"name\"\
      : node.name,\n                    \"docstring\": ast.get_docstring(node) or\
      \ \"\",\n                    \"lineno\": node.lineno,\n                    \"\
      end_lineno\": getattr(node, 'end_lineno', None)\n                })\n      \
      \      elif isinstance(node, ast.Import):\n                imports.extend([\n\
      \                    {\"type\": \"import\", \"name\": alias.name, \"asname\"\
      : alias.asname}\n                    for alias in node.names\n             \
      \   ])\n            elif isinstance(node, ast.ImportFrom):\n               \
      \  module_name = node.module if node.module else '.relative.' # Indica import\
      \ relativo se module for None\n                 imports.append({\n         \
      \            \"type\": \"from\",\n                     \"module\": module_name,\n\
      \                     \"level\": node.level, # Nível do import relativo (0 para\
      \ absoluto)\n                     \"names\": [(alias.name, alias.asname) for\
      \ alias in node.names]\n                 })\n        return {\"functions\":\
      \ functions, \"classes\": classes, \"imports\": imports, \"analysis_status\"\
      : \"success\"}\n    except SyntaxError as e:\n        return {\"error\": f\"\
      Erro de sintaxe Python: {e}\", \"lineno\": e.lineno, \"col_offset\": e.offset,\
      \ \"analysis_status\": \"failed_syntax\"}\n    except Exception as e:\n    \
      \    return {\"error\": f\"Erro inesperado ao analisar AST: {e}\", \"analysis_status\"\
      : \"failed_ast\"}\n\ndef get_sqlite_info(file_path: str, max_rows: int = 5)\
      \ -> Dict[str, Any]:\n    \"\"\"Extrai esquema e amostra de dados de um banco\
      \ de dados SQLite.\"\"\"\n    # Usar mode=ro (read-only) é mais seguro\n   \
      \ db_uri = f'file:{file_path}?mode=ro'\n    tables_data: Dict[str, Any] = {}\n\
      \    try:\n        # Timeout pode ser útil para bancos de dados bloqueados\n\
      \        conn = sqlite3.connect(db_uri, uri=True, timeout=5.0)\n        cursor\
      \ = conn.cursor()\n\n        # Listar tabelas\n        cursor.execute(\"SELECT\
      \ name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\"\
      ) # Ignora tabelas do sistema\n        tables = [row[0] for row in cursor.fetchall()]\n\
      \n        if not tables:\n            conn.close()\n            return {\"info\"\
      : \"Banco de dados vazio ou sem tabelas de usuário.\", \"tables\": {}}\n\n \
      \       for table_name in tables:\n            try:\n                # Obter\
      \ esquema da tabela\n                cursor.execute(f\"PRAGMA table_info('{table_name}');\"\
      )\n                columns = [{\"name\": row[1], \"type\": row[2], \"notnull\"\
      : bool(row[3]), \"default\": row[4], \"pk\": bool(row[5])}\n               \
      \            for row in cursor.fetchall()]\n\n                # Contar linhas\
      \ (pode ser lento em tabelas enormes)\n                try:\n              \
      \      cursor.execute(f\"SELECT COUNT(*) FROM '{table_name}';\")\n         \
      \           row_count = cursor.fetchone()[0]\n                except sqlite3.OperationalError\
      \ as count_e:\n                    # Pode falhar se a tabela for corrupta ou\
      \ virtual sem implementação\n                    print(f\"{Fore.YELLOW}Aviso:\
      \ Não foi possível contar linhas da tabela SQLite '{table_name}': {count_e}{Style.RESET_ALL}\"\
      )\n                    row_count = \"Erro ao Contar\"\n\n                # Obter\
      \ amostra de linhas\n                sample_rows_safe = []\n               \
      \ if row_count == 0 or row_count == \"Erro ao Contar\":\n                  \
      \   sample_rows = []\n                else:\n                    try:\n    \
      \                    cursor.execute(f\"SELECT * FROM '{table_name}' LIMIT {max_rows};\"\
      )\n                        sample_rows = cursor.fetchall()\n               \
      \         # Tratar BLOBs para evitar problemas na serialização (JSON/YAML)\n\
      \                        sample_rows_safe = [\n                            tuple(f\"\
      <bytes {len(item)}>\" if isinstance(item, bytes) else item for item in row)\n\
      \                            for row in sample_rows\n                      \
      \  ]\n                    except sqlite3.OperationalError as select_e:\n   \
      \                     print(f\"{Fore.YELLOW}Aviso: Não foi possível obter amostra\
      \ da tabela SQLite '{table_name}': {select_e}{Style.RESET_ALL}\")\n        \
      \                sample_rows = [\"Erro ao Ler Amostra\"]\n\n               \
      \ tables_data[table_name] = {\n                    \"columns\": columns,\n \
      \                   \"total_rows\": row_count,\n                    \"sample_rows\"\
      : sample_rows_safe\n                }\n\n            except sqlite3.OperationalError\
      \ as table_e:\n                 # Erro específico da tabela (ex: tabela corrupta)\n\
      \                print(f\"{Fore.YELLOW}Aviso: Erro operacional ao processar\
      \ tabela SQLite '{table_name}': {table_e}{Style.RESET_ALL}\")\n            \
      \    tables_data[table_name] = {\"error\": f\"Erro operacional: {table_e}\"\
      , \"columns\": [], \"total_rows\": \"Erro\", \"sample_rows\": []}\n\n      \
      \  conn.close()\n        return {\"tables\": tables_data, \"analysis_status\"\
      : \"success\"}\n\n    except sqlite3.OperationalError as conn_e:\n         #\
      \ Erro ao conectar (arquivo não é DB, bloqueado, permissão)\n         return\
      \ {\"error\": f\"Erro SQLite ao conectar (arquivo inválido, bloqueado ou sem\
      \ permissão?): {conn_e}\", \"analysis_status\": \"failed_connect\"}\n    except\
      \ Exception as e:\n        # Outros erros inesperados\n        return {\"error\"\
      : f\"Erro inesperado ao processar SQLite: {e}\", \"analysis_status\": \"failed_other\"\
      }\n\ndef get_json_info(file_path: str) -> Dict[str, Any]:\n    \"\"\"Obtém informações\
      \ básicas sobre um arquivo JSON.\"\"\"\n    info: Dict[str, Any] = {}\n    file_size\
      \ = get_file_size(file_path)\n    line_count = count_lines(file_path)\n\n  \
      \  info[\"tamanho_formatado\"] = format_size(file_size)\n    info[\"tamanho_bytes\"\
      ] = file_size if file_size >= 0 else \"Erro\"\n    info[\"numero_de_linhas\"\
      ] = line_count if line_count >= 0 else (\"Erro Codificação\" if line_count ==\
      \ -2 else \"Erro Leitura\")\n\n    # Tenta inferir a estrutura raiz (objeto\
      \ ou lista) lendo uma pequena parte\n    structure_type = \"desconhecido\"\n\
      \    if file_size > 0 and file_size < 5 * 1024 * 1024: # Tenta analisar apenas\
      \ arquivos menores para performance\n        try:\n            with open(file_path,\
      \ 'r', encoding='utf-8') as f:\n                # Lê um pedaço inicial, suficiente\
      \ para detectar a estrutura\n                # Cuidado com JSONs muito grandes\
      \ onde o início não é representativo\n                preview = f.read(2048)\n\
      \                # Tenta parsear o preview (pode falhar se o preview cortar\
      \ no meio de uma string ou estrutura)\n                try:\n              \
      \      # Remove vírgulas ou lixo no final que pode impedir o parse do preview\n\
      \                    preview_trimmed = preview.strip().rstrip(',').rstrip(']').rstrip('}')\n\
      \                    # Adiciona fechamento se necessário para tentar parsear\n\
      \                    if preview_trimmed.startswith('[') and not preview_trimmed.endswith(']'):\n\
      \                        data = json.loads(preview_trimmed + ']')\n        \
      \            elif preview_trimmed.startswith('{') and not preview_trimmed.endswith('}'):\n\
      \                        data = json.loads(preview_trimmed + '}')\n        \
      \            else:\n                         data = json.loads(preview_trimmed)\n\
      \n                    if isinstance(data, list):\n                        structure_type\
      \ = \"lista\"\n                    elif isinstance(data, dict):\n          \
      \              structure_type = \"objeto\"\n                    else:\n    \
      \                    structure_type = \"outro (valor primitivo?)\"\n       \
      \         except json.JSONDecodeError:\n                    # Falha ao parsear\
      \ o preview, acontece\n                    structure_type = \"não foi possível\
      \ determinar pelo preview\"\n        except Exception:\n            # Erro ao\
      \ ler o arquivo para preview\n            structure_type = \"erro ao ler preview\"\
      \n\n    info[\"tipo_estrutura_inferida\"] = structure_type\n    info[\"analysis_status\"\
      ] = \"success\" # Mesmo que o preview falhe, infos básicas foram coletadas\n\
      \    return info\n\ndef get_yaml_info(file_path: str) -> Dict[str, Any]:\n \
      \   \"\"\"Obtém informações básicas sobre um arquivo YAML.\"\"\"\n    info:\
      \ Dict[str, Any] = {}\n    file_size = get_file_size(file_path)\n    line_count\
      \ = count_lines(file_path)\n\n    info[\"tamanho_formatado\"] = format_size(file_size)\n\
      \    info[\"tamanho_bytes\"] = file_size if file_size >= 0 else \"Erro\"\n \
      \   info[\"numero_de_linhas\"] = line_count if line_count >= 0 else (\"Erro\
      \ Codificação\" if line_count == -2 else \"Erro Leitura\")\n\n    # Poderia\
      \ adicionar uma tentativa de parsear o início com PyYAML para inferir estrutura,\
      \ similar ao JSON\n    # Ex:\n    # try:\n    #     with open(file_path, 'r',\
      \ encoding='utf-8') as f:\n    #         preview_data = yaml.safe_load(f) #\
      \ Cuidado: lê o arquivo todo!\n    #         # Ou ler preview: preview = f.read(2048);\
      \ preview_data = yaml.safe_load(preview)\n    #     if isinstance(preview_data,\
      \ list): info[\"tipo_estrutura_inferida\"] = \"lista\"\n    #     elif isinstance(preview_data,\
      \ dict): info[\"tipo_estrutura_inferida\"] = \"objeto/mapa\"\n    # except Exception:\
      \ info[\"tipo_estrutura_inferida\"] = \"erro ao analisar\"\n\n    info[\"analysis_status\"\
      ] = \"success\"\n    return info\n\ndef format_size(size_in_bytes: int) -> str:\n\
      \    \"\"\"Formata o tamanho em bytes para KB, MB, GB.\"\"\"\n    if size_in_bytes\
      \ < 0: return \"Erro\"\n    if size_in_bytes == 0: return \"0 Bytes\"\n    if\
      \ size_in_bytes < 1024: return f\"{size_in_bytes} Bytes\"\n    if size_in_bytes\
      \ < 1024**2: return f\"{size_in_bytes/1024:.2f} KB\"\n    if size_in_bytes <\
      \ 1024**3: return f\"{size_in_bytes/(1024**2):.2f} MB\"\n    return f\"{size_in_bytes/(1024**3):.2f}\
      \ GB\"\n\n# Configurações de geração da IA\nAI_TEMPERATURE = 0.7 # Um pouco\
      \ mais determinístico para seguir instruções complexas\nAI_TOP_P = 0.9\nAI_TOP_K\
      \ = 50\nAI_MAX_TOKENS = 32800 # Ajuste conforme o modelo e a necessidade (modelos\
      \ 1.5 suportam mais)\n\ndef configurar_geracao(\n    temperatura: float = AI_TEMPERATURE,\n\
      \    top_p: float = AI_TOP_P,\n    top_k: int = AI_TOP_K,\n    max_tokens: int\
      \ = AI_MAX_TOKENS\n) -> genai.types.GenerationConfig:\n    \"\"\"Cria o objeto\
      \ de configuração de geração para a IA.\"\"\"\n    return genai.types.GenerationConfig(\n\
      \        temperature=temperatura,\n        top_p=top_p,\n        top_k=top_k,\n\
      \        max_output_tokens=max_tokens,\n        # response_mime_type=\"text/plain\"\
      \ # Garante texto puro se necessário\n    )\n\n# Função para enviar mensagens\
      \ para a IA com retentativas\ndef enviar_mensagem(sessao_chat: genai.ChatSession,\
      \ mensagem: str) -> Optional[str]:\n    \"\"\"Envia uma mensagem para a sessão\
      \ de chat da IA com retentativas.\"\"\"\n    MAX_RETRIES = 3 # Aumenta um pouco\
      \ as retentativas\n    RETRY_DELAY_SECONDS = 7 # Aumenta o delay\n\n    for\
      \ attempt in range(MAX_RETRIES):\n        try:\n            print(f\"{Fore.YELLOW}\U0001F9E0\
      \ Enviando prompt para IA ({NOME_MODELO}) - Tentativa {attempt + 1}/{MAX_RETRIES}...\"\
      )\n            # Medir tempo da chamada da IA\n            start_ai_time = time.time()\n\
      \            resposta = sessao_chat.send_message(mensagem)\n            end_ai_time\
      \ = time.time()\n            print(f\"{Fore.GREEN}✅ Resposta da IA recebida\
      \ em {end_ai_time - start_ai_time:.2f}s.\")\n\n            # Verificar bloqueios\
      \ ou falta de conteúdo\n            if not resposta.candidates:\n          \
      \      block_reason = \"Não especificado\"\n                safety_ratings =\
      \ \"N/A\"\n                try:\n                    block_reason = resposta.prompt_feedback.block_reason.name\n\
      \                    safety_ratings = str(resposta.prompt_feedback.safety_ratings)\n\
      \                except AttributeError: pass # Nem sempre esses atributos existem\n\
      \                print(f\"{Fore.RED}❗ Resposta da IA bloqueada ou sem candidatos.\"\
      )\n                print(f\"{Fore.RED}   Razão: {block_reason}\")\n        \
      \        print(f\"{Fore.RED}   Safety Ratings: {safety_ratings}\")\n       \
      \         # Não tentar novamente se for bloqueado por segurança\n          \
      \      if block_reason != \"BLOCK_REASON_UNSPECIFIED\":\n                  \
      \  return None\n                # Se for não especificado, talvez valha a pena\
      \ tentar novamente? Ou retornar None?\n                # Por segurança, retornamos\
      \ None aqui também.\n                return None\n\n            # Extrair texto\
      \ da primeira candidata (geralmente a única)\n            if resposta.candidates[0].content\
      \ and resposta.candidates[0].content.parts:\n                texto_resposta\
      \ = \"\".join(part.text for part in resposta.candidates[0].content.parts if\
      \ hasattr(part, 'text'))\n                if texto_resposta.strip():\n     \
      \               # Verificar safety ratings da resposta também\n            \
      \        try:\n                        response_safety = str(resposta.candidates[0].safety_ratings)\n\
      \                        if \"BLOCK\" in response_safety.upper(): # Verifica\
      \ se algum rating indica bloqueio\n                             print(f\"{Fore.YELLOW}⚠️\
      \ Resposta da IA contém conteúdo potencialmente problemático (Safety: {response_safety}).\"\
      )\n                             # Decidir se retorna ou não. Por segurança,\
      \ pode ser melhor retornar None ou uma msg de erro.\n                      \
      \       # return f\"Erro: Resposta da IA marcada com problemas de segurança:\
      \ {response_safety}\"\n                    except AttributeError: pass\n\n \
      \                   return texto_resposta\n                else:\n         \
      \           print(f\"{Fore.YELLOW}⚠️ Resposta da IA está vazia ou não contém\
      \ texto.\")\n                    # Considerar retentativa ou retornar vazio?\
      \ Retornar vazio é mais seguro.\n                    return \"\" # Retorna vazia,\
      \ mas não None\n            else:\n                 print(f\"{Fore.YELLOW}⚠️\
      \ Resposta da IA não contém partes de conteúdo ou texto.\")\n              \
      \   return \"\" # Retorna vazia\n\n        except Exception as e:\n        \
      \    print(f\"{Fore.RED}❗Erro ao comunicar com a IA (Tentativa {attempt + 1}/{MAX_RETRIES}):\
      \ {e}\")\n            # Verifica se é um erro específico que não justifica retentativa\
      \ (ex: API Key inválida)\n            if \"API key not valid\" in str(e):\n\
      \                print(f\"{Fore.RED}   Erro de chave de API. Interrompendo retentativas.\"\
      )\n                return None\n            if attempt < MAX_RETRIES - 1:\n\
      \                print(f\"{Fore.CYAN}    Aguardando {RETRY_DELAY_SECONDS}s para\
      \ tentar novamente...\")\n                time.sleep(RETRY_DELAY_SECONDS)\n\
      \            else:\n                print(f\"{Fore.RED}❗ Falha ao comunicar\
      \ com a IA após {MAX_RETRIES} tentativas.\")\n                return None\n\
      \    return None # Caso o loop termine sem sucesso\n\n# Função para varrer diretórios\n\
      def scan_directory(root_path: str = \".\") -> Dict[str, Any]:\n    \"\"\"Varre\
      \ o diretório raiz, analisa arquivos e retorna um dicionário com a estrutura.\"\
      \"\"\n    report: Dict[str, Any] = {}\n    abs_root_path = os.path.abspath(root_path)\n\
      \    print(f\"{Fore.CYAN}\U0001F50D Varrendo diretório: {abs_root_path}\")\n\
      \    print(f\"{Fore.CYAN}   Ignorando nomes/extensões: {IGNORE_LIST}\")\n  \
      \  items_processed, items_ignored, errors_occurred = 0, 0, 0\n\n    # Cria uma\
      \ lista de extensões e nomes completos para ignorar\n    ignore_extensions =\
      \ {item for item in IGNORE_LIST if item.startswith('.')}\n    ignore_filenames\
      \ = {item for item in IGNORE_LIST if not item.startswith('*') and not item.startswith('.')}\n\
      \    ignore_patterns = [item for item in IGNORE_LIST if item.startswith('*')]\
      \ # Para futuras melhorias com fnmatch\n\n    for current_root, dirs, files\
      \ in os.walk(root_path, topdown=True):\n        # Filtra diretórios ignorados\
      \ (modifica dirs in-place)\n        dirs[:] = [d for d in dirs if d not in ignore_filenames\
      \ and not d.startswith('.') and d not in IGNORE_LIST] # Adiciona checagem explícita\
      \ na IGNORE_LIST\n\n        # Calcula o caminho relativo para o relatório\n\
      \        relative_root = os.path.relpath(current_root, root_path)\n        if\
      \ relative_root == '.':\n            relative_root = 'Raiz do Projeto' # Nome\
      \ mais amigável para a raiz\n\n        root_report: Dict[str, Any] = {} # Relatório\
      \ para este diretório específico\n\n        for filename in files:\n       \
      \     file_path = os.path.join(current_root, filename)\n            _, file_ext\
      \ = os.path.splitext(filename)\n            file_ext_lower = file_ext.lower()\n\
      \            filename_lower = filename.lower()\n\n            # Verifica se\
      \ o arquivo deve ser ignorado\n            ignore_file = False\n           \
      \ if filename in ignore_filenames or filename_lower in ignore_filenames:\n \
      \               ignore_file = True\n            elif file_ext_lower in ignore_extensions:\n\
      \                ignore_file = True\n            elif filename.startswith('.'):\
      \ # Ignora arquivos ocultos\n                ignore_file = True\n          \
      \  else:\n                 # Checa padrões de extensão como '*.log'\n      \
      \           if any(pat.endswith(file_ext_lower) for pat in ignore_patterns if\
      \ pat.startswith('*.')):\n                      ignore_file = True\n\n     \
      \       if ignore_file:\n                items_ignored += 1\n              \
      \  continue # Pula para o próximo arquivo\n\n            # Processa o arquivo\
      \ válido\n            items_processed += 1\n            file_info: Dict[str,\
      \ Any] = {}\n            has_error = False\n\n            try:\n           \
      \     file_size = get_file_size(file_path)\n                line_count = count_lines(file_path)\
      \ # Pode retornar < 0\n\n                file_info = {\n                   \
      \ \"caminho_relativo\": os.path.relpath(file_path, root_path),\n           \
      \         \"tamanho_bytes\": file_size if file_size >= 0 else -1, # Usa -1 para\
      \ erro consistente\n                    \"tamanho_formatado\": format_size(file_size),\n\
      \                    \"numero_de_linhas\": line_count if line_count >= 0 else\
      \ (-2 if line_count == -2 else -1), # -1 Erro IO, -2 Erro Decode\n         \
      \           \"extensao\": file_ext_lower\n                }\n\n            \
      \    # Análise específica por tipo de arquivo\n                if file_ext_lower\
      \ == \".py\":\n                    py_analysis = get_python_info(file_path)\n\
      \                    if \"error\" in py_analysis: has_error = True\n       \
      \             file_info[\"python_analysis\"] = py_analysis\n               \
      \ elif file_ext_lower in (\".db\", \".sqlite\", \".sqlite3\"):\n           \
      \         sqlite_analysis = get_sqlite_info(file_path)\n                   \
      \ if \"error\" in sqlite_analysis: has_error = True\n                    file_info[\"\
      sqlite_info\"] = sqlite_analysis\n                elif file_ext_lower == \"\
      .json\":\n                    json_analysis = get_json_info(file_path)\n   \
      \                 # get_json_info não sinaliza erro explicitamente, mas pode\
      \ conter msgs\n                    file_info[\"json_info\"] = json_analysis\n\
      \                elif file_ext_lower in (\".yaml\", \".yml\"):\n           \
      \         yaml_analysis = get_yaml_info(file_path)\n                    file_info[\"\
      yaml_info\"] = yaml_analysis\n                # Adiciona preview para arquivos\
      \ de texto razoavelmente pequenos\n                elif line_count > 0 and file_size\
      \ > 0 and file_size < 1 * 1024 * 1024: # Preview até 1MB\n                 \
      \   preview = read_file_content(file_path, max_lines=15) # Aumenta um pouco\
      \ as linhas do preview\n                    if preview is not None:\n      \
      \                  file_info[\"content_preview\"] = preview\n              \
      \      # else: # Opcional: indicar que a leitura do preview falhou\n       \
      \             #     file_info[\"content_preview_error\"] = True\n\n        \
      \        # Se ocorreu erro em alguma análise específica, marca no log\n    \
      \            if has_error:\n                    errors_occurred += 1\n     \
      \               print(f\"{Fore.RED}  -> Erro ao analisar: {file_info.get('caminho_relativo')}{Style.RESET_ALL}\"\
      )\n                # else: # Log verboso opcional para sucesso\n           \
      \     #     print(f\"{Fore.GREEN}  + Ok: {file_info.get('caminho_relativo')}{Style.RESET_ALL}\"\
      )\n\n\n            except Exception as e:\n                errors_occurred +=\
      \ 1\n                print(f\"{Fore.RED}  -> Erro INESPERADO ao processar {filename}:\
      \ {e}\")\n                file_info[\"processing_error\"] = str(e) # Adiciona\
      \ erro geral ao info\n\n            # Adiciona informações do arquivo ao relatório\
      \ do diretório atual\n            root_report[filename] = file_info\n\n    \
      \    # Adiciona o relatório deste diretório ao relatório principal, se não estiver\
      \ vazio\n        if root_report:\n            report[relative_root] = root_report\n\
      \n    print(f\"{Fore.GREEN}\U0001F4CA Varredura concluída.\")\n    print(f\"\
      \   Itens analisados: {items_processed}\")\n    print(f\"   Itens ignorados:\
      \ {items_ignored}\")\n    if errors_occurred > 0:\n        print(f\"{Fore.RED}\
      \   Erros durante análise: {errors_occurred}\")\n    if items_processed == 0:\n\
      \        print(f\"{Fore.YELLOW}⚠️ Nenhum arquivo relevante encontrado para análise\
      \ detalhada.\")\n\n    return report\n\n# --- TEMPLATE HTML (Android Arch -\
      \ Atualizado - Apenas como GUIA DE ESTILO para a IA) ---\n# Este template NÃO\
      \ será mais usado diretamente para gerar o arquivo final.\n# Ele será incluído\
      \ no prompt para que a IA entenda o estilo visual desejado.\nHTML_STYLE_GUIDE_TEMPLATE\
      \ = \"\"\"\n<!DOCTYPE html>\n<html lang=\"pt-br\">\n<head>\n    <meta charset=\"\
      UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\
      >\n    <title>Arquitetura Android Detalhada - Estilo Moderno</title>\n    <style>\n\
      \        /* Reset Básico e Estilos Globais (Mantido do seu exemplo) */\n   \
      \     *, *::before, *::after {\n            box-sizing: border-box;\n      \
      \      margin: 0;\n            padding: 0;\n        }\n\n        body {\n  \
      \          font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n \
      \           background: linear-gradient(135deg, #1a1a2e 0%, #16213e 74%);\n\
      \            color: #e0e0e0;\n            display: flex;\n            justify-content:\
      \ center;\n            align-items: flex-start; /* Alinha ao topo para diagramas\
      \ longos */\n            min-height: 100vh;\n            padding: 60px 20px;\
      \ /* Mais padding vertical */\n            overflow-x: hidden;\n        }\n\n\
      \        /* Container Principal do Diagrama */\n        .diagram-container {\n\
      \            width: 95%; /* Um pouco mais largo para comportar mais detalhes\
      \ */\n            max-width: 1100px; /* Aumentado para mais conteúdo */\n  \
      \          background-color: rgba(255, 255, 255, 0.05);\n            border-radius:\
      \ 25px;\n            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.5);\n         \
      \   backdrop-filter: blur(12px);\n            border: 1px solid rgba(255, 255,\
      \ 255, 0.15);\n            padding: 35px; /* Mais padding interno */\n     \
      \       display: flex;\n            flex-direction: column;\n            gap:\
      \ 20px; /* Espaço ligeiramente maior entre camadas */\n            perspective:\
      \ 1800px; /* Perspectiva 3D um pouco mais acentuada */\n        }\n\n      \
      \  /* Estilo das Camadas */\n        .layer {\n            padding: 25px;\n\
      \            border-radius: 18px;\n            border: 1px solid rgba(255, 255,\
      \ 255, 0.1);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n     \
      \       transition: transform 0.4s ease, box-shadow 0.4s ease;\n           \
      \ transform-style: preserve-3d;\n        }\n\n        .layer:hover {\n     \
      \      /* transform: translateY(-3px) translateZ(8px); */ /* Efeito hover opcional\
      \ na camada */\n        }\n\n        /* Cores e Gradientes das Camadas (Mantido)\
      \ */\n        .layer-apps { background: linear-gradient(145deg, #00a9cc, #007bff);\
      \ } /* Azul Ciano -> Azul */\n        .layer-framework { background: linear-gradient(145deg,\
      \ #5cb85c, #4cae4c); } /* Verde Claro -> Verde */\n        .layer-native-libs\
      \ { background: linear-gradient(145deg, #9d6ac9, #8a2be2); } /* Roxo -> Azul\
      \ Violeta */\n        .layer-runtime { background: linear-gradient(145deg, #f0ad4e,\
      \ #ec971f); } /* Laranja Claro -> Laranja */\n        .layer-hal { background:\
      \ linear-gradient(145deg, #22b8c2, #1a98a1); } /* Azul-Verde -> Teal */\n  \
      \      .layer-kernel { background: linear-gradient(145deg, #d9534f, #c9302c);\
      \ } /* Vermelho -> Vermelho Escuro */\n\n        .layer-title {\n          \
      \  font-size: 1.5em; /* Título um pouco maior */\n            font-weight: 600;\n\
      \            color: #ffffff;\n            text-shadow: 0 2px 5px rgba(0,0,0,0.4);\n\
      \            margin-bottom: 25px; /* Mais espaço abaixo do título */\n     \
      \       text-align: center;\n            padding-bottom: 10px; /* Mais padding\
      \ abaixo */\n            border-bottom: 1px solid rgba(255, 255, 255, 0.3);\n\
      \        }\n\n         /* Título secundário dentro de uma camada */\n      \
      \  .sub-layer-title {\n             font-size: 1.1em;\n             font-weight:\
      \ 500;\n             color: rgba(255, 255, 255, 0.9);\n             text-align:\
      \ center;\n             margin-top: 15px;\n             margin-bottom: 15px;\n\
      \             padding-bottom: 5px;\n             border-bottom: 1px dashed rgba(255,\
      \ 255, 255, 0.2);\n        }\n\n        /* Grid para os Componentes dentro das\
      \ Camadas */\n        .components-grid {\n            display: grid;\n     \
      \       grid-template-columns: repeat(auto-fit, minmax(130px, 1fr)); /* Componentes\
      \ um pouco maiores */\n            gap: 18px; /* Espaço ligeiramente maior */\n\
      \        }\n\n        /* Layout especial para Framework (Managers vs Resto)\
      \ */\n         .framework-layout {\n            display: grid;\n           \
      \ grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); /* Colunas adaptáveis\
      \ */\n            gap: 25px;\n            align-items: start;\n         }\n\
      \         .framework-managers-grid { /* Grid específico para managers */\n \
      \            display: grid;\n             grid-template-columns: repeat(auto-fit,\
      \ minmax(110px, 1fr));\n             gap: 12px;\n         }\n\n         /* Layout\
      \ para Nativo/Runtime (Lado a Lado onde couber) */\n         .native-runtime-layout\
      \ {\n             display: grid;\n             grid-template-columns: repeat(auto-fit,\
      \ minmax(300px, 1fr)); /* Adapta melhor */\n             gap: 25px;\n      \
      \       align-items: start;\n             /* Removemos a cor da camada externa\
      \ aqui, cada sub-camada tem a sua */\n         }\n         /* Estilos para as\
      \ sub-camadas dentro do layout Nativo/Runtime */\n         .native-runtime-layout\
      \ > .layer {\n              padding: 20px; /* Adiciona padding interno às sub-camadas\
      \ */\n              border-radius: 15px; /* Bordas arredondadas */\n       \
      \       /* Mantém o fundo individual definido por .layer-native-libs ou .layer-runtime\
      \ */\n         }\n         .native-runtime-layout .layer-title { /* Título das\
      \ sub-camadas */\n              font-size: 1.3em;\n              margin-bottom:\
      \ 20px;\n              border-bottom-color: rgba(255, 255, 255, 0.25);\n   \
      \      }\n\n        /* Estilo dos Componentes Individuais */\n        .component\
      \ {\n            background-color: rgba(255, 255, 255, 0.15);\n            color:\
      \ #f0f8ff;\n            padding: 18px 15px; /* Mais padding vertical */\n  \
      \          border-radius: 12px;\n            font-size: 0.9em;\n           \
      \ text-align: center;\n            box-shadow: 0 5px 12px rgba(0, 0, 0, 0.25);\n\
      \            border: 1px solid rgba(255, 255, 255, 0.2);\n            cursor:\
      \ default;\n            transition: transform 0.35s cubic-bezier(0.25, 0.8,\
      \ 0.25, 1),\n                        box-shadow 0.35s cubic-bezier(0.25, 0.8,\
      \ 0.25, 1),\n                        background-color 0.35s ease;\n        \
      \    opacity: 0;\n            animation: fadeInScale 0.5s ease-out forwards;\n\
      \            display: flex;\n            flex-direction: column; /* Para permitir\
      \ descrição opcional abaixo */\n            align-items: center;\n         \
      \   justify-content: center;\n            min-height: 70px; /* Altura mínima\
      \ maior */\n            transform-style: preserve-3d;\n            position:\
      \ relative; /* Adicionado para tooltip potencial */\n        }\n\n         /*\
      \ Estilo para a descrição opcional dentro do componente (exemplo simples) */\n\
      \         .component-desc {\n             font-size: 0.75em;\n             color:\
      \ rgba(224, 224, 224, 0.7);\n             margin-top: 5px;\n             font-style:\
      \ italic;\n         }\n\n         /* Efeito Hover com Tooltip (Exemplo mais\
      \ elaborado pode ser usado pela IA) */\n        .component .tooltiptext {\n\
      \            visibility: hidden;\n            width: 160px;\n            background-color:\
      \ #555;\n            color: #fff;\n            text-align: center;\n       \
      \     border-radius: 6px;\n            padding: 5px 8px;\n            position:\
      \ absolute;\n            z-index: 1;\n            bottom: 110%; /* Position\
      \ above the component */\n            left: 50%;\n            margin-left: -80px;\
      \ /* Center the tooltip */\n            opacity: 0;\n            transition:\
      \ opacity 0.3s, visibility 0.3s;\n            font-size: 0.8em;\n          \
      \  pointer-events: none; /* Prevent tooltip from interfering */\n        }\n\
      \n        .component:hover {\n            transform: scale(1.07) translateZ(18px)\
      \ rotateY(4deg); /* Efeito 3D sutilmente ajustado */\n            background-color:\
      \ rgba(255, 255, 255, 0.28);\n            box-shadow: 0 10px 25px rgba(0, 0,\
      \ 0, 0.4);\n            z-index: 10;\n        }\n\n        /* Mostra tooltip\
      \ no hover (se a IA implementar com esta classe) */\n        .component:hover\
      \ .tooltiptext {\n            visibility: visible;\n            opacity: 1;\n\
      \        }\n\n\n        /* Placeholder para reticências */\n        .component.placeholder\
      \ {\n             font-size: 1.6em;\n             font-weight: bold;\n     \
      \        background-color: rgba(0, 0, 0, 0.1);\n             border-style: dashed;\n\
      \             color: rgba(255, 255, 255, 0.5);\n        }\n\n        /* Kernel\
      \ específico: Power Management e Binder */\n        .kernel-driver-special {\n\
      \            grid-column: 1 / -1; /* Ocupa a largura toda da grid */\n     \
      \       margin-top: 10px;\n             background-color: rgba(0, 0, 0, 0.25);\n\
      \             font-weight: bold;\n        }\n\n        /* Animação Fade-in com\
      \ Escala (Mantido) */\n        @keyframes fadeInScale {\n            from {\
      \ opacity: 0; transform: scale(0.95) translateY(10px); }\n            to { opacity:\
      \ 1; transform: scale(1) translateY(0); }\n        }\n\n        /* Responsividade\
      \ (Ajustada para mais detalhes) */\n        @media (max-width: 992px) { /* Ajuste\
      \ breakpoint */\n             .framework-layout { grid-template-columns: 1fr;\
      \ } /* Empilha antes */\n             .native-runtime-layout { grid-template-columns:\
      \ 1fr; } /* Empilha antes */\n        }\n        @media (max-width: 768px) {\n\
      \            .diagram-container { width: 95%; padding: 25px; }\n           \
      \ .layer { padding: 20px; }\n            .layer-title { font-size: 1.3em; }\n\
      \            .sub-layer-title { font-size: 1.0em; }\n            .components-grid\
      \ { grid-template-columns: repeat(auto-fit, minmax(110px, 1fr)); gap: 12px;\
      \ }\n            .component { font-size: 0.85em; padding: 15px 10px; min-height:\
      \ 60px; }\n             .component-desc { font-size: 0.7em; }\n        }\n \
      \        @media (max-width: 480px) {\n            body { padding: 20px 10px;\
      \ } /* Reduz padding do body */\n            .diagram-container { border-radius:\
      \ 15px; padding: 15px; }\n             .layer { border-radius: 12px; padding:\
      \ 15px;}\n             .layer-title { font-size: 1.15em; }\n             .sub-layer-title\
      \ { font-size: 0.9em; }\n             .components-grid { grid-template-columns:\
      \ repeat(auto-fit, minmax(90px, 1fr)); gap: 10px; }\n             .component\
      \ { font-size: 0.78em; padding: 12px 8px; border-radius: 8px; min-height: 55px;\
      \ }\n             .component:hover { transform: scale(1.04) translateZ(8px)\
      \ rotateY(0deg); } /* Reduz hover no mobile */\n              .component-desc\
      \ { display: none; } /* Oculta descrição em telas muito pequenas */\n      \
      \        .component .tooltiptext { display: none; } /* Oculta tooltip em telas\
      \ muito pequenas */\n         }\n\n    </style>\n</head>\n<body>\n\n    <div\
      \ class=\"diagram-container\">\n\n        <!-- Camada System Apps -->\n    \
      \    <!-- Aplicações que vêm pré-instaladas ou são essenciais para o sistema.\
      \ Usam as APIs do Framework. -->\n        <div class=\"layer layer-apps\">\n\
      \            <div class=\"layer-title\">System Apps Layer</div>\n          \
      \  <div class=\"components-grid\">\n                <div class=\"component\"\
      \ style=\"animation-delay: 0.1s;\">\n                    Phone (Dialer)\n  \
      \                  <span class=\"component-desc\">Chamadas</span>\n        \
      \            <span class=\"tooltiptext\">Gerencia chamadas de voz e vídeo.</span>\n\
      \                </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 0.15s;\">\n                    Contacts\n                    <span class=\"\
      component-desc\">Agenda</span>\n                    <span class=\"tooltiptext\"\
      >Armazena e gerencia contatos.</span>\n                </div>\n            \
      \    <div class=\"component\" style=\"animation-delay: 0.2s;\">\n          \
      \          Browser (Chrome/AOSP)\n                    <span class=\"component-desc\"\
      >Navegador Web</span>\n                    <span class=\"tooltiptext\">Renderiza\
      \ páginas web.</span>\n                </div>\n                <div class=\"\
      component\" style=\"animation-delay: 0.25s;\">\n                    Camera\n\
      \                    <span class=\"component-desc\">Captura de Mídia</span>\n\
      \                    <span class=\"tooltiptext\">Interface para fotos e vídeos.</span>\n\
      \                </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 0.3s;\">\n                    Settings\n                    <span class=\"\
      component-desc\">Configurações</span>\n                    <span class=\"tooltiptext\"\
      >Ajustes do sistema e apps.</span>\n                </div>\n               \
      \ <div class=\"component\" style=\"animation-delay: 0.35s;\">\n            \
      \        Clock\n                    <span class=\"component-desc\">Alarme/Timer</span>\n\
      \                    <span class=\"tooltiptext\">Relógio, alarme, cronômetro.</span>\n\
      \                 </div>\n                <div class=\"component\" style=\"\
      animation-delay: 0.4s;\">\n                    Calendar\n                  \
      \  <span class=\"component-desc\">Agenda Pessoal</span>\n                  \
      \  <span class=\"tooltiptext\">Gerencia eventos e lembretes.</span>\n      \
      \           </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 0.45s;\">\n                    Email/Gmail\n                    <span class=\"\
      component-desc\">Cliente Email</span>\n                    <span class=\"tooltiptext\"\
      >Envia e recebe emails.</span>\n                </div>\n                <div\
      \ class=\"component\" style=\"animation-delay: 0.5s;\">\n                  \
      \  Messages (SMS/MMS)\n                    <span class=\"component-desc\">Mensagens</span>\n\
      \                    <span class=\"tooltiptext\">Envia e recebe SMS/MMS/RCS.</span>\n\
      \                </div>\n                <div class=\"component placeholder\"\
      \ style=\"animation-delay: 0.55s;\">\n                    ...\n            \
      \        <span class=\"component-desc\">Outros Apps</span>\n               \
      \     <span class=\"tooltiptext\">Launcher, Play Store, etc.</span>\n      \
      \          </div>\n            </div>\n        </div>\n\n        <!-- Camada\
      \ Java API Framework -->\n        <!-- Conjunto rico de APIs escritas em Java/Kotlin\
      \ que os desenvolvedores usam para criar aplicativos. -->\n        <div class=\"\
      layer layer-framework\">\n            <div class=\"layer-title\">Java API Framework\
      \ Layer</div>\n            <div class=\"framework-layout\">\n              \
      \  <!-- Coluna Esquerda: Sistemas Fundamentais -->\n                <div>\n\
      \                    <h3 class=\"sub-layer-title\">Core Systems & Utilities</h3>\n\
      \                    <div class=\"components-grid\" style=\"grid-template-columns:\
      \ repeat(auto-fit, minmax(150px, 1fr));\"> <!-- Grid um pouco diferente aqui\
      \ -->\n                        <div class=\"component\" style=\"animation-delay:\
      \ 0.6s;\">\n                            Activity Manager\n                 \
      \           <span class=\"component-desc\">Ciclo de vida das Activities</span>\n\
      \                            <span class=\"tooltiptext\">Gerencia o ciclo de\
      \ vida e a pilha de Activities.</span>\n                        </div>\n   \
      \                     <div class=\"component\" style=\"animation-delay: 0.65s;\"\
      >\n                            Window Manager\n                            <span\
      \ class=\"component-desc\">Gerencia janelas/superfícies</span>\n           \
      \                  <span class=\"tooltiptext\">Controla a visibilidade e ordem\
      \ das janelas.</span>\n                        </div>\n                    \
      \    <div class=\"component\" style=\"animation-delay: 0.7s;\">\n          \
      \                  View System\n                            <span class=\"component-desc\"\
      >Widgets UI (Button, TextView)</span>\n                            <span class=\"\
      tooltiptext\">Blocos de construção para interfaces de usuário.</span>\n    \
      \                    </div>\n                        <div class=\"component\"\
      \ style=\"animation-delay: 0.75s;\">\n                            Content Providers\n\
      \                            <span class=\"component-desc\">Compartilhamento\
      \ de dados</span>\n                             <span class=\"tooltiptext\"\
      >Permite que apps compartilhem dados entre si.</span>\n                    \
      \     </div>\n                        <div class=\"component\" style=\"animation-delay:\
      \ 0.8s;\">\n                            Resource Manager\n                 \
      \           <span class=\"component-desc\">Acesso a assets (layouts, strings)</span>\n\
      \                            <span class=\"tooltiptext\">Gerencia recursos não-compilados\
      \ (imagens, layouts, etc.).</span>\n                        </div>\n       \
      \                 <div class=\"component\" style=\"animation-delay: 0.85s;\"\
      >\n                            Package Manager\n                           \
      \ <span class=\"component-desc\">Info/instalação de apps</span>\n          \
      \                  <span class=\"tooltiptext\">Obtém informações sobre apps\
      \ instalados.</span>\n                        </div>\n                    </div>\n\
      \                </div>\n                <!-- Coluna Direita: Managers Específicos\
      \ -->\n                <div>\n                     <h3 class=\"sub-layer-title\"\
      >Feature-Specific Managers</h3>\n                     <div class=\"framework-managers-grid\"\
      >\n                        <div class=\"component\" style=\"animation-delay:\
      \ 0.9s;\">\n                            Telephony Mgr\n                    \
      \        <span class=\"component-desc\">Info de rede/chamada</span>\n      \
      \                      <span class=\"tooltiptext\">Acessa status do telefone\
      \ e rede celular.</span>\n                        </div>\n                 \
      \       <div class=\"component\" style=\"animation-delay: 0.95s;\">\n      \
      \                      Location Mgr\n                            <span class=\"\
      component-desc\">GPS/Rede/Fused</span>\n                            <span class=\"\
      tooltiptext\">Obtém a localização do dispositivo.</span>\n                 \
      \       </div>\n                        <div class=\"component\" style=\"animation-delay:\
      \ 1.0s;\">\n                            Notification Mgr\n                 \
      \           <span class=\"component-desc\">Alertas na status bar</span>\n  \
      \                          <span class=\"tooltiptext\">Exibe notificações para\
      \ o usuário.</span>\n                         </div>\n                     \
      \   <div class=\"component\" style=\"animation-delay: 1.05s;\">\n          \
      \                  Sensor Manager\n                            <span class=\"\
      component-desc\">Acelerômetro, Giro, etc.</span>\n                         \
      \    <span class=\"tooltiptext\">Acessa os sensores de hardware.</span>\n  \
      \                      </div>\n                        <div class=\"component\"\
      \ style=\"animation-delay: 1.1s;\">\n                            Connectivity\
      \ Mgr\n                            <span class=\"component-desc\">Estado de\
      \ rede (WiFi/Dados)</span>\n                            <span class=\"tooltiptext\"\
      >Verifica e gerencia conexões de rede.</span>\n                        </div>\n\
      \                        <div class=\"component\" style=\"animation-delay: 1.15s;\"\
      >\n                            Power Manager\n                            <span\
      \ class=\"component-desc\">Wakelocks, Doze</span>\n                        \
      \    <span class=\"tooltiptext\">Gerencia o estado de energia do dispositivo.</span>\n\
      \                        </div>\n                        <div class=\"component\"\
      \ style=\"animation-delay: 1.2s;\">\n                            Storage Manager\n\
      \                            <span class=\"component-desc\">Info de armazenamento</span>\n\
      \                            <span class=\"tooltiptext\">Acessa informações\
      \ sobre o armazenamento.</span>\n                        </div>\n          \
      \               <div class=\"component\" style=\"animation-delay: 1.25s;\">\n\
      \                             Download Manager\n                           \
      \  <span class=\"component-desc\">Downloads em background</span>\n         \
      \                    <span class=\"tooltiptext\">Gerencia downloads longos.</span>\n\
      \                         </div>\n                         <div class=\"component\"\
      \ style=\"animation-delay: 1.3s;\">\n                             Account Manager\n\
      \                             <span class=\"component-desc\">Gerencia contas\
      \ online</span>\n                              <span class=\"tooltiptext\">Centraliza\
      \ o gerenciamento de contas de usuário.</span>\n                          </div>\n\
      \                         <div class=\"component placeholder\" style=\"animation-delay:\
      \ 1.35s;\">\n                             ...\n                            \
      \ <span class=\"component-desc\">Muitos outros</span>\n                    \
      \         <span class=\"tooltiptext\">AudioManager, WifiManager, BluetoothManager,\
      \ etc.</span>\n                         </div>\n                     </div>\n\
      \                </div>\n            </div>\n        </div>\n\n        <!--\
      \ Layout Agrupado: Native Libraries & Android Runtime -->\n        <!-- Esta\
      \ seção contém bibliotecas C/C++ nativas e o ambiente de execução ART. -->\n\
      \         <div class=\"native-runtime-layout\">\n            <!-- Sub-Camada\
      \ Native C/C++ Libraries -->\n            <!-- Bibliotecas escritas em C/C++\
      \ que fornecem funcionalidades de baixo nível, acessadas pelo Framework via\
      \ JNI. -->\n            <div class=\"layer layer-native-libs\">\n          \
      \      <div class=\"layer-title\">Native C/C++ Libraries Layer</div>\n     \
      \           <div class=\"components-grid\">\n                    <div class=\"\
      component\" style=\"animation-delay: 1.4s;\">\n                        libc\
      \ (Bionic)\n                        <span class=\"component-desc\">Standard\
      \ C Library</span>\n                         <span class=\"tooltiptext\">Implementação\
      \ otimizada da libc para Android.</span>\n                     </div>\n    \
      \                <div class=\"component\" style=\"animation-delay: 1.45s;\"\
      >\n                        Media Framework\n                        <span class=\"\
      component-desc\">Codecs (AAC, H.264)</span>\n                        <span class=\"\
      tooltiptext\">Suporte a reprodução e gravação de mídia.</span>\n           \
      \         </div>\n                    <div class=\"component\" style=\"animation-delay:\
      \ 1.5s;\">\n                        Surface Manager\n                      \
      \  <span class=\"component-desc\">Composição de telas</span>\n             \
      \           <span class=\"tooltiptext\">Compõe diferentes superfícies gráficas\
      \ na tela.</span>\n                    </div>\n                    <div class=\"\
      component\" style=\"animation-delay: 1.55s;\">\n                        OpenGL\
      \ ES / Vulkan\n                        <span class=\"component-desc\">APIs Gráficas\
      \ 2D/3D</span>\n                        <span class=\"tooltiptext\">APIs padrão\
      \ para renderização gráfica acelerada.</span>\n                    </div>\n\
      \                    <div class=\"component\" style=\"animation-delay: 1.6s;\"\
      >\n                        SQLite\n                        <span class=\"component-desc\"\
      >Banco de dados local</span>\n                         <span class=\"tooltiptext\"\
      >Engine de banco de dados relacional leve.</span>\n                    </div>\n\
      \                    <div class=\"component\" style=\"animation-delay: 1.65s;\"\
      >\n                        WebKit / Chromium\n                        <span\
      \ class=\"component-desc\">Motor de renderização Web</span>\n              \
      \          <span class=\"tooltiptext\">Usado pelo WebView para exibir conteúdo\
      \ web.</span>\n                     </div>\n                    <div class=\"\
      component\" style=\"animation-delay: 1.7s;\">\n                        Skia\n\
      \                        <span class=\"component-desc\">Engine Gráfica 2D</span>\n\
      \                         <span class=\"tooltiptext\">Biblioteca para desenho\
      \ 2D (usada pela UI).</span>\n                    </div>\n                 \
      \   <div class=\"component\" style=\"animation-delay: 1.75s;\">\n          \
      \              SSL\n                        <span class=\"component-desc\">Segurança\
      \ (HTTPS)</span>\n                         <span class=\"tooltiptext\">Implementa\
      \ TLS/SSL para conexões seguras.</span>\n                     </div>\n     \
      \               <div class=\"component\" style=\"animation-delay: 1.8s;\">\n\
      \                        FreeType\n                        <span class=\"component-desc\"\
      >Renderização de Fontes</span>\n                        <span class=\"tooltiptext\"\
      >Renderiza fontes TrueType e OpenType.</span>\n                    </div>\n\
      \                    <div class=\"component placeholder\" style=\"animation-delay:\
      \ 1.85s;\">\n                        ...\n                        <span class=\"\
      component-desc\">Outras libs</span>\n                         <span class=\"\
      tooltiptext\">libjpeg, libpng, zlib, etc.</span>\n                     </div>\n\
      \                </div>\n            </div>\n\n            <!-- Sub-Camada Android\
      \ Runtime (ART) -->\n            <!-- Ambiente de execução onde os aplicativos\
      \ Android rodam. Inclui a VM e bibliotecas Java base. -->\n            <div\
      \ class=\"layer layer-runtime\">\n                 <div class=\"layer-title\"\
      >Android Runtime (ART) Layer</div>\n                 <div class=\"components-grid\"\
      \ style=\"grid-template-columns: 1fr 1fr; gap: 20px;\"> <!-- Layout 2 colunas\
      \ fixas aqui -->\n                    <!-- Coluna ART VM -->\n             \
      \       <div class=\"component\" style=\"animation-delay: 1.9s; grid-row: span\
      \ 2; display: flex; flex-direction: column; justify-content: space-around; align-items:\
      \ center; padding: 25px;\">\n                         <span style=\"font-size:\
      \ 1.2em; font-weight: bold;\">ART Virtual Machine</span>\n                 \
      \        <span class=\"component-desc\" style=\"font-size: 0.85em; text-align:\
      \ center;\">Executa bytecode DEX. Usa AOT/JIT/GC otimizados.</span>\n      \
      \                    <span class=\"tooltiptext\">Android Runtime: Compilação\
      \ Ahead-of-Time (AOT) e Just-in-Time (JIT), Garbage Collection (GC).</span>\n\
      \                     </div>\n                     <!-- Coluna Core Libraries\
      \ -->\n                     <div class=\"component\" style=\"animation-delay:\
      \ 1.95s;\">\n                         Core Java/Kotlin Libraries\n         \
      \                <span class=\"component-desc\">Classes base (java.lang, kotlin.*,\
      \ Collections, I/O, etc.)</span>\n                          <span class=\"tooltiptext\"\
      >Fornece a funcionalidade das bibliotecas padrão Java/Kotlin.</span>\n     \
      \                </div>\n                     <div class=\"component\" style=\"\
      animation-delay: 2.0s;\">\n                         Dalvik Executable (DEX)\n\
      \                         <span class=\"component-desc\">Formato de bytecode</span>\n\
      \                         <span class=\"tooltiptext\">Formato compacto de bytecode\
      \ otimizado para dispositivos móveis.</span>\n                      </div>\n\
      \                </div>\n            </div>\n         </div>\n\n\n        <!--\
      \ Camada Hardware Abstraction Layer (HAL) -->\n        <!-- Define interfaces\
      \ padrão que expõem as capacidades do hardware do dispositivo para o Framework\
      \ API. -->\n        <div class=\"layer layer-hal\">\n            <div class=\"\
      layer-title\">Hardware Abstraction Layer (HAL)</div>\n            <div class=\"\
      components-grid\" style=\"grid-template-columns: repeat(auto-fit, minmax(120px,\
      \ 1fr));\">\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.05s;\">\n                    Audio HAL\n                    <span class=\"\
      component-desc\">Interface p/ áudio</span>\n                    <span class=\"\
      tooltiptext\">Interface padrão para hardware de áudio.</span>\n            \
      \    </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.1s;\">\n                    Camera HAL\n                    <span class=\"\
      component-desc\">Interface p/ câmera</span>\n                     <span class=\"\
      tooltiptext\">Interface padrão para hardware de câmera.</span>\n           \
      \      </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.15s;\">\n                    Sensors HAL\n                    <span class=\"\
      component-desc\">Interface p/ sensores</span>\n                    <span class=\"\
      tooltiptext\">Interface padrão para sensores (acel., giro., etc.).</span>\n\
      \                </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.2s;\">\n                    Bluetooth HAL\n                    <span class=\"\
      component-desc\">Interface p/ BT</span>\n                     <span class=\"\
      tooltiptext\">Interface padrão para hardware Bluetooth.</span>\n           \
      \      </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.25s;\">\n                    GPS/Location HAL\n                    <span\
      \ class=\"component-desc\">Interface p/ localização</span>\n               \
      \     <span class=\"tooltiptext\">Interface padrão para hardware de GPS/GNSS.</span>\n\
      \                </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.3s;\">\n                    WiFi HAL\n                    <span class=\"\
      component-desc\">Interface p/ Wi-Fi</span>\n                     <span class=\"\
      tooltiptext\">Interface padrão para hardware Wi-Fi.</span>\n               \
      \  </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.35s;\">\n                    Graphics HAL (Gralloc/Composer)\n         \
      \           <span class=\"component-desc\">Alocação/Composição Gráfica</span>\n\
      \                    <span class=\"tooltiptext\">Interfaces para alocação de\
      \ buffers gráficos (Gralloc) e composição de hardware (HW Composer).</span>\n\
      \                 </div>\n                <div class=\"component\" style=\"\
      animation-delay: 2.4s;\">\n                    RIL HAL (Telephony)\n       \
      \             <span class=\"component-desc\">Interface p/ Rádio</span>\n   \
      \                  <span class=\"tooltiptext\">Radio Interface Layer: Comunica\
      \ com o modem/baseband.</span>\n                 </div>\n                 <div\
      \ class=\"component\" style=\"animation-delay: 2.45s;\">\n                 \
      \    NFC HAL\n                     <span class=\"component-desc\">Interface\
      \ p/ NFC</span>\n                     <span class=\"tooltiptext\">Interface\
      \ padrão para hardware NFC.</span>\n                 </div>\n              \
      \   <div class=\"component\" style=\"animation-delay: 2.5s;\">\n           \
      \          Biometrics HAL\n                     <span class=\"component-desc\"\
      >Impressão digital, etc.</span>\n                     <span class=\"tooltiptext\"\
      >Interface padrão para hardware biométrico.</span>\n                 </div>\n\
      \                 <div class=\"component placeholder\" style=\"animation-delay:\
      \ 2.55s;\">\n                     ...\n                     <span class=\"component-desc\"\
      >Outros HALs</span>\n                     <span class=\"tooltiptext\">USB HAL,\
      \ Power HAL, DRM HAL, etc.</span>\n                 </div>\n            </div>\n\
      \        </div>\n\n        <!-- Camada Linux Kernel -->\n        <!-- O coração\
      \ do sistema, baseado no Kernel Linux. Gerencia processos, memória, dispositivos,\
      \ rede, etc. -->\n        <div class=\"layer layer-kernel\">\n            <div\
      \ class=\"layer-title\">Linux Kernel Layer</div>\n             <h3 class=\"\
      sub-layer-title\">Hardware Device Drivers</h3>\n            <div class=\"components-grid\"\
      \ style=\"grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));\"> <!--\
      \ Grid mais denso -->\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.6s;\">\n                    Display Driver\n                    <span class=\"\
      component-desc\">GPU/Tela</span>\n                     <span class=\"tooltiptext\"\
      >Controla o hardware de vídeo.</span>\n                </div>\n            \
      \    <div class=\"component\" style=\"animation-delay: 2.65s;\">\n         \
      \           Camera Driver\n                    <span class=\"component-desc\"\
      >Sensor Câmera</span>\n                     <span class=\"tooltiptext\">Controla\
      \ o sensor da câmera.</span>\n                </div>\n                <div class=\"\
      component\" style=\"animation-delay: 2.7s;\">\n                    Bluetooth\
      \ Driver\n                    <span class=\"component-desc\">Chip BT</span>\n\
      \                     <span class=\"tooltiptext\">Controla o chip Bluetooth.</span>\n\
      \                </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.75s;\">\n                    WiFi Driver\n                    <span class=\"\
      component-desc\">Chip Wi-Fi</span>\n                    <span class=\"tooltiptext\"\
      >Controla o chip Wi-Fi.</span>\n                </div>\n                <div\
      \ class=\"component\" style=\"animation-delay: 2.8s;\">\n                  \
      \  Audio Driver\n                    <span class=\"component-desc\">Codec/DSP\
      \ Áudio</span>\n                     <span class=\"tooltiptext\">Controla o\
      \ hardware de áudio.</span>\n                </div>\n                <div class=\"\
      component\" style=\"animation-delay: 2.85s;\">\n                    USB Driver\n\
      \                    <span class=\"component-desc\">Porta USB</span>\n     \
      \                <span class=\"tooltiptext\">Controla a porta USB.</span>\n\
      \                 </div>\n                <div class=\"component\" style=\"\
      animation-delay: 2.9s;\">\n                    Keypad/Touch Driver\n       \
      \             <span class=\"component-desc\">Entrada Tela</span>\n         \
      \            <span class=\"tooltiptext\">Controla a tela de toque e botões.</span>\n\
      \                </div>\n                <div class=\"component\" style=\"animation-delay:\
      \ 2.95s;\">\n                    Sensor Drivers\n                    <span class=\"\
      component-desc\">Físicos</span>\n                    <span class=\"tooltiptext\"\
      >Controla os sensores físicos.</span>\n                </div>\n            \
      \    <div class=\"component\" style=\"animation-delay: 3.0s;\">\n          \
      \          Memory Mgmt Driver\n                    <span class=\"component-desc\"\
      >Flash/RAM</span>\n                    <span class=\"tooltiptext\">Controla\
      \ a memória flash e RAM.</span>\n                </div>\n                 <div\
      \ class=\"component placeholder\" style=\"animation-delay: 3.05s;\">\n     \
      \                ...\n                     <span class=\"component-desc\">Outros\
      \ drivers</span>\n                     <span class=\"tooltiptext\">Drivers para\
      \ GPS, NFC, Bateria, etc.</span>\n                 </div>\n            </div>\n\
      \             <h3 class=\"sub-layer-title\">Core Kernel Services</h3>\n    \
      \         <div class=\"components-grid\" style=\"grid-template-columns: repeat(auto-fit,\
      \ minmax(140px, 1fr));\">\n                 <!-- Binder e Power Management como\
      \ itens especiais -->\n                 <div class=\"component kernel-driver-special\"\
      \ style=\"animation-delay: 3.1s;\">\n                     Binder (IPC) Driver\n\
      \                     <span class=\"component-desc\">Comunicação Inter-Processos\
      \ fundamental no Android</span>\n                     <span class=\"tooltiptext\"\
      >Mecanismo principal de IPC (Inter-Process Communication) do Android.</span>\n\
      \                 </div>\n                 <div class=\"component kernel-driver-special\"\
      \ style=\"animation-delay: 3.15s;\">\n                     Power Management\
      \ (PM)\n                     <span class=\"component-desc\">Gerenciamento de\
      \ energia, CPU frequency scaling, suspend</span>\n                      <span\
      \ class=\"tooltiptext\">Gerencia o consumo de energia (wakelocks, suspend-to-RAM).</span>\n\
      \                  </div>\n                 <div class=\"component\" style=\"\
      animation-delay: 3.2s;\">\n                     Process Management\n       \
      \              <span class=\"component-desc\">Criação/gerência de processos</span>\n\
      \                     <span class=\"tooltiptext\">Gerencia a execução e o ciclo\
      \ de vida dos processos.</span>\n                 </div>\n                 <div\
      \ class=\"component\" style=\"animation-delay: 3.25s;\">\n                 \
      \    Memory Management\n                     <span class=\"component-desc\"\
      >Alocação/liberação de memória (OOM Killer)</span>\n                     <span\
      \ class=\"tooltiptext\">Gerencia a memória RAM, incluindo o Low Memory Killer.</span>\n\
      \                  </div>\n                 <div class=\"component\" style=\"\
      animation-delay: 3.3s;\">\n                     Security (SELinux)\n       \
      \              <span class=\"component-desc\">Controle de acesso mandatório</span>\n\
      \                     <span class=\"tooltiptext\">Impõe políticas de segurança\
      \ (Mandatory Access Control).</span>\n                 </div>\n            \
      \     <div class=\"component\" style=\"animation-delay: 3.35s;\">\n        \
      \             Networking Stack\n                     <span class=\"component-desc\"\
      >TCP/IP, Sockets</span>\n                     <span class=\"tooltiptext\">Pilha\
      \ de protocolos de rede padrão do Linux.</span>\n                 </div>\n \
      \            </div>\n        </div>\n\n    </div>\n\n    <!-- Script JS opcional\
      \ (Mantido do seu exemplo) -->\n    <script>\n        // Pequeno script para\
      \ adicionar delays de animação dinamicamente se não definidos inline\n     \
      \   // e potencialmente inicializar tooltips JS mais complexos se a IA os gerar.\n\
      \        document.addEventListener('DOMContentLoaded', () => {\n           \
      \ const components = document.querySelectorAll('.component');\n            components.forEach((comp,\
      \ index) => {\n                // Aplica delay de animação CSS se não estiver\
      \ definido inline\n                if (!comp.style.animationDelay) {\n     \
      \               comp.style.animationDelay = `${index * 0.05 + 0.1}s`; // Adiciona\
      \ um pequeno delay base\n                }\n            });\n             //\
      \ console.log(\"Diagrama Carregado e Animações Aplicadas.\");\n        });\n\
      \    </script>\n\n</body>\n</html>\n\"\"\"\n\n# --- Função Principal de Geração\
      \ ---\n\ndef gerar_relatorio_ia(\n    project_data: Dict[str, Any],\n    project_name:\
      \ str\n) -> None:\n    \"\"\"\n    Gera relatórios: Markdown (descrição do projeto)\
      \ e HTML (diagrama de arquitetura do projeto).\n    O HTML é gerado pela IA\
      \ baseando-se nos dados do projeto e usando um template como guia de estilo.\n\
      \    \"\"\"\n    try:\n        model = genai.GenerativeModel(\n            model_name=NOME_MODELO,\n\
      \            generation_config=configurar_geracao(),\n            # Safety settings\
      \ podem ser ajustados aqui se necessário\n            # Exemplo: Bloquear conteúdo\
      \ mais sensível\n            # safety_settings={\n            #     'HATE':\
      \ 'BLOCK_MEDIUM_AND_ABOVE',\n            #     'HARASSMENT': 'BLOCK_MEDIUM_AND_ABOVE',\n\
      \            #     'SEXUAL' : 'BLOCK_MEDIUM_AND_ABOVE',\n            #     'DANGEROUS'\
      \ : 'BLOCK_MEDIUM_AND_ABOVE'\n            # }\n        )\n        sessao_chat\
      \ = model.start_chat(history=[])\n        print(f\"{Fore.CYAN}\U0001F916 Iniciando\
      \ sessão de chat com {NOME_MODELO}...\")\n    except Exception as e:\n     \
      \   print(f\"{Fore.RED}❗Erro fatal ao iniciar sessão de chat com a IA: {e}\"\
      )\n        print(f\"{Fore.RED}   Verifique o nome do modelo ('{NOME_MODELO}')\
      \ e as configurações.\")\n        return\n\n    generation_info = {\n      \
      \  \"os_system\": platform.system(),\n        \"os_release\": platform.release(),\n\
      \        \"hostname\": platform.node(),\n        \"generation_timestamp\": datetime.now().isoformat(),\n\
      \        \"python_version\": platform.python_version(),\n        \"ai_model\"\
      : NOME_MODELO,\n    }\n\n    # Constrói o prompt final com instruções revisadas\n\
      \    prompt = f\"\"\"\n    \n    sempre escolha o tema de cores, ou clara, ou\
      \ escura, sempre escolha usa, se inspire no template, mas crie algo 100 vezes\
      \ melhor\n    \n    o nivel de detalhe é 9999999 \n    \n    o nivel de design\
      \ é 999999999\n    \n    \n    o css js e tudo estilo tailwind mais de 200 componentes\
      \ tudo ao estado da arte\n    \n    mantenha consistencia de cores\n    \n \
      \   capture ao fundo toda as camadas o mais detalhe da mais rasa a mais profunda\n\
      \    \n    capture as camadas da arquitetura de software, nada é raso, tudo\
      \ é profundo e literal, os baloes de infroamcao sao lognos e completos, fala\
      \ o que é o que faz como faz como foi feito a escolha daquele componente, logica,\
      \ etc, \n    \n    use todos meus promtps cmo base e me surpreenda\n    \n \
      \   voce é o maior arquiteto de software do mundo - entenda a fundo o projeto,\
      \ entenda o mais detalhado o projeto, os arquivos, o codigo fonte, funcao, o\
      \ que faz, como faz, modulos, tudo que existe no projeto\n    \n    crie na\
      \ sua memoria uma enorome matriz de dados do projeto 6666 x6666 x6666 blocos\
      \ de dados unicos e chunks do projeto, codigo fonte, estrutura, funcoes, logica,\
      \ etc, ate mesmo a nivel de evolucao, sempre entenda o todo mas tambem o que\
      \ a de amis novo cofnorme nome e versoes, \n    \n    sempre entende o padrao\
      \ dos nomes pra entender o que era poc, mvp e atualizacoes e variacoes\n   \
      \ \n    nos blocos de detalhes, sempre use muito icones, emojis, melhore muito\
      \ use muito grid, 3d, blur, fade, box, flexbo,x grid, tailwind, repsonsividade,\
      \ gradiente, glass, 3d, fade blur\n    \n    \n    crie o html altamente longo,\
      \ completo, com inumeras sessoes, com blocos, com inumeros elementos por blocos,\
      \ cubra a fundo o projeto, entenda a fundo o projeto, crie sem footer e header\n\
      \    \n    --\n    \n    detalhe muito a fundo a arquitetura, crie inspierado,\
      \ mas adapte tudo que precisar\n    \n    nunca invente\n    nunca crie abreviado\n\
      \    \n    nunca deixe coisas faltando ou como .... etc tudo é declarado e ja\
      \ esta presente\n    \n    \n    **Sua Identidade:** Você é a Replika AI DocGen,\
      \ um especialista sênior em arquitetura de software e documentação técnica,\
      \ criado por Elias Andrade. Sua missão é analisar dados de projetos e gerar\
      \ documentação clara e visualizações de arquitetura impressionantes.\n\n   \
      \ **Tarefa Dupla:** Analise os dados estruturados de um projeto (fornecido em\
      \ YAML abaixo) e gere DOIS artefatos distintos:\n\n    **1. Documentação Técnica\
      \ em Markdown (`DOCUMENTACAO-PROJETO.md`):**\n        *   **Objetivo:** Criar\
      \ uum html snipept detalhado sobre o projeto '{project_name}', baseado EXCLUSIVAMENTE\
      \ nos dados YAML fornecidos.\n        *   **Conteúdo Essencial:**\n        \
      \    *   **Visão Geral:** Propósito principal do projeto, o problema que resolve.\n\
      \            *   **Funcionalidades Chave:** Liste as principais capacidades\
      \ identificadas.\n            *   **Tecnologias e Dependências:** Mencione linguagens,\
      \ bibliotecas, frameworks, bancos de dados identificados (resuma os imports/análises).\n\
      \            *   **Estrutura do Projeto:** Descreva brevemente a organização\
      \ dos diretórios e arquivos importantes (use os caminhos relativos).\n     \
      \       *   **Pontos de Atenção:** Se a análise (YAML) indicou erros (syntax\
      \ errors, DB errors, etc.), mencione-os.\n            *   **(Opcional) Como\
      \ Executar:** Se possível inferir dos arquivos (ex: main.py, package.json),\
      \ sugira comandos básicos.\n            *   **Estado Inferido:** (Ex: Protótipo,\
      \ Em desenvolvimento, Maduro) com base na complexidade e completude aparente.\n\
      \        *   **Estilo e Tom:** Técnico, claro, conciso e direto. Use formatação\
      \ Markdown (cabeçalhos, listas, `inline code`).\n        *   **Restrição CRÍTICA:**\
      \ NÃO inclua blocos de código fonte do projeto no Markdown. Descreva a estrutura\
      \ e o propósito, não copie o código.\n        *   **Autoria:** Inclua uma nota\
      \ no final: \"Documentação gerada por Replika AI DocGen (Elias Andrade) em {generation_info['generation_timestamp']}.\"\
      \n        *   **Emojis:** Use emojis relevantes para ilustrar seções (ex: \U0001F3AF\
      \ Propósito, \U0001F6E0️ Tecnologias, \U0001F4C1 Estrutura, \U0001F680 Execução,\
      \ ⚠️ Atenção).\n\n    **2. Diagrama de Arquitetura em HTML (`doc-web-diagram-data-hashtagh\
      \ unica .html`):**\n        *   **Objetivo:** Gerar um ARQUIVO HTML COMPLETO\
      \ (`<!DOCTYPE html>...</html>`) que visualize a arquitetura do software do projeto\
      \ '{project_name}', baseando-se nos dados do YAML (estrutura de diretórios,\
      \ arquivos Python, DBs, etc.).\n        *   **Conteúdo do Diagrama:** O diagrama\
      \ deve representar as **camadas lógicas ou componentes principais** do *projeto\
      \ analisado*. Use os dados do YAML para identificar:\n            *   Módulos\
      \ Python principais (baseado em arquivos .py com classes/funções significativas).\n\
      \            *   Possíveis camadas (ex: UI, Lógica de Negócios, Acesso a Dados\
      \ - inferir pela estrutura e nomes de arquivos/diretórios).\n            * \
      \  Componentes de dados (bancos SQLite, arquivos JSON/YAML importantes).\n \
      \           *   Dependências chave (imports relevantes).\n            *   Interconexões\
      \ (descreva ou mostre visualmente se possível, como um módulo usa outro ou acessa\
      \ um DB).\n        *   **GUIA DE ESTILO VISUAL (CRÍTICO):** Use o template HTML\
      \ fornecido abaixo **APENAS COMO INSPIRAÇÃO VISUAL**. **NÃO REPLIQUE O CONTEÚDO\
      \ DO ANDROID.** Sua tarefa é criar um diagrama com visual semelhante ao do exemplo\
      \ Android:\n            *   **Tema Escuro:** Use fundos escuros e texto claro,\
      \ seguindo a paleta do exemplo.\n            *   **Layout:** Use divs para representar\
      \ camadas (`.layer`) e componentes (`.component`). Organize-os usando CSS Grid\
      \ ou Flexbox de forma lógica (inspire-se nos layouts `.components-grid`, `.framework-layout`,\
      \ `.native-runtime-layout` do exemplo para organizar os componentes do projeto\
      \ real). Use títulos de camada (`.layer-title`) e sub-títulos (`.sub-layer-title`)\
      \ se apropriado.\n            *   **Estilo Moderno:** Use gradientes sutis nas\
      \ camadas (você pode escolher cores diferentes, mas mantenha o estilo), cantos\
      \ arredondados, sombras (`box-shadow`), efeito de vidro/blur (`backdrop-filter`\
      \ no container principal).\n            *   **Interatividade (Hover + Tooltip):**\
      \ Implemente tooltips ou descrições que aparecem ao passar o mouse sobre os\
      \ componentes (`.component`). Use uma estrutura similar a `<span class=\"tooltiptext\"\
      >...</span>` dentro do `.component` (como no exemplo ATUALIZADO) para mostrar\
      \ detalhes extraídos do YAML (ex: docstrings de funções/classes, colunas de\
      \ tabelas DB, tamanho/linhas de arquivos, previews de conteúdo). Adapte o CSS\
      \ `.component .tooltiptext` e `.component:hover .tooltiptext` do exemplo. Inclua\
      \ também uma breve descrição visível com `<span class=\"component-desc\">...</span>`.\n\
      \            *   **Responsividade:** O layout deve se adaptar a diferentes tamanhos\
      \ de tela (use media queries como no exemplo, ajustando breakpoints e estilos\
      \ conforme necessário para o SEU diagrama).\n            *   **Animações Sutis:**\
      \ Use animações de entrada (`@keyframes fadeInScale`) para tornar a apresentação\
      \ mais agradável, aplicando delays diferentes para cada componente.\n      \
      \      *   **Profundidade e Detalhe:** Esforce-se para criar um diagrama DETALHADO\
      \ e PROFUNDO, cobrindo o máximo possível de aspectos relevantes do projeto identificados\
      \ no YAML. Crie muitos blocos/componentes se a análise permitir. **Não use \"\
      ...\" ou \"outros\"**; represente explicitamente os elementos importantes identificados\
      \ nos dados YAML.\n        *   **Idioma:** Todo o texto visível no HTML (títulos,\
      \ nomes de componentes, descrições, tooltips) deve ser em **Português (pt-br)**.\n\
      \        *   **Formato:** Gere o HTML completo como um bloco de código delimitado\
      \ estritamente por ```html no início e ``` no final.\n        *   **NÃO INCLUA\
      \ UM RODAPÉ (FOOTER) PADRÃO NO HTML.** O script pós-processará e adicionará\
      \ um rodapé se necessário.\n        *   **Scripts JS:** Mantenha o pequeno script\
      \ JS no final do HTML (como no exemplo) para aplicar delays de animação dinamicamente,\
      \ caso não sejam definidos inline.\n\n\ndepois de criar toda a arquitetura de\
      \ softwae, dai crie de funcao, dai otura de bibliotecas, dai outra e pipeline\
      \ dai outra de estrutura de dados \n    **Guia de Estilo Visual HTML (Use para\
      \ INSPIRAÇÃO DE ESTILO E ESTRUTURA, NÃO COPIE o conteúdo Android):**\n    ```html\n\
      \    {HTML_STYLE_GUIDE_TEMPLATE}\n    ```\n\n    **Dados da Análise do Projeto\
      \ '{project_name}' (Base para AMBAS as tarefas):**\n    ```yaml\n    # Dados\
      \ da análise do projeto: {project_name}\n    # Gerado em: {generation_info['generation_timestamp']}\n\
      \    # Ambiente: {generation_info['hostname']} ({generation_info['os_system']}\
      \ {generation_info['os_release']}, Python {generation_info['python_version']})\n\
      \    ---\n    {yaml.dump(project_data, allow_unicode=True, default_flow_style=False,\
      \ sort_keys=False, width=150, indent=2)}\n    ---\n    ```\n\n    **Instrução\
      \ Final:** Gere primeiro o conteúdo Markdown completo para o `DOCUMENTACAO-PROJETO.md`.\
      \ Após o Markdown, gere o bloco de código HTML completo e válido para o `doc-web-diagram-data-hashtagh\
      \ unica .html`, seguindo TODAS as instruções acima, especialmente sobre usar\
      \ os dados do YAML e o guia de estilo visual ATUALIZADO. Delimite o HTML estritamente\
      \ com ```html ... ```.\n    \"\"\"\n\n    resposta_completa = enviar_mensagem(sessao_chat,\
      \ prompt)\n\n    if not resposta_completa:\n        print(f\"{Fore.RED}❗Erro:\
      \ Nenhuma resposta recebida da IA ou resposta vazia/bloqueada após retentativas.\"\
      )\n        return\n\n    print(f\"{Fore.CYAN}\U0001F4DD Processando a resposta\
      \ da IA...\")\n\n    # Extrair o bloco HTML da resposta\n    html_pattern =\
      \ re.compile(r\"```html\\s*(.*?)\\s*```\", re.DOTALL | re.IGNORECASE)\n    html_match\
      \ = html_pattern.search(resposta_completa)\n\n    markdown_content = resposta_completa\
      \ # Assume inicialmente que tudo é Markdown\n    html_content: Optional[str]\
      \ = None\n    html_filename = f\"doc-web-diagram-{__import__('datetime').datetime.now().strftime('%Y%m%d-%H%M%S')}-{__import__('hashlib').sha256(__import__('datetime').datetime.now().isoformat().encode()).hexdigest()[:8]}.html\"\
      \n\n    markdown_filename = \"DOCUMENTACAO-PROJETO.md\"\n\n    if html_match:\n\
      \        html_content = html_match.group(1).strip()\n        # Remove o bloco\
      \ HTML e os delimitadores do conteúdo Markdown\n        markdown_content = html_pattern.sub(\"\
      \", resposta_completa).strip()\n        print(f\"{Fore.GREEN}\U0001F4C4 Bloco\
      \ HTML encontrado e extraído.\")\n\n        # Validação básica do HTML extraído\n\
      \        if not html_content:\n            print(f\"{Fore.YELLOW}⚠️ O bloco\
      \ HTML extraído está vazio.\")\n            html_content = None # Descarta se\
      \ estiver vazio\n        elif not (html_content.lower().startswith(\"<!doctype\"\
      ) or html_content.lower().startswith(\"<html\")):\n             print(f\"{Fore.YELLOW}⚠️\
      \ O HTML extraído não parece ser um documento completo (sem DOCTYPE/html inicial).\
      \ Será salvo assim mesmo.\")\n        elif len(html_content) < 500: # Um diagrama\
      \ útil provavelmente será maior\n             print(f\"{Fore.YELLOW}⚠️ O conteúdo\
      \ HTML parece muito curto ({len(html_content)} caracteres). Pode estar incompleto\
      \ ou a IA não seguiu as instruções de detalhe.\")\n\n    else:\n        print(f\"\
      {Fore.YELLOW}⚠️ Bloco HTML (```html ... ```) não encontrado na resposta da IA.\"\
      )\n        print(f\"{Fore.YELLOW}   Todo o conteúdo recebido será salvo como\
      \ Markdown em {markdown_filename}.\")\n\n    # --- Salvando o arquivo Markdown\
      \ ---\n    try:\n        # Adiciona a nota de autoria ao final se não estiver\
      \ presente\n        autoria_ia = f\"Documentação gerada por Replika AI DocGen\
      \ (Elias Andrade) em {generation_info['generation_timestamp']}\"\n        if\
      \ autoria_ia not in markdown_content:\n            markdown_content += f\"\\\
      n\\n---\\n*{autoria_ia}*\"\n\n        with open(markdown_filename, 'w', encoding='utf-8')\
      \ as md_file:\n            md_file.write(markdown_content)\n        print(f\"\
      {Fore.GREEN}✅ Arquivo Markdown salvo: {markdown_filename}\")\n    except IOError\
      \ as e:\n        print(f\"{Fore.RED}❗Erro de IO ao salvar {markdown_filename}:\
      \ {e}\")\n    except Exception as e:\n        print(f\"{Fore.RED}❗Erro inesperado\
      \ ao salvar {markdown_filename}: {e}\")\n\n    # --- Salvando e Pós-Processando\
      \ o arquivo HTML ---\n    if html_content:\n        try:\n            final_html\
      \ = html_content\n            now_str = datetime.now().strftime('%d/%m/%Y %H:%M:%S')\n\
      \            hostname_str = generation_info['hostname']\n            os_str\
      \ = generation_info['os_system']\n\n            # 1. Atualizar o Título (sobrescreve\
      \ o da IA se existir)\n            title_tag = f\"<title>Diagrama de Arquitetura\
      \ | {project_name} | Replika AI</title>\"\n            # Tenta substituir um\
      \ <title> existente, senão insere no <head>\n            if re.search(r\"<head.*?>\"\
      , final_html, re.IGNORECASE | re.DOTALL):\n                 if re.search(r\"\
      <title>.*?</title>\", final_html, re.IGNORECASE | re.DOTALL):\n            \
      \         final_html = re.sub(r\"<title>.*?</title>\", title_tag, final_html,\
      \ count=1, flags=re.IGNORECASE | re.DOTALL)\n                 else:\n      \
      \               # Insere o title dentro do head se não existir\n           \
      \          final_html = re.sub(r\"(<head.*?>)\", r\"\\1\\n    \" + title_tag,\
      \ final_html, count=1, flags=re.IGNORECASE | re.DOTALL)\n            else:\n\
      \                 # Adiciona head e title se nem head existir (improvável para\
      \ HTML completo)\n                 final_html = final_html.replace(\"<html>\"\
      , f\"<html>\\n<head>\\n    {title_tag}\\n</head>\", 1)\n\n\n            # 2.\
      \ Lógica do Rodapé: Comentar o da IA se existir, senão adicionar o nosso\n \
      \           footer_added_by_script = False\n            # Padrão para detectar\
      \ um rodapé gerado pela IA ou pelo script (flexível)\n            footer_pattern\
      \ = re.compile(\n                r\"<footer.*?>(.*?(?:Gerado por|Diagrama|Projeto\
      \ Associado|Replika AI|{project_name}).*?)</footer>\".format(project_name=re.escape(project_name)),\n\
      \                re.IGNORECASE | re.DOTALL\n            )\n            # Padrão\
      \ para encontrar especificamente o rodapé *comentado* pelo script\n        \
      \    commented_footer_pattern = re.compile(r\"<!--\\s*<footer.*?Gerado por Replika\
      \ AI DocGen.*?</footer>\\s*-->\", re.IGNORECASE | re.DOTALL)\n\n           \
      \ footer_match = footer_pattern.search(final_html)\n\n            # Verifica\
      \ se NÃO é um rodapé já comentado por uma execução anterior deste script\n \
      \           if footer_match and not commented_footer_pattern.search(footer_match.group(0)):\n\
      \                print(f\"{Fore.YELLOW}⚠️ Rodapé detectado na resposta da IA.\
      \ Comentando-o.\")\n                ai_footer_content = footer_match.group(0)\n\
      \                # Comenta o bloco do rodapé encontrado\n                commented_footer\
      \ = f\"\\n<!-- Rodapé original da IA (comentado pelo script):\\n{ai_footer_content}\\\
      n-->\\n\"\n                final_html = final_html.replace(ai_footer_content,\
      \ commented_footer, 1)\n                # Mesmo comentando o da IA, adicionamos\
      \ o nosso para garantir consistência\n                print(f\"{Fore.CYAN}ℹ️\
      \ Adicionando rodapé padrão ao HTML.\")\n                footer_html = f\"\"\
      \"\n        <!-- Footer Adicionado pelo Script -->\n        <footer style=\"\
      text-align: center; margin-top: 30px; font-size: 0.85em; color: rgba(224, 224,\
      \ 224, 0.6); padding-top: 20px; border-top: 1px solid rgba(255, 255, 255, 0.1);\"\
      >\n            Diagrama da Arquitetura | Projeto: {project_name} <br>\n    \
      \        Gerado por Replika AI DocGen em {now_str} | Host: {hostname_str} ({os_str})\n\
      \        </footer>\n\"\"\"\n                # Tenta inserir o footer antes de\
      \ </body>, senão antes de </script> final, senão no fim\n                if\
      \ '</body>' in final_html.lower():\n                    final_html = re.sub(r\"\
      </body>\", f\"{footer_html}\\n</body>\", final_html, count=1, flags=re.IGNORECASE)\n\
      \                    footer_added_by_script = True\n                elif '</script>'\
      \ in final_html.lower():\n                     parts = final_html.rsplit('</script>',\
      \ 1)\n                     if len(parts) == 2:\n                         final_html\
      \ = parts[0] + '</script>' + footer_html + parts[1]\n                      \
      \   footer_added_by_script = True\n                # Se não encontrar body ou\
      \ script, tenta anexar antes de </html>\n                if not footer_added_by_script\
      \ and '</html>' in final_html.lower():\n                     final_html = re.sub(r\"\
      </html>\", f\"{footer_html}\\n</html>\", final_html, count=1, flags=re.IGNORECASE)\n\
      \                     footer_added_by_script = True\n                # Último\
      \ recurso: anexar ao final\n                if not footer_added_by_script:\n\
      \                    final_html += footer_html\n\n            else:\n      \
      \          # Se não encontrou rodapé da IA (ou era um já comentado), adiciona\
      \ o do script\n                print(f\"{Fore.CYAN}ℹ️ Adicionando rodapé padrão\
      \ ao HTML.\")\n                footer_html = f\"\"\"\n        <!-- Footer Adicionado\
      \ pelo Script -->\n        <footer style=\"text-align: center; margin-top: 30px;\
      \ font-size: 0.85em; color: rgba(224, 224, 224, 0.6); padding-top: 20px; border-top:\
      \ 1px solid rgba(255, 255, 255, 0.1);\">\n            Diagrama da Arquitetura\
      \ | Projeto: {project_name} <br>\n            Gerado por Replika AI DocGen em\
      \ {now_str} | Host: {hostname_str} ({os_str})\n        </footer>\n\"\"\"\n \
      \               # Tenta inserir o footer antes de </body>, senão antes de </script>\
      \ final, senão no fim\n                if '</body>' in final_html.lower():\n\
      \                    final_html = re.sub(r\"</body>\", f\"{footer_html}\\n</body>\"\
      , final_html, count=1, flags=re.IGNORECASE)\n                    footer_added_by_script\
      \ = True\n                elif '</script>' in final_html.lower():\n        \
      \             parts = final_html.rsplit('</script>', 1)\n                  \
      \   if len(parts) == 2:\n                         final_html = parts[0] + '</script>'\
      \ + footer_html + parts[1]\n                         footer_added_by_script\
      \ = True\n                # Se não encontrar body ou script, tenta anexar antes\
      \ de </html>\n                if not footer_added_by_script and '</html>' in\
      \ final_html.lower():\n                     final_html = re.sub(r\"</html>\"\
      , f\"{footer_html}\\n</html>\", final_html, count=1, flags=re.IGNORECASE)\n\
      \                     footer_added_by_script = True\n                # Último\
      \ recurso: anexar ao final\n                if not footer_added_by_script:\n\
      \                    final_html += footer_html\n\n            # 3. Salvar o\
      \ HTML final\n            with open(html_filename, 'w', encoding='utf-8') as\
      \ html_file:\n                html_file.write(final_html)\n            print(f\"\
      {Fore.GREEN}✅ Arquivo HTML (Diagrama do Projeto) salvo: {html_filename}\")\n\
      \n        except IOError as e:\n            print(f\"{Fore.RED}❗Erro de IO ao\
      \ pós-processar ou salvar {html_filename}: {e}\")\n        except Exception\
      \ as e:\n            print(f\"{Fore.RED}❗Erro inesperado ao pós-processar ou\
      \ salvar {html_filename}: {e}\")\n            import traceback\n           \
      \ traceback.print_exc() # Imprime stack trace para depuração\n\n# --- Função\
      \ Principal ---\ndef main():\n    \"\"\"Função principal que orquestra a varredura\
      \ e geração dos relatórios.\"\"\"\n    start_time = time.time()\n    project_path\
      \ = \".\" # Diretório atual como padrão\n    try:\n        # Tenta obter um\
      \ nome mais significativo para o projeto a partir do caminho absoluto\n    \
      \    abs_path = os.path.abspath(project_path)\n        project_name = os.path.basename(abs_path)\n\
      \        if not project_name or project_name == '.': # Caso rode de C:\\ ou\
      \ /\n             project_name = \"Projeto Raiz Desconhecido\"\n    except Exception:\n\
      \        project_name = \"Projeto Desconhecido\"\n\n    print(f\"\\n{Fore.YELLOW}{'='*70}\"\
      )\n    print(f\"\U0001F680 {Style.BRIGHT}Iniciando Replika AI DocGen - Geração\
      \ de Documentação e Diagrama{Style.NORMAL}\")\n    print(f\"   Projeto Alvo:\
      \ {Fore.CYAN}{project_name}{Style.RESET_ALL}\")\n    print(f\"   Diretório:\
      \    {Fore.CYAN}{abs_path}{Style.RESET_ALL}\")\n    print(f\"{'='*70}{Style.RESET_ALL}\\\
      n\")\n\n    project_data = scan_directory(project_path)\n\n    # Mesmo que a\
      \ análise não encontre arquivos, prossegue para a IA (ela pode lidar com dados\
      \ vazios)\n    if not project_data:\n        print(f\"{Fore.YELLOW}⚠️ Análise\
      \ do diretório não encontrou arquivos relevantes ou retornou vazia.\")\n   \
      \     # Cria uma entrada mínima para enviar à IA, indicando que nada foi encontrado\n\
      \        project_data = {\n            \"analise_info\": {\n               \
      \ \"status\": \"Diretório vazio ou sem arquivos analisáveis.\",\n          \
      \      \"timestamp\": datetime.now().isoformat(),\n                \"diretorio_raiz\"\
      : abs_path,\n                \"arquivos_processados\": 0,\n             }\n\
      \        }\n\n    # Salva o YAML de estrutura (mesmo que vazio/mínimo, pode\
      \ ser útil para depuração)\n    yaml_filename = \"estrutura_projeto_analisado.yaml\"\
      \ # Nome fixo para facilitar\n    try:\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n\
      \        hostname = platform.node().replace(' ', '_').lower().replace('.', '_')\
      \ # Nome de arquivo mais seguro\n        # Limita o tamanho do nome do projeto\
      \ no arquivo yaml para evitar nomes muito longos\n        safe_project_name\
      \ = \"\".join(c if c.isalnum() else \"_\" for c in project_name)[:30]\n    \
      \    # Mantém nome fixo, mas poderia ser dinâmico:\n        # yaml_filename\
      \ = f\"estrutura_{safe_project_name}_{hostname}_{timestamp}.yaml\"\n\n     \
      \   with open(yaml_filename, 'w', encoding='utf-8') as yaml_file:\n        \
      \    yaml.dump(project_data, yaml_file, allow_unicode=True, default_flow_style=False,\
      \ sort_keys=False, width=150, indent=2)\n        print(f\"{Fore.GREEN}\U0001F4BE\
      \ Dados da estrutura do projeto (para análise da IA) salvos em: {yaml_filename}\"\
      )\n    except IOError as e:\n         print(f\"{Fore.RED}❗Erro de IO ao salvar\
      \ YAML de estrutura: {e}\")\n    except Exception as e:\n         print(f\"\
      {Fore.RED}❗Erro inesperado ao salvar YAML de estrutura: {e}\")\n\n    # Envia\
      \ os dados (ou a mensagem de erro/vazio) para a IA gerar os relatórios\n   \
      \ gerar_relatorio_ia(project_data, project_name)\n\n    end_time = time.time()\n\
      \    print(f\"\\n{Fore.YELLOW}{'='*70}\")\n    print(f\"⏱️ {Style.BRIGHT}Processo\
      \ concluído em {end_time - start_time:.2f} segundos.{Style.NORMAL}\")\n    print(f\"\
      \   Verifique os arquivos gerados:\")\n    print(f\"   - Documentação: {Fore.CYAN}DOCUMENTACAO-PROJETO.md{Style.RESET_ALL}\"\
      )\n    print(f\"   - Diagrama HTML: {Fore.CYAN}doc-web-diagram-data-hashtagh\
      \ unica .html{Style.RESET_ALL}\")\n    print(f\"   - Dados YAML:    {Fore.CYAN}{yaml_filename}{Style.RESET_ALL}\"\
      )\n    print(f\"{'='*70}{Style.RESET_ALL}\\n\")\n\n\n# --- Execução ---\nif\
      \ __name__ == \"__main__\":\n    try:\n        main()\n    except KeyboardInterrupt:\n\
      \        print(f\"\\n{Fore.YELLOW}❗ Processo interrompido pelo usuário (Ctrl+C).{Style.RESET_ALL}\"\
      )\n    except Exception as e:\n        print(f\"\\n{Fore.RED}{Style.BRIGHT}\U0001F4A5\
      \ Erro crítico inesperado na execução principal: {e}{Style.RESET_ALL}\")\n \
      \       import traceback\n        print(f\"{Fore.RED}--- Stack Trace ---\")\n\
      \        traceback.print_exc()\n        print(f\"{Fore.RED}-------------------{Style.RESET_ALL}\"\
      )"
    tamanho: 0.09 MB
  documenta-apis.md:
    caminho_completo: .\documenta-apis.md
    numero_de_linhas: 287
    tamanho: 0.02 MB
  documenta-projeto-seletivo-v1-gemini2.py:
    caminho_completo: .\documenta-projeto-seletivo-v1-gemini2.py
    classes: []
    functions:
    - docstring: Retorna o diretório onde o script está sendo executado.
      end_lineno: 94
      lineno: 91
      name: get_script_directory
    - docstring: Cria a pasta de saída na base_dir se ela não existir.
      end_lineno: 104
      lineno: 96
      name: create_output_directory
    - docstring: Lista todos os arquivos .py em um diretório e subdiretórios, retornando
        caminhos relativos.
      end_lineno: 125
      lineno: 106
      name: get_python_files_from_dir
    - docstring: Permite ao usuário selecionar arquivos de uma lista usando inquirer.
        Retorna caminhos completos.
      end_lineno: 156
      lineno: 127
      name: select_files_interactive
    - docstring: Lê o conteúdo de um arquivo de texto (raw).
      end_lineno: 188
      lineno: 159
      name: read_file_content
    - docstring: Pede ao usuário um prompt adicional opcional.
      end_lineno: 194
      lineno: 190
      name: ask_for_user_prompt
    - docstring: Envia o código (como texto bruto) e os prompts para a IA e retorna
        a documentação.
      end_lineno: 304
      lineno: 196
      name: generate_documentation
    - docstring: Salva o conteúdo da documentação em um arquivo Markdown (.md).
      end_lineno: 348
      lineno: 307
      name: save_documentation
    - docstring: Pergunta ao usuário se deseja executar o processo novamente.
      end_lineno: 376
      lineno: 350
      name: ask_to_repeat
    - docstring: Controla o fluxo principal de documentação.
      end_lineno: 488
      lineno: 380
      name: main_documentation_loop
    imports:
    - asname: null
      name: os
    - asname: null
      name: platform
    - asname: null
      name: datetime
    - asname: genai
      name: google.generativeai
    - module: colorama
      names:
      - init
      - Fore
      - Style
    - asname: null
      name: inquirer
    - module: typing
      names:
      - List
      - Dict
      - Any
    - asname: null
      name: time
    - asname: null
      name: traceback
    numero_de_linhas: 503
    source_code: "# -*- coding: utf-8 -*-\nimport os\nimport platform\nimport datetime\n\
      import google.generativeai as genai\nfrom colorama import init, Fore, Style\n\
      import inquirer\nfrom typing import List, Dict, Any\nimport time\n\n# Inicializa\
      \ o Colorama (sempre reinicia a cor após cada print)\ninit(autoreset=True)\n\
      \n# --- Configurações ---\n# !!! ATENÇÃO MUITO IMPORTANTE !!!\n# ==========================================================================\n\
      # NUNCA coloque sua API Key diretamente no código em produção ou compartilhado.\n\
      # Use variáveis de ambiente (recomendado) ou um sistema seguro de gerenciamento\n\
      # de segredos. Expor sua chave pode levar ao uso indevido e custos inesperados.\n\
      # Este código é um EXEMPLO, substitua pela sua chave APENAS para teste local\n\
      # e ISOLADO, ciente dos riscos.\n# Exemplo usando variável de ambiente (preferível):\n\
      # API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n# if not API_KEY:\n#    print(Fore.RED\
      \ + Style.BRIGHT + \"Erro: Variável de ambiente GOOGLE_API_KEY não definida.\"\
      )\n#    exit()\n# ==========================================================================\n\
      API_KEY = 'AIzaSyC7dAwSyLKaVO2E-PA6UaacLZ4aLGtrXbY'  # <--- SUBSTITUA AQUI COM\
      \ MUITO CUIDADO!!!\n\n# Configuração da API do Google Generative AI\ntry:\n\
      \    genai.configure(api_key=API_KEY)\n    # Verifique modelos disponíveis se\
      \ necessário:\n    # for m in genai.list_models():\n    #   if 'generateContent'\
      \ in m.supported_generation_methods:\n    #     print(m.name)\n    NOME_MODELO\
      \ = \"gemini-1.5-flash\" # Modelo mais recente e geralmente capaz\n\n    # Configurações\
      \ de geração (ajuste conforme necessário)\n    generation_config = {\n     \
      \   \"temperature\": 0.7,\n        \"top_p\": 0.95,\n        \"top_k\": 64,\n\
      \        \"max_output_tokens\": 8192,\n        # CORREÇÃO: A API espera 'text/plain'\
      \ para respostas de texto genéricas.\n        # A *instrução* dentro do prompt\
      \ pedirá formatação Markdown.\n        \"response_mime_type\": \"text/plain\"\
      ,\n    }\n    model = genai.GenerativeModel(\n        model_name=NOME_MODELO,\n\
      \        generation_config=generation_config,\n        # safety_settings = Ajuste\
      \ as configurações de segurança se necessário\n        # Exemplo:\n        #\
      \ safety_settings=[\n        #    {\"category\": \"HARM_CATEGORY_HARASSMENT\"\
      , \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n        #    {\"category\": \"\
      HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n \
      \       #    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\"\
      : \"BLOCK_MEDIUM_AND_ABOVE\"},\n        #    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\"\
      , \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n        # ]\n    )\n    print(Fore.GREEN\
      \ + f\"Modelo Generative AI '{NOME_MODELO}' configurado com sucesso.\")\n\n\
      except ValueError as ve:\n    if \"API_KEY\" in str(ve):\n        print(Fore.RED\
      \ + Style.BRIGHT + \"Erro: API Key inválida ou não configurada corretamente.\"\
      )\n        print(Fore.YELLOW + \"Verifique se a API Key foi substituída corretamente\
      \ no código ou configurada via variável de ambiente.\")\n    else:\n       \
      \ print(Fore.RED + Style.BRIGHT + f\"Erro de valor ao configurar a API: {ve}\"\
      )\n    exit()\nexcept Exception as e:\n    print(Fore.RED + Style.BRIGHT + f\"\
      Erro inesperado ao configurar a API Generative AI: {e}\")\n    exit()\n\n\n\
      # Ícones para UI\nPYTHON_ICON = \"\U0001F40D\"\nFOLDER_ICON = \"\U0001F4C1\"\
      \nDOC_ICON = \"\U0001F4C4\"\nERROR_ICON = \"❌\"\nSUCCESS_ICON = \"✅\"\nQUESTION_ICON\
      \ = \"❓\"\nWAIT_ICON = \"⏳\"\nROCKET_ICON = \"\U0001F680\"\nWARNING_ICON = \"\
      ⚠️\"\n\n# Nome da pasta onde os documentos serão salvos (na raiz do script)\n\
      OUTPUT_FOLDER_NAME = \"documenta-projeto\"\n\n# --- Funções Auxiliares ---\n\
      \ndef get_script_directory() -> str:\n    \"\"\"Retorna o diretório onde o script\
      \ está sendo executado.\"\"\"\n    # Usa __file__ que é o caminho do script\
      \ atual\n    return os.path.dirname(os.path.abspath(__file__))\n\ndef create_output_directory(base_dir:\
      \ str) -> str:\n    \"\"\"Cria a pasta de saída na base_dir se ela não existir.\"\
      \"\"\n    output_path = os.path.join(base_dir, OUTPUT_FOLDER_NAME)\n    try:\n\
      \        os.makedirs(output_path, exist_ok=True)\n        return output_path\n\
      \    except OSError as e:\n        print(Fore.RED + f\"{ERROR_ICON} Erro ao\
      \ criar o diretório de saída '{output_path}': {e}\")\n        return \"\" #\
      \ Retorna vazio em caso de erro\n\ndef get_python_files_from_dir(directory_path:\
      \ str) -> List[str]:\n    \"\"\"Lista todos os arquivos .py em um diretório\
      \ e subdiretórios, retornando caminhos relativos.\"\"\"\n    python_files =\
      \ []\n    if not os.path.isdir(directory_path):\n        print(Fore.YELLOW +\
      \ f\"{WARNING_ICON} Aviso: O caminho '{directory_path}' não é um diretório válido.\"\
      )\n        return []\n    try:\n        # Normaliza o path de entrada para evitar\
      \ problemas com barras\n        start_path = os.path.abspath(directory_path)\n\
      \        for root, _, files in os.walk(start_path):\n            for file in\
      \ files:\n                if file.endswith(\".py\"):\n                    full_path\
      \ = os.path.join(root, file)\n                    # Calcula o caminho relativo\
      \ a partir do diretório fornecido pelo usuário\n                    relative_path\
      \ = os.path.relpath(full_path, start_path)\n                    python_files.append(relative_path)\n\
      \        return sorted(python_files) # Ordena para consistência\n    except\
      \ Exception as e:\n        print(Fore.RED + f\"{ERROR_ICON} Erro ao listar arquivos\
      \ Python em '{directory_path}': {e}\")\n        return []\n\ndef select_files_interactive(file_list:\
      \ List[str], base_path: str) -> List[str]:\n    \"\"\"Permite ao usuário selecionar\
      \ arquivos de uma lista usando inquirer. Retorna caminhos completos.\"\"\"\n\
      \    if not file_list:\n        print(Fore.YELLOW + f\"{WARNING_ICON} Nenhum\
      \ arquivo Python encontrado no diretório para selecionar.\")\n        return\
      \ []\n\n    # Mostra caminhos relativos na interface, mas armazena caminhos\
      \ completos\n    choices = [(f\"{PYTHON_ICON} {relative_f}\", os.path.join(base_path,\
      \ relative_f)) for relative_f in file_list]\n\n    questions = [\n        inquirer.Checkbox('selected_files',\n\
      \                          message=Fore.CYAN + f\"{QUESTION_ICON} Selecione\
      \ os arquivos .py para incluir na documentação (use ESPAÇO para marcar, ENTER\
      \ para confirmar):\",\n                          choices=choices,\n        \
      \                  )\n    ]\n    try:\n        answers = inquirer.prompt(questions,\
      \ theme=inquirer.themes.Default()) # Usar tema padrão\n        if answers and\
      \ 'selected_files' in answers:\n            # Retorna a lista de caminhos *completos*\
      \ dos arquivos selecionados\n            return answers['selected_files']\n\
      \        else:\n            # Caso o usuário cancele (Ctrl+C) ou não selecione\
      \ nada\n             print(Fore.YELLOW + f\"{WARNING_ICON} Nenhum arquivo selecionado.\"\
      )\n             return []\n    except Exception as e:\n        print(Fore.RED\
      \ + f\"{ERROR_ICON} Ocorreu um erro durante a seleção de arquivos: {e}\")\n\
      \        return []\n    except KeyboardInterrupt:\n        print(Fore.YELLOW\
      \ + \"\\nSeleção cancelada pelo usuário.\")\n        return []\n\n\ndef read_file_content(file_path:\
      \ str) -> str:\n    \"\"\"Lê o conteúdo de um arquivo de texto (raw).\"\"\"\n\
      \    try:\n        # Tenta detectar a codificação, mas usa utf-8 como fallback\
      \ robusto\n        encodings_to_try = ['utf-8', 'latin-1', 'cp1252']\n     \
      \   content = None\n        for enc in encodings_to_try:\n            try:\n\
      \                with open(file_path, 'r', encoding=enc) as f:\n           \
      \         content = f.read()\n                break # Sai do loop se a leitura\
      \ for bem-sucedida\n            except UnicodeDecodeError:\n               \
      \ continue # Tenta a próxima codificação\n            except Exception as inner_e:\n\
      \                 # Captura outros erros de leitura aqui para não falhar silenciosamente\n\
      \                 print(Fore.YELLOW + f\"{WARNING_ICON} Erro ao ler {os.path.basename(file_path)}\
      \ com encoding {enc}: {inner_e}\")\n                 continue\n\n        if\
      \ content is None:\n             print(Fore.RED + f\"{ERROR_ICON} Não foi possível\
      \ ler o arquivo {os.path.basename(file_path)} com as codificações testadas.\"\
      )\n             return \"\"\n        return content\n\n    except FileNotFoundError:\n\
      \        print(Fore.RED + f\"{ERROR_ICON} Arquivo não encontrado: {file_path}\"\
      )\n        return \"\"\n    except Exception as e:\n        # Erro genérico\
      \ se algo mais der errado\n        print(Fore.RED + f\"{ERROR_ICON} Erro inesperado\
      \ ao ler o arquivo {file_path}: {e}\")\n        return \"\"\n\ndef ask_for_user_prompt()\
      \ -> str:\n    \"\"\"Pede ao usuário um prompt adicional opcional.\"\"\"\n \
      \   print(Fore.CYAN + f\"\\n{QUESTION_ICON} Deseja adicionar alguma instrução\
      \ específica para a IA sobre como gerar a documentação?\")\n    user_input =\
      \ input(Fore.CYAN + Style.DIM + \" (Ex: Foque na API pública, explique a lógica\
      \ de negócios, ignore testes. Deixe em branco para usar o prompt padrão): \"\
      \ + Style.RESET_ALL)\n    return user_input.strip()\n\ndef generate_documentation(code_snippets:\
      \ Dict[str, str], user_prompt: str) -> str:\n    \"\"\"Envia o código (como\
      \ texto bruto) e os prompts para a IA e retorna a documentação.\"\"\"\n    if\
      \ not code_snippets:\n        print(Fore.YELLOW + f\"{WARNING_ICON} Nenhum conteúdo\
      \ de código para enviar à IA.\")\n        # Ainda pode gerar documentação se\
      \ houver um prompt do usuário\n        if not user_prompt:\n             return\
      \ \"Nenhum código ou instrução fornecida para documentação.\"\n\n    # Constrói\
      \ o contexto com os trechos de código (texto bruto)\n    # Usa o caminho relativo\
      \ como identificador para a IA\n    code_context = \"\\n\\n\".join(\n      \
      \  f\"--- INÍCIO ARQUIVO: {relative_path} ---\\n\"\n        f\"```python\\n\"\
      \n        f\"{content}\\n\" # Conteúdo bruto do arquivo .py\n        f\"```\\\
      n\"\n        f\"--- FIM ARQUIVO: {relative_path} ---\"\n        for relative_path,\
      \ content in code_snippets.items()\n    ) if code_snippets else \"Nenhum código\
      \ foi fornecido.\" # Mensagem se não houver snippets\n\n    # Prompt base para\
      \ guiar a IA\n    # Instruindo explicitamente para usar formato Markdown na\
      \ *resposta*\n    base_prompt = f\"\"\"\n    **Tarefa:** Gerar documentação\
      \ técnica abrangente em formato Markdown para um projeto Python, com base nos\
      \ arquivos de código fornecidos (como texto bruto) e nas instruções do usuário.\n\
      \n\n        responda longo, altamente detalhado, em mais de 1200 linhas, use\
      \ icones, emojis, altamente completo, técnico, em nivel de engenharia de software\
      \ e arquitetura de softeware, \n    **Foco Principal:**\n    *   **Visão Geral\
      \ e Propósito:** Descreva o objetivo central do projeto. Que problema ele resolve?\n\
      \    *   **Funcionalidades Chave:** Liste e explique as principais capacidades\
      \ e o que o software faz.\n    *   **Estrutura do Projeto (Inferida):** Com\
      \ base nos arquivos fornecidos, descreva como eles parecem se conectar. Qual\
      \ o fluxo de dados ou controle principal? (Seja cauteloso se poucos arquivos\
      \ foram fornecidos).\n    *   **Componentes Importantes:** Identifique classes,\
      \ funções ou módulos cruciais e explique seu papel.\n    *   **Como Usar/Executar\
      \ (se aplicável/inferível):** Forneça um guia básico sobre como iniciar ou interagir\
      \ com o projeto. Mencione pontos de entrada principais (como blocos `if __name__\
      \ == '__main__':`).\n    *   **Dependências Externas:** Liste as bibliotecas\
      \ externas importantes identificadas nos `import` statements.\n\n    **Instruções\
      \ de Geração:**\n    *   **Foco em Funcionalidade:** Priorize explicar *o que*\
      \ o código faz e *por quê*, em vez de apenas descrever *como* linha por linha.\n\
      \    *   **Clareza e Concisão:** Use linguagem clara e objetiva.\n    *   **Formato\
      \ Markdown:** Organize a documentação usando cabeçalhos (##, ###), listas (marcadores\
      \ ou numeradas), e blocos de código (\\`\\`\\`python ... \\`\\`\\`) para exemplos\
      \ curtos ou referências, *mas evite apenas copiar grandes blocos do código fonte\
      \ fornecido*.\n    *   **Interpretação vs. Repetição:** Vá além de simplesmente\
      \ parafrasear o código; explique o propósito no contexto do projeto.\n    *\
      \   **Evite Especulação Excessiva:** Se a informação não está clara no código,\
      \ mencione isso ou evite fazer suposições infundadas.\n\n    **Instrução Adicional\
      \ do Usuário:**\n    {user_prompt if user_prompt else \"Nenhuma instrução adicional\
      \ fornecida.\"}\n\n    **Código Fonte Fornecido (Texto Bruto):**\n    {code_context}\n\
      \n    **SAÍDA ESPERADA:** Documentação completa e bem estruturada em formato\
      \ **Markdown**.\n    \"\"\"\n\n    print(Fore.MAGENTA + f\"\\n{WAIT_ICON} Enviando\
      \ solicitação para a IA ({NOME_MODELO}). Isso pode levar alguns segundos ou\
      \ minutos dependendo do tamanho do código...\")\n\n    # Adiciona um pequeno\
      \ delay antes de enviar, pode ajudar em algumas situações de rede/API\n    time.sleep(1)\n\
      \n    try:\n        # Inicia um novo chat para cada documentação para evitar\
      \ misturar contextos antigos\n        chat_session = model.start_chat(history=[])\n\
      \        response = chat_session.send_message(base_prompt)\n\n        # Pequena\
      \ pausa após receber a resposta, caso haja processamento assíncrono\n      \
      \  time.sleep(1)\n\n        # Verifica se a resposta contém texto\n        if\
      \ response and hasattr(response, 'text') and response.text:\n            print(Fore.GREEN\
      \ + f\"{SUCCESS_ICON} Resposta recebida da IA!\")\n            return response.text\n\
      \        elif response and hasattr(response, 'parts'): # Modelos mais novos\
      \ podem usar 'parts'\n             full_text = \"\".join(part.text for part\
      \ in response.parts if hasattr(part, 'text'))\n             if full_text:\n\
      \                 print(Fore.GREEN + f\"{SUCCESS_ICON} Resposta (via 'parts')\
      \ recebida da IA!\")\n                 return full_text\n             else:\n\
      \                 print(Fore.YELLOW + f\"{WARNING_ICON} Resposta da IA recebida,\
      \ mas sem conteúdo textual nos 'parts'.\")\n                 # Tenta obter o\
      \ conteúdo bruto da resposta para depuração\n                 try:\n       \
      \              print(Fore.YELLOW + f\"Conteúdo bruto da resposta: {response}\"\
      )\n                 except Exception:\n                      pass # Ignora se\
      \ não conseguir imprimir a resposta bruta\n                 return \"Erro: A\
      \ IA retornou uma resposta sem conteúdo textual.\"\n        else:\n        \
      \    print(Fore.YELLOW + f\"{WARNING_ICON} A IA retornou uma resposta vazia\
      \ ou inesperada.\")\n            # Tenta obter o conteúdo bruto da resposta\
      \ para depuração\n            try:\n                 print(Fore.YELLOW + f\"\
      Conteúdo bruto da resposta: {response}\")\n            except Exception:\n \
      \                pass # Ignora se não conseguir imprimir a resposta bruta\n\
      \            return \"Erro: A IA retornou uma resposta vazia ou em formato inesperado.\"\
      \n\n    except google.api_core.exceptions.InvalidArgument as e:\n        print(Fore.RED\
      \ + Style.BRIGHT + f\"{ERROR_ICON} Erro de Argumento Inválido ao comunicar com\
      \ a API: {e}\")\n        if \"response_mime_type\" in str(e):\n            print(Fore.RED\
      \ + \"   -> Verifique se o 'response_mime_type' ('text/plain') é suportado pelo\
      \ modelo/API.\")\n        return f\"Erro de Argumento Inválido na API: {e}\"\
      \n    except google.generativeai.types.generation_types.BlockedPromptException\
      \ as bpe:\n         print(Fore.RED + Style.BRIGHT + f\"{ERROR_ICON} O prompt\
      \ foi bloqueado pela API devido a políticas de segurança.\")\n         print(Fore.YELLOW\
      \ + \"   -> Revise o código ou o prompt adicional para remover conteúdo potencialmente\
      \ problemático.\")\n         # Pode ser útil imprimir as razões do bloqueio,\
      \ se disponíveis\n         # print(f\"Block reasons: {bpe.block_reason}\") #\
      \ Depende da versão da lib\n         return \"Erro: Prompt bloqueado por razões\
      \ de segurança.\"\n    except Exception as e:\n        print(Fore.RED + Style.BRIGHT\
      \ + f\"{ERROR_ICON} Erro inesperado ao comunicar com a API Generative AI: {e}\"\
      )\n        # Tenta extrair detalhes do erro, se disponíveis (útil para erros\
      \ 4xx, 5xx)\n        if hasattr(e, 'response') and hasattr(e.response, 'text'):\n\
      \             print(Fore.RED + f\"Detalhes da resposta da API (se houver): {e.response.text}\"\
      )\n        return f\"Erro ao gerar documentação: {e}\"\n    except KeyboardInterrupt:\n\
      \        print(Fore.YELLOW + \"\\nGeração de documentação cancelada pelo usuário\
      \ durante a comunicação com a IA.\")\n        return \"Geração cancelada.\"\n\
      \n\ndef save_documentation(content: str, output_dir: str, project_name: str,\
      \ selected_files: List[str]) -> bool:\n    \"\"\"Salva o conteúdo da documentação\
      \ em um arquivo Markdown (.md).\"\"\"\n    if not content or content.startswith(\"\
      Erro:\") or content == \"Geração cancelada.\":\n         print(Fore.YELLOW +\
      \ f\"{WARNING_ICON} Nenhuma documentação válida para salvar.\")\n         return\
      \ False\n\n    try:\n        timestamp = datetime.datetime.now().strftime(\"\
      %Y%m%d_%H%M%S\")\n        # Limpa um pouco o nome do projeto para o nome do\
      \ arquivo\n        safe_project_name = \"\".join(c if c.isalnum() else \"_\"\
      \ for c in project_name)\n        filename = f\"doc_{safe_project_name}_{timestamp}.md\"\
      \ # Garante extensão .md\n        filepath = os.path.join(output_dir, filename)\n\
      \n        print(f\"\\n{WAIT_ICON} Preparando para salvar o arquivo: {filepath}\"\
      )\n\n        with open(filepath, 'w', encoding='utf-8') as f:\n            #\
      \ Cabeçalho do Arquivo Markdown\n            f.write(f\"# {DOC_ICON} Documentação\
      \ do Projeto: {project_name}\\n\\n\")\n            f.write(f\"**Gerado em:**\
      \ {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n          \
      \  f.write(f\"**Plataforma:** {platform.system()} {platform.release()}\\n\"\
      )\n            f.write(f\"**Modelo IA:** {NOME_MODELO}\\n\")\n\n           \
      \ if selected_files:\n                 f.write(f\"**Arquivos Analisados:**\\\
      n\")\n                 # Lista os arquivos relativos que foram usados\n    \
      \             base_dir = os.path.dirname(selected_files[0]) # Pega o dir base\
      \ do primeiro arquivo\n                 for full_path in selected_files:\n \
      \                   relative_p = os.path.relpath(full_path, os.path.dirname(base_dir))\
      \ # Caminho relativo ao pai do dir do projeto\n                    f.write(f\"\
      - `{relative_p}`\\n\")\n            else:\n                 f.write(\"**Arquivos\
      \ Analisados:** Nenhum código fonte foi incluído na análise.\\n\")\n\n     \
      \       f.write(\"\\n---\\n\\n\") # Separador\n\n            # Escreve o conteúdo\
      \ gerado pela IA\n            f.write(content)\n\n        print(Fore.GREEN +\
      \ Style.BRIGHT + f\"{SUCCESS_ICON} Documentação salva com sucesso em: {filepath}\"\
      )\n        return True\n    except Exception as e:\n        print(Fore.RED +\
      \ Style.BRIGHT + f\"{ERROR_ICON} Erro ao salvar o arquivo de documentação '{filepath}':\
      \ {e}\")\n        return False\n\ndef ask_to_repeat() -> bool:\n    \"\"\"Pergunta\
      \ ao usuário se deseja executar o processo novamente.\"\"\"\n    questions =\
      \ [\n        inquirer.Confirm('repeat',\n                         message=Fore.YELLOW\
      \ + f\"\\n{QUESTION_ICON} Deseja documentar outro projeto ou conjunto de arquivos?\"\
      ,\n                         default=False)\n    ]\n    try:\n        answers\
      \ = inquirer.prompt(questions, theme=inquirer.themes.Default())\n        # Retorna\
      \ False se answers for None (acontece com Ctrl+C no prompt)\n        return\
      \ answers['repeat'] if answers else False\n    except KeyboardInterrupt:\n \
      \        print(Fore.YELLOW + \"\\nOperação finalizada pelo usuário.\")\n   \
      \      return False\n    except Exception as e:\n        # Pode acontecer se\
      \ o terminal não suportar inquirer bem\n        print(Fore.RED + f\"{ERROR_ICON}\
      \ Erro ao tentar exibir a confirmação: {e}\")\n        # Fallback para input\
      \ simples\n        try:\n            response = input(Fore.YELLOW + f\"\\n{QUESTION_ICON}\
      \ Deseja documentar outro projeto? (s/N): \").lower()\n            return response\
      \ == 's'\n        except KeyboardInterrupt:\n            print(Fore.YELLOW +\
      \ \"\\nOperação finalizada pelo usuário.\")\n            return False\n    \
      \    except Exception as fallback_e:\n             print(Fore.RED + f\"{ERROR_ICON}\
      \ Erro no input de fallback: {fallback_e}\")\n             return False\n\n\n\
      # --- Função Principal ---\ndef main_documentation_loop():\n    \"\"\"Controla\
      \ o fluxo principal de documentação.\"\"\"\n    print(Fore.BLUE + Style.BRIGHT\
      \ + f\"\\n{ROCKET_ICON} Bem-vindo ao Documentador de Projetos com IA! {ROCKET_ICON}\"\
      )\n    print(Fore.WHITE + Style.DIM + \"Usando modelo: \" + NOME_MODELO)\n\n\
      \    script_dir = get_script_directory()\n    output_dir = create_output_directory(script_dir)\n\
      \n    if not output_dir:\n        print(Fore.RED + Style.BRIGHT + \"Não foi\
      \ possível criar ou acessar o diretório de saída. Encerrando.\")\n        return\n\
      \n    print(Fore.GREEN + f\"Os arquivos de documentação (.md) serão salvos em:\
      \ {output_dir}\")\n\n    while True:\n        # 1. Obter Diretório do Projeto\n\
      \        project_dir_input = input(Fore.CYAN + f\"\\n{FOLDER_ICON} Digite o\
      \ caminho para a pasta do projeto que deseja documentar (ou deixe em branco\
      \ para usar o diretório atual): \").strip()\n\n        if not project_dir_input:\n\
      \            project_dir = script_dir # Usa o diretório do script se nada for\
      \ digitado\n            print(Fore.WHITE + f\"Usando o diretório atual do script:\
      \ '{project_dir}'\")\n        else:\n            project_dir = os.path.abspath(project_dir_input)\
      \ # Garante caminho absoluto\n\n        if not os.path.isdir(project_dir):\n\
      \            print(Fore.RED + f\"{ERROR_ICON} Caminho fornecido não é um diretório\
      \ válido: '{project_dir}'. Tente novamente.\")\n            continue # Pede\
      \ o diretório novamente\n\n        # Tenta pegar um nome significativo para\
      \ o projeto (nome da pasta)\n        project_name = os.path.basename(project_dir)\n\
      \        if not project_name: # Pode acontecer se for a raiz (ex: C:\\)\n  \
      \          project_name = \"projeto_raiz\"\n        print(Fore.WHITE + f\"Analisando\
      \ o projeto: '{project_name}' em '{project_dir}'\")\n\n        # 2. Listar Arquivos\
      \ .py\n        py_files_relative = get_python_files_from_dir(project_dir)\n\n\
      \        # 3. Selecionar Arquivos Interativamente\n        # selected_full_paths\
      \ contém os caminhos *completos* dos arquivos selecionados\n        selected_full_paths\
      \ = select_files_interactive(py_files_relative, project_dir)\n\n        # 4.\
      \ Ler Conteúdo dos Arquivos Selecionados (Texto Bruto)\n        code_snippets\
      \ = {} # Dicionário para guardar {caminho_relativo: conteudo}\n        if selected_full_paths:\n\
      \            print(Fore.WHITE + f\"\\n{WAIT_ICON} Lendo o conteúdo de {len(selected_full_paths)}\
      \ arquivo(s) selecionado(s)...\")\n            files_read_count = 0\n      \
      \      files_error_count = 0\n            for full_file_path in selected_full_paths:\n\
      \                 # Garante que o caminho completo esteja normalizado\n    \
      \             normalized_path = os.path.normpath(full_file_path)\n         \
      \        content = read_file_content(normalized_path)\n                 if content\
      \ is not None: # Verifica se a leitura foi bem sucedida (não None)\n       \
      \              # Calcula o caminho relativo *a partir do diretório do projeto*\
      \ para usar como chave\n                     relative_path_for_key = os.path.relpath(normalized_path,\
      \ project_dir)\n                     code_snippets[relative_path_for_key] =\
      \ content\n                     files_read_count += 1\n                    \
      \ # print(Fore.GREEN + f\"  + Lido: {relative_path_for_key}\") # Opcional: verbosidade\n\
      \                 else:\n                     # read_file_content já imprime\
      \ o erro/aviso\n                     files_error_count += 1\n              \
      \       print(Fore.YELLOW + f\"  - Aviso: Falha ao ler ou conteúdo vazio para\
      \ {os.path.basename(normalized_path)}\")\n\n            if files_read_count\
      \ > 0:\n                print(Fore.GREEN + f\"Leitura concluída: {files_read_count}\
      \ arquivo(s) lido(s).\")\n            if files_error_count > 0:\n          \
      \      print(Fore.YELLOW + f\"{WARNING_ICON} {files_error_count} arquivo(s)\
      \ não puderam ser lidos ou estavam vazios.\")\n        else:\n            print(Fore.YELLOW\
      \ + f\"{WARNING_ICON} Nenhum arquivo Python selecionado para incluir o código\
      \ na análise.\")\n            # Pergunta se ainda quer continuar apenas com\
      \ o prompt\n            continue_without_code_q = [\n                 inquirer.Confirm('continue_no_code',\n\
      \                                  message=Fore.YELLOW + f\"{QUESTION_ICON}\
      \ Nenhum código será enviado à IA. Deseja continuar assim mesmo (apenas com\
      \ instruções adicionais, se houver)?\",\n                                  default=False)\n\
      \            ]\n            try:\n                answers = inquirer.prompt(continue_without_code_q,\
      \ theme=inquirer.themes.Default())\n                if not answers or not answers['continue_no_code']:\n\
      \                     print(Fore.BLUE + \"Ok, processo de documentação cancelado\
      \ para este projeto.\")\n                     if not ask_to_repeat():\n    \
      \                     break # Sai do loop principal (while True)\n         \
      \            else:\n                         continue # Volta para o início\
      \ do loop while (pedir novo projeto)\n            except Exception as ie:\n\
      \                 print(Fore.RED + f\"{ERROR_ICON} Erro no prompt de confirmação:\
      \ {ie}. Cancelando.\")\n                 if not ask_to_repeat():\n         \
      \           break\n                 else:\n                    continue\n  \
      \          except KeyboardInterrupt:\n                 print(Fore.YELLOW + \"\
      \\nOperação cancelada pelo usuário.\")\n                 break # Sai do loop\
      \ principal\n\n        # 5. Obter Prompt Adicional do Usuário\n        user_prompt\
      \ = ask_for_user_prompt()\n\n        # 6. Gerar Documentação com a IA\n    \
      \    # Passa os snippets de código (dict) e o prompt do usuário\n        documentation_content\
      \ = generate_documentation(code_snippets, user_prompt)\n\n        # 7. Salvar\
      \ Documentação (como .md)\n        # Passa também a lista de arquivos que foram\
      \ efetivamente lidos e enviados\n        files_actually_sent_paths = [os.path.join(project_dir,\
      \ rel_path) for rel_path in code_snippets.keys()]\n        save_documentation(documentation_content,\
      \ output_dir, project_name, files_actually_sent_paths)\n\n        # 8. Perguntar\
      \ se deseja repetir\n        if not ask_to_repeat():\n            break # Sai\
      \ do loop principal (while True)\n\n    print(Fore.BLUE + Style.BRIGHT + \"\\\
      nObrigado por usar o Documentador de Projetos! Até logo! \U0001F44B\")\n\n#\
      \ --- Ponto de Entrada ---\nif __name__ == \"__main__\":\n    try:\n       \
      \ main_documentation_loop()\n    except KeyboardInterrupt:\n        # Captura\
      \ Ctrl+C no nível mais alto para uma saída graciosa\n        print(Fore.YELLOW\
      \ + Style.BRIGHT + \"\\n\\nPrograma interrompido pelo usuário (Ctrl+C). Encerrando.\"\
      )\n    except Exception as e:\n        # Captura qualquer outra exceção não\
      \ tratada no loop principal\n        print(Fore.RED + Style.BRIGHT + f\"\\n{ERROR_ICON}\
      \ Ocorreu um erro fatal inesperado no fluxo principal:\")\n        import traceback\n\
      \        traceback.print_exc() # Imprime o traceback completo para depuração\n\
      \    finally:\n        print(Style.RESET_ALL) # Garante que as cores sejam resetadas\
      \ ao sair"
    tamanho: 0.03 MB
  estrutura_projeto_analisado.yaml:
    caminho_completo: .\estrutura_projeto_analisado.yaml
    numero_de_linhas: 17508
    tamanho: 0.70 MB
    yaml_info:
      numero_de_linhas: 17508
      tamanho: 0.70 MB
  estrutura_projeto_projeto message broker replika ai v1_win11pc_20250403_114105.yaml:
    caminho_completo: .\estrutura_projeto_projeto message broker replika ai v1_win11pc_20250403_114105.yaml
    numero_de_linhas: 6850
    tamanho: 0.51 MB
    yaml_info:
      numero_de_linhas: 6850
      tamanho: 0.51 MB
  estrutura_projeto_projeto message broker replika ai v1_win11pc_20250403_114128.yaml:
    caminho_completo: .\estrutura_projeto_projeto message broker replika ai v1_win11pc_20250403_114128.yaml
    numero_de_linhas: 7269
    tamanho: 0.54 MB
    yaml_info:
      numero_de_linhas: 7269
      tamanho: 0.54 MB
  geramensagem-v2-loop.py:
    caminho_completo: .\geramensagem-v2-loop.py
    classes: []
    functions:
    - docstring: Faz login usando a sessão para obter um token.
      end_lineno: 64
      lineno: 34
      name: get_access_token
    - docstring: Verifica/cria a fila usando a sessão.
      end_lineno: 113
      lineno: 66
      name: check_or_create_queue
    - docstring: Função executada por cada thread worker.
      end_lineno: 154
      lineno: 115
      name: message_sender_worker
    - docstring: Thread separada para reportar o status periodicamente.
      end_lineno: 181
      lineno: 158
      name: status_reporter
    imports:
    - asname: null
      name: requests
    - asname: null
      name: json
    - asname: null
      name: warnings
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: datetime
    - asname: null
      name: threading
    - asname: null
      name: queue
    - module: concurrent.futures
      names:
      - ThreadPoolExecutor
    numero_de_linhas: 268
    source_code: "# -*- coding: utf-8 -*-\nimport requests\nimport json\nimport warnings\n\
      import sys\nimport time\nimport datetime\nimport threading\nimport queue # Embora\
      \ não usemos uma Queue do módulo, o conceito é similar\nfrom concurrent.futures\
      \ import ThreadPoolExecutor # Alternativa mais moderna para gerenciar threads\n\
      \n# --- Configurações ---\nBASE_URL = \"https://localhost:8777\"\nQUEUE_NAME\
      \ = \"minha-fila-teste-stress\" # Fila para teste de stress\nMESSAGE_BASE_CONTENT\
      \ = \"Stress Test Msg\"\nUSERNAME = \"admin\"\nPASSWORD = \"admin\"\nNUM_WORKERS\
      \ = 20  # <<< NÚMERO DE THREADS CONCORRENTES >>> Ajuste conforme necessário\n\
      REPORT_INTERVAL = 5 # Segundos entre relatórios de status\n# --- Fim das Configurações\
      \ ---\n\n# Ignorar avisos sobre certificados SSL autoassinados\nwarnings.filterwarnings(\"\
      ignore\", message=\"Unverified HTTPS request\")\n\n# --- Globais e Sincronização\
      \ ---\nmessage_counter = 0\nsuccess_count = 0\nfail_count = 0\ncounter_lock\
      \ = threading.Lock() # Para proteger acesso aos contadores\nstop_event = threading.Event()\
      \ # Para sinalizar parada para as threads\nstart_time = 0.0\n# --- Fim Globais\
      \ ---\n\ndef get_access_token(session, base_url, username, password):\n    \"\
      \"\"Faz login usando a sessão para obter um token.\"\"\"\n    login_url = f\"\
      {base_url}/login\"\n    try:\n        print(f\"\U0001F511 Tentando fazer login\
      \ como '{username}' em {login_url}...\")\n        response = session.post( #\
      \ Usa a sessão\n            login_url,\n            data={\"username\": username,\
      \ \"password\": password},\n            verify=False,\n            timeout=15\
      \ # Timeout um pouco maior para login\n        )\n        response.raise_for_status()\n\
      \        token_data = response.json()\n        print(\"✅ Login bem-sucedido!\"\
      )\n        # Define o header de autorização na sessão para todas as requisições\
      \ futuras\n        access_token = token_data.get(\"access_token\")\n       \
      \ if access_token:\n            session.headers.update({\"Authorization\": f\"\
      Bearer {access_token}\"})\n            return access_token # Retorna o token\
      \ caso seja necessário fora da sessão\n        else:\n             print(\"\
      ❌ Token não encontrado na resposta do login.\")\n             return None\n\
      \    except requests.exceptions.RequestException as e:\n        print(f\"❌ Erro\
      \ de conexão ou HTTP ao tentar fazer login: {e}\")\n        if hasattr(e, 'response')\
      \ and e.response is not None:\n            try: print(f\"   Detalhe da API:\
      \ {e.response.json()}\")\n            except json.JSONDecodeError: print(f\"\
      \   Resposta (não JSON): {e.response.text[:200]}...\")\n        return None\n\
      \    except json.JSONDecodeError:\n        print(f\"❌ Erro ao decodificar a\
      \ resposta JSON do login.\")\n        return None\n\ndef check_or_create_queue(session,\
      \ base_url, queue_name):\n    \"\"\"Verifica/cria a fila usando a sessão.\"\"\
      \"\n    get_queue_url = f\"{base_url}/queues/{queue_name}\"\n    create_queue_url\
      \ = f\"{base_url}/queues\"\n    # Headers já estão na sessão (Authorization)\n\
      \n    try:\n        print(f\"ℹ️  Verificando se a fila '{queue_name}' existe...\"\
      )\n        response_get = session.get(get_queue_url, verify=False, timeout=10)\
      \ # Usa sessão\n\n        if response_get.status_code == 200:\n            print(f\"\
      \U0001F44D Fila '{queue_name}' já existe.\")\n            return True\n\n  \
      \      elif response_get.status_code == 404:\n            print(f\"⚠️  Fila\
      \ '{queue_name}' não encontrada. Tentando criar...\")\n            payload =\
      \ {\"name\": queue_name}\n            # Adiciona Content-Type especificamente\
      \ para esta requisição POST JSON\n            headers_post = {\"Content-Type\"\
      : \"application/json\"}\n            response_post = session.post( # Usa sessão\n\
      \                create_queue_url,\n                headers=headers_post, #\
      \ Adiciona o Content-Type aqui\n                json=payload,\n            \
      \    verify=False,\n                timeout=10\n            )\n\n          \
      \  if response_post.status_code == 201:\n                print(f\"✅ Fila '{queue_name}'\
      \ criada com sucesso!\")\n                time.sleep(0.5)\n                return\
      \ True\n            elif response_post.status_code == 409:\n               \
      \  print(f\"⚠️  A fila '{queue_name}' foi criada por outro processo (Erro 409).\
      \ OK.\")\n                 return True\n            else:\n                response_post.raise_for_status()\
      \ # Levanta erro para outros status\n                return False # Não deve\
      \ chegar aqui\n\n        else:\n            response_get.raise_for_status()\
      \ # Levanta erro para outros status no GET\n            return False # Não deve\
      \ chegar aqui\n\n    except requests.exceptions.RequestException as e:\n   \
      \     print(f\"❌ Erro ao verificar ou criar a fila '{queue_name}': {e}\")\n\
      \        if hasattr(e, 'response') and e.response is not None:\n           \
      \  try: print(f\"   Detalhe da API: {e.response.json()}\")\n             except\
      \ json.JSONDecodeError: print(f\"   Resposta (não JSON): {e.response.text[:200]}...\"\
      )\n        return False\n\ndef message_sender_worker(session, base_url, queue_name,\
      \ worker_id):\n    \"\"\"Função executada por cada thread worker.\"\"\"\n  \
      \  global message_counter, success_count, fail_count\n    publish_url = f\"\
      {base_url}/queues/{queue_name}/messages\"\n    headers_post = {\"Content-Type\"\
      : \"application/json\"} # Content-Type para o POST\n\n    while not stop_event.is_set():\
      \ # Continua enquanto o evento de parada não for setado\n        with counter_lock:\
      \ # Adquire o lock para obter um ID único\n            current_msg_id = message_counter\n\
      \            message_counter += 1\n        # O lock é liberado aqui\n\n    \
      \    full_message = f\"{MESSAGE_BASE_CONTENT} Worker {worker_id} Msg #{current_msg_id}\
      \ ({datetime.datetime.now().isoformat()})\"\n        payload = {\"content\"\
      : full_message}\n\n        try:\n            response = session.post(\n    \
      \            publish_url,\n                headers=headers_post, # Adiciona\
      \ Content-Type (Auth já está na sessão)\n                json=payload,\n   \
      \             verify=False,\n                timeout=5 # Timeout curto para\
      \ não prender a thread por muito tempo\n            )\n            response.raise_for_status()\
      \ # Lança exceção para erros 4xx/5xx\n\n            # Se chegou aqui, foi sucesso\n\
      \            with counter_lock: # Adquire o lock para atualizar contador de\
      \ sucesso\n                success_count += 1\n            # Lock liberado\n\
      \n        except requests.exceptions.Timeout:\n            with counter_lock:\
      \ fail_count += 1\n            # print(f\"T{worker_id}:T\", end=\"\", flush=True)\
      \ # Timeout\n        except requests.exceptions.RequestException as e:\n   \
      \         with counter_lock: fail_count += 1\n            # Opcional: Logar\
      \ o erro, mas pode poluir muito\n            # status = e.response.status_code\
      \ if hasattr(e, 'response') and e.response else 'N/A'\n            # print(f\"\
      T{worker_id}:E{status}\", end=\"\", flush=True) # Erro com status\n        except\
      \ Exception as e: # Captura outras exceções inesperadas\n             with counter_lock:\
      \ fail_count += 1\n             # print(f\"T{worker_id}:X\", end=\"\", flush=True)\
      \ # Erro genérico\n        # REMOVEMOS O time.sleep() DAQUI PARA MÁXIMA VELOCIDADE\n\
      \ndef status_reporter():\n    \"\"\"Thread separada para reportar o status periodicamente.\"\
      \"\"\n    global start_time\n    last_report_time = time.time()\n    last_success_count\
      \ = 0\n\n    while not stop_event.wait(REPORT_INTERVAL): # Espera pelo intervalo\
      \ ou pelo evento de parada\n        now = time.time()\n        elapsed_interval\
      \ = now - last_report_time\n        \n        with counter_lock: # Lê contadores\
      \ com segurança\n            current_success = success_count\n            current_fail\
      \ = fail_count\n            current_total = message_counter\n\n        interval_success\
      \ = current_success - last_success_count\n        rate = interval_success /\
      \ elapsed_interval if elapsed_interval > 0 else 0\n        total_elapsed = now\
      \ - start_time\n        overall_rate = current_success / total_elapsed if total_elapsed\
      \ > 0 else 0\n\n        print(f\"\\n[Status {time.strftime('%H:%M:%S')}] Total:\
      \ {current_total} | Sucesso: {current_success} ({interval_success} no intervalo)\
      \ | Falhas: {current_fail} | Taxa Intervalo: {rate:.1f} msg/s | Taxa Média:\
      \ {overall_rate:.1f} msg/s\")\n        \n        last_report_time = now\n  \
      \      last_success_count = current_success\n\n\n# --- Execução Principal ---\n\
      if __name__ == \"__main__\":\n    print(\"--- Cliente de Teste de Stress (Máxima\
      \ Velocidade) ---\")\n    print(f\"Alvo: {BASE_URL}\")\n    print(f\"Fila: {QUEUE_NAME}\"\
      )\n    print(f\"Workers: {NUM_WORKERS}\")\n\n    # Cria uma única sessão para\
      \ ser compartilhada por todas as threads\n    # A sessão gerencia o pool de\
      \ conexões e headers comuns\n    session = requests.Session()\n    session.verify\
      \ = False # Ignora verificação SSL para toda a sessão\n\n    # 1. Obter token\
      \ de acesso e configurar na sessão\n    token = get_access_token(session, BASE_URL,\
      \ USERNAME, PASSWORD)\n    if not token:\n        print(\"\\n--- Falha no Login.\
      \ Abortando. ---\")\n        sys.exit(1)\n\n    print(\"\\n--- Preparação da\
      \ Fila ---\")\n    # 2. Verificar/Criar a fila usando a sessão\n    queue_is_ready\
      \ = check_or_create_queue(session, BASE_URL, QUEUE_NAME)\n    if not queue_is_ready:\n\
      \        print(f\"\\n--- Falha ao preparar a fila '{QUEUE_NAME}'. Abortando.\
      \ ---\")\n        session.close() # Fecha a sessão\n        sys.exit(1)\n\n\
      \    print(f\"\\n--- Iniciando {NUM_WORKERS} workers para stress na fila '{QUEUE_NAME}'\
      \ ---\")\n    print(\"Pressione Ctrl+C para parar...\")\n\n    start_time =\
      \ time.time() # Marca o tempo de início\n\n    threads = []\n    # Inicia a\
      \ thread de relatório\n    reporter_thread = threading.Thread(target=status_reporter,\
      \ daemon=True) # Daemon=True para não impedir saída\n    reporter_thread.start()\n\
      \n    # Cria e inicia as threads worker\n    for i in range(NUM_WORKERS):\n\
      \        thread = threading.Thread(target=message_sender_worker, args=(session,\
      \ BASE_URL, QUEUE_NAME, i + 1))\n        thread.start()\n        threads.append(thread)\n\
      \n    try:\n        # Mantém a thread principal viva esperando as workers terminarem\
      \ (o que só acontece com Ctrl+C)\n        # Ou poderíamos simplesmente esperar\
      \ pelo Ctrl+C aqui\n        while not stop_event.is_set():\n             time.sleep(0.5)\
      \ # Evita que a thread principal consuma 100% CPU apenas esperando\n\n    except\
      \ KeyboardInterrupt:\n        print(\"\\n\\n\U0001F6D1 Interrupção pelo usuário\
      \ recebida. Sinalizando parada para as threads...\")\n        stop_event.set()\
      \ # Sinaliza para todas as threads pararem\n\n    finally:\n        print(\"\
      Aguardando workers finalizarem...\")\n        # Espera todas as threads worker\
      \ terminarem\n        for thread in threads:\n            thread.join(timeout=10)\
      \ # Dá um tempo para as threads terminarem\n\n        # A thread reporter é\
      \ daemon, então não precisamos esperar por ela explicitamente se o programa\
      \ sair\n\n        # Fecha a sessão de requests para liberar conexões\n     \
      \   session.close()\n\n        # 5. Imprimir estatísticas finais\n        end_time\
      \ = time.time()\n        total_time = end_time - start_time\n        # Lê os\
      \ contadores finais (o lock não é estritamente necessário aqui,\n        # pois\
      \ as threads já pararam, mas é boa prática)\n        with counter_lock:\n  \
      \          final_total = message_counter\n            final_success = success_count\n\
      \            final_fail = fail_count\n\n        print(\"\\n--- Resumo Final\
      \ do Teste de Stress ---\")\n        print(f\"Tempo total de execução: {total_time:.2f}\
      \ segundos\")\n        print(f\"Total de mensagens tentadas: {final_total}\"\
      )\n        print(f\"Total de mensagens publicadas com sucesso: {final_success}\"\
      )\n        print(f\"Total de falhas na publicação: {final_fail}\")\n       \
      \ if total_time > 0:\n            average_rate = final_success / total_time\n\
      \            print(f\"Taxa média de publicação (sucesso): {average_rate:.2f}\
      \ mensagens/segundo\")\n        else:\n            print(\"Taxa média de publicação:\
      \ N/A (tempo de execução muito curto)\")\n        print(\"--------------------------------------\"\
      )\n        sys.exit(0)"
    tamanho: 0.01 MB
  geramensagem-v3-massive-loop.py:
    caminho_completo: .\geramensagem-v3-massive-loop.py
    classes: []
    functions:
    - docstring: Faz login usando a sessão para obter um token.
      end_lineno: 64
      lineno: 34
      name: get_access_token
    - docstring: Verifica/cria a fila usando a sessão.
      end_lineno: 113
      lineno: 66
      name: check_or_create_queue
    - docstring: Função executada por cada thread worker.
      end_lineno: 154
      lineno: 115
      name: message_sender_worker
    - docstring: Thread separada para reportar o status periodicamente.
      end_lineno: 181
      lineno: 158
      name: status_reporter
    imports:
    - asname: null
      name: requests
    - asname: null
      name: json
    - asname: null
      name: warnings
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: datetime
    - asname: null
      name: threading
    - asname: null
      name: queue
    - module: concurrent.futures
      names:
      - ThreadPoolExecutor
    numero_de_linhas: 268
    source_code: "# -*- coding: utf-8 -*-\nimport requests\nimport json\nimport warnings\n\
      import sys\nimport time\nimport datetime\nimport threading\nimport queue # Embora\
      \ não usemos uma Queue do módulo, o conceito é similar\nfrom concurrent.futures\
      \ import ThreadPoolExecutor # Alternativa mais moderna para gerenciar threads\n\
      \n# --- Configurações ---\nBASE_URL = \"https://localhost:8777\"\nQUEUE_NAME\
      \ = \"minha-fila-teste-stress\" # Fila para teste de stress\nMESSAGE_BASE_CONTENT\
      \ = \"Stress Test Msg\"\nUSERNAME = \"admin\"\nPASSWORD = \"admin\"\nNUM_WORKERS\
      \ = 60  # <<< NÚMERO DE THREADS CONCORRENTES >>> Ajuste conforme necessário\n\
      REPORT_INTERVAL = 5 # Segundos entre relatórios de status\n# --- Fim das Configurações\
      \ ---\n\n# Ignorar avisos sobre certificados SSL autoassinados\nwarnings.filterwarnings(\"\
      ignore\", message=\"Unverified HTTPS request\")\n\n# --- Globais e Sincronização\
      \ ---\nmessage_counter = 0\nsuccess_count = 0\nfail_count = 0\ncounter_lock\
      \ = threading.Lock() # Para proteger acesso aos contadores\nstop_event = threading.Event()\
      \ # Para sinalizar parada para as threads\nstart_time = 0.0\n# --- Fim Globais\
      \ ---\n\ndef get_access_token(session, base_url, username, password):\n    \"\
      \"\"Faz login usando a sessão para obter um token.\"\"\"\n    login_url = f\"\
      {base_url}/login\"\n    try:\n        print(f\"\U0001F511 Tentando fazer login\
      \ como '{username}' em {login_url}...\")\n        response = session.post( #\
      \ Usa a sessão\n            login_url,\n            data={\"username\": username,\
      \ \"password\": password},\n            verify=False,\n            timeout=15\
      \ # Timeout um pouco maior para login\n        )\n        response.raise_for_status()\n\
      \        token_data = response.json()\n        print(\"✅ Login bem-sucedido!\"\
      )\n        # Define o header de autorização na sessão para todas as requisições\
      \ futuras\n        access_token = token_data.get(\"access_token\")\n       \
      \ if access_token:\n            session.headers.update({\"Authorization\": f\"\
      Bearer {access_token}\"})\n            return access_token # Retorna o token\
      \ caso seja necessário fora da sessão\n        else:\n             print(\"\
      ❌ Token não encontrado na resposta do login.\")\n             return None\n\
      \    except requests.exceptions.RequestException as e:\n        print(f\"❌ Erro\
      \ de conexão ou HTTP ao tentar fazer login: {e}\")\n        if hasattr(e, 'response')\
      \ and e.response is not None:\n            try: print(f\"   Detalhe da API:\
      \ {e.response.json()}\")\n            except json.JSONDecodeError: print(f\"\
      \   Resposta (não JSON): {e.response.text[:200]}...\")\n        return None\n\
      \    except json.JSONDecodeError:\n        print(f\"❌ Erro ao decodificar a\
      \ resposta JSON do login.\")\n        return None\n\ndef check_or_create_queue(session,\
      \ base_url, queue_name):\n    \"\"\"Verifica/cria a fila usando a sessão.\"\"\
      \"\n    get_queue_url = f\"{base_url}/queues/{queue_name}\"\n    create_queue_url\
      \ = f\"{base_url}/queues\"\n    # Headers já estão na sessão (Authorization)\n\
      \n    try:\n        print(f\"ℹ️  Verificando se a fila '{queue_name}' existe...\"\
      )\n        response_get = session.get(get_queue_url, verify=False, timeout=10)\
      \ # Usa sessão\n\n        if response_get.status_code == 200:\n            print(f\"\
      \U0001F44D Fila '{queue_name}' já existe.\")\n            return True\n\n  \
      \      elif response_get.status_code == 404:\n            print(f\"⚠️  Fila\
      \ '{queue_name}' não encontrada. Tentando criar...\")\n            payload =\
      \ {\"name\": queue_name}\n            # Adiciona Content-Type especificamente\
      \ para esta requisição POST JSON\n            headers_post = {\"Content-Type\"\
      : \"application/json\"}\n            response_post = session.post( # Usa sessão\n\
      \                create_queue_url,\n                headers=headers_post, #\
      \ Adiciona o Content-Type aqui\n                json=payload,\n            \
      \    verify=False,\n                timeout=10\n            )\n\n          \
      \  if response_post.status_code == 201:\n                print(f\"✅ Fila '{queue_name}'\
      \ criada com sucesso!\")\n                time.sleep(0.5)\n                return\
      \ True\n            elif response_post.status_code == 409:\n               \
      \  print(f\"⚠️  A fila '{queue_name}' foi criada por outro processo (Erro 409).\
      \ OK.\")\n                 return True\n            else:\n                response_post.raise_for_status()\
      \ # Levanta erro para outros status\n                return False # Não deve\
      \ chegar aqui\n\n        else:\n            response_get.raise_for_status()\
      \ # Levanta erro para outros status no GET\n            return False # Não deve\
      \ chegar aqui\n\n    except requests.exceptions.RequestException as e:\n   \
      \     print(f\"❌ Erro ao verificar ou criar a fila '{queue_name}': {e}\")\n\
      \        if hasattr(e, 'response') and e.response is not None:\n           \
      \  try: print(f\"   Detalhe da API: {e.response.json()}\")\n             except\
      \ json.JSONDecodeError: print(f\"   Resposta (não JSON): {e.response.text[:200]}...\"\
      )\n        return False\n\ndef message_sender_worker(session, base_url, queue_name,\
      \ worker_id):\n    \"\"\"Função executada por cada thread worker.\"\"\"\n  \
      \  global message_counter, success_count, fail_count\n    publish_url = f\"\
      {base_url}/queues/{queue_name}/messages\"\n    headers_post = {\"Content-Type\"\
      : \"application/json\"} # Content-Type para o POST\n\n    while not stop_event.is_set():\
      \ # Continua enquanto o evento de parada não for setado\n        with counter_lock:\
      \ # Adquire o lock para obter um ID único\n            current_msg_id = message_counter\n\
      \            message_counter += 1\n        # O lock é liberado aqui\n\n    \
      \    full_message = f\"{MESSAGE_BASE_CONTENT} Worker {worker_id} Msg #{current_msg_id}\
      \ ({datetime.datetime.now().isoformat()})\"\n        payload = {\"content\"\
      : full_message}\n\n        try:\n            response = session.post(\n    \
      \            publish_url,\n                headers=headers_post, # Adiciona\
      \ Content-Type (Auth já está na sessão)\n                json=payload,\n   \
      \             verify=False,\n                timeout=5 # Timeout curto para\
      \ não prender a thread por muito tempo\n            )\n            response.raise_for_status()\
      \ # Lança exceção para erros 4xx/5xx\n\n            # Se chegou aqui, foi sucesso\n\
      \            with counter_lock: # Adquire o lock para atualizar contador de\
      \ sucesso\n                success_count += 1\n            # Lock liberado\n\
      \n        except requests.exceptions.Timeout:\n            with counter_lock:\
      \ fail_count += 1\n            # print(f\"T{worker_id}:T\", end=\"\", flush=True)\
      \ # Timeout\n        except requests.exceptions.RequestException as e:\n   \
      \         with counter_lock: fail_count += 1\n            # Opcional: Logar\
      \ o erro, mas pode poluir muito\n            # status = e.response.status_code\
      \ if hasattr(e, 'response') and e.response else 'N/A'\n            # print(f\"\
      T{worker_id}:E{status}\", end=\"\", flush=True) # Erro com status\n        except\
      \ Exception as e: # Captura outras exceções inesperadas\n             with counter_lock:\
      \ fail_count += 1\n             # print(f\"T{worker_id}:X\", end=\"\", flush=True)\
      \ # Erro genérico\n        # REMOVEMOS O time.sleep() DAQUI PARA MÁXIMA VELOCIDADE\n\
      \ndef status_reporter():\n    \"\"\"Thread separada para reportar o status periodicamente.\"\
      \"\"\n    global start_time\n    last_report_time = time.time()\n    last_success_count\
      \ = 0\n\n    while not stop_event.wait(REPORT_INTERVAL): # Espera pelo intervalo\
      \ ou pelo evento de parada\n        now = time.time()\n        elapsed_interval\
      \ = now - last_report_time\n        \n        with counter_lock: # Lê contadores\
      \ com segurança\n            current_success = success_count\n            current_fail\
      \ = fail_count\n            current_total = message_counter\n\n        interval_success\
      \ = current_success - last_success_count\n        rate = interval_success /\
      \ elapsed_interval if elapsed_interval > 0 else 0\n        total_elapsed = now\
      \ - start_time\n        overall_rate = current_success / total_elapsed if total_elapsed\
      \ > 0 else 0\n\n        print(f\"\\n[Status {time.strftime('%H:%M:%S')}] Total:\
      \ {current_total} | Sucesso: {current_success} ({interval_success} no intervalo)\
      \ | Falhas: {current_fail} | Taxa Intervalo: {rate:.1f} msg/s | Taxa Média:\
      \ {overall_rate:.1f} msg/s\")\n        \n        last_report_time = now\n  \
      \      last_success_count = current_success\n\n\n# --- Execução Principal ---\n\
      if __name__ == \"__main__\":\n    print(\"--- Cliente de Teste de Stress (Máxima\
      \ Velocidade) ---\")\n    print(f\"Alvo: {BASE_URL}\")\n    print(f\"Fila: {QUEUE_NAME}\"\
      )\n    print(f\"Workers: {NUM_WORKERS}\")\n\n    # Cria uma única sessão para\
      \ ser compartilhada por todas as threads\n    # A sessão gerencia o pool de\
      \ conexões e headers comuns\n    session = requests.Session()\n    session.verify\
      \ = False # Ignora verificação SSL para toda a sessão\n\n    # 1. Obter token\
      \ de acesso e configurar na sessão\n    token = get_access_token(session, BASE_URL,\
      \ USERNAME, PASSWORD)\n    if not token:\n        print(\"\\n--- Falha no Login.\
      \ Abortando. ---\")\n        sys.exit(1)\n\n    print(\"\\n--- Preparação da\
      \ Fila ---\")\n    # 2. Verificar/Criar a fila usando a sessão\n    queue_is_ready\
      \ = check_or_create_queue(session, BASE_URL, QUEUE_NAME)\n    if not queue_is_ready:\n\
      \        print(f\"\\n--- Falha ao preparar a fila '{QUEUE_NAME}'. Abortando.\
      \ ---\")\n        session.close() # Fecha a sessão\n        sys.exit(1)\n\n\
      \    print(f\"\\n--- Iniciando {NUM_WORKERS} workers para stress na fila '{QUEUE_NAME}'\
      \ ---\")\n    print(\"Pressione Ctrl+C para parar...\")\n\n    start_time =\
      \ time.time() # Marca o tempo de início\n\n    threads = []\n    # Inicia a\
      \ thread de relatório\n    reporter_thread = threading.Thread(target=status_reporter,\
      \ daemon=True) # Daemon=True para não impedir saída\n    reporter_thread.start()\n\
      \n    # Cria e inicia as threads worker\n    for i in range(NUM_WORKERS):\n\
      \        thread = threading.Thread(target=message_sender_worker, args=(session,\
      \ BASE_URL, QUEUE_NAME, i + 1))\n        thread.start()\n        threads.append(thread)\n\
      \n    try:\n        # Mantém a thread principal viva esperando as workers terminarem\
      \ (o que só acontece com Ctrl+C)\n        # Ou poderíamos simplesmente esperar\
      \ pelo Ctrl+C aqui\n        while not stop_event.is_set():\n             time.sleep(0.5)\
      \ # Evita que a thread principal consuma 100% CPU apenas esperando\n\n    except\
      \ KeyboardInterrupt:\n        print(\"\\n\\n\U0001F6D1 Interrupção pelo usuário\
      \ recebida. Sinalizando parada para as threads...\")\n        stop_event.set()\
      \ # Sinaliza para todas as threads pararem\n\n    finally:\n        print(\"\
      Aguardando workers finalizarem...\")\n        # Espera todas as threads worker\
      \ terminarem\n        for thread in threads:\n            thread.join(timeout=10)\
      \ # Dá um tempo para as threads terminarem\n\n        # A thread reporter é\
      \ daemon, então não precisamos esperar por ela explicitamente se o programa\
      \ sair\n\n        # Fecha a sessão de requests para liberar conexões\n     \
      \   session.close()\n\n        # 5. Imprimir estatísticas finais\n        end_time\
      \ = time.time()\n        total_time = end_time - start_time\n        # Lê os\
      \ contadores finais (o lock não é estritamente necessário aqui,\n        # pois\
      \ as threads já pararam, mas é boa prática)\n        with counter_lock:\n  \
      \          final_total = message_counter\n            final_success = success_count\n\
      \            final_fail = fail_count\n\n        print(\"\\n--- Resumo Final\
      \ do Teste de Stress ---\")\n        print(f\"Tempo total de execução: {total_time:.2f}\
      \ segundos\")\n        print(f\"Total de mensagens tentadas: {final_total}\"\
      )\n        print(f\"Total de mensagens publicadas com sucesso: {final_success}\"\
      )\n        print(f\"Total de falhas na publicação: {final_fail}\")\n       \
      \ if total_time > 0:\n            average_rate = final_success / total_time\n\
      \            print(f\"Taxa média de publicação (sucesso): {average_rate:.2f}\
      \ mensagens/segundo\")\n        else:\n            print(\"Taxa média de publicação:\
      \ N/A (tempo de execução muito curto)\")\n        print(\"--------------------------------------\"\
      )\n        sys.exit(0)"
    tamanho: 0.01 MB
  geramensagem.py:
    caminho_completo: .\geramensagem.py
    classes: []
    functions:
    - docstring: Faz login na API para obter um token de acesso.
      end_lineno: 42
      lineno: 19
      name: get_access_token
    - docstring: Verifica se a fila existe. Se não, tenta criá-la.
      end_lineno: 93
      lineno: 44
      name: check_or_create_queue
    - docstring: Publica uma mensagem na fila especificada usando o token.
      end_lineno: 127
      lineno: 95
      name: publish_message_to_queue
    imports:
    - asname: null
      name: requests
    - asname: null
      name: json
    - asname: null
      name: warnings
    - asname: null
      name: sys
    - asname: null
      name: time
    numero_de_linhas: 156
    source_code: "# -*- coding: utf-8 -*-\nimport requests\nimport json\nimport warnings\n\
      import sys\nimport time # Adicionado para um pequeno delay opcional\n\n# ---\
      \ Configurações ---\nBASE_URL = \"https://localhost:8777\"\nQUEUE_NAME = \"\
      minha-fila-teste\" # A fila que queremos usar/criar\nMESSAGE_CONTENT = \"hello\
      \ world\" # Mensagem específica\nUSERNAME = \"admin\"\nPASSWORD = \"admin\"\n\
      # --- Fim das Configurações ---\n\n# Ignorar avisos sobre certificados SSL autoassinados\
      \ (APENAS PARA DESENVOLVIMENTO)\nwarnings.filterwarnings(\"ignore\", message=\"\
      Unverified HTTPS request\")\n\ndef get_access_token(base_url, username, password):\n\
      \    \"\"\"Faz login na API para obter um token de acesso.\"\"\"\n    login_url\
      \ = f\"{base_url}/login\"\n    try:\n        print(f\"\U0001F511 Tentando fazer\
      \ login como '{username}' em {login_url}...\")\n        response = requests.post(\n\
      \            login_url,\n            data={\"username\": username, \"password\"\
      : password},\n            verify=False, # Ignora verificação SSL\n         \
      \   timeout=10\n        )\n        response.raise_for_status()\n        token_data\
      \ = response.json()\n        print(\"✅ Login bem-sucedido!\")\n        return\
      \ token_data.get(\"access_token\")\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"❌ Erro de conexão ou HTTP ao tentar fazer login: {e}\"\
      )\n        if hasattr(e, 'response') and e.response is not None:\n         \
      \   try: print(f\"   Detalhe da API: {e.response.json()}\")\n            except\
      \ json.JSONDecodeError: print(f\"   Resposta (não JSON): {e.response.text[:200]}...\"\
      )\n        return None\n    except json.JSONDecodeError:\n        print(f\"\
      ❌ Erro ao decodificar a resposta JSON do login.\")\n        return None\n\n\
      def check_or_create_queue(base_url, queue_name, token):\n    \"\"\"Verifica\
      \ se a fila existe. Se não, tenta criá-la.\"\"\"\n    get_queue_url = f\"{base_url}/queues/{queue_name}\"\
      \n    create_queue_url = f\"{base_url}/queues\"\n    headers = {\"Authorization\"\
      : f\"Bearer {token}\"}\n\n    try:\n        print(f\"ℹ️  Verificando se a fila\
      \ '{queue_name}' existe...\")\n        response_get = requests.get(get_queue_url,\
      \ headers=headers, verify=False, timeout=5)\n\n        if response_get.status_code\
      \ == 200:\n            print(f\"\U0001F44D Fila '{queue_name}' já existe.\"\
      )\n            return True # Fila existe\n\n        elif response_get.status_code\
      \ == 404:\n            print(f\"⚠️  Fila '{queue_name}' não encontrada. Tentando\
      \ criar...\")\n            payload = {\"name\": queue_name}\n            headers_post\
      \ = {**headers, \"Content-Type\": \"application/json\"} # Adiciona Content-Type\n\
      \            response_post = requests.post(\n                create_queue_url,\n\
      \                headers=headers_post,\n                json=payload,\n    \
      \            verify=False,\n                timeout=10\n            )\n\n  \
      \          if response_post.status_code == 201: # 201 Created\n            \
      \    print(f\"✅ Fila '{queue_name}' criada com sucesso!\")\n               \
      \ # Pequeno delay opcional para garantir que a fila esteja pronta no DB\n  \
      \              time.sleep(0.5)\n                return True # Fila criada\n\
      \            elif response_post.status_code == 409: # 409 Conflict\n       \
      \          print(f\"⚠️  A fila '{queue_name}' foi criada por outro processo\
      \ enquanto verificávamos (Erro 409). Considerando como sucesso.\")\n       \
      \          return True # Fila já existe (provavelmente criada entre o GET e\
      \ o POST)\n            else:\n                # Outro erro durante a criação\n\
      \                response_post.raise_for_status() # Lança exceção para outros\
      \ erros HTTP\n                return False # Falha inesperada na criação (nunca\
      \ deve chegar aqui se raise_for_status funcionar)\n\n        else:\n       \
      \     # Erro inesperado ao verificar a fila\n            response_get.raise_for_status()\n\
      \            return False # Falha inesperada na verificação\n\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"❌ Erro ao verificar ou criar a fila '{queue_name}':\
      \ {e}\")\n        if hasattr(e, 'response') and e.response is not None:\n  \
      \          try: print(f\"   Detalhe da API: {e.response.json()}\")\n       \
      \     except json.JSONDecodeError: print(f\"   Resposta (não JSON): {e.response.text[:200]}...\"\
      )\n        return False # Falha\n\ndef publish_message_to_queue(base_url, queue_name,\
      \ message, token):\n    \"\"\"Publica uma mensagem na fila especificada usando\
      \ o token.\"\"\"\n    publish_url = f\"{base_url}/queues/{queue_name}/messages\"\
      \n    headers = {\n        \"Authorization\": f\"Bearer {token}\",\n       \
      \ \"Content-Type\": \"application/json\"\n    }\n    payload = {\"content\"\
      : message}\n    try:\n        print(f\"\U0001F4E4 Publicando mensagem na fila\
      \ '{queue_name}'...\")\n        print(f\"   Conteúdo: '{message}'\")\n     \
      \   response = requests.post(\n            publish_url,\n            headers=headers,\n\
      \            json=payload,\n            verify=False,\n            timeout=10\n\
      \        )\n        response.raise_for_status() # Lança exceção para erros HTTP\
      \ (4xx, 5xx)\n        response_data = response.json()\n        print(f\"✅ Mensagem\
      \ publicada com sucesso!\")\n        print(f\"   ID da Mensagem: {response_data.get('message_id')}\"\
      )\n        return response_data\n    except requests.exceptions.RequestException\
      \ as e:\n        print(f\"❌ Erro de conexão ou HTTP ao publicar mensagem:\"\
      )\n        if hasattr(e, 'response') and e.response is not None:\n         \
      \    try: print(f\"   Detalhe da API: {e.response.json()}\")\n             except\
      \ json.JSONDecodeError: print(f\"   Resposta (não JSON): {e.response.text[:200]}...\"\
      )\n        else: print(f\"   Erro: {e}\")\n        return None\n    except json.JSONDecodeError:\n\
      \        print(f\"❌ Erro ao decodificar a resposta JSON da publicação.\")\n\
      \        return None\n\n# --- Execução Principal ---\nif __name__ == \"__main__\"\
      :\n    print(\"--- Cliente da API Message Broker (v2: Cria Fila se não existir)\
      \ ---\")\n\n    # 1. Obter token de acesso\n    access_token = get_access_token(BASE_URL,\
      \ USERNAME, PASSWORD)\n\n    if not access_token:\n        print(\"\\n--- Falha\
      \ no Login. Abortando. ---\")\n        sys.exit(1)\n\n    print(\"\\n--- Preparação\
      \ da Fila ---\")\n    # 2. Verificar se a fila existe e criar se necessário\n\
      \    queue_is_ready = check_or_create_queue(BASE_URL, QUEUE_NAME, access_token)\n\
      \n    if not queue_is_ready:\n        print(f\"\\n--- Falha ao garantir a existência\
      \ da fila '{QUEUE_NAME}'. Abortando. ---\")\n        sys.exit(1)\n\n    print(\"\
      \\n--- Publicação da Mensagem ---\")\n    # 3. Publicar a mensagem\n    result\
      \ = publish_message_to_queue(BASE_URL, QUEUE_NAME, MESSAGE_CONTENT, access_token)\n\
      \n    if result:\n        print(\"\\n--- Operação Concluída com Sucesso ---\"\
      )\n    else:\n        print(\"\\n--- Falha na Publicação da Mensagem ---\")\n\
      \        sys.exit(1) # Sair com código de erro se a publicação falhar"
    tamanho: 0.01 MB
  libs.txt:
    caminho_completo: .\libs.txt
    numero_de_linhas: 3
    tamanho: 0.00 MB
  limpa-banco-.py:
    caminho_completo: .\limpa-banco-.py
    classes: []
    functions:
    - docstring: "Limpa os dados das tabelas 'blockchain_blocos', 'transacao' e 'pool_mineracao'\n\
        no banco de dados SQLite especificado, mantendo apenas as duas primeiras linhas\
        \ de cada tabela.\nAs outras linhas serão completamente removidas.\nApós a\
        \ limpeza, executa VACUUM para reduzir o tamanho do arquivo DB.\n\nArgs:\n\
        \    db_path (str): Caminho para o arquivo do banco de dados SQLite."
      end_lineno: 57
      lineno: 4
      name: limpar_tabelas_blockchain_mantendo_duas_linhas
    imports:
    - asname: null
      name: sqlite3
    - asname: null
      name: os
    numero_de_linhas: 75
    source_code: "import sqlite3\nimport os\n\ndef limpar_tabelas_blockchain_mantendo_duas_linhas(db_path):\n\
      \    \"\"\"\n    Limpa os dados das tabelas 'blockchain_blocos', 'transacao'\
      \ e 'pool_mineracao'\n    no banco de dados SQLite especificado, mantendo apenas\
      \ as duas primeiras linhas de cada tabela.\n    As outras linhas serão completamente\
      \ removidas.\n    Após a limpeza, executa VACUUM para reduzir o tamanho do arquivo\
      \ DB.\n\n    Args:\n        db_path (str): Caminho para o arquivo do banco de\
      \ dados SQLite.\n    \"\"\"\n    conn = None  # Inicializa conn fora do bloco\
      \ try para usar no finally\n    try:\n        # Conecta ao banco de dados SQLite\n\
      \        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n\n\
      \        tabelas_para_limpar = ['blockchain_blocos', 'transacao', 'pool_mineracao']\n\
      \n        for tabela in tabelas_para_limpar:\n            # Conta o número de\
      \ linhas antes da limpeza\n            cursor.execute(f\"SELECT COUNT(*) FROM\
      \ {tabela}\")\n            linhas_antes = cursor.fetchone()[0]\n           \
      \ print(f\"Tabela '{tabela}': Linhas antes da limpeza: {linhas_antes}\")\n\n\
      \            # Deleta todos os dados da tabela, exceto as duas primeiras linhas\
      \ ordenadas por ID\n            cursor.execute(f\"\"\"\n                DELETE\
      \ FROM {tabela}\n                WHERE id NOT IN (SELECT id FROM {tabela} ORDER\
      \ BY id ASC LIMIT 2)\n            \"\"\")\n            print(f\"Dados da tabela\
      \ '{tabela}' limpos, mantendo as 2 primeiras linhas.\")\n\n            # Conta\
      \ o número de linhas após a limpeza\n            cursor.execute(f\"SELECT COUNT(*)\
      \ FROM {tabela}\")\n            linhas_depois = cursor.fetchone()[0]\n     \
      \       print(f\"Tabela '{tabela}': Linhas após a limpeza: {linhas_depois}\"\
      )\n\n        # Commita as alterações (IMPORTANTE: Commitar antes do VACUUM)\n\
      \        conn.commit()\n        print(\"Alterações commitadas.\")\n\n      \
      \  # Executa VACUUM para reduzir o tamanho do arquivo\n        cursor.execute(\"\
      VACUUM\")\n        conn.commit() # Commita o VACUUM também\n        print(\"\
      Comando VACUUM executado para reduzir o tamanho do arquivo.\")\n\n\n       \
      \ print(\"Operação de limpeza concluída (mantendo as duas primeiras linhas de\
      \ cada tabela e reduzindo o tamanho do DB).\")\n\n    except sqlite3.Error as\
      \ e:\n        print(f\"Erro ao limpar o banco de dados: {e}\")\n\n    finally:\n\
      \        if conn:\n            conn.close()\n\nif __name__ == \"__main__\":\n\
      \    db_file = 'blockchain.db' # Nome do arquivo do banco de dados na raiz\n\
      \    db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), db_file)\
      \ # Caminho completo para o db\n\n    if os.path.exists(db_path):\n        tamanho_inicial\
      \ = os.path.getsize(db_path) / (1024 * 1024) # Tamanho em MB\n        print(f\"\
      Tamanho inicial do banco de dados: {tamanho_inicial:.2f} MB\")\n        limpar_tabelas_blockchain_mantendo_duas_linhas(db_path)\n\
      \        tamanho_final = os.path.getsize(db_path) / (1024 * 1024) # Tamanho\
      \ em MB\n        print(f\"Tamanho final do banco de dados após limpeza e VACUUM:\
      \ {tamanho_final:.2f} MB\")\n        if tamanho_final < tamanho_inicial:\n \
      \           print(\"O tamanho do banco de dados foi reduzido com sucesso!\"\
      )\n        else:\n            print(\"O tamanho do banco de dados não foi reduzido\
      \ (ou a redução foi insignificante).\")\n\n    else:\n        print(f\"Banco\
      \ de dados '{db_path}' não encontrado na raiz do script.\")"
    tamanho: 0.00 MB
  message-broker-v1.py:
    caminho_completo: .\message-broker-v1.py
    classes:
    - docstring: null
      end_lineno: 139
      lineno: 104
      name: Settings
    - docstring: null
      end_lineno: 170
      lineno: 156
      name: ColoramaFormatter
    - docstring: null
      end_lineno: 198
      lineno: 172
      name: JsonFormatter
    - docstring: null
      end_lineno: 369
      lineno: 368
      name: QueueBase
    - docstring: null
      end_lineno: 372
      lineno: 371
      name: QueueCreate
    - docstring: null
      end_lineno: 380
      lineno: 374
      name: QueueResponse
    - docstring: null
      end_lineno: 383
      lineno: 382
      name: MessageBase
    - docstring: null
      end_lineno: 386
      lineno: 385
      name: MessageCreate
    - docstring: null
      end_lineno: 395
      lineno: 388
      name: MessageResponse
    - docstring: null
      end_lineno: 400
      lineno: 397
      name: Token
    - docstring: null
      end_lineno: 417
      lineno: 402
      name: StatsResponse
    - docstring: null
      end_lineno: 420
      lineno: 419
      name: LogFileResponse
    - docstring: null
      end_lineno: 424
      lineno: 423
      name: QueueCreatePayload
    - docstring: null
      end_lineno: 427
      lineno: 426
      name: MessagePayload
    - docstring: null
      end_lineno: 431
      lineno: 429
      name: MessagePublishResponse
    - docstring: null
      end_lineno: 438
      lineno: 433
      name: MessageConsumeResponse
    - docstring: null
      end_lineno: 454
      lineno: 441
      name: Queue
    - docstring: null
      end_lineno: 476
      lineno: 456
      name: Message
    - docstring: null
      end_lineno: 1522
      lineno: 1481
      name: QueueGQL
    - docstring: null
      end_lineno: 1543
      lineno: 1525
      name: MessageGQL
    - docstring: null
      end_lineno: 1604
      lineno: 1547
      name: QueryGQL
    - docstring: null
      end_lineno: 1674
      lineno: 1609
      name: MutationGQL
    - docstring: null
      end_lineno: 451
      lineno: 449
      name: Meta
    - docstring: null
      end_lineno: 473
      lineno: 469
      name: Meta
    functions:
    - docstring: null
      end_lineno: 231
      lineno: 231
      name: log_debug
    - docstring: null
      end_lineno: 232
      lineno: 232
      name: log_info
    - docstring: null
      end_lineno: 233
      lineno: 233
      name: log_success
    - docstring: null
      end_lineno: 234
      lineno: 234
      name: log_warning
    - docstring: null
      end_lineno: 235
      lineno: 235
      name: log_error
    - docstring: null
      end_lineno: 236
      lineno: 236
      name: log_critical
    - docstring: null
      end_lineno: 237
      lineno: 237
      name: log_pipeline
    - docstring: null
      end_lineno: 285
      lineno: 254
      name: generate_self_signed_cert
    - docstring: null
      end_lineno: 170
      lineno: 160
      name: format
    - docstring: null
      end_lineno: 175
      lineno: 174
      name: formatTime
    - docstring: null
      end_lineno: 198
      lineno: 177
      name: format
    - docstring: null
      end_lineno: 454
      lineno: 453
      name: __str__
    - docstring: null
      end_lineno: 476
      lineno: 475
      name: __str__
    - docstring: null
      end_lineno: 1017
      lineno: 974
      name: read_and_parse_log_sync
    - docstring: Helper to map from Tortoise ORM model, injecting queue name.
      end_lineno: 1543
      lineno: 1534
      name: from_orm
    imports:
    - asname: null
      name: asyncio
    - asname: null
      name: json
    - asname: null
      name: logging
    - asname: null
      name: os
    - asname: null
      name: platform
    - asname: null
      name: secrets
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: traceback
    - module: contextlib
      names:
      - asynccontextmanager
    - module: datetime
      names:
      - datetime
      - timezone
      - timedelta
    - module: typing
      names:
      - Dict
      - Any
      - Optional
      - List
      - Union
      - AsyncGenerator
    - module: collections
      names:
      - deque
    - asname: null
      name: hashlib
    - asname: null
      name: os
    - asname: null
      name: sys
    - module: fastapi
      names:
      - FastAPI
      - Request
      - Response
      - Depends
      - HTTPException
      - status
      - BackgroundTasks
      - Path
      - Query
    - module: fastapi.middleware.cors
      names:
      - CORSMiddleware
    - module: fastapi.security
      names:
      - OAuth2PasswordBearer
      - OAuth2PasswordRequestForm
      - HTTPBearer
      - HTTPAuthorizationCredentials
    - module: fastapi.responses
      names:
      - JSONResponse
      - StreamingResponse
    - asname: null
      name: uvicorn
    - module: jose
      names:
      - JWTError
      - jwt
    - module: pydantic
      names:
      - BaseModel
      - ValidationError
      - Field
      - EmailStr
      - ConfigDict
    - module: tortoise
      names:
      - Tortoise
      - fields
      - models
    - module: tortoise.exceptions
      names:
      - DoesNotExist
      - IntegrityError
    - module: colorama
      names:
      - init
      - Fore
      - Style
    - module: cryptography
      names:
      - x509
    - module: cryptography.x509.oid
      names:
      - NameOID
    - module: cryptography.hazmat.primitives
      names:
      - hashes
    - module: cryptography.hazmat.backends
      names:
      - default_backend
    - module: cryptography.hazmat.primitives
      names:
      - serialization
    - module: cryptography.hazmat.primitives.asymmetric
      names:
      - rsa
    - asname: null
      name: psutil
    - module: werkzeug.utils
      names:
      - secure_filename
    - module: slowapi
      names:
      - Limiter
      - _rate_limit_exceeded_handler
    - module: slowapi.util
      names:
      - get_remote_address
    - module: slowapi.errors
      names:
      - RateLimitExceeded
    - module: slowapi.middleware
      names:
      - SlowAPIMiddleware
    - asname: null
      name: strawberry
    - module: strawberry.fastapi
      names:
      - GraphQLRouter
    - module: strawberry.types
      names:
      - Info
    - asname: aioredis
      name: redis.asyncio
    - asname: null
      name: ipaddress
    - asname: null
      name: ipaddress
    numero_de_linhas: 1910
    source_code: "# -*- coding: utf-8 -*-\n\"\"\"\nAsync Message Broker API V3.1.1\
      \ - FastAPI + Tortoise ORM + SQLite (Refactored)\n----------------------------------------------------------------------------\n\
      Features:\n- FastAPI async web framework\n- Tortoise ORM with SQLite backend\n\
      - JWT Authentication (access & refresh tokens) via python-jose\n- Message Queues\
      \ (Create, List, Delete)\n- Message Handling (Publish, Consume (async safe),\
      \ Ack, Nack)\n- Server-Sent Events (SSE) via StreamingResponse + Redis Pub/Sub\n\
      - Rate Limiting via SlowAPI + Redis\n- GraphQL endpoint via Strawberry-graphql\n\
      - System Stats collection (psutil)\n- Self-signed certificate generation\n-\
      \ Structured JSON and colored console logging\n- Automatic OpenAPI/Swagger documentation\n\
      - Improved error handling, async operations, and code structure.\n\"\"\"\n\n\
      # --- Standard Library Imports ---\nimport asyncio\nimport json\nimport logging\n\
      import os\nimport platform\nimport secrets\nimport sys\nimport time\nimport\
      \ traceback\nfrom contextlib import asynccontextmanager\nfrom datetime import\
      \ datetime, timezone, timedelta\nfrom typing import Dict, Any, Optional, List,\
      \ Union, AsyncGenerator\nfrom collections import deque # For efficient log tailing\n\
      \n# --- Hashing ---\nimport hashlib\n# from passlib.context import CryptContext\
      \ # Recommended for password hashing (see login endpoint)\n\n# --- Third-Party\
      \ Imports ---\ntry:\n    # Core FastAPI & ASGI\n    from fastapi import (FastAPI,\
      \ Request, Response, Depends, HTTPException, status,\n                     \
      \    BackgroundTasks, Path, Query as FastQuery)\n    from fastapi.middleware.cors\
      \ import CORSMiddleware\n    from fastapi.security import (OAuth2PasswordBearer,\
      \ OAuth2PasswordRequestForm,\n                                  HTTPBearer,\
      \ HTTPAuthorizationCredentials)\n    from fastapi.responses import JSONResponse,\
      \ StreamingResponse\n    import uvicorn\n\n    # JWT Handling\n    from jose\
      \ import JWTError, jwt\n    # Use Field for validation, EmailStr for user examples\n\
      \    from pydantic import BaseModel, ValidationError, Field, EmailStr, ConfigDict\n\
      \n    # Database (Tortoise ORM)\n    from tortoise import Tortoise, fields,\
      \ models\n    # from tortoise.contrib.fastapi import register_tortoise # Not\
      \ needed with lifespan\n    from tortoise.exceptions import DoesNotExist, IntegrityError\n\
      \n    # Logging & Output\n    from colorama import init, Fore, Style\n\n   \
      \ # Certificates\n    from cryptography import x509\n    from cryptography.x509.oid\
      \ import NameOID\n    from cryptography.hazmat.primitives import hashes\n  \
      \  from cryptography.hazmat.backends import default_backend\n    from cryptography.hazmat.primitives\
      \ import serialization\n    from cryptography.hazmat.primitives.asymmetric import\
      \ rsa\n\n    # System Stats\n    import psutil\n\n    # Utilities\n    from\
      \ werkzeug.utils import secure_filename\n\n    # Rate Limiting\n    from slowapi\
      \ import Limiter, _rate_limit_exceeded_handler\n    from slowapi.util import\
      \ get_remote_address\n    from slowapi.errors import RateLimitExceeded\n   \
      \ from slowapi.middleware import SlowAPIMiddleware\n\n    # GraphQL\n    import\
      \ strawberry\n    from strawberry.fastapi import GraphQLRouter\n    from strawberry.types\
      \ import Info\n\n    # Redis Client (for SSE Pub/Sub and Rate Limiting)\n  \
      \  import redis.asyncio as aioredis # Use async redis client\n\nexcept ImportError\
      \ as e:\n    missing_pkg = str(e).split(\"'\")[-2]\n    print(f\"\\nERROR: Missing\
      \ dependency '{missing_pkg}'.\")\n    print(\"Please install all required packages\
      \ by running:\")\n    print(\"\\n  pip install fastapi uvicorn[standard] tortoise-orm\
      \ aiosqlite pydantic[email] python-jose[cryptography] passlib[bcrypt] colorama\
      \ cryptography psutil Werkzeug slowapi redis strawberry-graphql[fastapi] Jinja2\\\
      n\")\n    # Jinja2 needed by slowapi internals\n    sys.exit(1)\n\n# --- Initialize\
      \ Colorama ---\ninit(autoreset=True)\n\n# --- Configuration ---\nclass Settings:\n\
      \    PROJECT_NAME: str = \"Message Broker API V3.1.1 (FastAPI/Refactored)\"\n\
      \    VERSION: str = \"0.3.1.1-fastapi-tortoise\"\n    API_PORT: int = 8777\n\
      \    # Secrets (Use environment variables for production!)\n    JWT_SECRET_KEY:\
      \ str = os.environ.get('JWT_SECRET_KEY', secrets.token_hex(32))\n    ALGORITHM:\
      \ str = \"HS256\"\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60 * 1 # 1 hour\n\
      \    REFRESH_TOKEN_EXPIRE_DAYS: int = 30\n    # Database (SQLite Async with\
      \ Tortoise ORM)\n    DB_DIR: str = 'databases'\n    DB_FILENAME: str = 'message_broker_v3.db'\n\
      \    DB_PATH: str = os.path.abspath(os.path.join(DB_DIR, DB_FILENAME))\n   \
      \ DATABASE_URL: str = f\"sqlite:///{DB_PATH}\" # Use triple slash for relative\
      \ paths if needed, but absolute is safer\n    # Redis (For SSE & Rate Limiting)\n\
      \    REDIS_HOST: str = os.environ.get('REDIS_HOST', 'localhost')\n    REDIS_PORT:\
      \ int = int(os.environ.get('REDIS_PORT', 6379))\n    REDIS_URL: str = f\"redis://{REDIS_HOST}:{REDIS_PORT}\"\
      \n    REDIS_SSE_DB: int = 0 # Use DB 0 for SSE Pub/Sub\n    REDIS_RATE_LIMIT_DB:\
      \ int = 1 # Use DB 1 for Rate Limiting\n    # Directories\n    LOG_DIR: str\
      \ = 'logs_v3'\n    CERT_DIR: str = 'certs_v3'\n    # Files\n    CERT_FILE: str\
      \ = os.path.join(CERT_DIR, 'cert.pem')\n    KEY_FILE: str = os.path.join(CERT_DIR,\
      \ 'key_nopass.pem')\n    # CORS\n    ALLOWED_ORIGINS: List[str] = [\"*\"] #\
      \ Be more specific in production\n    # Rate Limiting\n    DEFAULT_RATE_LIMIT:\
      \ str = \"100/minute\"\n    # Logging\n    LOG_LEVEL_STR: str = os.environ.get(\"\
      LOG_LEVEL\", \"INFO\").upper()\n    LOG_LEVEL: int = getattr(logging, LOG_LEVEL_STR,\
      \ logging.INFO)\n    LOG_FORMAT_CONSOLE: str = '%(asctime)s - %(levelname)s\
      \ - %(message)s'\n    # Env type for reload/debug toggle\n    APP_ENV: str =\
      \ os.environ.get(\"APP_ENV\", \"production\").lower()\n\nsettings = Settings()\n\
      \n# --- Create Directories ---\nos.makedirs(settings.LOG_DIR, exist_ok=True)\n\
      os.makedirs(settings.CERT_DIR, exist_ok=True)\nos.makedirs(settings.DB_DIR,\
      \ exist_ok=True)\n\n# --- Logging Setup ---\ntimestamp = datetime.now().strftime(\"\
      %Y%m%d_%H%M%S\")\nunique_hash = hashlib.sha1(str(os.getpid()).encode()).hexdigest()[:8]\n\
      LOG_FILENAME = os.path.join(settings.LOG_DIR, f\"broker_log_{timestamp}_{unique_hash}.json\"\
      )\n\n# --- Logging Setup ---\n# ... (timestamp, unique_hash, LOG_FILENAME remain\
      \ the same) ...\n\nclass ColoramaFormatter(logging.Formatter):\n    LEVEL_COLORS\
      \ = { logging.DEBUG: Fore.CYAN, logging.INFO: Fore.GREEN, logging.WARNING: Fore.YELLOW,\
      \ logging.ERROR: Fore.RED, logging.CRITICAL: Fore.MAGENTA }\n    LEVEL_ICONS\
      \ = { logging.DEBUG: \"⚙️ \", logging.INFO: \"ℹ️ \", logging.WARNING: \"⚠️ \"\
      , logging.ERROR: \"❌ \", logging.CRITICAL: \"\U0001F525 \", 'SUCCESS': \"✅ \"\
      , 'PIPELINE': \"➡️ \", 'DB': \"\U0001F4BE \", 'AUTH': \"\U0001F511 \", 'QUEUE':\
      \ \"\U0001F4E5 \", 'MSG': \"✉️ \", 'HTTP': \"\U0001F310 \", 'STATS': \"\U0001F4CA\
      \ \", 'LOGS': \"\U0001F4C4 \", 'SEC': \"\U0001F6E1️ \", 'ASYNC': \"⚡ \", 'GRAPHQL':\
      \ \"\U0001F353 \", 'SSE': \"\U0001F4E1 \", 'RATELIMIT': \"⏱️ \", 'STARTUP':\
      \ '\U0001F680', 'SHUTDOWN': '\U0001F6D1'}\n    # --- CORRECTED FORMAT METHOD\
      \ ---\n    def format(self, record):\n        level_color = self.LEVEL_COLORS.get(record.levelno,\
      \ Fore.WHITE)\n        icon_type = getattr(record, 'icon_type', record.levelname)\
      \ # Use icon_type if provided\n        icon = self.LEVEL_ICONS.get(icon_type,\
      \ \"\")\n\n        # record.asctime is already formatted by the time format()\
      \ is called,\n        # based on the datefmt provided during Formatter initialization\
      \ or to the Handler.\n        # We will set the datefmt when creating the formatter\
      \ instance below.\n        log_message_content = f\"[{record.levelname}] {icon}{record.getMessage()}\"\
      \n        log_line = f\"{record.asctime} - {record.name} - {level_color}{Style.BRIGHT}{log_message_content}{Style.RESET_ALL}\"\
      \n        return log_line\n\nclass JsonFormatter(logging.Formatter):\n    #\
      \ Keep your existing JsonFormatter as it correctly uses datetime.isoformat()\n\
      \    def formatTime(self, record, datefmt=None):\n        return datetime.fromtimestamp(record.created,\
      \ tz=timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n\
      \n    def format(self, record):\n        log_record = {\n            'timestamp':\
      \ self.formatTime(record),\n            'level': record.levelname,\n       \
      \     'name': record.name,\n            'pid': record.process,\n           \
      \ 'thread': record.threadName,\n            'message': record.getMessage(),\n\
      \            'pathname': record.pathname,\n            'lineno': record.lineno,\n\
      \        }\n        if hasattr(record, 'icon_type'):\n            log_record['icon_type']\
      \ = record.icon_type\n        if hasattr(record, 'extra_data') and isinstance(record.extra_data,\
      \ dict):\n            log_record.update(record.extra_data)\n        if record.exc_info:\n\
      \            log_record['exception'] = {\n                'type': record.exc_info[0].__name__,\n\
      \                'value': str(record.exc_info[1]),\n                'traceback':\
      \ \"\".join(traceback.format_exception(*record.exc_info)) if settings.APP_ENV\
      \ == 'development' else 'Traceback hidden in production'\n            }\n  \
      \      return json.dumps(log_record, ensure_ascii=False, default=str)\n\n# Configure\
      \ root logger slightly differently if needed, but focusing on app logger\nlogger\
      \ = logging.getLogger(\"MessageBroker\")\nlogger.setLevel(settings.LOG_LEVEL)\n\
      logger.propagate = False # Prevent duplicate logs if root logger also has handlers\n\
      \n# Define the date format string ONCE\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S' #\
      \ REMOVED %f\n\n# Avoid adding handlers multiple times if script is reloaded\n\
      if not logger.handlers:\n    # --- CONSOLE HANDLER ---\n    console_handler\
      \ = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(settings.LOG_LEVEL)\n\
      \    # Instantiate the formatter and pass the date format\n    console_formatter\
      \ = ColoramaFormatter(datefmt=DATE_FORMAT)\n    console_handler.setFormatter(console_formatter)\n\
      \n    # --- FILE HANDLER ---\n    file_handler = logging.FileHandler(LOG_FILENAME,\
      \ mode='a', encoding='utf-8')\n    file_handler.setLevel(settings.LOG_LEVEL)\n\
      \    # JsonFormatter handles its own timestamp formatting internally, no datefmt\
      \ needed here\n    file_formatter = JsonFormatter()\n    file_handler.setFormatter(file_formatter)\n\
      \n    logger.addHandler(console_handler)\n    logger.addHandler(file_handler)\n\
      \n# --- Logging Helper Functions ---\n# ... (keep your log_debug, log_info,\
      \ etc. functions as they are) ...\n\n# --- Logging Helper Functions ---\ndef\
      \ log_debug(message: str, icon_type: str = 'DEBUG', extra: Optional[Dict[str,\
      \ Any]] = None): logger.debug(message, extra={'icon_type': icon_type, 'extra_data':\
      \ extra or {}})\ndef log_info(message: str, icon_type: str = 'INFO', extra:\
      \ Optional[Dict[str, Any]] = None): logger.info(message, extra={'icon_type':\
      \ icon_type, 'extra_data': extra or {}})\ndef log_success(message: str, icon_type:\
      \ str = 'SUCCESS', extra: Optional[Dict[str, Any]] = None): logger.info(message,\
      \ extra={'icon_type': icon_type, 'extra_data': extra or {}})\ndef log_warning(message:\
      \ str, icon_type: str = 'WARNING', extra: Optional[Dict[str, Any]] = None):\
      \ logger.warning(message, extra={'icon_type': icon_type, 'extra_data': extra\
      \ or {}})\ndef log_error(message: str, exc_info: bool = False, icon_type: str\
      \ = 'ERROR', extra: Optional[Dict[str, Any]] = None): logger.error(message,\
      \ exc_info=exc_info, extra={'icon_type': icon_type, 'extra_data': extra or {}})\n\
      def log_critical(message: str, exc_info: bool = False, icon_type: str = 'CRITICAL',\
      \ extra: Optional[Dict[str, Any]] = None): logger.critical(message, exc_info=exc_info,\
      \ extra={'icon_type': icon_type, 'extra_data': extra or {}})\ndef log_pipeline(message:\
      \ str, icon_type: str = 'PIPELINE', extra: Optional[Dict[str, Any]] = None):\
      \ logger.info(message, extra={'icon_type': icon_type, 'extra_data': extra or\
      \ {}})\n\n\n# --- Password Hashing Context ---\n# !!! IMPORTANT SECURITY WARNING\
      \ !!!\n# The hardcoded 'admin':'admin' password in the /login route is INSECURE.\n\
      # For production, uncomment and use passlib for proper password hashing.\n#\
      \ Example:\n# pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"\
      auto\")\n# def verify_password(plain_password, hashed_password):\n#     return\
      \ pwd_context.verify(plain_password, hashed_password)\n# def get_password_hash(password):\n\
      #     return pwd_context.hash(password)\n# You would then store the HASHED password,\
      \ not the plain one.\n\n\n# --- Certificate Generation ---\ndef generate_self_signed_cert(cert_path:\
      \ str, key_path: str, key_password: Optional[bytes] = None, common_name: str\
      \ = \"localhost\"):\n    log_info(f\"\U0001F6E1️ Generating new RSA private\
      \ key and self-signed certificate for CN='{common_name}'...\", icon_type='SEC')\n\
      \    try:\n        private_key = rsa.generate_private_key(public_exponent=65537,\
      \ key_size=2048, backend=default_backend())\n        subject = issuer = x509.Name([\n\
      \            x509.NameAttribute(NameOID.COUNTRY_NAME, u\"XX\"), x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME,\
      \ u\"Default\"),\n            x509.NameAttribute(NameOID.LOCALITY_NAME, u\"\
      Default\"), x509.NameAttribute(NameOID.ORGANIZATION_NAME, u\"Message Broker\
      \ V3\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, common_name),\n\
      \        ])\n        # Add Subject Alternative Name (SAN) for browser compatibility\
      \ (localhost + 127.0.0.1)\n        san_extension = x509.SubjectAlternativeName([x509.DNSName(common_name),\
      \ x509.IPAddress(ipaddress.ip_address(\"127.0.0.1\"))])\n        import ipaddress\
      \ # Need to import this\n\n        cert_builder = x509.CertificateBuilder().subject_name(subject).issuer_name(issuer).public_key(private_key.public_key())\
      \ \\\n            .serial_number(x509.random_serial_number()).not_valid_before(datetime.now(timezone.utc))\
      \ \\\n            .not_valid_after(datetime.now(timezone.utc) + timedelta(days=365))\
      \ \\\n            .add_extension(san_extension, critical=False) # Add SAN\n\
      \        certificate = cert_builder.sign(private_key, hashes.SHA256(), default_backend())\n\
      \n        key_pem_encryption = serialization.NoEncryption()\n        if key_password:\
      \ key_pem_encryption = serialization.BestAvailableEncryption(key_password)\n\
      \        with open(key_path, \"wb\") as f: f.write(private_key.private_bytes(encoding=serialization.Encoding.PEM,\
      \ format=serialization.PrivateFormat.PKCS8, encryption_algorithm=key_pem_encryption))\n\
      \        log_success(f\"\U0001F511 Private key saved: {key_path}\", icon_type='SEC')\n\
      \        with open(cert_path, \"wb\") as f: f.write(certificate.public_bytes(serialization.Encoding.PEM))\n\
      \        log_success(f\"\U0001F4DC Self-signed certificate saved: {cert_path}\"\
      , icon_type='SEC')\n        return True\n    except ImportError:\n        log_critical(\"\
      The 'ipaddress' module is needed for certificate generation with IP SAN. Please\
      \ install it.\", icon_type='CRITICAL')\n        return False\n    except Exception\
      \ as e:\n        log_critical(f\"Failed to generate certificates/key: {e}\"\
      , exc_info=True, icon_type='CRITICAL')\n        return False\n\n# --- Application\
      \ Statistics ---\napp_stats: Dict[str, Any] = {\n    \"start_time\": datetime.now(timezone.utc),\n\
      \    \"requests_total\": 0, \"requests_by_route\": {}, \"requests_by_status\"\
      : {},\n    \"queues_total\": 0, \"messages_total\": 0, \"messages_pending\"\
      : 0,\n    \"messages_processing\": 0, \"messages_processed\": 0, \"messages_failed\"\
      : 0,\n    \"last_error\": None,\n    \"system\": {\n        \"python_version\"\
      : platform.python_version(), \"platform\": platform.system(),\n        \"platform_release\"\
      : platform.release(), \"architecture\": platform.machine(),\n    },\n    \"\
      broker_specific\": {\n        \"framework\": \"FastAPI\",\n        \"version\"\
      : settings.VERSION,\n        \"db_engine\": \"sqlite (tortoise-orm)\",\n   \
      \     \"auth_method\": \"jwt (access+refresh, python-jose)\",\n        \"notification\"\
      : \"sse (redis pub/sub)\",\n        \"rate_limit\": \"redis (slowapi)\",\n \
      \       \"graphql\": \"strawberry-graphql\"\n    }\n}\nstats_lock = asyncio.Lock()\
      \ # Use asyncio Lock for safe async updates\n\nasync def update_request_stats(route_template:\
      \ str, method: str, status_code: int):\n    \"\"\"Updates request counters asynchronously\
      \ and safely.\"\"\"\n    async with stats_lock:\n        app_stats[\"requests_total\"\
      ] += 1\n        route_stats = app_stats[\"requests_by_route\"].setdefault(route_template,\
      \ {})\n        route_stats[method] = route_stats.get(method, 0) + 1\n      \
      \  app_stats[\"requests_by_status\"][str(status_code)] = app_stats[\"requests_by_status\"\
      ].get(str(status_code), 0) + 1\n\nasync def update_broker_stats():\n    \"\"\
      \"Updates broker stats from the database asynchronously and concurrently.\"\"\
      \"\n    log_pipeline(\"\U0001F4CA Fetching broker stats from DB...\", icon_type='STATS')\n\
      \    try:\n        q_count_task = Queue.all().count()\n        m_pending_task\
      \ = Message.filter(status='pending').count()\n        m_processing_task = Message.filter(status='processing').count()\n\
      \        m_processed_task = Message.filter(status='processed').count()\n   \
      \     m_failed_task = Message.filter(status='failed').count()\n\n        q_count,\
      \ pending, processing, processed, failed = await asyncio.gather(\n         \
      \   q_count_task, m_pending_task, m_processing_task, m_processed_task, m_failed_task\n\
      \        )\n        total = pending + processing + processed + failed\n\n  \
      \      async with stats_lock:\n            app_stats[\"queues_total\"] = q_count\n\
      \            app_stats[\"messages_pending\"] = pending\n            app_stats[\"\
      messages_processing\"] = processing\n            app_stats[\"messages_processed\"\
      ] = processed\n            app_stats[\"messages_failed\"] = failed\n       \
      \     app_stats[\"messages_total\"] = total\n            # Clear last error\
      \ on successful update if it was set\n            if app_stats[\"last_error\"\
      ] and \"Broker Stats Update Failed\" in app_stats[\"last_error\"]:\n       \
      \          app_stats[\"last_error\"] = None\n\n        log_success(\"\U0001F4CA\
      \ Broker stats updated.\", icon_type='STATS', extra={'counts': {'queues': q_count,\
      \ 'pending': pending, 'processing': processing, 'processed': processed, 'failed':\
      \ failed}})\n\n    except Exception as e:\n        log_error(f\"Error updating\
      \ broker stats: {e}\", icon_type='STATS', exc_info=True)\n        async with\
      \ stats_lock:\n            app_stats[\"last_error\"] = f\"Broker Stats Update\
      \ Failed: {datetime.now(timezone.utc).isoformat()}\"\n\n# --- Database Setup\
      \ (Tortoise ORM with SQLite) ---\nasync def init_tortoise():\n    \"\"\"Initialize\
      \ Tortoise ORM and create schemas if they don't exist.\"\"\"\n    log_info(f\"\
      \U0001F4BE Configuring Tortoise ORM for SQLite: {settings.DATABASE_URL}\", icon_type='DB')\n\
      \    try:\n        await Tortoise.init(\n            db_url=settings.DATABASE_URL,\n\
      \            modules={'models': ['__main__']} # Models are in this script\n\
      \        )\n        await Tortoise.generate_schemas(safe=True) # safe=True avoids\
      \ errors if tables exist\n        log_success(\"\U0001F4BE ORM tables verified/created\
      \ successfully.\", icon_type='DB')\n        await update_broker_stats() # Populate\
      \ initial stats\n    except Exception as e:\n        log_critical(f\"Fatal:\
      \ Failed to initialize Tortoise ORM: {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        sys.exit(1)\n\n# --- Pydantic Models (Input/Output Schemas) ---\nclass\
      \ QueueBase(BaseModel):\n    name: str = Field(..., min_length=1, max_length=255,\
      \ description=\"Unique name for the queue\")\n\nclass QueueCreate(QueueBase):\n\
      \    pass\n\nclass QueueResponse(QueueBase):\n    id: int\n    created_at: datetime\n\
      \    updated_at: datetime\n    message_count: int = Field(default=0, description=\"\
      Current number of messages in the queue\")\n\n    model_config = ConfigDict(from_attributes=True)\
      \ # Pydantic v2 ORM mode\n\nclass MessageBase(BaseModel):\n    content: str\
      \ = Field(..., min_length=1, description=\"The content/payload of the message\"\
      )\n\nclass MessageCreate(MessageBase):\n    pass\n\nclass MessageResponse(MessageBase):\n\
      \    id: int\n    queue_id: int\n    status: str = Field(description=\"Current\
      \ status: pending, processing, processed, failed\")\n    created_at: datetime\n\
      \    updated_at: datetime\n\n    model_config = ConfigDict(from_attributes=True)\n\
      \nclass Token(BaseModel):\n    access_token: str\n    refresh_token: str\n \
      \   token_type: str = \"bearer\"\n\nclass StatsResponse(BaseModel):\n    start_time:\
      \ str = Field(description=\"ISO 8601 timestamp when the server started (UTC)\"\
      )\n    uptime_seconds: float = Field(description=\"Server uptime in seconds\"\
      )\n    uptime_human: str = Field(description=\"Human-readable server uptime\
      \ (e.g., 1d 2h 30m 15s)\")\n    requests_total: int\n    requests_by_route:\
      \ Dict[str, Dict[str, int]]\n    requests_by_status: Dict[str, int] # Keys are\
      \ string representations of status codes\n    queues_total: int\n    messages_total:\
      \ int\n    messages_pending: int\n    messages_processing: int\n    messages_processed:\
      \ int\n    messages_failed: int\n    last_error: Optional[str] = Field(None,\
      \ description=\"Timestamp and type of the last unhandled error, if any\")\n\
      \    system: Dict[str, Any] = Field(description=\"System metrics (CPU, Memory,\
      \ Disk, etc.)\")\n    broker_specific: Dict[str, str] = Field(description=\"\
      Broker implementation details\")\n\nclass LogFileResponse(BaseModel):\n    log_files:\
      \ List[str]\n\n# Payload Models for specific endpoints\nclass QueueCreatePayload(BaseModel):\n\
      \    name: str = Field(..., min_length=1, max_length=255)\n\nclass MessagePayload(BaseModel):\n\
      \    content: str = Field(..., min_length=1)\n\nclass MessagePublishResponse(BaseModel):\n\
      \    message: str = Field(default=\"Message published successfully\")\n    message_id:\
      \ int\n\nclass MessageConsumeResponse(BaseModel):\n    message_id: int\n   \
      \ queue: str\n    content: str\n    status: str = Field(default='processing')\
      \ # Status after consumption\n    retrieved_at: datetime\n\n# --- Tortoise ORM\
      \ Models ---\nclass Queue(models.Model):\n    id = fields.IntField(pk=True)\n\
      \    name = fields.CharField(max_length=255, unique=True, index=True, description=\"\
      Unique queue name\")\n    created_at = fields.DatetimeField(auto_now_add=True)\n\
      \    updated_at = fields.DatetimeField(auto_now=True)\n    # Relationship accessor\
      \ from Message -> Queue\n    messages: fields.ReverseRelation[\"Message\"]\n\
      \n    class Meta:\n        table = \"queues\"\n        ordering = [\"name\"\
      ]\n\n    def __str__(self):\n        return self.name\n\nclass Message(models.Model):\n\
      \    id = fields.IntField(pk=True)\n    queue: fields.ForeignKeyRelation[Queue]\
      \ = fields.ForeignKeyField(\n        'models.Queue', related_name='messages',\
      \ on_delete=fields.CASCADE, description=\"The queue this message belongs to\"\
      \n    )\n    content = fields.TextField(description=\"Message payload\")\n \
      \   status = fields.CharField(\n        max_length=20, default='pending', index=True,\n\
      \        description=\"Status: pending, processing, processed, failed\"\n  \
      \  )\n    created_at = fields.DatetimeField(auto_now_add=True, index=True)\n\
      \    updated_at = fields.DatetimeField(auto_now=True)\n\n    class Meta:\n \
      \       table = \"messages\"\n        # Composite index to speed up finding\
      \ the oldest pending message in a queue\n        indexes = [(\"queue_id\", \"\
      status\", \"created_at\")]\n        ordering = [\"created_at\"] # Default ordering\n\
      \n    def __str__(self):\n        return f\"Message {self.id} ({self.status})\"\
      \n\n\n# --- Redis Connection Pool ---\nredis_sse_pool: Optional[aioredis.ConnectionPool]\
      \ = None\nredis_rate_limit_pool: Optional[aioredis.ConnectionPool] = None\n\
      redis_sse: Optional[aioredis.Redis] = None\nredis_limiter_client: Optional[aioredis.Redis]\
      \ = None\n\nasync def setup_redis():\n    \"\"\"Initializes Redis connection\
      \ pools and clients.\"\"\"\n    global redis_sse_pool, redis_rate_limit_pool,\
      \ redis_sse, redis_limiter_client\n    try:\n        log_pipeline(\"\U0001F4E1\
      \ Configuring Redis connections...\", icon_type='SSE')\n        redis_sse_pool\
      \ = aioredis.ConnectionPool.from_url(f\"{settings.REDIS_URL}/{settings.REDIS_SSE_DB}\"\
      , decode_responses=True, max_connections=20, health_check_interval=30)\n   \
      \     redis_rate_limit_pool = aioredis.ConnectionPool.from_url(f\"{settings.REDIS_URL}/{settings.REDIS_RATE_LIMIT_DB}\"\
      , decode_responses=True, max_connections=20, health_check_interval=30)\n\n \
      \       redis_sse = aioredis.Redis(connection_pool=redis_sse_pool)\n       \
      \ redis_limiter_client = aioredis.Redis(connection_pool=redis_rate_limit_pool)\n\
      \n        # Verify connections\n        await redis_sse.ping()\n        await\
      \ redis_limiter_client.ping()\n        log_success(\"\U0001F4E1 Redis connections\
      \ established and verified.\", icon_type='SSE')\n        return True\n\n   \
      \ except aioredis.RedisError as e:\n        log_critical(f\"Fatal: Failed to\
      \ connect to Redis at {settings.REDIS_URL}: {e}. SSE/Rate Limiting unavailable.\"\
      , icon_type='CRITICAL', exc_info=True)\n        # Allow startup without Redis?\
      \ Depends on requirements. Set clients to None.\n        redis_sse = None\n\
      \        redis_limiter_client = None\n        return False\n    except Exception\
      \ as e:\n        log_critical(f\"Fatal: Unexpected error during Redis setup:\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        redis_sse = None\n  \
      \      redis_limiter_client = None\n        return False # Treat unexpected\
      \ error as critical failure for Redis\n\nasync def shutdown_redis():\n    \"\
      \"\"Closes Redis connections and pools gracefully.\"\"\"\n    log_pipeline(\"\
      \U0001F50C Closing Redis connections...\", icon_type='SHUTDOWN')\n    # Close\
      \ clients first\n    if redis_sse:\n        try: await redis_sse.close()\n \
      \       except Exception as e: log_warning(f\"Error closing Redis SSE client:\
      \ {e}\", icon_type='SSE')\n    if redis_limiter_client:\n        try: await\
      \ redis_limiter_client.close()\n        except Exception as e: log_warning(f\"\
      Error closing Redis Limiter client: {e}\", icon_type='RATELIMIT')\n    # Then\
      \ disconnect pools\n    if redis_sse_pool:\n        try: await redis_sse_pool.disconnect(inuse_connections=True)\n\
      \        except Exception as e: log_warning(f\"Error disconnecting Redis SSE\
      \ pool: {e}\", icon_type='SSE')\n    if redis_rate_limit_pool:\n        try:\
      \ await redis_rate_limit_pool.disconnect(inuse_connections=True)\n        except\
      \ Exception as e: log_warning(f\"Error disconnecting Redis Limiter pool: {e}\"\
      , icon_type='RATELIMIT')\n    log_success(\"\U0001F50C Redis connections/pools\
      \ closed.\", icon_type='SHUTDOWN')\n\n# --- Lifespan Context Manager (Startup/Shutdown\
      \ Events) ---\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n   \
      \ # Startup Sequence\n    log_info(\"\U0001F680 Application Startup Initiated...\"\
      , icon_type='STARTUP')\n    # 1. Initialize Tortoise ORM\n    await init_tortoise()\n\
      \    # 2. Initialize Redis\n    redis_ok = await setup_redis()\n    limiter_client\
      \ = None # Initialize to None\n    if redis_ok:\n        # Store clients in\
      \ app state for potential direct access (optional)\n        app.state.redis_sse\
      \ = redis_sse\n        app.state.redis_limiter = redis_limiter_client\n    \
      \    limiter_client = redis_limiter_client # Get the client for SlowAPI\n  \
      \  else:\n        log_warning(\"Redis setup failed, proceeding without Redis\
      \ features (SSE, Rate Limiting).\", icon_type='WARNING')\n        app.state.redis_sse\
      \ = None\n        app.state.redis_limiter = None\n\n    # --- MOVED FROM @app.on_event\
      \ ---\n    # 3. Configure and add SlowAPI middleware AFTER Redis client is potentially\
      \ initialized\n    if limiter_client:\n        app.add_middleware(SlowAPIMiddleware,\
      \ redis_client=limiter_client)\n        log_info(f\"⏱️ Rate Limiter configured\
      \ with Redis backend (DB {settings.REDIS_RATE_LIMIT_DB}).\", icon_type='RATELIMIT')\n\
      \    else:\n        # Fallback to in-memory store if Redis client setup failed\n\
      \        app.add_middleware(SlowAPIMiddleware)\n        log_warning(\"⏱️ Rate\
      \ Limiter configured with In-Memory backend (Redis unavailable).\", icon_type='RATELIMIT')\n\
      \    # --- END MOVED SECTION ---\n\n    log_success(\"\U0001F680 Application\
      \ Startup Complete.\", icon_type='STARTUP')\n    yield\n    # Shutdown Sequence\n\
      \    log_info(\"\U0001F6D1 Application Shutdown Initiated...\", icon_type='SHUTDOWN')\n\
      \    # 1. Close Redis Connections\n    await shutdown_redis()\n    # 2. Close\
      \ Database Connections\n    try:\n        await Tortoise.close_connections()\n\
      \        log_success(\"\U0001F4BE Database connections closed.\", icon_type='DB')\n\
      \    except Exception as e:\n         log_warning(f\"Error closing Tortoise\
      \ connections: {e}\", icon_type='DB')\n    log_success(\"\U0001F6D1 Application\
      \ Shutdown Complete.\", icon_type='SHUTDOWN')\n\n# --- FastAPI Application Setup\
      \ ---\nlog_info(f\"\U0001F680 Initializing FastAPI Application ({settings.PROJECT_NAME}\
      \ v{settings.VERSION})...\", icon_type='STARTUP')\napp = FastAPI(\n    title=settings.PROJECT_NAME,\n\
      \    version=settings.VERSION,\n    description=__doc__.split('---')[0].strip(),\
      \ # Use module docstring\n    lifespan=lifespan,\n    docs_url=\"/docs\",\n\
      \    redoc_url=\"/redoc\",\n    openapi_tags=[ # Define tags for better organization\
      \ in Swagger UI\n        {\"name\": \"General\", \"description\": \"Basic health\
      \ and info endpoints\"},\n        {\"name\": \"Authentication\", \"description\"\
      : \"User login and token management\"},\n        {\"name\": \"Monitoring\",\
      \ \"description\": \"System stats and log viewing\"},\n        {\"name\": \"\
      Queues\", \"description\": \"Operations for managing message queues\"},\n  \
      \      {\"name\": \"Messages\", \"description\": \"Publishing, consuming, and\
      \ managing messages\"},\n        {\"name\": \"Realtime (SSE)\", \"description\"\
      : \"Server-Sent Event streams for queue updates\"},\n        {\"name\": \"GraphQL\"\
      , \"description\": \"GraphQL API endpoint\"},\n    ]\n)\n\n# --- Rate Limiter\
      \ Setup (SlowAPI with Async Redis or Memory Fallback) ---\nlimiter = Limiter(key_func=get_remote_address,\
      \ default_limits=[settings.DEFAULT_RATE_LIMIT])\napp.state.limiter = limiter\
      \ # Make limiter available globally if needed\napp.add_exception_handler(RateLimitExceeded,\
      \ _rate_limit_exceeded_handler)\n\n@app.on_event(\"startup\")\nasync def startup_configure_slowapi_middleware():\n\
      \    \"\"\"Adds SlowAPI middleware after Redis client is potentially initialized\
      \ by lifespan.\"\"\"\n    # Access the client stored in app.state by the lifespan\
      \ manager\n    limiter_client = getattr(app.state, \"redis_limiter\", None)\n\
      \    if limiter_client:\n        app.add_middleware(SlowAPIMiddleware, redis_client=limiter_client)\n\
      \        log_info(f\"⏱️ Rate Limiter configured with Redis backend (DB {settings.REDIS_RATE_LIMIT_DB}).\"\
      , icon_type='RATELIMIT')\n    else:\n        # Fallback to in-memory store if\
      \ Redis client setup failed\n        app.add_middleware(SlowAPIMiddleware)\n\
      \        log_warning(\"⏱️ Rate Limiter configured with In-Memory backend (Redis\
      \ unavailable).\", icon_type='RATELIMIT')\n\n# --- CORS Middleware ---\napp.add_middleware(\n\
      \    CORSMiddleware,\n    allow_origins=settings.ALLOWED_ORIGINS,\n    allow_credentials=True,\n\
      \    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\nlog_info(f\"\U0001F6E1\
      ️ CORS configured for origins: {settings.ALLOWED_ORIGINS}\", icon_type='SEC')\n\
      \n# --- Authentication Dependencies ---\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"\
      login\", auto_error=False) # auto_error=False to handle optional auth later\
      \ if needed\nbearer_scheme = HTTPBearer(auto_error=False)\n\nasync def create_jwt_token(data:\
      \ dict, expires_delta: timedelta) -> str:\n    to_encode = data.copy()\n   \
      \ expire = datetime.now(timezone.utc) + expires_delta\n    to_encode.update({\"\
      exp\": expire, \"iat\": datetime.now(timezone.utc)})\n    encoded_jwt = jwt.encode(to_encode,\
      \ settings.JWT_SECRET_KEY, algorithm=settings.ALGORITHM)\n    return encoded_jwt\n\
      \nasync def create_access_token(username: str) -> str:\n    return await create_jwt_token(\n\
      \        {\"sub\": username, \"type\": \"access\"}, timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n\
      \    )\n\nasync def create_refresh_token(username: str) -> str:\n    return\
      \ await create_jwt_token(\n        {\"sub\": username, \"type\": \"refresh\"\
      }, timedelta(days=settings.REFRESH_TOKEN_EXPIRE_DAYS)\n    )\n\n# Unified Token\
      \ Decode Logic\nasync def _decode_token(token: str, expected_type: str) -> str:\n\
      \    \"\"\"Decodes JWT, validates type and sub, returns username or raises HTTPException.\"\
      \"\"\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n\
      \        detail=f\"Could not validate {expected_type} token\",\n        headers={\"\
      WWW-Authenticate\": f\"Bearer error=\\\"invalid_token\\\", error_description=\\\
      \"Invalid {expected_type} token\\\"\"},\n    )\n    if not token:\n        raise\
      \ credentials_exception\n\n    try:\n        payload = jwt.decode(\n       \
      \      token,\n             settings.JWT_SECRET_KEY,\n             algorithms=[settings.ALGORITHM],\n\
      \             options={\"verify_aud\": False} # No audience verification for\
      \ this example\n        )\n        username: Optional[str] = payload.get(\"\
      sub\")\n        token_type: Optional[str] = payload.get(\"type\")\n\n      \
      \  if username is None or token_type != expected_type:\n            log_warning(f\"\
      {expected_type.capitalize()} token validation failed: 'sub' missing or type\
      \ mismatch ('{token_type}' != '{expected_type}').\", icon_type='AUTH', extra={\"\
      payload\": payload})\n            raise credentials_exception\n\n        # log_debug(f\"\
      User '{username}' authenticated via {expected_type} token.\", icon_type='AUTH')\n\
      \        return username\n    except JWTError as e:\n        log_warning(f\"\
      {expected_type.capitalize()} token validation JWTError: {e}\", icon_type='AUTH',\
      \ extra={\"token\": token[:10] + \"...\"})\n        raise credentials_exception\n\
      \    except Exception as e:\n         log_error(f\"Unexpected error during {expected_type}\
      \ token decode: {e}\", icon_type='AUTH', exc_info=True)\n         raise credentials_exception\
      \ # Re-raise as the original unauthorized exception\n\n# Dependency for Access\
      \ Token\nasync def get_current_user(token: Optional[str] = Depends(oauth2_scheme))\
      \ -> str:\n    \"\"\"Dependency to validate JWT access token and return the\
      \ username.\"\"\"\n    # If token is None (because auto_error=False), raise\
      \ manually\n    if token is None:\n         raise HTTPException(\n         \
      \   status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Not authenticated\"\
      ,\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    return\
      \ await _decode_token(token, \"access\")\n\n# Dependency for Refresh Token (expects\
      \ Bearer header)\nasync def validate_refresh_token(credentials: Optional[HTTPAuthorizationCredentials]\
      \ = Depends(bearer_scheme)) -> str:\n    \"\"\"Dependency to validate JWT refresh\
      \ token from Bearer header and return username.\"\"\"\n    if credentials is\
      \ None:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n\
      \            detail=\"Refresh token missing or invalid header\",\n         \
      \   headers={\"WWW-Authenticate\": \"Bearer error=\\\"invalid_request\\\"\"\
      },\n        )\n    return await _decode_token(credentials.credentials, \"refresh\"\
      )\n\n\n# --- Stats Update Middleware ---\n@app.middleware(\"http\")\nasync def\
      \ update_stats_middleware(request: Request, call_next):\n    start_time_mw =\
      \ time.perf_counter()\n    response = await call_next(request)\n    process_time_mw\
      \ = time.perf_counter() - start_time_mw\n    response.headers[\"X-Process-Time\"\
      ] = f\"{process_time_mw:.4f}s\" # Add units\n\n    # Update request stats after\
      \ response is generated\n    route = request.scope.get(\"route\")\n    if route\
      \ and hasattr(route, 'path'):\n        route_template = route.path\n       \
      \ # More robust ignore list, also handles potential None route path\n      \
      \  ignored_prefixes = ('/docs', '/redoc', '/openapi.json', '/stream', '/logs',\
      \ '/graphql', '/favicon.ico', '/stats')\n        if route_template and not route_template.startswith(ignored_prefixes):\n\
      \            await update_request_stats(route_template, request.method, response.status_code)\n\
      \n    return response\n\n# --- Helper Function for DB Lookups ---\nasync def\
      \ _get_queue_or_404(queue_name: str, conn=None) -> Queue:\n    \"\"\"Fetches\
      \ a queue by name or raises HTTPException 404. Can use existing transaction\
      \ connection.\"\"\"\n    try:\n        query = Queue.all()\n        if conn:\
      \ query = query.using_connection(conn)\n        queue = await query.get(name=queue_name)\n\
      \        return queue\n    except DoesNotExist:\n        log_warning(f\"Queue\
      \ '{queue_name}' not found in database.\", icon_type='DB')\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=f\"Queue '{queue_name}' not found\")\n    except Exception as e:\n\
      \        log_error(f\"Database error fetching queue '{queue_name}': {e}\", icon_type='DB',\
      \ exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Database error retrieving queue\")\n\n# --- SSE Notification Function\
      \ ---\nasync def notify_sse(queue_name: str, message_id: int, event_type: str):\n\
      \    \"\"\"Publishes a notification via Redis Pub/Sub for SSE listeners.\"\"\
      \"\n    if not redis_sse:\n        log_warning(f\"Cannot send SSE notification\
      \ for queue '{queue_name}': Redis SSE client unavailable.\", icon_type='SSE')\n\
      \        return\n    try:\n        sse_data = json.dumps({\"queue\": queue_name,\
      \ \"message_id\": message_id, \"event\": event_type, \"timestamp\": datetime.now(timezone.utc).isoformat()})\n\
      \        redis_channel = f\"sse:{queue_name}\"\n        # log_pipeline(f\"\U0001F4E1\
      \ Publishing SSE to Redis '{redis_channel}': {sse_data}\", icon_type='SSE')\
      \ # Can be verbose\n        published_count = await redis_sse.publish(redis_channel,\
      \ sse_data)\n        if published_count > 0:\n             log_debug(f\"\U0001F4E1\
      \ SSE published to '{redis_channel}' ({published_count} listeners). Data: {sse_data}\"\
      , icon_type='SSE')\n        else:\n             log_debug(f\"\U0001F4E1 SSE\
      \ published to '{redis_channel}' (0 listeners). Data: {sse_data}\", icon_type='SSE')\n\
      \n    except aioredis.RedisError as e:\n        log_error(f\"Redis error publishing\
      \ SSE for queue '{queue_name}': {e}\", icon_type='SSE', exc_info=True)\n   \
      \ except Exception as e:\n        log_error(f\"Error preparing/publishing SSE\
      \ notification for queue '{queue_name}': {e}\", icon_type='SSE', exc_info=True)\n\
      \n\n# --- =================== ---\n# --- API ROUTE DEFINITIONS ---\n# --- ===================\
      \ ---\n\n# --- General Routes ---\n@app.get(\"/\", tags=[\"General\"], summary=\"\
      Health Check\")\n@limiter.limit(\"5/second\")\nasync def index(request: Request):\n\
      \    \"\"\"Provides a basic health check and server information.\"\"\"\n   \
      \ log_info(\"\U0001F310 GET / request\", icon_type='HTTP', extra={\"client\"\
      : request.client.host})\n    return {\n        \"message\": settings.PROJECT_NAME,\n\
      \        \"status\": \"ok\",\n        \"version\": settings.VERSION,\n     \
      \   \"timestamp\": datetime.now(timezone.utc).isoformat()\n    }\n\n# --- Authentication\
      \ Routes ---\n@app.post(\"/login\", response_model=Token, tags=[\"Authentication\"\
      ], summary=\"User Login\")\n@limiter.limit(\"10/minute\") # Stricter limit for\
      \ login attempts\nasync def login_for_access_token(\n    request: Request,\n\
      \    form_data: OAuth2PasswordRequestForm = Depends(),\n):\n    \"\"\"\n   \
      \ Handles user login using OAuth2 compatible form data (username/password).\n\
      \n    **Note:** Uses insecure hardcoded credentials ('admin'/'admin') for demo\
      \ purposes.\n    Replace with secure password verification (e.g., using passlib)\
      \ in production.\n    \"\"\"\n    log_info(f\"\U0001F511 POST /login attempt\
      \ for user: '{form_data.username}'\", icon_type='AUTH', extra={\"client\": request.client.host})\n\
      \n    # --- !!! REPLACE WITH SECURE PASSWORD VERIFICATION !!! ---\n    # Example\
      \ using passlib (if pwd_context is configured):\n    # user = await User.get_or_none(username=form_data.username)\
      \ # Fetch user from DB\n    # if not user or not verify_password(form_data.password,\
      \ user.hashed_password):\n    #     log_warning(...)\n    #     raise HTTPException(...)\n\
      \    if form_data.username == 'admin' and form_data.password == 'admin': # INSECURE\
      \ DEMO\n        log_pipeline(f\"Credentials valid for '{form_data.username}'.\
      \ Generating tokens...\")\n        access_token = await create_access_token(username=form_data.username)\n\
      \        refresh_token = await create_refresh_token(username=form_data.username)\n\
      \        log_success(f\"Tokens generated for '{form_data.username}'.\", icon_type='AUTH')\n\
      \        return Token(access_token=access_token, refresh_token=refresh_token)\n\
      \    else:\n        log_warning(f\"Login failed for '{form_data.username}':\
      \ Invalid credentials.\", icon_type='AUTH')\n        raise HTTPException(\n\
      \            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"\
      Incorrect username or password\",\n            headers={\"WWW-Authenticate\"\
      : \"Bearer error=\\\"invalid_grant\\\"\"},\n        )\n\n@app.post(\"/refresh\"\
      , response_model=Token, tags=[\"Authentication\"], summary=\"Refresh Access\
      \ Token\")\n@limiter.limit(\"20/minute\")\nasync def refresh_access_token(\n\
      \    request: Request,\n    username: str = Depends(validate_refresh_token)\
      \ # Validates refresh token in header\n):\n    \"\"\"Issues a new access and\
      \ refresh token using a valid refresh token (passed via Bearer auth header).\"\
      \"\"\n    log_info(f\"\U0001F511 POST /refresh request by user '{username}'\"\
      , icon_type='AUTH', extra={\"client\": request.client.host})\n    new_access_token\
      \ = await create_access_token(username=username)\n    # Rotate refresh token\
      \ for better security\n    new_refresh_token = await create_refresh_token(username=username)\n\
      \    log_success(f\"New access/refresh tokens generated for '{username}'.\"\
      , icon_type='AUTH')\n    return Token(access_token=new_access_token, refresh_token=new_refresh_token)\n\
      \n# --- Monitoring Routes ---\n@app.get(\"/stats\", response_model=StatsResponse,\
      \ tags=[\"Monitoring\"], summary=\"Get System Statistics\")\n@limiter.limit(\"\
      30/minute\")\nasync def get_stats(\n    request: Request,\n    current_user:\
      \ str = Depends(get_current_user)\n) -> StatsResponse:\n    \"\"\"Returns current\
      \ application, system, and broker statistics (requires authentication).\"\"\"\
      \n    log_info(f\"\U0001F4CA GET /stats request by user '{current_user}'\",\
      \ icon_type='STATS', extra={\"client\": request.client.host})\n\n    # Update\
      \ broker stats from DB (uses Tortoise)\n    await update_broker_stats()\n\n\
      \    # Collect system stats using psutil (in thread pool for potentially blocking\
      \ calls)\n    system_metrics = {}\n    try:\n        process = psutil.Process(os.getpid())\n\
      \n        async def _get_psutil_data():\n            mem_info = process.memory_info()\n\
      \            proc_cpu = process.cpu_percent(interval=0.1) # Blocking call\n\
      \            sys_cpu = psutil.cpu_percent(interval=0.1) # Blocking call\n  \
      \          virt_mem = psutil.virtual_memory() # Blocking call\n            try:\n\
      \                disk_parts = psutil.disk_partitions(all=False) # Blocking call\n\
      \            except Exception as disk_e:\n                log_warning(f\"Could\
      \ not get disk partitions: {disk_e}\", icon_type='STATS')\n                disk_parts\
      \ = []\n\n            disk_usage_data = {}\n            for part in disk_parts:\n\
      \                try:\n                    # Basic filtering of irrelevant partitions\n\
      \                    if not os.path.exists(part.mountpoint) or not os.path.ismount(part.mountpoint):\
      \ continue\n                    if 'loop' in part.device or 'snap' in part.device\
      \ or part.fstype in ['squashfs', 'tmpfs', 'devtmpfs', 'fuse.gvfsd-fuse', 'overlay']:\
      \ continue\n                    usage = psutil.disk_usage(part.mountpoint) #\
      \ Blocking call\n                    disk_usage_data[part.mountpoint] = {\n\
      \                        \"total_gb\": round(usage.total / (1024**3), 2),\n\
      \                        \"used_gb\": round(usage.used / (1024**3), 2),\n  \
      \                      \"free_gb\": round(usage.free / (1024**3), 2),\n    \
      \                    \"percent\": usage.percent\n                    }\n   \
      \             except Exception as part_e:\n                    log_warning(f\"\
      Could not get disk usage for {getattr(part, 'mountpoint', 'N/A')}: {part_e}\"\
      , icon_type='STATS')\n\n            return {\n                \"cpu_percent\"\
      : sys_cpu,\n                \"memory_total_gb\": round(virt_mem.total / (1024**3),\
      \ 2),\n                \"memory_available_gb\": round(virt_mem.available / (1024**3),\
      \ 2),\n                \"memory_used_gb\": round(virt_mem.used / (1024**3),\
      \ 2),\n                \"memory_percent\": virt_mem.percent,\n             \
      \   \"disk_usage\": disk_usage_data or {\"info\": \"No valid partitions found\
      \ or error reading usage.\"},\n                \"process_memory_mb\": round(mem_info.rss\
      \ / (1024**2), 2),\n                \"process_cpu_percent\": proc_cpu,\n   \
      \             \"load_average\": os.getloadavg() if hasattr(os, 'getloadavg')\
      \ else \"N/A\",\n                \"cpu_count_logical\": psutil.cpu_count(logical=True),\n\
      \                \"cpu_count_physical\": psutil.cpu_count(logical=False),\n\
      \            }\n\n        system_metrics = await asyncio.to_thread(_get_psutil_data)\n\
      \n    except ImportError:\n        log_warning(\"psutil not installed, system\
      \ stats unavailable.\", icon_type='STATS')\n        system_metrics[\"error\"\
      ] = \"psutil package not installed\"\n    except Exception as e:\n        log_warning(f\"\
      Error collecting system stats: {e}\", icon_type='STATS', exc_info=True)\n  \
      \      system_metrics[\"error\"] = f\"psutil data collection failed: {type(e).__name__}\"\
      \n\n    # Construct response data safely using the lock\n    response_data =\
      \ {}\n    async with stats_lock:\n        current_stats_copy = app_stats.copy()\
      \ # Work on a copy\n        current_stats_copy[\"system\"].update(system_metrics)\
      \ # Merge system metrics\n\n        # Calculate uptime\n        start_time_dt\
      \ = current_stats_copy[\"start_time\"]\n        uptime_delta = datetime.now(timezone.utc)\
      \ - start_time_dt\n        uptime_seconds = uptime_delta.total_seconds()\n \
      \       current_stats_copy[\"uptime_seconds\"] = round(uptime_seconds, 2)\n\n\
      \        days, rem = divmod(int(uptime_seconds), 86400)\n        hours, rem\
      \ = divmod(rem, 3600)\n        minutes, seconds = divmod(rem, 60)\n        parts\
      \ = [f\"{days}d\" if days else \"\", f\"{hours}h\" if hours else \"\", f\"{minutes}m\"\
      \ if minutes else \"\", f\"{seconds}s\"]\n        current_stats_copy[\"uptime_human\"\
      ] = \" \".join(p for p in parts if p) or \"0s\"\n\n        # Ensure dates are\
      \ strings, status codes are strings\n        current_stats_copy[\"start_time\"\
      ] = start_time_dt.isoformat()\n        # requests_by_status keys are already\
      \ strings from update_request_stats\n        response_data = current_stats_copy\n\
      \n    log_success(f\"Stats returned for user '{current_user}'.\", icon_type='STATS')\n\
      \    try:\n        # Validate final data against the Pydantic model\n      \
      \  return StatsResponse.model_validate(response_data)\n    except ValidationError\
      \ as e:\n        log_critical(f\"Stats data validation failed: {e.errors()}\"\
      , icon_type='CRITICAL', extra={\"invalid_stats\": response_data})\n        raise\
      \ HTTPException(status_code=500, detail=\"Internal Server Error: Failed to generate\
      \ valid stats data.\")\n\n\n@app.get(\"/logs\", response_model=LogFileResponse,\
      \ tags=[\"Monitoring\"], summary=\"List Log Files\")\n@limiter.limit(\"10/minute\"\
      )\nasync def list_log_files(\n    request: Request,\n    current_user: str =\
      \ Depends(get_current_user)\n):\n    \"\"\"Lists available JSON log files in\
      \ the configured log directory (requires authentication).\"\"\"\n    log_info(f\"\
      \U0001F4C4 GET /logs request by user '{current_user}'\", icon_type='LOGS', extra={\"\
      client\": request.client.host})\n    try:\n        # Use asyncio.to_thread for\
      \ os.listdir\n        log_files_all = await asyncio.to_thread(os.listdir, settings.LOG_DIR)\n\
      \        log_files_json = sorted(\n            [f for f in log_files_all if\
      \ f.endswith('.json') and os.path.isfile(os.path.join(settings.LOG_DIR, f))],\n\
      \            reverse=True # Show newest first\n        )\n        log_success(f\"\
      Found {len(log_files_json)} JSON log files.\", icon_type='LOGS')\n        return\
      \ LogFileResponse(log_files=log_files_json)\n    except FileNotFoundError:\n\
      \         log_error(f\"Log directory '{settings.LOG_DIR}' not found.\", icon_type='LOGS')\n\
      \         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"\
      Log directory configured but not found\")\n    except OSError as e:\n      \
      \  log_error(f\"Error listing log files in '{settings.LOG_DIR}': {e}\", exc_info=True,\
      \ icon_type='LOGS')\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error accessing log directory\")\n\n@app.get(\"/logs/{filename:path}\"\
      , response_model=List[Dict[str, Any]], tags=[\"Monitoring\"], summary=\"Get\
      \ Log File Content\")\n@limiter.limit(\"60/minute\") # Limit log reads\nasync\
      \ def get_log_file(\n    request: Request,\n    filename: str = Path(..., title=\"\
      Log filename\", description=\"Name of the JSON log file to retrieve\"),\n  \
      \  start: Optional[int] = FastQuery(None, ge=1, description=\"Start line number\
      \ (1-based index)\"),\n    end: Optional[int] = FastQuery(None, ge=1, description=\"\
      End line number (inclusive)\"),\n    tail: Optional[int] = FastQuery(None, ge=1,\
      \ le=10000, description=\"Return last N lines (max 10000)\"), # Limit tail size\n\
      \    current_user: str = Depends(get_current_user)\n) -> List[Dict]:\n    \"\
      \"\"\n    Retrieves the content of a specific JSON log file, allowing slicing\
      \ or tailing (requires authentication).\n    Each line is parsed as JSON. Invalid\
      \ lines are returned with an error indicator.\n    \"\"\"\n    safe_filename\
      \ = secure_filename(filename)\n    if not safe_filename or safe_filename !=\
      \ filename or not safe_filename.endswith('.json'):\n        log_warning(f\"\
      Invalid log file access attempt: '{filename}' by user '{current_user}'\", icon_type='SEC')\n\
      \        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"\
      Invalid or non-JSON log filename provided\")\n\n    log_path = os.path.join(settings.LOG_DIR,\
      \ safe_filename)\n    log_info(f\"\U0001F4C4 GET /logs/{safe_filename} request\
      \ by '{current_user}' (start={start}, end={end}, tail={tail})\", icon_type='LOGS')\n\
      \n    # Define synchronous file reading logic\n    def read_and_parse_log_sync():\n\
      \        if not os.path.isfile(log_path):\n            return None # Indicate\
      \ file not found\n\n        lines_to_parse = []\n        try:\n            if\
      \ tail is not None and tail > 0:\n                with open(log_path, 'r', encoding='utf-8')\
      \ as f:\n                    # Use deque for efficient tailing\n           \
      \         lines_to_parse = deque(f, maxlen=tail)\n            else:\n      \
      \          with open(log_path, 'r', encoding='utf-8') as f:\n              \
      \      all_lines_iter = enumerate(f, 1) # 1-based line numbers\n           \
      \         line_count_in_range = 0\n                    for line_num, line in\
      \ all_lines_iter:\n                        if start is not None and line_num\
      \ < start: continue\n                        if end is not None and line_num\
      \ > end: break\n                        lines_to_parse.append(line.strip())\n\
      \                        line_count_in_range += 1\n                        #\
      \ Prevent excessive memory usage for open-ended ranges\n                   \
      \     if start is not None and end is None and line_count_in_range >= 10000:\n\
      \                            log_warning(f\"Log file read for '{safe_filename}'\
      \ truncated at 10000 lines (start={start}, no end).\", icon_type='LOGS')\n \
      \                           lines_to_parse.append(json.dumps({\"_warning\":\
      \ \"Result set truncated at 10000 lines\", \"_limit\": 10000}))\n          \
      \                  break\n        except Exception as read_exc:\n          \
      \  log_error(f\"Error reading log file '{safe_filename}': {read_exc}\", exc_info=True,\
      \ icon_type='LOGS')\n            # Return an error entry instead of raising\
      \ here to indicate read failure\n            return [{\"_error\": f\"Failed\
      \ to read file: {read_exc}\"}]\n\n        # Parse JSON lines\n        parsed_lines\
      \ = []\n        for i, line in enumerate(lines_to_parse):\n            line_num_info\
      \ = f\"tail_{i+1}\" if tail else (start or 1) + i\n            try:\n      \
      \          if line: # Avoid parsing empty lines\n                    parsed_lines.append(json.loads(line))\n\
      \                # Optionally add indicator for empty lines if not tailing:\n\
      \                # elif tail is None: parsed_lines.append({\"_info\": \"Empty\
      \ line\", \"_line\": line_num_info})\n            except json.JSONDecodeError:\n\
      \                parsed_lines.append({\"_error\": \"Invalid JSON\", \"_line\"\
      : line_num_info, \"_raw\": line[:250]}) # Include raw snippet\n            except\
      \ Exception as parse_exc:\n                 parsed_lines.append({\"_error\"\
      : f\"Parsing error: {parse_exc}\", \"_line\": line_num_info, \"_raw\": line[:250]})\n\
      \n        return parsed_lines\n\n    # Run the synchronous function in a thread\
      \ pool\n    try:\n        result_lines = await asyncio.to_thread(read_and_parse_log_sync)\n\
      \n        if result_lines is None:\n            log_warning(f\"Log file not\
      \ found: {log_path}\", icon_type='LOGS')\n            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=f\"Log file '{safe_filename}' not found\")\n\n        log_success(f\"\
      {len(result_lines)} log entries returned from '{safe_filename}'.\", icon_type='LOGS')\n\
      \        return result_lines\n\n    except HTTPException:\n        raise # Re-raise\
      \ existing HTTP exceptions\n    except Exception as e:\n        log_error(f\"\
      Unexpected error processing log file '{safe_filename}': {e}\", exc_info=True,\
      \ icon_type='LOGS')\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Unexpected error processing log file\")\n\n# --- Queue Routes ---\n\
      @app.get(\"/queues\", response_model=List[QueueResponse], tags=[\"Queues\"],\
      \ summary=\"List All Queues\")\n@limiter.limit(\"60/minute\")\nasync def list_queues(\n\
      \    request: Request,\n    current_user: str = Depends(get_current_user),\n\
      ) -> List[QueueResponse]:\n    \"\"\"Lists all available message queues, including\
      \ the count of messages in each (requires authentication).\"\"\"\n    log_info(f\"\
      \U0001F4CB GET /queues request by user '{current_user}'\", icon_type='QUEUE')\n\
      \    try:\n        queues = await Queue.all().order_by('name')\n        if not\
      \ queues:\n            return [] # Return empty list if no queues exist\n\n\
      \        # Fetch message counts concurrently\n        count_tasks = {q.id: Message.filter(queue_id=q.id).count()\
      \ for q in queues}\n        message_counts = await asyncio.gather(*count_tasks.values())\n\
      \        # Map counts back to queues using the keys from count_tasks\n     \
      \   counts_dict = dict(zip(count_tasks.keys(), message_counts))\n\n        response_list\
      \ = [\n            QueueResponse(\n                id=q.id,\n              \
      \  name=q.name,\n                created_at=q.created_at,\n                updated_at=q.updated_at,\n\
      \                message_count=counts_dict.get(q.id, 0) # Get count from gathered\
      \ results\n            ) for q in queues\n        ]\n        log_success(f\"\
      Returned {len(response_list)} queues.\", icon_type='QUEUE')\n        return\
      \ response_list\n    except Exception as e:\n        log_error(f\"Error listing\
      \ queues: {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error retrieving queue list\")\n\n@app.post(\"/queues\", response_model=QueueResponse,\
      \ status_code=status.HTTP_201_CREATED, tags=[\"Queues\"], summary=\"Create New\
      \ Queue\")\n@limiter.limit(\"30/minute\")\nasync def create_queue(\n    request:\
      \ Request,\n    payload: QueueCreatePayload, # Use dedicated payload model\n\
      \    current_user: str = Depends(get_current_user),\n) -> QueueResponse:\n \
      \   \"\"\"Creates a new message queue. Returns 409 Conflict if the queue name\
      \ already exists (requires authentication).\"\"\"\n    queue_name = payload.name\n\
      \    log_info(f\"➕ POST /queues request by '{current_user}' to create '{queue_name}'\"\
      , icon_type='QUEUE')\n    try:\n        # Use get_or_create for atomic check-and-create\n\
      \        new_queue, created = await Queue.get_or_create(name=queue_name)\n \
      \       if not created:\n            log_warning(f\"Queue '{queue_name}' already\
      \ exists. Creation request denied (409).\", icon_type='QUEUE')\n           \
      \ raise HTTPException(\n                status_code=status.HTTP_409_CONFLICT,\n\
      \                detail=f\"Queue with name '{queue_name}' already exists.\"\n\
      \            )\n        log_success(f\"Queue '{queue_name}' created successfully\
      \ (ID: {new_queue.id}).\", icon_type='QUEUE')\n        # Convert ORM model to\
      \ Pydantic response model (message_count defaults to 0)\n        return QueueResponse.model_validate(new_queue)\n\
      \    except IntegrityError: # Should be caught by get_or_create, but as a fallback\n\
      \         log_warning(f\"IntegrityError during queue creation for '{queue_name}'.\
      \ Likely already exists.\", icon_type='DB')\n         raise HTTPException(\n\
      \             status_code=status.HTTP_409_CONFLICT,\n             detail=f\"\
      Queue with name '{queue_name}' already exists (database constraint).\"\n   \
      \      )\n    except Exception as e:\n        log_error(f\"Error creating queue\
      \ '{queue_name}': {e}\", icon_type='CRITICAL', exc_info=True)\n        raise\
      \ HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"\
      Error creating queue\")\n\n@app.get(\"/queues/{queue_name}\", response_model=QueueResponse,\
      \ tags=[\"Queues\"], summary=\"Get Queue Details\")\n@limiter.limit(\"60/minute\"\
      )\nasync def get_queue(\n    request: Request,\n    queue_name: str = Path(...,\
      \ description=\"Name of the queue\"),\n    current_user: str = Depends(get_current_user),\n\
      ) -> QueueResponse:\n    \"\"\"Gets details for a specific queue by name, including\
      \ its message count (requires authentication).\"\"\"\n    log_info(f\"\U0001F4E5\
      \ GET /queues/{queue_name} request by user '{current_user}'\", icon_type='QUEUE')\n\
      \    try:\n        queue = await _get_queue_or_404(queue_name) # Handles 404\n\
      \        message_count = await Message.filter(queue_id=queue.id).count()\n \
      \       log_success(f\"Details for queue '{queue_name}' returned.\", icon_type='QUEUE')\n\
      \        response = QueueResponse.model_validate(queue)\n        response.message_count\
      \ = message_count\n        return response\n    except HTTPException:\n    \
      \    raise # Let 404 from _get_queue_or_404 pass through\n    except Exception\
      \ as e:\n        log_error(f\"Error getting queue details for '{queue_name}':\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error retrieving queue details\")\n\n@app.delete(\"/queues/{queue_name}\"\
      , status_code=status.HTTP_204_NO_CONTENT, tags=[\"Queues\"], summary=\"Delete\
      \ Queue\")\n@limiter.limit(\"10/minute\") # Lower limit for destructive actions\n\
      async def delete_queue(\n    request: Request,\n    queue_name: str = Path(...,\
      \ description=\"Name of the queue to delete\"),\n    current_user: str = Depends(get_current_user),\n\
      ) -> Response:\n    \"\"\"\n    Deletes a queue and all its associated messages\
      \ (due to cascade delete).\n    Returns 204 No Content on success (requires\
      \ authentication).\n    \"\"\"\n    log_info(f\"\U0001F5D1️ DELETE /queues/{queue_name}\
      \ request by user '{current_user}'\", icon_type='QUEUE')\n    try:\n       \
      \ queue = await _get_queue_or_404(queue_name) # Handles 404\n        queue_id\
      \ = queue.id # Get ID for logging before deletion\n        log_pipeline(f\"\
      Queue '{queue_name}' (ID: {queue_id}) found. Proceeding with deletion...\")\n\
      \n        # Tortoise ORM handles cascade deletion based on the ForeignKey(on_delete=CASCADE)\n\
      \        await queue.delete()\n\n        log_success(f\"Queue '{queue_name}'\
      \ (ID: {queue_id}) and associated messages deleted successfully.\", icon_type='QUEUE')\n\
      \        # Return an empty response with 204 status code\n        return Response(status_code=status.HTTP_204_NO_CONTENT)\n\
      \    except HTTPException:\n        raise # Let 404 pass through\n    except\
      \ Exception as e:\n        log_error(f\"Error deleting queue '{queue_name}':\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error deleting queue\")\n\n\n# --- Message Routes ---\n@app.post(\"\
      /queues/{queue_name}/messages\", response_model=MessagePublishResponse, status_code=status.HTTP_201_CREATED,\
      \ tags=[\"Messages\"], summary=\"Publish Message\")\n@limiter.limit(\"100/second\"\
      ) # Allow higher rate for publishing\nasync def publish_message(\n    # Non-default\
      \ arguments first\n    request: Request,\n    payload: MessagePayload,     \
      \      # Request body\n    background_tasks: BackgroundTasks, # FastAPI dependency\
      \ injection\n    # Default arguments (Path, Depends) last\n    queue_name: str\
      \ = Path(..., description=\"Name of the target queue\"),\n    current_user:\
      \ str = Depends(get_current_user), # Authentication\n) -> MessagePublishResponse:\n\
      \    \"\"\"Publishes a new message with the given content to the specified queue\
      \ (requires authentication).\"\"\"\n    log_info(f\"\U0001F4E4 POST /queues/{queue_name}/messages\
      \ by '{current_user}'\", icon_type='MSG', extra={\"content_preview\": payload.content[:50]\
      \ + \"...\"})\n    try:\n        queue = await _get_queue_or_404(queue_name)\
      \ # Handles 404\n        log_pipeline(f\"Queue '{queue_name}' found. Creating\
      \ message...\")\n        new_message = await Message.create(\n            queue=queue,\
      \ # Pass the ORM object\n            content=payload.content,\n            status='pending'\
      \ # Initial status\n        )\n        log_success(f\"Message ID {new_message.id}\
      \ published to queue '{queue_name}'.\", icon_type='MSG')\n\n        # Notify\
      \ SSE listeners in the background\n        background_tasks.add_task(notify_sse,\
      \ queue_name, new_message.id, \"new_message\")\n\n        return MessagePublishResponse(message_id=new_message.id)\n\
      \    except HTTPException:\n        raise # Let 404 pass through\n    except\
      \ Exception as e:\n        log_error(f\"Error publishing message to queue '{queue_name}':\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error publishing message\")\n\n@app.get(\"/queues/{queue_name}/messages/consume\"\
      , response_model=Optional[MessageConsumeResponse], tags=[\"Messages\"], summary=\"\
      Consume Message\")\n@limiter.limit(\"60/second\") # Rate limit consumption attempts\n\
      async def consume_message(\n    request: Request,\n    queue_name: str = Path(...,\
      \ description=\"Name of the queue to consume from\"),\n    current_user: str\
      \ = Depends(get_current_user),\n) -> Optional[MessageConsumeResponse]:\n   \
      \ \"\"\"\n    Atomically consumes the oldest 'pending' message from the specified\
      \ queue.\n    Marks the message status as 'processing' and returns it.\n   \
      \ Returns null (HTTP 200) if the queue is empty or has no 'pending' messages.\n\
      \    Requires authentication.\n    \"\"\"\n    log_info(f\"\U0001F4E9 GET /queues/{queue_name}/messages/consume\
      \ request by '{current_user}'\", icon_type='MSG', extra={\"client\": request.client.host})\n\
      \    try:\n        queue = await _get_queue_or_404(queue_name) # Handles 404\n\
      \n        # Use a transaction for atomic read-then-update\n        conn = Tortoise.get_connection(\"\
      default\")\n        async with conn.in_transaction() as tx:\n            # Find\
      \ the oldest pending message and lock the row (best effort in SQLite)\n    \
      \        message = await Message.filter(\n                queue_id=queue.id,\n\
      \                status='pending'\n            ).using_connection(tx).order_by('created_at').select_for_update().first()\n\
      \n            if not message:\n                log_info(f\"No pending messages\
      \ found in queue '{queue_name}' for consumption.\", icon_type='MSG')\n     \
      \           # Return None, FastAPI converts Optional[Model] to null in JSON\
      \ response with HTTP 200\n                return None\n\n            # Mark\
      \ as processing and update timestamp\n            message.status = 'processing'\n\
      \            message.updated_at = datetime.now(timezone.utc)\n            #\
      \ Save only the changed fields\n            await message.save(using_connection=tx,\
      \ update_fields=['status', 'updated_at'])\n\n            log_success(f\"Message\
      \ ID {message.id} consumed from queue '{queue_name}' by '{current_user}' (status\
      \ -> processing).\", icon_type='MSG')\n            # Return the consumed message\
      \ details\n            return MessageConsumeResponse(\n                message_id=message.id,\n\
      \                queue=queue_name,\n                content=message.content,\n\
      \                status=message.status, # Should be 'processing'\n         \
      \       retrieved_at=message.updated_at\n            )\n\n    except HTTPException:\n\
      \        raise # Let 404 pass through\n    except IntegrityError as e: # e.g.,\
      \ if locking causes issues or unexpected constraint violation\n        log_warning(f\"\
      DB integrity error during consumption from '{queue_name}': {e}\", icon_type='DB')\n\
      \        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=\"\
      Conflict during message consumption attempt, try again.\")\n    except Exception\
      \ as e:\n        log_error(f\"Error consuming message from queue '{queue_name}':\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error consuming message\")\n\n@app.post(\"/messages/{message_id}/ack\"\
      , status_code=status.HTTP_200_OK, response_model=Dict[str, str], tags=[\"Messages\"\
      ], summary=\"Acknowledge Message\")\n@limiter.limit(\"100/second\")\nasync def\
      \ acknowledge_message(\n    # Non-default args first\n    request: Request,\n\
      \    background_tasks: BackgroundTasks,\n    # Default args last\n    message_id:\
      \ int = Path(..., ge=1, description=\"ID of the message to acknowledge\"),\n\
      \    current_user: str = Depends(get_current_user)\n) -> Dict[str, str]:\n \
      \   \"\"\"\n    Marks a message currently in the 'processing' state as 'processed'.\n\
      \    Requires authentication. Returns 404 if message not found, or 409 if message\
      \ is not 'processing'.\n    \"\"\"\n    log_info(f\"✅ POST /messages/{message_id}/ack\
      \ request by '{current_user}'\", icon_type='MSG')\n    try:\n        conn =\
      \ Tortoise.get_connection(\"default\")\n        async with conn.in_transaction()\
      \ as tx:\n            # Find the message, ensuring it's 'processing' and lock\
      \ it\n            message = await Message.filter(\n                id=message_id,\n\
      \                status='processing' # MUST be 'processing' to be ACK'd\n  \
      \          ).using_connection(tx).select_for_update().get_or_none()\n\n    \
      \        if not message:\n                # Check if message exists but has\
      \ wrong status\n                existing_msg = await Message.filter(id=message_id).using_connection(tx).first()\n\
      \                if existing_msg:\n                    log_warning(f\"ACK failed\
      \ for message {message_id}: Found but status is '{existing_msg.status}', not\
      \ 'processing'.\", icon_type='MSG')\n                    raise HTTPException(\n\
      \                        status_code=status.HTTP_409_CONFLICT,\n           \
      \             detail=f\"Message {message_id} is in '{existing_msg.status}' state,\
      \ cannot ACK.\"\n                    )\n                else:\n            \
      \        log_warning(f\"ACK failed for message {message_id}: Not found.\", icon_type='MSG')\n\
      \                    raise HTTPException(\n                        status_code=status.HTTP_404_NOT_FOUND,\n\
      \                        detail=f\"Message {message_id} not found.\"\n     \
      \               )\n\n            # Mark as processed\n            original_queue\
      \ = await message.queue.first().using_connection(tx) # Get related queue within\
      \ transaction\n            if not original_queue:\n                 # This shouldn't\
      \ happen due to FK constraints, but defensively check\n                 log_error(f\"\
      Critical: Message {message_id} has no associated queue during ACK.\", icon_type='DB')\n\
      \                 raise HTTPException(status_code=500, detail=\"Internal error:\
      \ Message queue association lost.\")\n            original_queue_name = original_queue.name\n\
      \n            message.status = 'processed'\n            message.updated_at =\
      \ datetime.now(timezone.utc)\n            await message.save(using_connection=tx,\
      \ update_fields=['status', 'updated_at'])\n\n            # Optional: Delete\
      \ the message after successful processing?\n            # await message.delete(using_connection=tx)\n\
      \            # log_pipeline(f\"Message ID {message_id} deleted after ACK.\"\
      , icon_type='MSG')\n\n            log_success(f\"Message ID {message_id} acknowledged\
      \ by '{current_user}' (status -> processed).\", icon_type='MSG')\n         \
      \   # Notify SSE listeners about the successful processing\n            background_tasks.add_task(notify_sse,\
      \ original_queue_name, message.id, \"message_processed\")\n            return\
      \ {\"detail\": f\"Message {message_id} acknowledged successfully.\"}\n\n   \
      \ except HTTPException:\n        raise # Let 404/409 pass through\n    except\
      \ Exception as e:\n        log_error(f\"Error acknowledging message {message_id}:\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error acknowledging message\")\n\n@app.post(\"/messages/{message_id}/nack\"\
      , status_code=status.HTTP_200_OK, response_model=Dict[str, str], tags=[\"Messages\"\
      ], summary=\"Negative Acknowledge Message\")\n@limiter.limit(\"100/second\"\
      )\nasync def negative_acknowledge_message(\n    # Non-default args first\n \
      \   request: Request,\n    background_tasks: BackgroundTasks,\n    # Default\
      \ args last\n    message_id: int = Path(..., ge=1, description=\"ID of the message\
      \ to NACK\"),\n    requeue: bool = FastQuery(False, description=\"If true, reset\
      \ status to 'pending'. If false, set status to 'failed'.\"),\n    current_user:\
      \ str = Depends(get_current_user)\n) -> Dict[str, str]:\n    \"\"\"\n    Marks\
      \ a 'processing' message as 'failed' or requeues it ('pending').\n    Requires\
      \ authentication. Returns 404 if message not found, or 409 if message is not\
      \ 'processing'.\n    \"\"\"\n    action = \"requeued\" if requeue else \"marked\
      \ as failed\"\n    log_info(f\"❌ POST /messages/{message_id}/nack request by\
      \ '{current_user}' (requeue={requeue})\", icon_type='MSG')\n    try:\n     \
      \   conn = Tortoise.get_connection(\"default\")\n        async with conn.in_transaction()\
      \ as tx:\n            message = await Message.filter(\n                id=message_id,\n\
      \                status='processing' # MUST be 'processing' to be NACK'd\n \
      \           ).using_connection(tx).select_for_update().get_or_none()\n\n   \
      \         if not message:\n                existing_msg = await Message.filter(id=message_id).using_connection(tx).first()\n\
      \                if existing_msg:\n                    log_warning(f\"NACK failed\
      \ for message {message_id}: Found but status is '{existing_msg.status}', not\
      \ 'processing'.\", icon_type='MSG')\n                    raise HTTPException(status_code=status.HTTP_409_CONFLICT,\
      \ detail=f\"Message {message_id} is in '{existing_msg.status}' state, cannot\
      \ NACK.\")\n                else:\n                    log_warning(f\"NACK failed\
      \ for message {message_id}: Not found.\", icon_type='MSG')\n               \
      \     raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f\"\
      Message {message_id} not found.\")\n\n            original_queue = await message.queue.first().using_connection(tx)\n\
      \            if not original_queue:\n                 log_error(f\"Critical:\
      \ Message {message_id} has no associated queue during NACK.\", icon_type='DB')\n\
      \                 raise HTTPException(status_code=500, detail=\"Internal error:\
      \ Message queue association lost.\")\n            original_queue_name = original_queue.name\n\
      \n            new_status = 'pending' if requeue else 'failed'\n            message.status\
      \ = new_status\n            message.updated_at = datetime.now(timezone.utc)\n\
      \            await message.save(using_connection=tx, update_fields=['status',\
      \ 'updated_at'])\n\n            log_success(f\"Message ID {message_id} NACK'd\
      \ by '{current_user}' (status -> {new_status}).\", icon_type='MSG')\n      \
      \      event_type = \"message_requeued\" if requeue else \"message_failed\"\n\
      \            background_tasks.add_task(notify_sse, original_queue_name, message.id,\
      \ event_type)\n\n            return {\"detail\": f\"Message {message_id} successfully\
      \ {action}.\"}\n\n    except HTTPException:\n        raise # Let 404/409 pass\
      \ through\n    except Exception as e:\n        log_error(f\"Error NACK'ing message\
      \ {message_id}: {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=f\"Error negatively acknowledging message (action: {action})\")\n\n\
      \n# --- Server-Sent Events (SSE) Stream ---\n@app.get(\"/stream/{queue_name}\"\
      , tags=[\"Realtime (SSE)\"], summary=\"Subscribe to Queue Events\")\nasync def\
      \ sse_stream_queue(\n    request: Request,\n    queue_name: str = Path(...,\
      \ description=\"Queue name to subscribe to for events\"),\n    current_user:\
      \ str = Depends(get_current_user) # Protect stream\n):\n    \"\"\"Provides a\
      \ Server-Sent Event stream for real-time updates on a specific queue (requires\
      \ authentication).\"\"\"\n    if not redis_sse:\n         log_error(\"SSE stream\
      \ unavailable: Redis client not configured or connection failed.\", icon_type='CRITICAL')\n\
      \         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\
      \ detail=\"SSE service is currently unavailable due to Redis connection issues.\"\
      )\n\n    log_info(f\"\U0001F4E1 SSE stream requested for queue '{queue_name}'\
      \ by user '{current_user}'\", icon_type='SSE', extra={\"client\": request.client.host})\n\
      \n    # Validate queue exists before starting the potentially long-running generator\n\
      \    try:\n        await _get_queue_or_404(queue_name)\n    except HTTPException\
      \ as e:\n        # Log the attempt and re-raise the exception (e.g., 404)\n\
      \        log_warning(f\"Attempt to stream non-existent queue '{queue_name}'\
      \ by '{current_user}'. Denying.\", icon_type='SSE')\n        raise e # Re-raise\
      \ the HTTP 404 exception\n\n    async def event_generator() -> AsyncGenerator[str,\
      \ None]:\n        pubsub = None\n        redis_channel = f\"sse:{queue_name}\"\
      \n        is_subscribed = False\n        keep_alive_interval = 15 # Send keep-alive\
      \ every 15 seconds\n        disconnect_check_interval = 2 # Check for client\
      \ disconnect every 2 seconds\n\n        try:\n            pubsub = redis_sse.pubsub(ignore_subscribe_messages=True)\n\
      \            await pubsub.subscribe(redis_channel)\n            is_subscribed\
      \ = True\n            log_success(f\"\U0001F4E1 Subscribed to Redis channel\
      \ '{redis_channel}' for SSE stream (user: {current_user}).\", icon_type='SSE')\n\
      \n            # Send initial connection confirmation message\n            connect_data\
      \ = json.dumps({'event': 'connected', 'queue': queue_name, 'channel': redis_channel,\
      \ 'timestamp': datetime.now(timezone.utc).isoformat()})\n            yield f\"\
      event: system\\ndata: {connect_data}\\n\\n\"\n\n            last_keep_alive\
      \ = time.monotonic()\n\n            while True:\n                # Check for\
      \ client disconnect periodically\n                if await request.is_disconnected():\n\
      \                     log_info(f\"\U0001F4E1 SSE client for '{queue_name}' disconnected\
      \ (user: {current_user}). Closing stream.\", icon_type='SSE')\n            \
      \         break\n\n                try:\n                    # Wait for a message\
      \ with a timeout slightly longer than disconnect check\n                   \
      \ message = await pubsub.get_message(ignore_subscribe_messages=True, timeout=disconnect_check_interval)\n\
      \                    if message and message.get(\"type\") == \"message\":\n\
      \                        data = message['data']\n                        # log_debug(f\"\
      \U0001F4E1 SSE Data Received from Redis '{redis_channel}': {data[:150]}...\"\
      , icon_type='SSE')\n                        # Assume data from notify_sse is\
      \ already valid JSON\n                        yield f\"event: message\\ndata:\
      \ {data}\\n\\n\"\n                        last_keep_alive = time.monotonic()\
      \ # Reset keep-alive timer on message\n\n                    # Send keep-alive\
      \ periodically if no messages received\n                    elif time.monotonic()\
      \ - last_keep_alive > keep_alive_interval:\n                        yield \"\
      : keep-alive\\n\\n\"\n                        last_keep_alive = time.monotonic()\n\
      \n                except asyncio.TimeoutError:\n                    # Timeout\
      \ just means no message received, continue loop\n                    # Send\
      \ keep-alive if needed based on timer check above\n                    if time.monotonic()\
      \ - last_keep_alive > keep_alive_interval:\n                        yield \"\
      : keep-alive\\n\\n\"\n                        last_keep_alive = time.monotonic()\n\
      \                    continue # Go back to checking disconnect/waiting for message\n\
      \                except aioredis.RedisError as redis_err:\n                \
      \    log_error(f\"Redis error reading pub/sub for '{redis_channel}': {redis_err}\"\
      , icon_type='SSE', exc_info=True)\n                    error_data = json.dumps({'error':\
      \ 'Redis connection error', 'channel': redis_channel, 'timestamp': datetime.now(timezone.utc).isoformat()})\n\
      \                    yield f\"event: error\\ndata: {error_data}\\n\\n\"\n  \
      \                  await asyncio.sleep(5) # Backoff before breaking\n      \
      \              break # Exit on persistent Redis errors\n                except\
      \ Exception as e:\n                    # Catch unexpected errors within the\
      \ loop\n                    log_error(f\"Unexpected error in SSE generator for\
      \ '{redis_channel}': {e}\", icon_type='CRITICAL', exc_info=True)\n         \
      \           try:\n                         error_data = json.dumps({'error':\
      \ 'Internal server error in SSE stream', 'channel': redis_channel, 'timestamp':\
      \ datetime.now(timezone.utc).isoformat()})\n                         yield f\"\
      event: error\\ndata: {error_data}\\n\\n\"\n                    except Exception:\
      \ pass # Ignore if can't send error message\n                    break # Exit\
      \ loop on unexpected error\n        except asyncio.CancelledError:\n       \
      \      log_info(f\"\U0001F4E1 SSE stream for '{queue_name}' task cancelled (user:\
      \ {current_user}).\", icon_type='SSE')\n        except Exception as e:\n   \
      \          # Catch errors during initial setup (subscribe etc.)\n          \
      \   log_error(f\"Error setting up SSE stream generator for '{queue_name}': {e}\"\
      , icon_type='CRITICAL', exc_info=True)\n             # Can't yield here if setup\
      \ failed, error handled by FastAPI's exception handlers\n        finally:\n\
      \            # Cleanup Redis PubSub resources\n            if pubsub:\n    \
      \            try:\n                    if is_subscribed:\n                 \
      \       log_pipeline(f\"\U0001F4E1 Unsubscribing from Redis channel '{redis_channel}'...\"\
      , icon_type='SSE')\n                        await pubsub.unsubscribe(redis_channel)\n\
      \                    await pubsub.close()\n                    log_pipeline(f\"\
      \U0001F4E1 Closed Redis PubSub client for '{redis_channel}'.\", icon_type='SSE')\n\
      \                except Exception as close_e:\n                    log_warning(f\"\
      Error closing Redis PubSub resources for '{redis_channel}': {close_e}\", icon_type='SSE')\n\
      \n    # Return the streaming response\n    headers = {'Cache-Control': 'no-cache',\
      \ 'Connection': 'keep-alive', 'X-Accel-Buffering': 'no'} # Nginx buffering off\n\
      \    return StreamingResponse(event_generator(), media_type=\"text/event-stream\"\
      , headers=headers)\n\n\n# --- GraphQL Setup (Strawberry) ---\nlog_info(\"\U0001F353\
      \ Configuring GraphQL endpoint with Strawberry...\", icon_type='GRAPHQL')\n\n\
      # --- Strawberry Type Definitions ---\n@strawberry.type(description=\"Represents\
      \ a message queue\")\nclass QueueGQL:\n    # ... (id, name, created_at, updated_at,\
      \ message_count field definitions) ...\n\n    @strawberry.field(description=\"\
      Retrieves messages belonging to this queue, filterable by status\")\n    async\
      \ def messages(\n        self, info: Info,\n        # --- CORRECTED ARGUMENTS\
      \ ---\n        status: Optional[str] = strawberry.field(default=None, description=\"\
      Filter messages by status (pending, processing, processed, failed)\"),\n   \
      \     limit: int = strawberry.field(default=10, description=\"Maximum number\
      \ of messages to return (1-100)\"),\n        offset: int = strawberry.field(default=0,\
      \ description=\"Number of messages to skip (for pagination)\")\n        # ---\
      \ END CORRECTIONS ---\n    ) -> List[\"MessageGQL\"]:\n        \"\"\"Resolver\
      \ to fetch messages related to this queue with filtering and pagination.\"\"\
      \"\n        log_debug(f\"GQL: Fetching messages for Queue ID {self.id} (status={status},\
      \ limit={limit}, offset={offset})\")\n        valid_statuses = ['pending', 'processing',\
      \ 'processed', 'failed']\n        if status and status not in valid_statuses:\n\
      \             # Use Strawberry's error handling\n             raise ValueError(f\"\
      Invalid status filter: '{status}'. Must be one of {valid_statuses}.\")\n\n \
      \       # Sanitize limit and offset\n        limit = max(1, min(limit, 100))\
      \ # Enforce reasonable limit\n        offset = max(0, offset)\n\n        try:\n\
      \             # Convert strawberry.ID back to int for DB query\n           \
      \  queue_id_int = int(self.id)\n             query = Message.filter(queue_id=queue_id_int)\n\
      \             if status:\n                 query = query.filter(status=status)\n\
      \n             # Apply ordering, limit, and offset\n             messages_db\
      \ = await query.order_by('-created_at').offset(offset).limit(limit) # Get latest\
      \ first\n\n             # Map ORM models to GQL types (queue name is available\
      \ from self.name)\n             return [MessageGQL.from_orm(m, queue_name_str=self.name)\
      \ for m in messages_db]\n        except ValueError as ve: # Catch ID parsing\
      \ error or status validation error\n            log_warning(f\"GQL messages\
      \ resolver validation error for queue {self.id}: {ve}\")\n            raise\
      \ ve # Let Strawberry handle the GraphQL error response\n        except Exception\
      \ as e:\n            log_error(f\"GQL messages resolver error for queue {self.id}:\
      \ {e}\", exc_info=True)\n            # Returning empty list on error is safer\
      \ than raising a generic 500 in GQL\n            return []\n\n@strawberry.type(description=\"\
      Represents a message within a queue\")\nclass MessageGQL:\n    id: strawberry.ID\
      \ = strawberry.field(description=\"Unique identifier for the message\")\n  \
      \  queue_name: str = strawberry.field(description=\"Name of the queue this message\
      \ belongs to\")\n    content: str = strawberry.field(description=\"Payload content\
      \ of the message\")\n    status: str = strawberry.field(description=\"Current\
      \ status (pending, processing, processed, failed)\")\n    created_at: datetime\
      \ = strawberry.field(description=\"Timestamp when the message was created (UTC)\"\
      )\n    updated_at: datetime = strawberry.field(description=\"Timestamp when\
      \ the message was last updated (UTC)\")\n\n    @classmethod\n    def from_orm(cls,\
      \ model: Message, queue_name_str: str) -> \"MessageGQL\":\n         \"\"\"Helper\
      \ to map from Tortoise ORM model, injecting queue name.\"\"\"\n         return\
      \ cls(\n             id=strawberry.ID(str(model.id)),\n             queue_name=queue_name_str,\
      \ # Inject name passed from QueueGQL resolver\n             content=model.content,\n\
      \             status=model.status,\n             created_at=model.created_at,\n\
      \             updated_at=model.updated_at,\n         )\n\n# --- Strawberry Query\
      \ Root ---\n@strawberry.type\nclass QueryGQL:\n    @strawberry.field(description=\"\
      Retrieves a list of all available message queues\")\n    async def all_queues(self,\
      \ info: Info) -> List[QueueGQL]:\n        log_info(\"\U0001F353 GraphQL Query:\
      \ all_queues\", icon_type='GRAPHQL')\n        try:\n             queues_db =\
      \ await Queue.all().order_by('name')\n             # Map ORM models to GQL types\n\
      \             # message_count and messages are resolved by QueueGQL field resolvers\n\
      \             return [\n                 QueueGQL(\n                     id=strawberry.ID(str(q.id)),\n\
      \                     name=q.name,\n                     created_at=q.created_at,\n\
      \                     updated_at=q.updated_at\n                 ) for q in queues_db\n\
      \             ]\n        except Exception as e:\n             log_error(f\"\
      GraphQL all_queues error: {e}\", icon_type='GRAPHQL', exc_info=True)\n     \
      \        # Return empty list on error\n             return []\n\n    @strawberry.field(description=\"\
      Retrieves a specific message queue by its unique name\")\n    async def queue_by_name(self,\
      \ info: Info, name: str = strawberry.argument(description=\"The name of the\
      \ queue to retrieve\")) -> Optional[QueueGQL]:\n        log_info(f\"\U0001F353\
      \ GraphQL Query: queue_by_name (name='{name}')\", icon_type='GRAPHQL')\n   \
      \     try:\n            queue_db = await Queue.get_or_none(name=name)\n    \
      \        if queue_db:\n                 # Map ORM model to GQL type\n      \
      \           return QueueGQL(\n                     id=strawberry.ID(str(queue_db.id)),\n\
      \                     name=queue_db.name,\n                     created_at=queue_db.created_at,\n\
      \                     updated_at=queue_db.updated_at\n                 )\n \
      \           else:\n                 log_warning(f\"GraphQL: Queue '{name}' not\
      \ found.\", icon_type='GRAPHQL')\n                 return None # Return null\
      \ if not found\n        except Exception as e:\n             log_error(f\"GraphQL\
      \ queue_by_name error for '{name}': {e}\", icon_type='GRAPHQL', exc_info=True)\n\
      \             return None # Return null on error\n\n    @strawberry.field(description=\"\
      Retrieves a specific message by its unique ID\")\n    async def message_by_id(self,\
      \ info: Info, id: strawberry.ID = strawberry.argument(description=\"The unique\
      \ ID of the message\")) -> Optional[MessageGQL]:\n        log_info(f\"\U0001F353\
      \ GraphQL Query: message_by_id (id={id})\", icon_type='GRAPHQL')\n        try:\n\
      \            message_db = await Message.get_or_none(id=int(id)).select_related('queue')\
      \ # Fetch related queue for name\n            if message_db and message_db.queue:\n\
      \                 # Map ORM model to GQL type\n                 return MessageGQL.from_orm(message_db,\
      \ queue_name_str=message_db.queue.name)\n            else:\n               \
      \  log_warning(f\"GraphQL: Message ID {id} not found or has no queue.\", icon_type='GRAPHQL')\n\
      \                 return None\n        except (ValueError, DoesNotExist):\n\
      \             log_warning(f\"GraphQL: Message ID {id} not found or invalid.\"\
      , icon_type='GRAPHQL')\n             return None\n        except Exception as\
      \ e:\n             log_error(f\"GraphQL message_by_id error for ID {id}: {e}\"\
      , icon_type='GRAPHQL', exc_info=True)\n             return None\n\n\n# --- Strawberry\
      \ Mutation Root ---\n@strawberry.type\nclass MutationGQL:\n    @strawberry.mutation(description=\"\
      Creates a new message queue\")\n    async def create_queue(self, info: Info,\
      \ name: str = strawberry.argument(description=\"Unique name for the new queue\"\
      )) -> QueueGQL:\n         # Access context if needed for auth: user = info.context.get(\"\
      current_user\")\n         log_info(f\"\U0001F353 GraphQL Mutation: create_queue\
      \ (name='{name}')\", icon_type='GRAPHQL')\n         try:\n             new_queue,\
      \ created = await Queue.get_or_create(name=name)\n             if not created:\n\
      \                  raise Exception(f\"Queue '{name}' already exists.\") # Raise\
      \ GQL-handled exception\n\n             log_success(f\"GQL: Queue '{name}' created\
      \ (ID: {new_queue.id}).\", icon_type='QUEUE')\n             # Map ORM to GQL\
      \ type\n             return QueueGQL(\n                 id=strawberry.ID(str(new_queue.id)),\n\
      \                 name=new_queue.name,\n                 created_at=new_queue.created_at,\n\
      \                 updated_at=new_queue.updated_at\n             )\n        \
      \ except Exception as e: # Catch DB errors or the explicit raise above\n   \
      \           log_error(f\"GraphQL create_queue error: {e}\", icon_type='GRAPHQL',\
      \ exc_info=isinstance(e, IntegrityError)) # Less verbose trace for known conflict\n\
      \              raise Exception(f\"Failed to create queue '{name}': {e}\") #\
      \ Propagate as GraphQL error\n\n    @strawberry.mutation(description=\"Deletes\
      \ a queue and all its messages\")\n    async def delete_queue(self, info: Info,\
      \ name: str = strawberry.argument(description=\"Name of the queue to delete\"\
      )) -> bool:\n        log_info(f\"\U0001F353 GraphQL Mutation: delete_queue (name='{name}')\"\
      , icon_type='GRAPHQL')\n        try:\n            queue = await Queue.get_or_none(name=name)\n\
      \            if not queue:\n                 raise Exception(f\"Queue '{name}'\
      \ not found.\")\n\n            await queue.delete() # Cascade delete handled\
      \ by ORM\n            log_success(f\"GQL: Queue '{name}' deleted successfully.\"\
      , icon_type='QUEUE')\n            return True\n        except Exception as e:\n\
      \             log_error(f\"GraphQL delete_queue error for '{name}': {e}\", icon_type='GRAPHQL',\
      \ exc_info=True)\n             raise Exception(f\"Failed to delete queue '{name}':\
      \ {e}\")\n\n\n    @strawberry.mutation(description=\"Publishes a message to\
      \ a specified queue\")\n    async def publish_message(\n        self, info:\
      \ Info,\n        queue_name: str = strawberry.argument(description=\"Name of\
      \ the target queue\"),\n        content: str = strawberry.argument(description=\"\
      Message content/payload\")\n    ) -> MessageGQL:\n        # background_tasks\
      \ = info.context.get(\"background_tasks\") # Get from context if needed\n  \
      \      log_info(f\"\U0001F353 GraphQL Mutation: publish_message (queue='{queue_name}')\"\
      , icon_type='GRAPHQL')\n        try:\n            queue = await Queue.get_or_none(name=queue_name)\n\
      \            if not queue:\n                 raise Exception(f\"Queue '{queue_name}'\
      \ not found.\")\n\n            new_message = await Message.create(queue=queue,\
      \ content=content, status='pending')\n            log_success(f\"GQL: Message\
      \ ID {new_message.id} published to queue '{queue_name}'.\", icon_type='MSG')\n\
      \n            # Background task for SSE notification (cannot directly access\
      \ FastAPI's background_tasks here easily)\n            # Option 1: Don't notify\
      \ SSE from GQL mutations\n            # Option 2: Use a separate async task\
      \ runner (e.g., Celery, ARQ) triggered here\n            # Option 3: Pass BackgroundTasks\
      \ through context (more complex setup)\n            # For simplicity, omitting\
      \ SSE notification from GQL mutation here.\n            # await notify_sse(queue_name,\
      \ new_message.id, \"new_message\") # Would need global redis_sse access\n\n\
      \            return MessageGQL.from_orm(new_message, queue_name_str=queue_name)\n\
      \n        except Exception as e:\n            log_error(f\"GraphQL publish_message\
      \ error to queue '{queue_name}': {e}\", icon_type='GRAPHQL', exc_info=True)\n\
      \            raise Exception(f\"Failed to publish message: {e}\")\n\n\n# ---\
      \ GraphQL Context Getter ---\nasync def get_graphql_context(\n    request: Request,\
      \ # Access request object\n    response: Response, # Access response object\n\
      \    background_tasks: BackgroundTasks, # Inject background tasks\n    # Use\
      \ HTTPBearer for token, allows optional authentication if needed later\n   \
      \ auth: Optional[HTTPAuthorizationCredentials] = Depends(bearer_scheme)\n) ->\
      \ Dict:\n    \"\"\"Provides context for GraphQL resolvers, including authenticated\
      \ user and background tasks.\"\"\"\n    context = {\n        \"request\": request,\n\
      \        \"response\": response,\n        \"background_tasks\": background_tasks,\
      \ # Make BT available if needed by mutations\n        \"current_user\": None\n\
      \    }\n    if auth: # If Authorization header was present\n        try:\n \
      \           # Use the internal decode logic, expecting an access token for GQL\
      \ access\n            username = await _decode_token(auth.credentials, \"access\"\
      )\n            context[\"current_user\"] = username\n        except HTTPException\
      \ as auth_exc:\n            # GQL should ideally raise its own errors, but we\
      \ can log here\n            log_warning(f\"GraphQL authentication failed: {auth_exc.detail}\"\
      , icon_type='AUTH')\n            # Do not raise HTTPException here; let Strawberry\
      \ handle lack of user if resolvers require it\n            # Resolvers should\
      \ check `info.context.get(\"current_user\")` if auth is mandatory\n\n    return\
      \ context\n\n\n# --- Initialize GraphQL Schema and Router ---\ngql_schema =\
      \ strawberry.Schema(query=QueryGQL, mutation=MutationGQL)\ngraphql_app = GraphQLRouter(\n\
      \    gql_schema,\n    context_getter=get_graphql_context, # Use custom context\
      \ getter\n    graphiql=None, # Deprecated: Use graphql_ide instead\n    graphql_ide=\"\
      apollo-sandbox\" # Preferred: \"apollo-sandbox\", \"graphiql\"\n)\n\napp.include_router(\n\
      \    graphql_app,\n    prefix=\"/graphql\",\n    tags=[\"GraphQL\"],\n    #\
      \ Authentication is handled within the context_getter/resolvers now\n)\nlog_success(\"\
      \U0001F353 GraphQL endpoint /graphql configured.\", icon_type='GRAPHQL')\n\n\
      \n# --- Global Exception Handlers ---\n# Order handlers from most specific to\
      \ least specific\n\n@app.exception_handler(DoesNotExist)\nasync def tortoise_does_not_exist_handler(request:\
      \ Request, exc: DoesNotExist):\n    \"\"\"Handles Tortoise DoesNotExist errors,\
      \ returning 404.\"\"\"\n    model_name = str(exc).split(\":\")[0] # Attempt\
      \ to get model name\n    detail = f\"Resource not found ({model_name}).\"\n\
      \    log_warning(f\"Resource Not Found (DB): {exc} ({request.method} {request.url.path})\"\
      , icon_type='DB', extra={\"client\": request.client.host})\n    return JSONResponse(\n\
      \        status_code=status.HTTP_404_NOT_FOUND,\n        content={\"detail\"\
      : detail},\n    )\n\n@app.exception_handler(IntegrityError)\nasync def tortoise_integrity_error_handler(request:\
      \ Request, exc: IntegrityError):\n    \"\"\"Handles Tortoise IntegrityError\
      \ (e.g., unique constraint), returning 409.\"\"\"\n    detail = \"Database conflict\
      \ occurred.\"\n    # Try to extract specific constraint violation message if\
      \ available (driver-dependent)\n    if hasattr(exc, 'args') and exc.args:\n\
      \         detail += f\" Details: {exc.args[0]}\"\n    log_warning(f\"Database\
      \ Integrity Conflict: {exc} ({request.method} {request.url.path})\", icon_type='DB',\
      \ extra={\"client\": request.client.host})\n    return JSONResponse(\n     \
      \   status_code=status.HTTP_409_CONFLICT,\n        content={\"detail\": detail},\n\
      \    )\n\n@app.exception_handler(ValidationError)\nasync def pydantic_validation_exception_handler(request:\
      \ Request, exc: ValidationError):\n    \"\"\"Handles Pydantic validation errors,\
      \ returning 422.\"\"\"\n    log_warning(f\"Request Validation Error: {exc.errors()}\
      \ ({request.method} {request.url.path})\", icon_type='HTTP', extra={\"client\"\
      : request.client.host})\n    # Provide structured error details\n    return\
      \ JSONResponse(\n        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n\
      \        content={\"detail\": \"Request validation failed\", \"errors\": exc.errors()},\n\
      \    )\n\n@app.exception_handler(HTTPException)\nasync def http_exception_handler(request:\
      \ Request, exc: HTTPException):\n    \"\"\"Handles FastAPI's standard HTTPExceptions.\"\
      \"\"\n    log_level = log_warning if 400 <= exc.status_code < 500 else log_error\n\
      \    icon = 'HTTP' if 400 <= exc.status_code < 500 else 'ERROR'\n    log_level(\n\
      \        f\"HTTP Error Handled: Status={exc.status_code}, Detail='{exc.detail}'\
      \ ({request.method} {request.url.path})\",\n        icon_type=icon,\n      \
      \  extra={\"client\": request.client.host if request.client else \"N/A\"}\n\
      \    )\n    return JSONResponse(\n        status_code=exc.status_code,\n   \
      \     content={\"detail\": exc.detail},\n        headers=getattr(exc, \"headers\"\
      , None), # Include headers like WWW-Authenticate\n    )\n\n@app.exception_handler(Exception)\n\
      async def generic_exception_handler(request: Request, exc: Exception):\n   \
      \ \"\"\"Generic fallback handler for any unhandled exceptions, returning 500.\"\
      \"\"\n    tb_str = \"\".join(traceback.format_exception(etype=type(exc), value=exc,\
      \ tb=exc.__traceback__))\n    log_critical(\n        f\"Unhandled Internal Server\
      \ Error: {type(exc).__name__}: {exc} ({request.method} {request.url.path})\"\
      ,\n        icon_type='CRITICAL',\n        exc_info=False, # Traceback logged\
      \ separately\n        extra={\n            \"client\": request.client.host if\
      \ request.client else \"N/A\",\n            \"traceback_summary\": tb_str.splitlines()[-3:],\
      \ # Log last few lines of traceback\n            \"full_traceback\": tb_str\
      \ # Include full traceback in JSON log if needed\n        }\n    )\n    # Update\
      \ global error state\n    async with stats_lock:\n        app_stats[\"last_error\"\
      ] = f\"Unhandled {type(exc).__name__} @ {datetime.now(timezone.utc).isoformat()}\"\
      \n\n    return JSONResponse(\n        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n\
      \        content={\"detail\": \"An unexpected internal server error occurred.\
      \ Please check server logs.\"},\n    )\n\n# --- Main Execution Block ---\nimport\
      \ os\nimport sys\n# Assume the following are defined/imported elsewhere:\n#\
      \ - settings (with CERT_DIR, CERT_FILE, KEY_FILE attributes)\n# - log_info,\
      \ log_warning, log_critical, log_success functions\n# - generate_self_signed_cert\
      \ function\n\nif __name__ == '__main__':\n    log_info(\"\U0001F3C1 Main execution\
      \ block started...\", icon_type='STARTUP')\n\n    # --- 1. Check/Generate Self-Signed\
      \ Certificates for HTTPS ---\n    log_info(\"Checking for SSL certificate and\
      \ key...\", icon_type='SEC')\n    try:\n        # Ensure the certificate directory\
      \ exists\n        os.makedirs(settings.CERT_DIR, exist_ok=True)\n\n        cert_exists\
      \ = os.path.exists(settings.CERT_FILE)\n        key_exists = os.path.exists(settings.KEY_FILE)\n\
      \n        # Check if both certificate and key file exist\n        if cert_exists\
      \ and key_exists:\n            log_success(f\"\U0001F6E1️ SSL Certificate '{os.path.basename(settings.CERT_FILE)}'\
      \ and Key '{os.path.basename(settings.KEY_FILE)}' found in '{settings.CERT_DIR}'.\"\
      , icon_type='SEC')\n        else:\n            # If one or both are missing,\
      \ attempt generation\n            missing_files = []\n            if not cert_exists:\
      \ missing_files.append(os.path.basename(settings.CERT_FILE))\n            if\
      \ not key_exists: missing_files.append(os.path.basename(settings.KEY_FILE))\n\
      \            log_warning(f\"SSL {' / '.join(missing_files)} not found. Generating\
      \ new self-signed ones for localhost...\", icon_type='SEC')\n\n            try:\n\
      \                # Import 'ipaddress' only when needed for generation\n    \
      \            # This avoids an unnecessary import if certs already exist.\n \
      \               import ipaddress # noqa: F401 -- Keep import here as it's conditional\n\
      \                log_info(\"Attempting to generate self-signed certificates...\"\
      , icon_type='GEN')\n\n                if not generate_self_signed_cert(settings.CERT_FILE,\
      \ settings.KEY_FILE, common_name=\"localhost\"):\n                    # The\
      \ function itself should ideally log details, but we catch the failure indication\n\
      \                    log_critical(\"Critical failure generating SSL certificates\
      \ (function returned false). Aborting.\", icon_type='CRITICAL')\n          \
      \          sys.exit(1)\n                else:\n                    log_success(\"\
      ✅ Successfully generated self-signed SSL certificate and key.\", icon_type='SEC')\n\
      \n            except ImportError:\n                log_critical(\"The 'ipaddress'\
      \ module is required to generate certificates with IP SAN. Install it (`pip\
      \ install ipaddress`) or provide existing certs.\", icon_type='CRITICAL')\n\
      \                sys.exit(1)\n            except Exception as cert_gen_e:\n\
      \                # Catch any other unexpected error during the generation process\n\
      \                log_critical(f\"Unexpected error during certificate generation:\
      \ {cert_gen_e}\", icon_type='CRITICAL')\n                sys.exit(1)\n\n   \
      \ except Exception as setup_e:\n         # Catch potential errors during directory\
      \ creation or initial path checks\n         log_critical(f\"Unexpected error\
      \ during initial certificate setup check: {setup_e}\", icon_type='CRITICAL')\n\
      \         sys.exit(1)\n\n    # --- Continue with the rest of the main execution\
      \ ---\n    log_info(\"Initial setup checks complete. Proceeding...\", icon_type='SETUP')\n\
      \    # ... (rest of your main script logic would go here) ...\n    # For example:\n\
      \    # server = setup_server()\n    # server.run()\n\n    # DB Init and Redis\
      \ Init are handled by the lifespan manager\n\n    # Log Configuration Summary\n\
      \    log_info(f\"=== Configuration Summary ===\", icon_type='INFO')\n    log_info(f\"\
      \  Project: {settings.PROJECT_NAME} v{settings.VERSION}\", icon_type='INFO')\n\
      \    log_info(f\"  Environment: {settings.APP_ENV}\", icon_type='INFO')\n  \
      \  log_info(f\"  Log Level: {settings.LOG_LEVEL_STR}\", icon_type='LOGS')\n\
      \    log_info(f\"  JWT Secret: {'Set (Hidden)' if settings.JWT_SECRET_KEY !=\
      \ secrets.token_hex(32) else 'Using Generated Default'}\", icon_type='AUTH')\n\
      \    log_info(f\"  DB Path: {settings.DB_PATH}\", icon_type='DB')\n    log_info(f\"\
      \  Redis URL: {settings.REDIS_URL} (SSE DB: {settings.REDIS_SSE_DB}, Limiter\
      \ DB: {settings.REDIS_RATE_LIMIT_DB})\", icon_type='SSE')\n    log_info(f\"\
      \  Rate Limit: {settings.DEFAULT_RATE_LIMIT}\", icon_type='RATELIMIT')\n   \
      \ log_info(f\"  CORS Origins: {settings.ALLOWED_ORIGINS}\", icon_type='HTTP')\n\
      \    log_info(f\"  Log Dir: {settings.LOG_DIR}\", icon_type='LOGS')\n    log_info(f\"\
      \  Cert Dir: {settings.CERT_DIR}\", icon_type='SEC')\n    log_info(f\"============================\"\
      , icon_type='INFO')\n\n\n    # Determine Uvicorn settings based on environment\n\
      \    reload_enabled = settings.APP_ENV == \"development\"\n    log_level_uvicorn\
      \ = \"debug\" if reload_enabled else \"info\"\n\n    log_info(f\"\U0001F310\U0001F680\
      \ Starting Uvicorn server on https://0.0.0.0:{settings.API_PORT}\", icon_type='STARTUP',\
      \ extra={\"reload\": reload_enabled, \"log_level\": log_level_uvicorn})\n  \
      \  log_info(f\"   Access API root at: https://localhost:{settings.API_PORT}/\"\
      , icon_type='HTTP')\n    log_info(f\"   Swagger UI docs:  https://localhost:{settings.API_PORT}/docs\"\
      , icon_type='HTTP')\n    log_info(f\"   ReDoc docs:       https://localhost:{settings.API_PORT}/redoc\"\
      , icon_type='HTTP')\n    log_info(f\"   GraphQL endpoint: https://localhost:{settings.API_PORT}/graphql\"\
      , icon_type='GRAPHQL')\n    log_info(\"   Press Ctrl+C to stop the server.\"\
      , icon_type='INFO')\n\n    try:\n        uvicorn.run(\n            \"__main__:app\"\
      , # Point to the FastAPI app instance in this file\n            host=\"0.0.0.0\"\
      ,\n            port=settings.API_PORT,\n            log_level=log_level_uvicorn,\n\
      \            ssl_keyfile=settings.KEY_FILE,\n            ssl_certfile=settings.CERT_FILE,\n\
      \            reload=reload_enabled,\n            # lifespan=\"on\" # Uvicorn\
      \ detects lifespan automatically\n            use_colors=True # Enable Uvicorn's\
      \ own color logs if desired\n        )\n    except KeyboardInterrupt:\n    \
      \    log_info(\"\\n\U0001F6A6 Server shutdown requested via Ctrl+C.\", icon_type='SHUTDOWN')\n\
      \    except Exception as e:\n        # Catch potential startup errors (e.g.,\
      \ port binding)\n        log_critical(f\"Fatal: Failed to start or run Uvicorn\
      \ server: {e}\", exc_info=True)\n        sys.exit(1)\n    finally:\n       \
      \ log_info(\"\U0001F3C1 Uvicorn server process finished.\", icon_type='SHUTDOWN')"
    tamanho: 0.10 MB
  message-broker-v2-clean.py:
    caminho_completo: .\message-broker-v2-clean.py
    classes:
    - docstring: null
      end_lineno: 97
      lineno: 74
      name: Settings
    - docstring: null
      end_lineno: 133
      lineno: 122
      name: ColoramaFormatter
    - docstring: null
      end_lineno: 154
      lineno: 135
      name: JsonFormatter
    - docstring: null
      end_lineno: 360
      lineno: 358
      name: QueueBase
    - docstring: null
      end_lineno: 362
      lineno: 362
      name: QueueCreatePayload
    - docstring: null
      end_lineno: 369
      lineno: 364
      name: QueueResponse
    - docstring: null
      end_lineno: 372
      lineno: 371
      name: MessageBase
    - docstring: null
      end_lineno: 374
      lineno: 374
      name: MessagePayload
    - docstring: null
      end_lineno: 382
      lineno: 376
      name: MessageResponse
    - docstring: null
      end_lineno: 387
      lineno: 384
      name: MessagePublishResponse
    - docstring: null
      end_lineno: 395
      lineno: 389
      name: MessageConsumeResponse
    - docstring: null
      end_lineno: 401
      lineno: 397
      name: Token
    - docstring: null
      end_lineno: 423
      lineno: 405
      name: StatsResponse
    - docstring: null
      end_lineno: 427
      lineno: 425
      name: LogFileResponse
    - docstring: null
      end_lineno: 445
      lineno: 430
      name: Queue
    - docstring: null
      end_lineno: 468
      lineno: 447
      name: Message
    - docstring: null
      end_lineno: 1486
      lineno: 1468
      name: MessageGQL
    - docstring: null
      end_lineno: 1544
      lineno: 1489
      name: QueueGQL
    - docstring: null
      end_lineno: 1601
      lineno: 1548
      name: QueryGQL
    - docstring: null
      end_lineno: 1676
      lineno: 1605
      name: MutationGQL
    - docstring: null
      end_lineno: 442
      lineno: 440
      name: Meta
    - docstring: null
      end_lineno: 465
      lineno: 461
      name: Meta
    functions:
    - docstring: null
      end_lineno: 182
      lineno: 182
      name: log_debug
    - docstring: null
      end_lineno: 183
      lineno: 183
      name: log_info
    - docstring: null
      end_lineno: 184
      lineno: 184
      name: log_success
    - docstring: null
      end_lineno: 185
      lineno: 185
      name: log_warning
    - docstring: null
      end_lineno: 186
      lineno: 186
      name: log_error
    - docstring: null
      end_lineno: 187
      lineno: 187
      name: log_critical
    - docstring: null
      end_lineno: 188
      lineno: 188
      name: log_pipeline
    - docstring: null
      end_lineno: 246
      lineno: 191
      name: generate_self_signed_cert
    - docstring: null
      end_lineno: 133
      lineno: 126
      name: format
    - docstring: null
      end_lineno: 137
      lineno: 136
      name: formatTime
    - docstring: null
      end_lineno: 154
      lineno: 139
      name: format
    - docstring: null
      end_lineno: 445
      lineno: 444
      name: __str__
    - docstring: null
      end_lineno: 468
      lineno: 467
      name: __str__
    - docstring: null
      end_lineno: 1071
      lineno: 1010
      name: read_and_parse_log_sync
    - docstring: Helper to create MessageGQL from Tortoise Message model.
      end_lineno: 1486
      lineno: 1477
      name: from_orm
    - docstring: null
      end_lineno: 887
      lineno: 821
      name: _get_psutil_data_sync
    - docstring: null
      end_lineno: 967
      lineno: 966
      name: list_dir_sync
    imports:
    - asname: null
      name: asyncio
    - asname: null
      name: json
    - asname: null
      name: logging
    - asname: null
      name: os
    - asname: null
      name: platform
    - asname: null
      name: secrets
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: traceback
    - asname: null
      name: re
    - module: contextlib
      names:
      - asynccontextmanager
    - module: datetime
      names:
      - datetime
      - timezone
      - timedelta
    - module: typing
      names:
      - Dict
      - Any
      - Optional
      - List
      - AsyncGenerator
      - Union
    - module: collections
      names:
      - deque
    - asname: null
      name: hashlib
    - asname: null
      name: ipaddress
    - module: tortoise
      names:
      - Tortoise
      - fields
      - models
    - module: tortoise.exceptions
      names:
      - DoesNotExist
      - IntegrityError
    - module: tortoise.transactions
      names:
      - in_transaction
    - module: fastapi
      names:
      - FastAPI
      - Request
      - Response
      - Depends
      - HTTPException
      - status
      - BackgroundTasks
      - Path
      - Query
    - module: fastapi.middleware.cors
      names:
      - CORSMiddleware
    - module: fastapi.security
      names:
      - OAuth2PasswordBearer
      - OAuth2PasswordRequestForm
      - HTTPBearer
      - HTTPAuthorizationCredentials
    - module: fastapi.responses
      names:
      - JSONResponse
    - asname: null
      name: uvicorn
    - module: jose
      names:
      - JWTError
      - jwt
    - module: pydantic
      names:
      - BaseModel
      - ValidationError
      - Field
      - EmailStr
      - ConfigDict
      - field_validator
    - module: colorama
      names:
      - init
      - Fore
      - Style
    - module: cryptography
      names:
      - x509
    - module: cryptography.x509.oid
      names:
      - NameOID
    - module: cryptography.hazmat.primitives
      names:
      - hashes
    - module: cryptography.hazmat.backends
      names:
      - default_backend
    - module: cryptography.hazmat.primitives
      names:
      - serialization
    - module: cryptography.hazmat.primitives.asymmetric
      names:
      - rsa
    - asname: null
      name: psutil
    - module: werkzeug.utils
      names:
      - secure_filename
    - module: slowapi
      names:
      - Limiter
      - _rate_limit_exceeded_handler
    - module: slowapi.util
      names:
      - get_remote_address
    - module: slowapi.errors
      names:
      - RateLimitExceeded
    - module: slowapi.middleware
      names:
      - SlowAPIMiddleware
    - asname: null
      name: strawberry
    - module: strawberry.fastapi
      names:
      - GraphQLRouter
    - module: strawberry.types
      names:
      - Info
    - asname: null
      name: re
    numero_de_linhas: 1929
    source_code: "# -*- coding: utf-8 -*-\nimport asyncio\nimport json\nimport logging\n\
      import os\nimport platform\nimport secrets\nimport sys\nimport time\nimport\
      \ traceback\nimport re # Import missing re\nfrom contextlib import asynccontextmanager\n\
      from datetime import datetime, timezone, timedelta\nfrom typing import Dict,\
      \ Any, Optional, List, AsyncGenerator, Union # Added Union\nfrom collections\
      \ import deque\nimport hashlib\nimport ipaddress\n\n# --- Tortoise ORM Imports\
      \ ---\n# Ensure these are present\nfrom tortoise import Tortoise, fields, models\n\
      from tortoise.exceptions import DoesNotExist, IntegrityError\nfrom tortoise.transactions\
      \ import in_transaction # <<< ESSENTIAL IMPORT FOR FIXES\n\n# --- Dependency\
      \ Imports (Try/Except for User Feedback) ---\ntry:\n    from fastapi import\
      \ (FastAPI, Request, Response, Depends, HTTPException, status,\n           \
      \              BackgroundTasks, Path, Query as FastQuery)\n    from fastapi.middleware.cors\
      \ import CORSMiddleware\n    from fastapi.security import (OAuth2PasswordBearer,\
      \ OAuth2PasswordRequestForm,\n                                  HTTPBearer,\
      \ HTTPAuthorizationCredentials)\n    from fastapi.responses import JSONResponse\n\
      \    import uvicorn\n\n    from jose import JWTError, jwt\n    # Pydantic v2+\
      \ usage\n    from pydantic import BaseModel, ValidationError, Field, EmailStr,\
      \ ConfigDict, field_validator\n\n    # Tortoise already imported above\n\n \
      \   from colorama import init, Fore, Style\n\n    from cryptography import x509\n\
      \    from cryptography.x509.oid import NameOID\n    from cryptography.hazmat.primitives\
      \ import hashes\n    from cryptography.hazmat.backends import default_backend\n\
      \    from cryptography.hazmat.primitives import serialization\n    from cryptography.hazmat.primitives.asymmetric\
      \ import rsa\n\n    import psutil\n    from werkzeug.utils import secure_filename\n\
      \n    from slowapi import Limiter, _rate_limit_exceeded_handler\n    from slowapi.util\
      \ import get_remote_address\n    from slowapi.errors import RateLimitExceeded\n\
      \    from slowapi.middleware import SlowAPIMiddleware\n\n    import strawberry\n\
      \    from strawberry.fastapi import GraphQLRouter\n    from strawberry.types\
      \ import Info\n\nexcept ImportError as e:\n    missing_pkg = str(e).split(\"\
      '\")[-2]\n    print(f\"\\nERROR: Missing dependency '{missing_pkg}'.\")\n  \
      \  print(\"Please install all required packages by running:\")\n    # Updated\
      \ install command list\n    print(\"\\n  pip install fastapi uvicorn[standard]\
      \ tortoise-orm aiosqlite pydantic[email] python-jose[cryptography] colorama\
      \ cryptography psutil Werkzeug slowapi strawberry-graphql[fastapi] Jinja2 ipaddress\
      \ passlib Werkzeug\\n\")\n    sys.exit(1)\n\n# --- Basic Setup ---\ninit(autoreset=True)\
      \ # Initialize Colorama\n\n# --- Settings ---\nclass Settings:\n    PROJECT_NAME:\
      \ str = \"Message Broker API V3.1.5 (FastAPI/Tortoise/Fixes)\" # Updated Name\n\
      \    VERSION: str = \"0.3.1.5-fastapi-tortoise-fixes\" # Updated Version\n \
      \   API_PORT: int = 8777\n    # IMPORTANT: Generate a strong secret key and\
      \ set it via environment variable in production!\n    # Example generation:\
      \ python -c 'import secrets; print(secrets.token_hex(32))'\n    JWT_SECRET_KEY:\
      \ str = os.environ.get('JWT_SECRET_KEY', '!!_CHANGE_ME_IN_PRODUCTION_' + secrets.token_hex(16)\
      \ + '_!!')\n    ALGORITHM: str = \"HS256\"\n    ACCESS_TOKEN_EXPIRE_MINUTES:\
      \ int = 60 * 1 # 1 hour\n    REFRESH_TOKEN_EXPIRE_DAYS: int = 30\n    DB_DIR:\
      \ str = 'databases'\n    DB_FILENAME: str = 'message_broker_v3.db'\n    DB_PATH:\
      \ str = os.path.abspath(os.path.join(DB_DIR, DB_FILENAME))\n    DATABASE_URL:\
      \ str = f\"sqlite:///{DB_PATH}\"\n    LOG_DIR: str = 'logs_v3'\n    CERT_DIR:\
      \ str = 'certs_v3'\n    CERT_FILE: str = os.path.join(CERT_DIR, 'cert.pem')\n\
      \    KEY_FILE: str = os.path.join(CERT_DIR, 'key_nopass.pem')\n    ALLOWED_ORIGINS:\
      \ List[str] = [\"*\"] # WARNING: \"*\" is insecure for production. List specific\
      \ origins.\n    DEFAULT_RATE_LIMIT: str = \"200/minute\" # Default limit for\
      \ most endpoints\n    HIGH_TRAFFIC_RATE_LIMIT: str = \"200/second\" # Higher\
      \ limit for publish/consume/ack/nack\n    LOG_LEVEL_STR: str = os.environ.get(\"\
      LOG_LEVEL\", \"INFO\").upper()\n    LOG_LEVEL: int = getattr(logging, LOG_LEVEL_STR,\
      \ logging.INFO)\n    APP_ENV: str = os.environ.get(\"APP_ENV\", \"production\"\
      ).lower() # 'development' or 'production'\n\nsettings = Settings()\n\n# ---\
      \ Security Warnings ---\nif \"CHANGE_ME_IN_PRODUCTION\" in settings.JWT_SECRET_KEY\
      \ and settings.APP_ENV == \"production\":\n    print(f\"{Fore.RED}{Style.BRIGHT}\U0001F6A8\
      \ CRITICAL SECURITY WARNING: Running in PRODUCTION environment with a DEFAULT\
      \ JWT_SECRET_KEY! Generate a strong secret and set the JWT_SECRET_KEY environment\
      \ variable.{Style.RESET_ALL}\")\n    # Consider exiting if in production with\
      \ default secret: sys.exit(1)\nelif \"CHANGE_ME_IN_PRODUCTION\" in settings.JWT_SECRET_KEY:\n\
      \     print(f\"{Fore.YELLOW}⚠️ SECURITY WARNING: Using a generated default JWT_SECRET_KEY.\
      \ Set the JWT_SECRET_KEY environment variable for persistent sessions between\
      \ restarts.{Style.RESET_ALL}\")\n\nif settings.ALLOWED_ORIGINS == [\"*\"] and\
      \ settings.APP_ENV == \"production\":\n    print(f\"{Fore.YELLOW}⚠️ SECURITY\
      \ WARNING: CORS ALLOWED_ORIGINS is set to '*' in production. This is insecure.\
      \ Specify allowed origins explicitly.{Style.RESET_ALL}\")\n\n\n# --- Directory\
      \ Setup ---\nos.makedirs(settings.LOG_DIR, exist_ok=True)\nos.makedirs(settings.CERT_DIR,\
      \ exist_ok=True)\nos.makedirs(settings.DB_DIR, exist_ok=True)\n\n# --- Logging\
      \ Setup ---\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nunique_hash\
      \ = hashlib.sha1(str(os.getpid()).encode()).hexdigest()[:8]\nLOG_FILENAME =\
      \ os.path.join(settings.LOG_DIR, f\"broker_log_{timestamp}_{unique_hash}.json\"\
      )\n\nclass ColoramaFormatter(logging.Formatter):\n    LEVEL_COLORS = { logging.DEBUG:\
      \ Fore.CYAN, logging.INFO: Fore.GREEN, logging.WARNING: Fore.YELLOW, logging.ERROR:\
      \ Fore.RED, logging.CRITICAL: Fore.MAGENTA }\n    LEVEL_ICONS = { logging.DEBUG:\
      \ \"⚙️ \", logging.INFO: \"ℹ️ \", logging.WARNING: \"⚠️ \", logging.ERROR: \"\
      ❌ \", logging.CRITICAL: \"\U0001F525 \", 'SUCCESS': \"✅ \", 'PIPELINE': \"➡️\
      \ \", 'DB': \"\U0001F4BE \", 'AUTH': \"\U0001F511 \", 'QUEUE': \"\U0001F4E5\
      \ \", 'MSG': \"✉️ \", 'HTTP': \"\U0001F310 \", 'STATS': \"\U0001F4CA \", 'LOGS':\
      \ \"\U0001F4C4 \", 'SEC': \"\U0001F6E1️ \", 'ASYNC': \"⚡ \", 'GRAPHQL': \"\U0001F353\
      \ \", 'RATELIMIT': \"⏱️ \", 'STARTUP': '\U0001F680', 'SHUTDOWN': '\U0001F6D1\
      ', 'GEN': '✨', 'SETUP': '\U0001F527'}\n\n    def format(self, record):\n   \
      \     level_color = self.LEVEL_COLORS.get(record.levelno, Fore.WHITE)\n    \
      \    icon_type = getattr(record, 'icon_type', record.levelname)\n        icon\
      \ = self.LEVEL_ICONS.get(icon_type, \"\")\n        formatted_time = self.formatTime(record,\
      \ self.datefmt)\n        log_message_content = f\"[{record.levelname}] {icon}{record.getMessage()}\"\
      \n        log_line = f\"{formatted_time} - {record.name} - {level_color}{Style.BRIGHT}{log_message_content}{Style.RESET_ALL}\"\
      \n        return log_line\n\nclass JsonFormatter(logging.Formatter):\n    def\
      \ formatTime(self, record, datefmt=None):\n        return datetime.fromtimestamp(record.created,\
      \ tz=timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n\
      \n    def format(self, record):\n        log_record = {\n            'timestamp':\
      \ self.formatTime(record), 'level': record.levelname, 'name': record.name,\n\
      \            'pid': record.process, 'thread': record.threadName, 'message':\
      \ record.getMessage(),\n            'pathname': record.pathname, 'lineno': record.lineno,\n\
      \        }\n        if hasattr(record, 'icon_type'): log_record['icon_type']\
      \ = record.icon_type\n        if hasattr(record, 'extra_data') and isinstance(record.extra_data,\
      \ dict): log_record.update(record.extra_data)\n        if record.exc_info:\n\
      \            # Only include full traceback in development for security\n   \
      \         traceback_str = \"\".join(traceback.format_exception(*record.exc_info))\
      \ if settings.APP_ENV == 'development' else 'Traceback hidden in production'\n\
      \            log_record['exception'] = {\n                'type': record.exc_info[0].__name__,\
      \ 'value': str(record.exc_info[1]),\n                'traceback': traceback_str\n\
      \            }\n        return json.dumps(log_record, ensure_ascii=False, default=str)\n\
      \nlogger = logging.getLogger(\"MessageBroker\")\nlogger.setLevel(settings.LOG_LEVEL)\n\
      logger.propagate = False\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\nif not logger.handlers:\n\
      \    # Console Handler (Colored Text)\n    console_handler = logging.StreamHandler(sys.stdout)\n\
      \    console_handler.setLevel(settings.LOG_LEVEL)\n    console_formatter = ColoramaFormatter(datefmt=DATE_FORMAT)\n\
      \    console_handler.setFormatter(console_formatter)\n    logger.addHandler(console_handler)\n\
      \n    # File Handler (JSON)\n    try:\n        file_handler = logging.FileHandler(LOG_FILENAME,\
      \ mode='a', encoding='utf-8')\n        file_handler.setLevel(settings.LOG_LEVEL)\n\
      \        file_formatter = JsonFormatter()\n        file_handler.setFormatter(file_formatter)\n\
      \        logger.addHandler(file_handler)\n    except Exception as e:\n     \
      \    # Log error about file handler to console if it fails\n         logger.error(f\"\
      ❌ CRITICAL: Failed to initialize file logging ({LOG_FILENAME}): {e}\", exc_info=True)\n\
      \n\n# --- Logging Helper Functions ---\ndef log_debug(message: str, icon_type:\
      \ str = 'DEBUG', extra: Optional[Dict[str, Any]] = None): logger.debug(message,\
      \ extra={'icon_type': icon_type, 'extra_data': extra or {}})\ndef log_info(message:\
      \ str, icon_type: str = 'INFO', extra: Optional[Dict[str, Any]] = None): logger.info(message,\
      \ extra={'icon_type': icon_type, 'extra_data': extra or {}})\ndef log_success(message:\
      \ str, icon_type: str = 'SUCCESS', extra: Optional[Dict[str, Any]] = None):\
      \ logger.info(message, extra={'icon_type': icon_type, 'extra_data': extra or\
      \ {}})\ndef log_warning(message: str, icon_type: str = 'WARNING', extra: Optional[Dict[str,\
      \ Any]] = None): logger.warning(message, extra={'icon_type': icon_type, 'extra_data':\
      \ extra or {}})\ndef log_error(message: str, exc_info: bool = False, icon_type:\
      \ str = 'ERROR', extra: Optional[Dict[str, Any]] = None): logger.error(message,\
      \ exc_info=exc_info, extra={'icon_type': icon_type, 'extra_data': extra or {}})\n\
      def log_critical(message: str, exc_info: bool = False, icon_type: str = 'CRITICAL',\
      \ extra: Optional[Dict[str, Any]] = None): logger.critical(message, exc_info=exc_info,\
      \ extra={'icon_type': icon_type, 'extra_data': extra or {}})\ndef log_pipeline(message:\
      \ str, icon_type: str = 'PIPELINE', extra: Optional[Dict[str, Any]] = None):\
      \ logger.info(message, extra={'icon_type': icon_type, 'extra_data': extra or\
      \ {}})\n\n# --- SSL Certificate Generation ---\ndef generate_self_signed_cert(cert_path:\
      \ str, key_path: str, key_password: Optional[bytes] = None, common_name: str\
      \ = \"localhost\"):\n    log_info(f\"\U0001F6E1️ Generating new RSA private\
      \ key and self-signed certificate for CN='{common_name}'...\", icon_type='GEN')\n\
      \    try:\n        private_key = rsa.generate_private_key(public_exponent=65537,\
      \ key_size=2048, backend=default_backend())\n        subject = issuer = x509.Name([\n\
      \            x509.NameAttribute(NameOID.COUNTRY_NAME, u\"XX\"),\n          \
      \  x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, u\"DefaultState\"),\n\
      \            x509.NameAttribute(NameOID.LOCALITY_NAME, u\"DefaultCity\"),\n\
      \            x509.NameAttribute(NameOID.ORGANIZATION_NAME, u\"Message Broker\
      \ SelfSigned\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, common_name),\n\
      \        ])\n        # Add Subject Alternative Name (SAN) for localhost IP and\
      \ DNS name\n        san_extension = x509.SubjectAlternativeName([\n        \
      \    x509.DNSName(common_name),\n            x509.IPAddress(ipaddress.ip_address(\"\
      127.0.0.1\")),\n            # Add other IPs/DNS names if needed, e.g., x509.DNSName(\"\
      my-service.local\")\n        ])\n        cert_builder = x509.CertificateBuilder().subject_name(subject).issuer_name(issuer).public_key(private_key.public_key())\
      \ \\\n            .serial_number(x509.random_serial_number()).not_valid_before(datetime.now(timezone.utc)\
      \ - timedelta(days=1)) \\\n            .not_valid_after(datetime.now(timezone.utc)\
      \ + timedelta(days=365*2)) \\\n            .add_extension(san_extension, critical=False)\
      \ # SAN is not critical\n\n        # Add Basic Constraints extension (recommended\
      \ for self-signed certs)\n        cert_builder = cert_builder.add_extension(\n\
      \            x509.BasicConstraints(ca=False, path_length=None), critical=True,\n\
      \        )\n\n        certificate = cert_builder.sign(private_key, hashes.SHA256(),\
      \ default_backend())\n\n        # Choose key encryption (NoEncryption is fine\
      \ for local dev, use password in staging/prod)\n        key_pem_encryption =\
      \ serialization.NoEncryption()\n        if key_password:\n             log_info(\"\
      \U0001F511 Encrypting private key with provided password.\", icon_type='SEC')\n\
      \             key_pem_encryption = serialization.BestAvailableEncryption(key_password)\n\
      \n        # Write private key to file\n        with open(key_path, \"wb\") as\
      \ f:\n             f.write(private_key.private_bytes(\n                 encoding=serialization.Encoding.PEM,\n\
      \                 format=serialization.PrivateFormat.PKCS8, # Use PKCS8, more\
      \ modern than TraditionalOpenSSL\n                 encryption_algorithm=key_pem_encryption\n\
      \             ))\n        log_success(f\"\U0001F511 Private key saved: {key_path}\"\
      , icon_type='SEC')\n\n        # Write certificate to file\n        with open(cert_path,\
      \ \"wb\") as f:\n             f.write(certificate.public_bytes(serialization.Encoding.PEM))\n\
      \        log_success(f\"\U0001F4DC Self-signed certificate saved: {cert_path}\"\
      , icon_type='SEC')\n        return True\n    except ImportError:\n        #\
      \ This should not happen if dependencies are installed, but good practice\n\
      \        log_critical(\"The 'ipaddress' module is required for certificate generation.\
      \ Please install it (`pip install ipaddress`).\", icon_type='CRITICAL')\n  \
      \      return False\n    except Exception as e:\n        log_critical(f\"Failed\
      \ to generate certificates/key: {e}\", exc_info=True, icon_type='CRITICAL')\n\
      \        return False\n\n# --- Application State & Stats ---\n# Store timestamp\
      \ as datetime object\n# This dictionary holds the *source* data for the /stats\
      \ endpoint\napp_stats: Dict[str, Any] = {\n    \"start_time\": datetime.now(timezone.utc),\n\
      \    \"requests_total\": 0,\n    \"requests_by_route\": {}, # Structure: {\"\
      /path\": {\"GET\": count, \"POST\": count}, ...}\n    \"requests_by_status\"\
      : {}, # Structure: {\"200\": count, \"404\": count, ...}\n    \"queues_total\"\
      : 0,\n    \"messages_total\": 0,\n    \"messages_pending\": 0,\n    \"messages_processing\"\
      : 0,\n    \"messages_processed\": 0,\n    \"messages_failed\": 0,\n    \"last_error\"\
      : None,\n    \"last_error_timestamp\": None, # <<< Keep as datetime or None\n\
      \    \"system\": {\n        \"python_version\": platform.python_version(), \"\
      platform\": platform.system(),\n        \"platform_release\": platform.release(),\
      \ \"architecture\": platform.machine(),\n    },\n    \"broker_specific\": {\n\
      \        \"framework\": \"FastAPI\", \"version\": settings.VERSION, \"db_engine\"\
      : \"sqlite (tortoise-orm)\",\n        \"auth_method\": \"jwt (access+refresh,\
      \ python-jose)\",\n        \"notification\": \"None\", \"rate_limit\": \"In-Memory\
      \ (slowapi)\",\n        \"graphql\": \"strawberry-graphql\"\n    }\n}\nstats_lock\
      \ = asyncio.Lock() # Lock for thread-safe updates to app_stats\n\n# --- Stats\
      \ Update Functions ---\nasync def update_request_stats(route_template: str,\
      \ method: str, status_code: int):\n    \"\"\"Increment request counters safely.\"\
      \"\"\n    async with stats_lock:\n        app_stats[\"requests_total\"] += 1\n\
      \        # Update requests by route/method\n        route_stats = app_stats[\"\
      requests_by_route\"].setdefault(route_template, {})\n        route_stats[method]\
      \ = route_stats.get(method, 0) + 1\n        # Update requests by status code\n\
      \        status_code_str = str(status_code) # Ensure status code is string key\n\
      \        app_stats[\"requests_by_status\"][status_code_str] = app_stats[\"requests_by_status\"\
      ].get(status_code_str, 0) + 1\n        # Log the update for debugging if needed\
      \ (set level higher than DEBUG usually)\n        log_debug(f\"Stats Update:\
      \ route='{route_template}', method='{method}', status={status_code}. New totals:\
      \ route={route_stats[method]}, status={app_stats['requests_by_status'][status_code_str]}\"\
      , icon_type='STATS')\n\nasync def update_broker_stats():\n    \"\"\"Fetch queue\
      \ and message counts from DB and update stats.\"\"\"\n    log_pipeline(\"\U0001F4CA\
      \ Fetching broker stats from DB...\", icon_type='STATS')\n    try:\n       \
      \ # <<< FIX: Check if Tortoise connections are initialized >>>\n        # Using\
      \ `Tortoise.apps` is a slightly more public/stable way than `_connections`\n\
      \        if not Tortoise.apps:\n             log_warning(\"DB not initialized,\
      \ cannot update broker stats.\", icon_type='DB')\n             return\n\n  \
      \      # Use asyncio.gather for concurrent DB queries\n        q_count_task\
      \ = Queue.all().count()\n        m_pending_task = Message.filter(status='pending').count()\n\
      \        m_processing_task = Message.filter(status='processing').count()\n \
      \       m_processed_task = Message.filter(status='processed').count()\n    \
      \    m_failed_task = Message.filter(status='failed').count()\n\n        q_count,\
      \ pending, processing, processed, failed = await asyncio.gather(\n         \
      \   q_count_task, m_pending_task, m_processing_task, m_processed_task, m_failed_task\n\
      \        )\n        total = pending + processing + processed + failed\n\n  \
      \      async with stats_lock:\n            app_stats[\"queues_total\"] = q_count\n\
      \            app_stats[\"messages_pending\"] = pending\n            app_stats[\"\
      messages_processing\"] = processing\n            app_stats[\"messages_processed\"\
      ] = processed\n            app_stats[\"messages_failed\"] = failed\n       \
      \     app_stats[\"messages_total\"] = total\n            # Clear last error\
      \ if update was successful and it was a stats update error\n            if app_stats[\"\
      last_error\"] and \"Broker Stats Update Failed\" in app_stats[\"last_error\"\
      ]:\n                 app_stats[\"last_error\"] = None\n                 app_stats[\"\
      last_error_timestamp\"] = None # Reset timestamp as well\n        log_success(\"\
      \U0001F4CA Broker stats updated.\", icon_type='STATS', extra={'counts': {'queues':\
      \ q_count, 'pending': pending, 'processing': processing, 'processed': processed,\
      \ 'failed': failed}})\n    except Exception as e:\n        # Store timestamp\
      \ as datetime object here\n        error_time = datetime.now(timezone.utc)\n\
      \        error_msg = f\"Broker Stats Update Failed at {error_time.isoformat()}:\
      \ {type(e).__name__}\"\n        log_error(f\"Error updating broker stats: {e}\"\
      , icon_type='STATS', exc_info=True)\n        async with stats_lock:\n      \
      \      app_stats[\"last_error\"] = error_msg\n            app_stats[\"last_error_timestamp\"\
      ] = error_time # <<< Store datetime object\n\n# --- Tortoise ORM Setup ---\n\
      async def init_tortoise():\n    \"\"\"Initialize Tortoise ORM connection and\
      \ generate schemas.\"\"\"\n    log_info(f\"\U0001F4BE Configuring Tortoise ORM\
      \ for SQLite: {settings.DATABASE_URL}\", icon_type='DB')\n    try:\n       \
      \ await Tortoise.init(\n            db_url=settings.DATABASE_URL,\n        \
      \    modules={'models': ['__main__']} # Looks for models in the current script\
      \ (__name__ == '__main__')\n        )\n        log_info(\"\U0001F4BE Generating\
      \ DB schemas if necessary...\", icon_type='DB')\n        await Tortoise.generate_schemas(safe=True)\
      \ # Creates tables if they don't exist, doesn't alter existing ones dangerously\n\
      \        log_success(\"\U0001F4BE ORM tables verified/created successfully.\"\
      , icon_type='DB')\n        # Initial stats population only after DB is confirmed\
      \ ready\n        await update_broker_stats()\n    except Exception as e:\n \
      \       log_critical(f\"Fatal: Failed to initialize Tortoise ORM: {e}\", icon_type='CRITICAL',\
      \ exc_info=True)\n        sys.exit(1) # Cannot run without DB\n\n# --- Pydantic\
      \ Models (Data Validation & Serialization) ---\n# Use ConfigDict for Pydantic\
      \ V2+\n# Enable populate_by_name=True to allow using field names or aliases\n\
      # Enable from_attributes=True to allow creating models from ORM objects\nPYDANTIC_CONFIG\
      \ = ConfigDict(populate_by_name=True, from_attributes=True)\n\nclass QueueBase(BaseModel):\n\
      \    name: str = Field(..., min_length=1, max_length=255, pattern=r\"^[a-zA-Z0-9_-]+$\"\
      ,\n                      description=\"Unique queue name (alphanumeric, underscore,\
      \ hyphen).\")\n\nclass QueueCreatePayload(QueueBase): pass # Alias for input\n\
      \nclass QueueResponse(QueueBase):\n    id: int\n    created_at: datetime\n \
      \   updated_at: datetime\n    message_count: int = Field(default=0, description=\"\
      Current number of messages in the queue\")\n    model_config = PYDANTIC_CONFIG\n\
      \nclass MessageBase(BaseModel):\n    content: str = Field(..., min_length=1,\
      \ description=\"The content/payload of the message (arbitrary string)\")\n\n\
      class MessagePayload(MessageBase): pass # Alias for input\n\nclass MessageResponse(MessageBase):\n\
      \    id: int\n    queue_id: int\n    status: str = Field(description=\"Current\
      \ status: pending, processing, processed, failed\")\n    created_at: datetime\n\
      \    updated_at: datetime\n    model_config = PYDANTIC_CONFIG\n\nclass MessagePublishResponse(BaseModel):\n\
      \    message: str = Field(default=\"Message published successfully\")\n    message_id:\
      \ int\n    model_config = PYDANTIC_CONFIG\n\nclass MessageConsumeResponse(BaseModel):\n\
      \    message_id: int\n    queue: str # Queue name included for context\n   \
      \ content: str\n    status: str = Field(default='processing', description=\"\
      Should always be 'processing' on successful consume\")\n    retrieved_at: datetime\
      \ # Timestamp when the message status changed to 'processing'\n    model_config\
      \ = PYDANTIC_CONFIG\n\nclass Token(BaseModel):\n    access_token: str\n    refresh_token:\
      \ str\n    token_type: str = \"bearer\"\n    model_config = PYDANTIC_CONFIG\n\
      \n# <<< FIX: Correct typing for timestamp fields >>>\n# This model defines the\
      \ structure of the JSON response for the /stats endpoint\nclass StatsResponse(BaseModel):\n\
      \    start_time: datetime # Keep as datetime, Pydantic handles serialization\
      \ to ISO string\n    uptime_seconds: float\n    uptime_human: str\n    requests_total:\
      \ int\n    # These match the keys in app_stats and the dashboard's expectations\n\
      \    requests_by_route: Dict[str, Dict[str, int]] = Field(description=\"Count\
      \ of requests per route template and HTTP method\")\n    requests_by_status:\
      \ Dict[str, int] = Field(description=\"Count of requests per HTTP status code\"\
      )\n    queues_total: int\n    messages_total: int\n    messages_pending: int\n\
      \    messages_processing: int\n    messages_processed: int\n    messages_failed:\
      \ int\n    last_error: Optional[str]\n    last_error_timestamp: Optional[datetime]\
      \ # Keep as datetime, Pydantic handles serialization\n    system: Dict[str,\
      \ Any]\n    broker_specific: Dict[str, Any] # Allow more flexibility here\n\
      \    model_config = PYDANTIC_CONFIG\n\nclass LogFileResponse(BaseModel):\n \
      \   log_files: List[str]\n    model_config = PYDANTIC_CONFIG\n\n# --- Tortoise\
      \ ORM Models ---\nclass Queue(models.Model):\n    id = fields.IntField(pk=True)\n\
      \    # Ensure name constraints match Pydantic validation\n    name = fields.CharField(max_length=255,\
      \ unique=True, index=True, description=\"Unique queue name\")\n    created_at\
      \ = fields.DatetimeField(auto_now_add=True)\n    updated_at = fields.DatetimeField(auto_now=True)\n\
      \n    # Reverse relation: allows accessing messages from a queue instance (queue.messages)\n\
      \    messages: fields.ReverseRelation[\"Message\"]\n\n    class Meta:\n    \
      \    table = \"queues\"\n        ordering = [\"name\"] # Default ordering when\
      \ querying multiple queues\n\n    def __str__(self):\n        return self.name\n\
      \nclass Message(models.Model):\n    id = fields.IntField(pk=True)\n    # Foreign\
      \ key relation: defines the many-to-one relationship (many messages to one queue)\n\
      \    queue: fields.ForeignKeyRelation[Queue] = fields.ForeignKeyField(\n   \
      \     'models.Queue', related_name='messages', on_delete=fields.CASCADE, # Cascade\
      \ delete: deleting a queue deletes its messages\n        description=\"The queue\
      \ this message belongs to\"\n    )\n    content = fields.TextField(description=\"\
      Message payload\")\n    # Define allowed status values explicitly if possible,\
      \ or use validation elsewhere\n    status = fields.CharField(max_length=20,\
      \ default='pending', index=True,\n                              description=\"\
      Status: pending, processing, processed, failed\")\n    created_at = fields.DatetimeField(auto_now_add=True,\
      \ index=True) # Index for ordering/filtering\n    updated_at = fields.DatetimeField(auto_now=True)\n\
      \n    class Meta:\n        table = \"messages\"\n        # Compound index useful\
      \ for finding the oldest pending message in a queue efficiently\n        indexes\
      \ = [(\"queue_id\", \"status\", \"created_at\")]\n        ordering = [\"created_at\"\
      ] # Default ordering for messages\n\n    def __str__(self):\n        return\
      \ f\"Message {self.id} (Queue: {self.queue_id}, Status: {self.status})\"\n\n\
      # --- Lifespan Context Manager (Startup/Shutdown Events) ---\n@asynccontextmanager\n\
      async def lifespan(app_ref: FastAPI): # Renamed arg to avoid shadowing 'app'\n\
      \    # Startup Sequence\n    log_info(\"\U0001F680 Application Startup Initiated...\"\
      , icon_type='STARTUP')\n    await init_tortoise()\n    # Note: Middleware (CORS,\
      \ Rate Limiter, Stats) is added *after* FastAPI() instance creation\n    # but\
      \ *before* routes are defined or the server starts running requests.\n    log_success(\"\
      \U0001F680 Application Startup Complete. Ready to accept connections.\", icon_type='STARTUP')\n\
      \    yield # Application runs here\n    # Shutdown Sequence\n    log_info(\"\
      \U0001F6D1 Application Shutdown Initiated...\", icon_type='SHUTDOWN')\n    try:\n\
      \        log_info(\"\U0001F4BE Closing database connections...\", icon_type='DB')\n\
      \        await Tortoise.close_connections()\n        log_success(\"\U0001F4BE\
      \ Database connections closed gracefully.\", icon_type='DB')\n    except Exception\
      \ as e:\n         log_warning(f\"⚠️ Error closing Tortoise connections during\
      \ shutdown: {e}\", icon_type='DB')\n    log_success(\"\U0001F6D1 Application\
      \ Shutdown Complete.\", icon_type='SHUTDOWN')\n\n\n# --- FastAPI Application\
      \ Setup ---\nlog_info(f\"\U0001F680 Initializing FastAPI Application ({settings.PROJECT_NAME}\
      \ v{settings.VERSION})...\", icon_type='SETUP')\napp = FastAPI(\n    title=settings.PROJECT_NAME,\
      \ version=settings.VERSION,\n    description=\"Asynchronous Message Broker API\
      \ using FastAPI, Tortoise ORM, and SQLite.\",\n    lifespan=lifespan, # Assign\
      \ the lifespan manager for startup/shutdown events\n    docs_url=\"/docs\",\
      \ # URL for Swagger UI\n    redoc_url=\"/redoc\", # URL for ReDoc documentation\n\
      \    openapi_tags=[ # Define tags for organizing endpoints in docs\n       \
      \ {\"name\": \"General\", \"description\": \"Basic health and info endpoints\"\
      },\n        {\"name\": \"Authentication\", \"description\": \"User login and\
      \ token management (JWT)\"},\n        {\"name\": \"Monitoring\", \"description\"\
      : \"System statistics and log viewing\"},\n        {\"name\": \"Queues\", \"\
      description\": \"Operations for managing message queues\"},\n        {\"name\"\
      : \"Messages\", \"description\": \"Publishing, consuming, and managing messages\"\
      },\n        {\"name\": \"GraphQL\", \"description\": \"GraphQL API endpoint\
      \ (alternative to REST)\"},\n    ]\n)\n\n# --- Rate Limiter Setup (Must be added\
      \ BEFORE routes are hit) ---\nlimiter = Limiter(key_func=get_remote_address,\
      \ default_limits=[settings.DEFAULT_RATE_LIMIT])\napp.state.limiter = limiter\
      \ # Make limiter accessible via app state if needed elsewhere\napp.add_middleware(SlowAPIMiddleware)\
      \ # Add the middleware to process requests\napp.add_exception_handler(RateLimitExceeded,\
      \ _rate_limit_exceeded_handler) # Handle rate limit exceeded errors globally\n\
      log_info(f\"⏱️ Rate Limiter configured (Default: {settings.DEFAULT_RATE_LIMIT},\
      \ High Traffic: {settings.HIGH_TRAFFIC_RATE_LIMIT}).\", icon_type='RATELIMIT')\n\
      \n# --- CORS Middleware ---\n# IMPORTANT: Configure origins explicitly for production\
      \ security.\napp.add_middleware(\n    CORSMiddleware, allow_origins=settings.ALLOWED_ORIGINS,\
      \ allow_credentials=True,\n    allow_methods=[\"*\"], # Allow all standard methods\n\
      \    allow_headers=[\"*\"], # Allow all standard headers\n)\nlog_info(f\"\U0001F6E1\
      ️ CORS configured for origins: {settings.ALLOWED_ORIGINS}\", icon_type='SEC')\n\
      \n# --- Authentication Setup & Dependencies ---\n# Token URL points to the /login\
      \ endpoint\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"login\", auto_error=False)\
      \ # auto_error=False allows checking token existence manually in dependencies\n\
      bearer_scheme = HTTPBearer(auto_error=False) # For validating refresh tokens\
      \ in Authorization header\n\nasync def create_jwt_token(data: dict, expires_delta:\
      \ timedelta) -> str:\n    \"\"\"Creates a JWT token with expiry.\"\"\"\n   \
      \ to_encode = data.copy()\n    issue_time = datetime.now(timezone.utc)\n   \
      \ expire = issue_time + expires_delta\n    to_encode.update({\"exp\": expire,\
      \ \"iat\": issue_time})\n    # Add 'iss' (issuer) and 'aud' (audience) claims\
      \ for better practice if needed\n    # to_encode.update({\"iss\": \"MyBrokerApp\"\
      , \"aud\": \"BrokerClients\"})\n    encoded_jwt = jwt.encode(to_encode, settings.JWT_SECRET_KEY,\
      \ algorithm=settings.ALGORITHM)\n    return encoded_jwt\n\nasync def create_access_token(username:\
      \ str) -> str:\n    \"\"\"Creates an access token (short-lived).\"\"\"\n   \
      \ return await create_jwt_token(\n        {\"sub\": username, \"type\": \"access\"\
      },\n        timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n    )\n\
      \nasync def create_refresh_token(username: str) -> str:\n    \"\"\"Creates a\
      \ refresh token (long-lived).\"\"\"\n    return await create_jwt_token(\n  \
      \      {\"sub\": username, \"type\": \"refresh\"},\n        timedelta(days=settings.REFRESH_TOKEN_EXPIRE_DAYS)\n\
      \    )\n\nasync def _decode_token(token: str, expected_type: str) -> str:\n\
      \    \"\"\"\n    Decodes and validates a JWT token.\n    Returns the username\
      \ (subject) if valid and matches expected type.\n    Raises HTTPException 401\
      \ otherwise.\n    \"\"\"\n    credentials_exception = HTTPException(\n     \
      \   status_code=status.HTTP_401_UNAUTHORIZED, detail=f\"Could not validate {expected_type}\
      \ token\",\n        headers={\"WWW-Authenticate\": f\"Bearer error=\\\"invalid_token\\\
      \", error_description=\\\"Invalid {expected_type} token\\\"\"},\n    )\n   \
      \ if not token:\n        log_warning(f\"Token decode attempt failed: No token\
      \ provided (expected type: {expected_type}).\", icon_type='AUTH')\n        raise\
      \ credentials_exception\n\n    try:\n        payload = jwt.decode(\n       \
      \     token,\n            settings.JWT_SECRET_KEY,\n            algorithms=[settings.ALGORITHM],\n\
      \            # Specify audience if you set it during encoding: options={\"verify_aud\"\
      : True}, audience=\"BrokerClients\"\n            options={\"verify_aud\": False}\
      \ # Disable audience verification if not used\n        )\n        username:\
      \ Optional[str] = payload.get(\"sub\")\n        token_type: Optional[str] =\
      \ payload.get(\"type\")\n\n        if username is None or token_type != expected_type:\n\
      \            log_warning(f\"{expected_type.capitalize()} token validation failed:\
      \ 'sub' missing or type mismatch (Got '{token_type}', Expected '{expected_type}').\"\
      , icon_type='AUTH', extra={\"payload_keys\": list(payload.keys())})\n      \
      \      raise credentials_exception\n\n        # --- Optional: Add further checks\
      \ ---\n        # E.g., check if the user exists in a user database and is active\n\
      \        # user = await get_user_from_db(username) # Hypothetical function\n\
      \        # if not user or not user.is_active:\n        #     log_warning(f\"\
      Authentication failed for '{username}': User not found or inactive.\", icon_type='AUTH')\n\
      \        #     raise credentials_exception\n        # --- End Optional Checks\
      \ ---\n\n        # If all checks pass, return the username\n        return username\n\
      \n    except JWTError as e:\n        # Handles expired tokens, invalid signatures,\
      \ etc.\n        log_warning(f\"{expected_type.capitalize()} token validation\
      \ JWTError: {e}\", icon_type='AUTH', extra={\"token_preview\": token[:10] +\
      \ \"...\"})\n        # Provide more specific error detail if possible\n    \
      \    detail = f\"Invalid {expected_type} token: {e}\"\n        if \"expired\"\
      \ in str(e).lower():\n             detail = f\"{expected_type.capitalize()}\
      \ token has expired\"\n             credentials_exception.headers[\"WWW-Authenticate\"\
      ] = f\"Bearer error=\\\"invalid_token\\\", error_description=\\\"Token expired\\\
      \"\"\n        credentials_exception.detail = detail\n        raise credentials_exception\n\
      \    except Exception as e:\n         # Catch unexpected errors during decoding\n\
      \         log_error(f\"Unexpected error during {expected_type} token decode:\
      \ {e}\", icon_type='AUTH', exc_info=True)\n         # Raise a generic 401 to\
      \ avoid leaking internal details\n         raise credentials_exception\n\nasync\
      \ def get_current_user(token: Optional[str] = Depends(oauth2_scheme)) -> str:\n\
      \    \"\"\"Dependency to get the current user from the access token in Authorization\
      \ header.\"\"\"\n    if token is None:\n        # This case happens if Authorization\
      \ header is missing or not using Bearer scheme\n        raise HTTPException(\n\
      \            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"\
      Not authenticated\",\n            headers={\"WWW-Authenticate\": \"Bearer\"\
      } # Signal that Bearer token is expected\n        )\n    # Decode and validate\
      \ the access token\n    return await _decode_token(token, \"access\")\n\nasync\
      \ def validate_refresh_token(credentials: Optional[HTTPAuthorizationCredentials]\
      \ = Depends(bearer_scheme)) -> str:\n    \"\"\"Dependency to validate a refresh\
      \ token passed in the Authorization: Bearer header.\"\"\"\n    if credentials\
      \ is None:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n\
      \            detail=\"Refresh token missing or invalid Authorization header\
      \ format\",\n            headers={\"WWW-Authenticate\": \"Bearer error=\\\"\
      invalid_request\\\", error_description=\\\"Refresh token required\\\"\"}\n \
      \       )\n    # Decode and validate the refresh token\n    return await _decode_token(credentials.credentials,\
      \ \"refresh\")\n\n# --- Middleware for Stats Update ---\n@app.middleware(\"\
      http\")\nasync def update_stats_middleware(request: Request, call_next):\n \
      \   \"\"\"Middleware to update request stats and add X-Process-Time header.\"\
      \"\"\n    start_time_mw = time.perf_counter()\n    response = None # Initialize\
      \ response to None\n    status_code = 500 # Default to 500 in case of early\
      \ exception\n    try:\n        response = await call_next(request)\n       \
      \ process_time_mw = time.perf_counter() - start_time_mw\n        response.headers[\"\
      X-Process-Time\"] = f\"{process_time_mw:.4f}s\"\n        status_code = response.status_code\
      \ # Get status code from actual response\n\n    except Exception as e:\n   \
      \      # If an exception occurs deeper in the stack, log it and re-raise\n \
      \        # Let the global exception handlers determine the final status code\n\
      \         process_time_mw = time.perf_counter() - start_time_mw\n         #\
      \ Log the unhandled exception here BEFORE it gets caught by global handlers\n\
      \         # Use a distinct log message to differentiate from the global handler\
      \ log\n         log_error(\n             f\"Unhandled exception propagated to\
      \ stats middleware ({request.method} {request.url.path}) after {process_time_mw:.4f}s:\
      \ {type(e).__name__}: {e}\",\n             exc_info=True, # Include traceback\
      \ here for context\n             icon_type='ERROR'\n         )\n         # Re-raise\
      \ the exception to be handled by FastAPI's exception handlers\n         raise\
      \ e\n    finally:\n        # Update stats regardless of whether an exception\
      \ occurred, using the determined status code\n        # Note: If an exception\
      \ occurred, `response` might be None if `call_next` failed early\n        route\
      \ = request.scope.get(\"route\")\n        if route and hasattr(route, 'path'):\n\
      \            route_template = route.path\n\n            # --- FIX: Corrected\
      \ ignore logic for stats ---\n            # Define prefixes/paths to ignore\
      \ for request counting more accurately\n            # Ignore docs, IDEs, OpenAPI\
      \ schema, GraphQL IDE/schema, and favicons by prefix\n            ignored_prefixes\
      \ = ('/docs', '/redoc', '/openapi.json', '/graphql', '/favicon.ico')\n     \
      \       # Ignore the root health check path, the stats endpoint itself, and\
      \ the log listing endpoint explicitly by path\n            ignored_paths = ('/',\
      \ '/stats', '/logs') # Note: /logs/{filename} WILL be counted now.\n\n     \
      \       # Check if the current route should be ignored\n            should_ignore\
      \ = False\n            if route_template:\n                if any(route_template.startswith(prefix)\
      \ for prefix in ignored_prefixes):\n                    should_ignore = True\n\
      \                    log_debug(f\"Ignoring stats update for route (prefix match):\
      \ {route_template}\", icon_type='STATS')\n                elif route_template\
      \ in ignored_paths:\n                     should_ignore = True\n           \
      \          log_debug(f\"Ignoring stats update for route (path match): {route_template}\"\
      , icon_type='STATS')\n            # --- End FIX ---\n\n            # Only update\
      \ stats if the route should NOT be ignored\n            if route_template and\
      \ not should_ignore:\n                try:\n                    # Use the status_code\
      \ determined above (either from response or 500 for exception)\n           \
      \         await update_request_stats(route_template, request.method, status_code)\n\
      \                except Exception as stats_e:\n                     # Log error\
      \ if stats update fails, but don't fail the request\n                     log_error(f\"\
      Failed to update request stats: {stats_e}\", icon_type='STATS', exc_info=True)\n\
      \            # else: # Kept for potential debugging\n            #    if route_template:\
      \ # Only log if template was found but ignored\n            #        log_debug(f\"\
      Final decision: Ignoring stats update for route: {route_template}\", icon_type='STATS')\n\
      \n\n    # If response was successfully generated, return it\n    if response:\n\
      \        return response\n    else:\n        # This case should ideally be handled\
      \ by the global exception handler re-raising,\n        # but as a fallback,\
      \ return a generic error if response is still None.\n        log_critical(\"\
      Middleware finished without a response object (likely due to early exception).\
      \ Returning 500.\", icon_type=\"CRITICAL\")\n        return JSONResponse(\n\
      \            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n          \
      \  content={\"detail\": \"Internal server error occurred during request processing.\"\
      },\n        )\n\n\n# --- Helper Function for DB Lookups with 404 ---\nasync\
      \ def _get_queue_or_404(queue_name: str, conn=None) -> Queue:\n    \"\"\"Helper\
      \ to fetch a Queue by name or raise HTTPException 404. Allows using an existing\
      \ transaction connection.\"\"\"\n    try:\n        query = Queue.all()\n   \
      \     if conn: # If a transaction connection is provided, use it\n         \
      \   # Correct way to apply connection to a QuerySet\n            query = query.using_connection(conn)\n\
      \        # Fetch the queue by name\n        queue = await query.get(name=queue_name)\n\
      \        return queue\n    except DoesNotExist:\n        log_warning(f\"Queue\
      \ '{queue_name}' not found in database.\", icon_type='DB')\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=f\"Queue '{queue_name}' not found\")\n    except Exception as e:\n\
      \        # Log unexpected DB errors\n        log_error(f\"Database error fetching\
      \ queue '{queue_name}': {e}\", icon_type='DB', exc_info=True)\n        # Raise\
      \ a generic 500 for unexpected DB issues\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Database error retrieving queue\")\n\n# --- API ROUTE DEFINITIONS\
      \ ---\n\n# --- General Endpoints ---\n@app.get(\"/\", tags=[\"General\"], summary=\"\
      Health Check\")\n@limiter.limit(\"5/second\") # Lower limit for basic check\n\
      async def index(request: Request):\n    \"\"\"Provides a basic health check,\
      \ server information, and current timestamp.\"\"\"\n    client_host = request.client.host\
      \ if request.client else 'N/A'\n    log_info(\"\U0001F310 GET / request\", icon_type='HTTP',\
      \ extra={\"client\": client_host})\n    return {\n        \"message\": f\"Welcome\
      \ to {settings.PROJECT_NAME}\",\n        \"status\": \"ok\",\n        \"version\"\
      : settings.VERSION,\n        \"timestamp\": datetime.now(timezone.utc).isoformat()\n\
      \    }\n\n# --- Authentication Endpoints ---\n@app.post(\"/login\", response_model=Token,\
      \ tags=[\"Authentication\"], summary=\"User Login\")\n@limiter.limit(\"10/minute\"\
      ) # Limit login attempts to mitigate brute-force\nasync def login_for_access_token(request:\
      \ Request, form_data: OAuth2PasswordRequestForm = Depends()):\n    \"\"\"\n\
      \    Handles user login using standard OAuth2 password flow.\n    **WARNING:\
      \ Uses hardcoded 'admin'/'admin' credentials. Replace with secure authentication.**\n\
      \    \"\"\"\n    client_host = request.client.host if request.client else 'N/A'\n\
      \    log_info(f\"\U0001F511 POST /login attempt for user: '{form_data.username}'\"\
      , icon_type='AUTH', extra={\"client\": client_host})\n\n    # --- !!! VERY IMPORTANT:\
      \ Replace this placeholder with secure password verification !!! ---\n    #\
      \ Example using passlib (install with `pip install passlib[bcrypt]`)\n    #\
      \ from passlib.context import CryptContext\n    # pwd_context = CryptContext(schemes=[\"\
      bcrypt\"], deprecated=\"auto\")\n    # async def verify_password(plain_password,\
      \ hashed_password):\n    #     return pwd_context.verify(plain_password, hashed_password)\n\
      \    # # Replace with actual user lookup and password hash retrieval from DB\n\
      \    # user = await get_user_from_db(form_data.username) # Hypothetical DB function\n\
      \    # if not user or not await verify_password(form_data.password, user.hashed_password):\n\
      \    #     log_warning(f\"Login failed for '{form_data.username}': Invalid credentials.\"\
      , icon_type='AUTH')\n    #     raise HTTPException(\n    #         status_code=status.HTTP_401_UNAUTHORIZED,\
      \ detail=\"Incorrect username or password\",\n    #         headers={\"WWW-Authenticate\"\
      : \"Bearer error=\\\"invalid_grant\\\"\"}, )\n    # --- !!! End of Security\
      \ Placeholder !!! ---\n\n    # --- Hardcoded credentials (FOR DEVELOPMENT/DEMO\
      \ ONLY) ---\n    if form_data.username == 'admin' and form_data.password ==\
      \ 'admin':\n        log_warning(\"\U0001F6A8 Using hardcoded 'admin'/'admin'\
      \ credentials for login. This is insecure!\", icon_type='AUTH')\n        # Credentials\
      \ match, generate tokens\n        access_token = await create_access_token(username=form_data.username)\n\
      \        refresh_token = await create_refresh_token(username=form_data.username)\n\
      \        log_success(f\"Tokens generated for '{form_data.username}'.\", icon_type='AUTH')\n\
      \        return Token(access_token=access_token, refresh_token=refresh_token)\n\
      \    else:\n        # Credentials do not match\n        log_warning(f\"Login\
      \ failed for '{form_data.username}': Invalid credentials.\", icon_type='AUTH')\n\
      \        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n\
      \            detail=\"Incorrect username or password\",\n            headers={\"\
      WWW-Authenticate\": \"Bearer error=\\\"invalid_grant\\\"\"}, # Standard OAuth2\
      \ error\n        )\n\n@app.post(\"/refresh\", response_model=Token, tags=[\"\
      Authentication\"], summary=\"Refresh Access Token\")\n@limiter.limit(\"20/minute\"\
      ) # Allow slightly more refreshes than logins\nasync def refresh_access_token(request:\
      \ Request, username: str = Depends(validate_refresh_token)):\n    \"\"\"\n \
      \   Issues a new access and refresh token using a valid refresh token provided\
      \ in the\n    `Authorization: Bearer <refresh_token>` header.\n    \"\"\"\n\
      \    client_host = request.client.host if request.client else 'N/A'\n    log_info(f\"\
      \U0001F511 POST /refresh request validated for user '{username}'\", icon_type='AUTH',\
      \ extra={\"client\": client_host})\n    # If validate_refresh_token dependency\
      \ succeeded, the username is valid\n    new_access_token = await create_access_token(username=username)\n\
      \    new_refresh_token = await create_refresh_token(username=username) # Issue\
      \ a new refresh token as well (optional, but good practice)\n    log_success(f\"\
      New access/refresh tokens generated for '{username}' via refresh.\", icon_type='AUTH')\n\
      \    return Token(access_token=new_access_token, refresh_token=new_refresh_token)\n\
      \n# --- Monitoring Endpoints ---\n@app.get(\"/stats\", response_model=StatsResponse,\
      \ tags=[\"Monitoring\"], summary=\"Get System Statistics\")\n@limiter.limit(\"\
      30/minute\") # Moderate limit for stats endpoint\nasync def get_stats(request:\
      \ Request, current_user: str = Depends(get_current_user)) -> StatsResponse:\n\
      \    \"\"\"Returns current application, system, and message broker statistics.\
      \ Requires authentication.\"\"\"\n    client_host = request.client.host if request.client\
      \ else 'N/A'\n    log_info(f\"\U0001F4CA GET /stats request by user '{current_user}'\"\
      , icon_type='STATS', extra={\"client\": client_host})\n\n    # Ensure broker\
      \ stats are reasonably fresh before returning\n    await update_broker_stats()\n\
      \n    # Collect system metrics using psutil in a non-blocking way\n    system_metrics\
      \ = {}\n    try:\n        process = psutil.Process(os.getpid())\n        # Define\
      \ the synchronous function to be run in a thread\n        def _get_psutil_data_sync():\n\
      \            # Use non-blocking calls or short intervals where possible\n  \
      \          mem_info = process.memory_info()\n            # Get CPU percents\
      \ (can be slightly blocking, use short interval)\n            proc_cpu = process.cpu_percent(interval=0.05)\
      \ # Very short interval\n            sys_cpu = psutil.cpu_percent(interval=0.05)\n\
      \            virt_mem = psutil.virtual_memory()\n\n            # Disk usage\
      \ (can be slow, especially on network drives)\n            disk_usage_data =\
      \ {}\n            try:\n                # Get only physical partitions (all=False)\
      \ to potentially speed up\n                partitions = psutil.disk_partitions(all=False)\n\
      \            except Exception as disk_e:\n                log_warning(f\"Could\
      \ not get disk partitions: {disk_e}\", icon_type='STATS')\n                partitions\
      \ = []\n\n            for part in partitions:\n                # Filter out\
      \ unwanted types and potentially problematic mounts\n                unwanted_fstypes\
      \ = ['squashfs', 'tmpfs', 'devtmpfs', 'fuse.gvfsd-fuse', 'overlay', 'autofs']\n\
      \                mountpoint = getattr(part, 'mountpoint', None)\n          \
      \      if not mountpoint or 'loop' in part.device or 'snap' in part.device or\
      \ part.fstype in unwanted_fstypes:\n                    continue\n         \
      \       try:\n                    # Check mountpoint exists before getting usage\n\
      \                    if os.path.exists(mountpoint):\n                      \
      \ usage = psutil.disk_usage(mountpoint)\n                       disk_usage_data[mountpoint]\
      \ = {\n                           \"total_gb\": round(usage.total / (1024**3),\
      \ 2),\n                           \"used_gb\": round(usage.used / (1024**3),\
      \ 2),\n                           \"free_gb\": round(usage.free / (1024**3),\
      \ 2),\n                           \"percent\": usage.percent\n             \
      \          }\n                except (FileNotFoundError, PermissionError, OSError)\
      \ as part_e:\n                    # Log errors for specific partitions but continue\n\
      \                    log_warning(f\"Could not get disk usage for {mountpoint}:\
      \ {part_e}\", icon_type='STATS')\n\n            # Load average (only available\
      \ on Unix-like systems)\n            load_avg = os.getloadavg() if hasattr(os,\
      \ 'getloadavg') else \"N/A\"\n\n            # Gather open file descriptors and\
      \ thread count carefully\n            open_fds = \"N/A\"\n            thread_count\
      \ = \"N/A\"\n            try: open_fds = len(process.open_files())\n       \
      \     except (psutil.AccessDenied, NotImplementedError, Exception) as fd_e:\
      \ log_warning(f\"Could not get open file descriptors: {fd_e}\", icon_type=\"\
      STATS\")\n            try: thread_count = process.num_threads()\n          \
      \  except (psutil.AccessDenied, NotImplementedError, Exception) as th_e: log_warning(f\"\
      Could not get thread count: {th_e}\", icon_type=\"STATS\")\n\n\n           \
      \ return {\n                \"cpu_percent\": sys_cpu,\n                \"memory_total_gb\"\
      : round(virt_mem.total / (1024**3), 2),\n                \"memory_available_gb\"\
      : round(virt_mem.available / (1024**3), 2),\n                \"memory_used_gb\"\
      : round(virt_mem.used / (1024**3), 2),\n                \"memory_percent\":\
      \ virt_mem.percent,\n                \"disk_usage\": disk_usage_data or {\"\
      info\": \"No valid partitions found or error reading usage.\"},\n          \
      \      \"process_memory_rss_mb\": round(mem_info.rss / (1024**2), 2), # Resident\
      \ Set Size\n                \"process_memory_vms_mb\": round(mem_info.vms /\
      \ (1024**2), 2), # Virtual Memory Size\n                \"process_cpu_percent\"\
      : proc_cpu,\n                \"load_average\": load_avg,\n                \"\
      cpu_count_logical\": psutil.cpu_count(logical=True),\n                \"cpu_count_physical\"\
      : psutil.cpu_count(logical=False),\n                \"open_file_descriptors\"\
      : open_fds,\n                \"thread_count\": thread_count,\n             \
      \   # <<< Dashboard expects process_memory_mb, let's add it >>>\n          \
      \      \"process_memory_mb\": round(mem_info.rss / (1024**2), 2) # Using RSS\
      \ as the main process memory metric\n            }\n        # Run the synchronous\
      \ function in a separate thread\n        system_metrics = await asyncio.to_thread(_get_psutil_data_sync)\n\
      \n    except ImportError:\n        system_metrics[\"error\"] = \"psutil package\
      \ not installed. Cannot provide detailed system metrics.\"\n        log_warning(\"\
      psutil package not found. Install with `pip install psutil` for detailed system\
      \ stats.\", icon_type='STATS')\n    except Exception as e:\n        log_warning(f\"\
      Error collecting system stats with psutil: {e}\", icon_type='STATS', exc_info=True)\n\
      \        system_metrics[\"error\"] = f\"psutil data collection failed: {type(e).__name__}\"\
      \n\n    # Prepare response data safely using the lock\n    response_data = {}\n\
      \    async with stats_lock:\n        # Create a copy to avoid modifying the\
      \ global state directly while processing\n        # Ensure all expected keys\
      \ from app_stats are copied\n        current_stats_copy = app_stats.copy()\n\
      \n        # Merge collected system metrics into the system info dictionary\n\
      \        # Ensure the 'system' key exists before merging\n        if \"system\"\
      \ not in current_stats_copy:\n            current_stats_copy[\"system\"] = {}\n\
      \        current_stats_copy[\"system\"].update(system_metrics)\n\n        #\
      \ Calculate uptime\n        start_time_dt = current_stats_copy[\"start_time\"\
      ]\n        uptime_delta = datetime.now(timezone.utc) - start_time_dt\n     \
      \   uptime_seconds = uptime_delta.total_seconds()\n        current_stats_copy[\"\
      uptime_seconds\"] = round(uptime_seconds, 2)\n\n        # Format uptime into\
      \ human-readable string (e.g., \"2d 3h 15m 30s\")\n        days, rem = divmod(int(uptime_seconds),\
      \ 86400)\n        hours, rem = divmod(rem, 3600)\n        minutes, seconds =\
      \ divmod(rem, 60)\n        parts = []\n        if days: parts.append(f\"{days}d\"\
      )\n        if hours: parts.append(f\"{hours}h\")\n        if minutes: parts.append(f\"\
      {minutes}m\")\n        if seconds or not parts: parts.append(f\"{seconds}s\"\
      ) # Always show seconds if other parts are zero\n        current_stats_copy[\"\
      uptime_human\"] = \" \".join(parts)\n\n        # Timestamps (`start_time`, `last_error_timestamp`)\
      \ are already datetime objects\n        # Pydantic's `StatsResponse` model will\
      \ handle serialization to ISO strings.\n\n        # --- Ensure required fields\
      \ for the dashboard are present ---\n        # The middleware should be populating\
      \ these, but ensure they exist in the dict before validation\n        current_stats_copy.setdefault(\"\
      requests_by_route\", {})\n        current_stats_copy.setdefault(\"requests_by_status\"\
      , {})\n        # ---\n\n        response_data = current_stats_copy\n\n     \
      \   # Debugging: Log the exact data structure being passed to validation\n \
      \       log_debug(f\"Data before Pydantic validation in /stats: {response_data}\"\
      , icon_type=\"STATS\")\n\n    log_success(f\"Stats returned for user '{current_user}'.\"\
      , icon_type='STATS')\n    # Validate the final structure against the Pydantic\
      \ model before returning\n    try:\n        # Pydantic automatically converts\
      \ datetime to ISO strings during validation/serialization\n        validated_response\
      \ = StatsResponse.model_validate(response_data)\n        # Log the structure\
      \ *after* validation/serialization if needed for debugging dashboard issues\n\
      \        # log_debug(f\"Data *after* Pydantic validation/serialization in /stats:\
      \ {validated_response.model_dump_json(indent=2)}\", icon_type=\"STATS\")\n \
      \       return validated_response\n    except ValidationError as e:\n      \
      \  # Log the validation error and the data that failed\n        log_critical(f\"\
      Stats data failed Pydantic validation: {e.errors()}\", icon_type='CRITICAL',\
      \ extra={\"invalid_stats_data\": response_data})\n        # Return 500 if the\
      \ generated stats don't match the model schema\n        raise HTTPException(status_code=500,\
      \ detail=\"Internal Server Error: Failed to generate valid stats data.\")\n\n\
      \n\n@app.get(\"/logs\", response_model=LogFileResponse, tags=[\"Monitoring\"\
      ], summary=\"List Log Files\")\n@limiter.limit(\"10/minute\") # Less frequent\
      \ access generally needed\nasync def list_log_files(request: Request, current_user:\
      \ str = Depends(get_current_user)):\n    \"\"\"Lists available JSON log files\
      \ found in the configured log directory. Requires authentication.\"\"\"\n  \
      \  client_host = request.client.host if request.client else 'N/A'\n    log_info(f\"\
      \U0001F4C4 GET /logs request by user '{current_user}'\", icon_type='LOGS', extra={\"\
      client\": client_host})\n    try:\n        # Use asyncio.to_thread for potentially\
      \ blocking os.listdir\n        def list_dir_sync():\n            return os.listdir(settings.LOG_DIR)\n\
      \n        log_files_all = await asyncio.to_thread(list_dir_sync)\n\n       \
      \ # Filter for .json files and sort newest first (based on filename convention)\n\
      \        log_files_json = sorted(\n            [f for f in log_files_all if\
      \ f.endswith('.json') and os.path.isfile(os.path.join(settings.LOG_DIR, f))],\n\
      \            reverse=True # Assumes YYYYMMDD_HHMMSS prefix for sorting\n   \
      \     )\n        log_success(f\"Found {len(log_files_json)} JSON log files in\
      \ '{settings.LOG_DIR}'.\", icon_type='LOGS')\n        return LogFileResponse(log_files=log_files_json)\n\
      \    except FileNotFoundError:\n        log_error(f\"Log directory '{settings.LOG_DIR}'\
      \ configured but not found.\", icon_type='LOGS')\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=\"Log directory not found on server\")\n    except OSError as e:\n\
      \        log_error(f\"Error listing log files in '{settings.LOG_DIR}': {e}\"\
      , exc_info=True, icon_type='LOGS')\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error accessing log directory\")\n\n@app.get(\"/logs/{filename:path}\"\
      , response_model=List[Dict[str, Any]], tags=[\"Monitoring\"], summary=\"Get\
      \ Log File Content\")\n@limiter.limit(\"60/minute\") # Allow more frequent access\
      \ to view individual logs\nasync def get_log_file(\n    request: Request,\n\
      \    filename: str = Path(..., description=\"The name of the JSON log file to\
      \ retrieve (e.g., broker_log_YYYYMMDD_HHMMSS_hash.json).\"),\n    start: Optional[int]\
      \ = FastQuery(None, ge=1, description=\"Start reading from this line number\
      \ (1-based index).\"),\n    end: Optional[int] = FastQuery(None, ge=1, description=\"\
      Stop reading at this line number (inclusive, 1-based index).\"),\n    tail:\
      \ Optional[int] = FastQuery(None, ge=1, le=10000, description=\"Retrieve only\
      \ the last N lines (max 10000). Overrides start/end if provided.\"),\n    current_user:\
      \ str = Depends(get_current_user)\n) -> List[Dict]:\n    \"\"\"\n    Retrieves\
      \ the content of a specific log file, parsing each line as JSON.\n    Supports\
      \ retrieving ranges of lines or the last N lines (tail). Requires authentication.\n\
      \    \"\"\"\n    # --- Security: Sanitize filename ---\n    # Prevents directory\
      \ traversal (e.g., ../../etc/passwd) and ensures it's likely a log file.\n \
      \   safe_filename = secure_filename(filename)\n    if not safe_filename or safe_filename\
      \ != filename or not safe_filename.startswith('broker_log_') or not safe_filename.endswith('.json'):\n\
      \        log_warning(f\"Invalid log file access attempt: '{filename}' by user\
      \ '{current_user}'\", icon_type='SEC')\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\
      \ detail=\"Invalid or potentially unsafe log filename provided.\")\n\n    log_path\
      \ = os.path.join(settings.LOG_DIR, safe_filename)\n    log_info(f\"\U0001F4C4\
      \ GET /logs/{safe_filename} request by '{current_user}' (start={start}, end={end},\
      \ tail={tail})\", icon_type='LOGS')\n\n    # --- File Reading and Parsing (in\
      \ thread to avoid blocking) ---\n    def read_and_parse_log_sync() -> Optional[List[Dict]]:\n\
      \        if not os.path.isfile(log_path):\n            log_warning(f\"Log file\
      \ not found at path: {log_path}\", icon_type='LOGS')\n            return None\
      \ # Signal file not found\n\n        lines_to_process: Union[deque, List[str]]\
      \ = []\n        try:\n            with open(log_path, 'r', encoding='utf-8')\
      \ as f:\n                if tail is not None and tail > 0:\n               \
      \     # Efficiently get last 'tail' lines using deque\n                    lines_to_process\
      \ = deque(f, maxlen=tail)\n                else:\n                    # Read\
      \ line by line, applying start/end limits if present\n                    lines_to_process\
      \ = []\n                    line_count_read = 0\n                    # Line\
      \ numbers are 1-based for user input, enumerate provides 0-based\n         \
      \           for line_num_0based, line in enumerate(f):\n                   \
      \     line_num_1based = line_num_0based + 1\n                        # Skip\
      \ lines before start\n                        if start is not None and line_num_1based\
      \ < start:\n                            continue\n                        #\
      \ Stop reading lines after end\n                        if end is not None and\
      \ line_num_1based > end:\n                            break\n              \
      \          # Add the line (strip whitespace)\n                        stripped_line\
      \ = line.strip()\n                        if stripped_line: # Avoid adding empty\
      \ lines\n                            lines_to_process.append(stripped_line)\n\
      \                            line_count_read += 1\n                        #\
      \ Safety break: Limit lines read if only start is given (prevent huge reads)\n\
      \                        if start is not None and end is None and line_count_read\
      \ >= 10000:\n                            log_warning(f\"Log read for {safe_filename}\
      \ truncated at 10000 lines due to missing 'end' parameter.\", icon_type='LOGS')\n\
      \                            lines_to_process.append(json.dumps({\"_warning\"\
      : \"Result set truncated at 10000 lines (specify 'end' for more)\", \"_limit\"\
      : 10000}))\n                            break\n        except FileNotFoundError:\
      \ # Should be caught by os.path.isfile, but handle defensively\n           \
      \  log_warning(f\"Log file disappeared during read: {log_path}\", icon_type='LOGS')\n\
      \             return None\n        except Exception as read_exc:\n         \
      \   log_error(f\"Error reading log file '{safe_filename}': {read_exc}\", exc_info=True,\
      \ icon_type='LOGS')\n            # Return a list containing just the error for\
      \ the client\n            return [{\"_error\": f\"Failed to read file: {type(read_exc).__name__}.\
      \ Check server logs for details.\"}]\n\n        # --- Parse JSON lines ---\n\
      \        parsed_lines: List[Dict[str, Any]] = []\n        for i, line in enumerate(lines_to_process):\n\
      \            if not line: continue # Skip empty lines (double check)\n\n   \
      \         line_num_info = f\"tail_{i+1}\" if tail else (start or 1) + i # Approximate\
      \ original line number for context\n            try:\n                parsed_line_data\
      \ = json.loads(line)\n                if isinstance(parsed_line_data, dict):\
      \ # Ensure it's a dictionary\n                     parsed_lines.append(parsed_line_data)\n\
      \                else:\n                     # Handle cases where a line is\
      \ valid JSON but not an object (e.g., just a string)\n                     parsed_lines.append({\"\
      _warning\": \"Line parsed but is not a JSON object\", \"_line\": line_num_info,\
      \ \"_type\": type(parsed_line_data).__name__, \"_raw\": line[:250]})\n     \
      \       except json.JSONDecodeError:\n                # Include error info and\
      \ truncated raw line for debugging\n                parsed_lines.append({\"\
      _error\": \"Invalid JSON format\", \"_line\": line_num_info, \"_raw\": line[:250]\
      \ + ('...' if len(line)>250 else '')})\n            except Exception as parse_exc:\n\
      \                 # Catch other potential parsing issues\n                 parsed_lines.append({\"\
      _error\": f\"Parsing error: {parse_exc}\", \"_line\": line_num_info, \"_raw\"\
      : line[:250] + ('...' if len(line)>250 else '')})\n        return parsed_lines\n\
      \n    try:\n        # Run the synchronous file I/O and parsing in a thread\n\
      \        result_lines = await asyncio.to_thread(read_and_parse_log_sync)\n\n\
      \        if result_lines is None:\n            # File was not found by the reading\
      \ function\n            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=f\"Log file '{safe_filename}' not found.\")\n\n        log_success(f\"\
      {len(result_lines)} log entries returned from '{safe_filename}'.\", icon_type='LOGS')\n\
      \        return result_lines\n    except HTTPException:\n        raise # Re-raise\
      \ expected HTTP exceptions (400, 404)\n    except Exception as e:\n        log_error(f\"\
      Unexpected error processing log file '{safe_filename}': {e}\", exc_info=True,\
      \ icon_type='LOGS')\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Unexpected error processing log file. Check server logs.\")\n\n#\
      \ --- Queue Management Endpoints ---\n@app.get(\"/queues\", response_model=List[QueueResponse],\
      \ tags=[\"Queues\"], summary=\"List All Queues\")\n@limiter.limit(\"60/minute\"\
      ) # Allow fairly frequent listing\nasync def list_queues(request: Request, current_user:\
      \ str = Depends(get_current_user)) -> List[QueueResponse]:\n    \"\"\"Lists\
      \ all available message queues, including a count of messages in each. Requires\
      \ authentication.\"\"\"\n    log_info(f\"\U0001F4CB GET /queues request by user\
      \ '{current_user}'\", icon_type='QUEUE')\n    try:\n        # Fetch all queues\
      \ ordered by name\n        queues = await Queue.all().order_by('name')\n   \
      \     if not queues:\n            log_info(\"No queues found in the database.\"\
      , icon_type='QUEUE')\n            return [] # Return empty list if no queues\
      \ exist\n\n        # Fetch message counts for all queues concurrently for efficiency\n\
      \        count_tasks = {q.id: Message.filter(queue_id=q.id).count() for q in\
      \ queues}\n        # Run count queries in parallel\n        message_counts_results\
      \ = await asyncio.gather(*count_tasks.values())\n        # Create a dictionary\
      \ mapping queue_id to its count\n        counts_dict = dict(zip(count_tasks.keys(),\
      \ message_counts_results))\n\n        # Build the response list, validating\
      \ each item with the Pydantic model\n        response_list = []\n        for\
      \ q in queues:\n            try:\n                 response_item = QueueResponse(\n\
      \                     id=q.id, name=q.name, created_at=q.created_at, updated_at=q.updated_at,\n\
      \                     message_count=counts_dict.get(q.id, 0) # Get count from\
      \ dict, default 0\n                 )\n                 response_list.append(response_item)\n\
      \            except ValidationError as e:\n                 # Log if a specific\
      \ queue fails validation, but continue with others\n                 log_error(f\"\
      Queue data validation failed for queue ID {q.id} ('{q.name}'): {e.errors()}\"\
      , icon_type='QUEUE')\n\n        log_success(f\"Returned {len(response_list)}\
      \ queues.\", icon_type='QUEUE')\n        return response_list\n    except Exception\
      \ as e:\n        log_error(f\"Error listing queues: {e}\", icon_type='CRITICAL',\
      \ exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error retrieving queue list from database\")\n\n@app.post(\"/queues\"\
      , response_model=QueueResponse, status_code=status.HTTP_201_CREATED, tags=[\"\
      Queues\"], summary=\"Create New Queue\")\n@limiter.limit(\"30/minute\") # Less\
      \ frequent operation than listing\nasync def create_queue(request: Request,\
      \ payload: QueueCreatePayload, current_user: str = Depends(get_current_user))\
      \ -> QueueResponse:\n    \"\"\"\n    Creates a new message queue. The name must\
      \ be unique. Requires authentication.\n    \"\"\"\n    queue_name = payload.name\n\
      \    log_info(f\"➕ POST /queues request by '{current_user}' to create queue\
      \ '{queue_name}'\", icon_type='QUEUE')\n    try:\n        # Use Tortoise's get_or_create\
      \ for atomicity.\n        # It attempts to get the queue, and if it doesn't\
      \ exist, creates it within a transaction.\n        new_queue, created = await\
      \ Queue.get_or_create(name=queue_name)\n\n        if not created:\n        \
      \    # The queue already existed\n            log_warning(f\"Queue '{queue_name}'\
      \ already exists. Creation request denied (409).\", icon_type='QUEUE')\n   \
      \         raise HTTPException(\n                status_code=status.HTTP_409_CONFLICT,\n\
      \                detail=f\"Queue with name '{queue_name}' already exists.\"\n\
      \            )\n\n        # Queue was successfully created\n        log_success(f\"\
      ✅ Queue '{queue_name}' created successfully (ID: {new_queue.id}).\", icon_type='QUEUE')\n\
      \        # Validate the newly created queue object against the response model\n\
      \        # Manually set message_count to 0 for the response, as it's definitely\
      \ empty\n        response = QueueResponse.model_validate(new_queue)\n      \
      \  response.message_count = 0\n        return response\n\n    except IntegrityError:\
      \ # Catch potential DB unique constraint violation as a fallback\n        log_warning(f\"\
      IntegrityError during queue creation for '{queue_name}'. Likely already exists\
      \ (concurrent request?).\", icon_type='DB')\n        raise HTTPException(status_code=status.HTTP_409_CONFLICT,\
      \ detail=f\"Queue with name '{queue_name}' already exists (database constraint\
      \ violation).\")\n    except ValidationError as e: # Catch Pydantic validation\
      \ errors on the payload\n        log_warning(f\"Queue creation validation error\
      \ for '{queue_name}': {e.errors()}\", icon_type='QUEUE')\n        # Return 422\
      \ for validation errors\n        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\
      \ detail=e.errors())\n    except Exception as e:\n        log_error(f\"Error\
      \ creating queue '{queue_name}': {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Unexpected error creating queue\")\n\n@app.get(\"/queues/{queue_name}\"\
      , response_model=QueueResponse, tags=[\"Queues\"], summary=\"Get Queue Details\"\
      )\n@limiter.limit(\"60/minute\")\nasync def get_queue(request: Request, queue_name:\
      \ str = Path(..., description=\"The name of the queue to retrieve.\"), current_user:\
      \ str = Depends(get_current_user)) -> QueueResponse:\n    \"\"\"Gets details\
      \ for a specific queue by its name, including current message count. Requires\
      \ authentication.\"\"\"\n    log_info(f\"\U0001F4E5 GET /queues/{queue_name}\
      \ request by user '{current_user}'\", icon_type='QUEUE')\n    try:\n       \
      \ # Use the helper function to get the queue or raise 404\n        queue = await\
      \ _get_queue_or_404(queue_name)\n        # Get the count of messages associated\
      \ with this queue\n        message_count = await Message.filter(queue_id=queue.id).count()\n\
      \        log_success(f\"Details for queue '{queue_name}' (ID: {queue.id}) returned.\"\
      , icon_type='QUEUE')\n        # Validate the queue object and add the count\
      \ before returning\n        response = QueueResponse.model_validate(queue)\n\
      \        response.message_count = message_count\n        return response\n \
      \   except HTTPException:\n        raise # Re-raise 404 from helper or any 500\
      \ from DB errors\n    except Exception as e:\n        log_error(f\"Unexpected\
      \ error getting queue details for '{queue_name}': {e}\", icon_type='CRITICAL',\
      \ exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error retrieving queue details\")\n\n@app.delete(\"/queues/{queue_name}\"\
      , status_code=status.HTTP_204_NO_CONTENT, tags=[\"Queues\"], summary=\"Delete\
      \ Queue\")\n@limiter.limit(\"10/minute\") # Deletion should be infrequent and\
      \ controlled\nasync def delete_queue(request: Request, queue_name: str = Path(...,\
      \ description=\"The name of the queue to delete.\"), current_user: str = Depends(get_current_user))\
      \ -> Response:\n    \"\"\"\n    Deletes a queue and all its associated messages\
      \ (due to CASCADE constraint in the Message model).\n    This operation is irreversible.\
      \ Requires authentication.\n    \"\"\"\n    log_info(f\"\U0001F5D1️ DELETE /queues/{queue_name}\
      \ request by user '{current_user}'\", icon_type='QUEUE')\n    try:\n       \
      \ # Find the queue first to ensure it exists (raises 404 if not)\n        queue\
      \ = await _get_queue_or_404(queue_name)\n        queue_id = queue.id # Get ID\
      \ for logging before deletion\n        log_pipeline(f\"Queue '{queue_name}'\
      \ (ID: {queue_id}) found. Proceeding with deletion...\")\n\n        # Perform\
      \ the delete operation. Tortoise handles cascading deletes based on the model's\
      \ ForeignKey definition.\n        await queue.delete()\n\n        log_success(f\"\
      ✅ Queue '{queue_name}' (ID: {queue_id}) and associated messages deleted successfully.\"\
      , icon_type='QUEUE')\n        # Return 204 No Content on successful deletion\n\
      \        return Response(status_code=status.HTTP_204_NO_CONTENT)\n    except\
      \ HTTPException:\n        raise # Re-raise 404 from helper\n    except Exception\
      \ as e:\n        log_error(f\"Error deleting queue '{queue_name}': {e}\", icon_type='CRITICAL',\
      \ exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error deleting queue\")\n\n\n# --- Message Operations Endpoints ---\n\
      @app.post(\"/queues/{queue_name}/messages\", response_model=MessagePublishResponse,\
      \ status_code=status.HTTP_201_CREATED, tags=[\"Messages\"], summary=\"Publish\
      \ Message\")\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT) # Allow high\
      \ traffic for publishing\nasync def publish_message(\n    request: Request,\n\
      \    payload: MessagePayload, # Request body containing the message content\n\
      \    queue_name: str = Path(..., description=\"The name of the target queue.\"\
      ),\n    current_user: str = Depends(get_current_user) # Requires authentication\n\
      ) -> MessagePublishResponse:\n    \"\"\"Publishes a new message with the given\
      \ content to the specified queue. Requires authentication.\"\"\"\n    # Log\
      \ only a preview to avoid logging potentially large/sensitive content fully\n\
      \    content_preview = payload.content[:80] + ('...' if len(payload.content)\
      \ > 80 else '')\n    log_info(f\"\U0001F4E4 POST /queues/{queue_name}/messages\
      \ request by '{current_user}'\", icon_type='MSG', extra={\"content_preview\"\
      : content_preview})\n    try:\n        # Ensure the target queue exists (raises\
      \ 404 if not)\n        queue = await _get_queue_or_404(queue_name)\n       \
      \ log_pipeline(f\"Queue '{queue_name}' (ID: {queue.id}) found. Creating message...\"\
      )\n\n        # Create the message in the database with 'pending' status\n  \
      \      new_message = await Message.create(queue=queue, content=payload.content,\
      \ status='pending')\n\n        log_success(f\"✅ Message ID {new_message.id}\
      \ published to queue '{queue_name}'.\", icon_type='MSG')\n        # Optionally,\
      \ update overall broker stats in the background if performance is critical\n\
      \        # background_tasks.add_task(update_broker_stats)\n        return MessagePublishResponse(message_id=new_message.id)\n\
      \    except HTTPException:\n        raise # Re-raise 404 if queue not found\n\
      \    except ValidationError as e: # Catch Pydantic validation errors on the\
      \ payload\n        log_warning(f\"Message publish validation error to '{queue_name}':\
      \ {e.errors()}\", icon_type='MSG')\n        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\
      \ detail=e.errors())\n    except Exception as e:\n        log_error(f\"Error\
      \ publishing message to queue '{queue_name}': {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error publishing message\")\n\n\n@app.post(\"/messages/{message_id}/ack\"\
      , response_model=MessageResponse, tags=[\"Messages\"], summary=\"Acknowledge\
      \ Message\")\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT)  # High traffic\
      \ endpoint\nasync def acknowledge_message(\n    request: Request,  # Added request\
      \ parameter for rate limiter\n    message_id: int = Path(..., description=\"\
      The ID of the message to acknowledge.\"),\n    current_user: str = Depends(get_current_user)\
      \  # Requires authentication\n) -> MessageResponse:\n    \"\"\"\n    Acknowledges\
      \ a previously consumed message by marking it as 'completed'.\n    This confirms\
      \ the message has been successfully processed by the consumer.\n    The message\
      \ must be in the 'processing' state to be acknowledged.\n    Returns the final\
      \ message status details.\n    Requires authentication.\n    \"\"\"\n    log_info(f\"\
      ✅ POST /messages/{message_id}/ack request by '{current_user}'\", icon_type='MSG')\n\
      \n    try:\n        # Start transaction for atomic operations\n        async\
      \ with in_transaction(\"default\") as tx:\n            # Find the message -\
      \ must exist and be in 'processing' state\n            message = await Message.filter(id=message_id).select_for_update().first()\n\
      \            \n            if not message:\n                log_warning(f\"\
      Message ID {message_id} not found during acknowledgment.\", icon_type='MSG')\n\
      \                raise HTTPException(\n                    status_code=status.HTTP_404_NOT_FOUND,\n\
      \                    detail=f\"Message with ID {message_id} not found.\"\n \
      \               )\n                \n            if message.status != 'processing':\n\
      \                log_warning(f\"Cannot acknowledge message ID {message_id}:\
      \ invalid status '{message.status}' (must be 'processing').\", icon_type='MSG')\n\
      \                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n\
      \                    detail=f\"Message must be in 'processing' status to be\
      \ acknowledged. Current status: {message.status}\"\n                )\n    \
      \            \n            # Update message status to completed\n          \
      \  message.status = 'completed'\n            message.updated_at = datetime.now(timezone.utc)\
      \  # Record completion time\n            \n            # Save the changes\n\
      \            await message.save(update_fields=['status', 'updated_at'])\n  \
      \          \n            # Get queue name for response\n            queue =\
      \ await message.queue\n            queue_name = queue.name if queue else \"\
      unknown\"  # Fallback if relationship query fails\n        \n        # Transaction\
      \ committed successfully at this point\n        log_success(f\"✅ Message ID\
      \ {message_id} successfully acknowledged (status -> completed).\", icon_type='MSG')\n\
      \        \n        # Return success response using MessageResponse model\n \
      \       return MessageResponse(\n            id=message.id,\n            queue=queue_name,\n\
      \            content=message.content,\n            status=message.status,  #\
      \ Will be 'completed'\n            created_at=message.created_at,\n        \
      \    updated_at=message.updated_at  # Timestamp of acknowledgment\n        )\n\
      \        \n    except HTTPException as http_exc:\n        # Re-raise HTTP exceptions\
      \ - already logged by handler\n        raise http_exc\n    except Exception\
      \ as e:\n        # Log unexpected errors and return 500\n        log_error(f\"\
      Error acknowledging message {message_id}: {str(e)}\", icon_type='ERROR', exc_info=True)\n\
      \        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n\
      \            detail=\"Error acknowledging message\"\n        )\n\n\n@app.post(\"\
      /messages/{message_id}/ack\", status_code=status.HTTP_200_OK, response_model=Dict[str,\
      \ str], tags=[\"Messages\"], summary=\"Acknowledge Message\")\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT)\
      \ # High traffic expected\nasync def acknowledge_message(\n    request: Request,\n\
      \    background_tasks: BackgroundTasks, # Can be used for background tasks after\
      \ ack\n    message_id: int = Path(..., ge=1, description=\"The ID of the message\
      \ to acknowledge.\"),\n    current_user: str = Depends(get_current_user) # Requires\
      \ authentication\n) -> Dict[str, str]:\n    \"\"\"\n    Marks a message currently\
      \ in the 'processing' state as 'processed'.\n    Uses a transaction with SELECT\
      \ FOR UPDATE to prevent race conditions.\n    Requires authentication.\n   \
      \ \"\"\"\n    log_info(f\"✅ POST /messages/{message_id}/ack request by '{current_user}'\"\
      , icon_type='MSG')\n    try:\n        # Start transaction for atomic find-and-update\n\
      \        async with in_transaction(\"default\") as tx:\n            # Find the\
      \ message by ID *only if its status is 'processing'*, lock it, using the transaction\n\
      \            message = await Message.filter(id=message_id, status='processing')\
      \ \\\n                                   .using_connection(tx) \\\n        \
      \                           .select_for_update() \\\n                      \
      \             .get_or_none() # Use get_or_none to handle not found gracefully\n\
      \n            # Check if the message was found in the correct state\n      \
      \      if not message:\n                # If not found in 'processing' state,\
      \ check if it exists at all or has a different status\n                # Check\
      \ status without locking again, just to provide a better error message\n   \
      \             existing_msg_status = await Message.filter(id=message_id) \\\n\
      \                                                   .using_connection(tx) \\\
      \n                                                   .values_list('status',\
      \ flat=True) \\\n                                                   .first()\n\
      \                if existing_msg_status:\n                    # Message exists\
      \ but is not 'processing' (e.g., already acked, failed, or still pending)\n\
      \                    log_warning(f\"ACK failed for message {message_id}: Expected\
      \ status 'processing', found '{existing_msg_status}'.\", icon_type='MSG')\n\
      \                    raise HTTPException(\n                        status_code=status.HTTP_409_CONFLICT,\n\
      \                        detail=f\"Message {message_id} is in status '{existing_msg_status}',\
      \ cannot ACK. Only 'processing' messages can be acknowledged.\"\n          \
      \          )\n                else:\n                    # Message ID does not\
      \ exist in the database\n                    log_warning(f\"ACK failed: Message\
      \ {message_id} not found.\", icon_type='MSG')\n                    raise HTTPException(\n\
      \                        status_code=status.HTTP_404_NOT_FOUND,\n          \
      \              detail=f\"Message with ID {message_id} not found.\"\n       \
      \             )\n\n            # Message found and is in 'processing' state.\
      \ Update status.\n            message.status = 'processed'\n            message.updated_at\
      \ = datetime.now(timezone.utc)\n            # Save changes using the transaction\
      \ connection\n            await message.save(using_connection=tx, update_fields=['status',\
      \ 'updated_at'])\n            # Transaction commits automatically here\n\n \
      \       log_success(f\"✅ Message ID {message_id} acknowledged successfully by\
      \ '{current_user}' (status -> processed).\", icon_type='MSG')\n        # Optionally\
      \ update overall broker stats in the background\n        # background_tasks.add_task(update_broker_stats)\n\
      \        return {\"detail\": f\"Message {message_id} acknowledged successfully.\"\
      }\n\n    except HTTPException:\n        raise # Re-raise 404, 409 from checks\n\
      \    except IntegrityError as e:\n         log_warning(f\"DB integrity error\
      \ during ACK for message {message_id}: {e}\", icon_type='DB')\n         raise\
      \ HTTPException(status_code=status.HTTP_409_CONFLICT, detail=\"Database conflict\
      \ during message acknowledgement.\")\n    except Exception as e:\n        log_error(f\"\
      Error acknowledging message {message_id}: {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error acknowledging message\")\n\n\n@app.post(\"/messages/{message_id}/nack\"\
      , status_code=status.HTTP_200_OK, response_model=Dict[str, str], tags=[\"Messages\"\
      ], summary=\"Negative Acknowledge Message\")\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT)\
      \ # High traffic expected\nasync def negative_acknowledge_message(\n    request:\
      \ Request,\n    background_tasks: BackgroundTasks, # For potential background\
      \ tasks\n    message_id: int = Path(..., ge=1, description=\"The ID of the message\
      \ to NACK.\"),\n    requeue: bool = FastQuery(False, description=\"If true,\
      \ set status back to 'pending' for reprocessing. If false, set status to 'failed'.\"\
      ),\n    current_user: str = Depends(get_current_user) # Requires authentication\n\
      ) -> Dict[str, str]:\n    \"\"\"\n    Negatively acknowledges a message currently\
      \ in the 'processing' state.\n    This typically means processing failed.\n\
      \    - If `requeue` is true, the message status is set back to 'pending' to\
      \ be consumed again later.\n    - If `requeue` is false (default), the message\
      \ status is set to 'failed'.\n    Uses a transaction with SELECT FOR UPDATE.\
      \ Requires authentication.\n    \"\"\"\n    action = \"requeued (pending)\"\
      \ if requeue else \"marked as failed\"\n    log_info(f\"❌ POST /messages/{message_id}/nack\
      \ request by '{current_user}' (requeue={requeue})\", icon_type='MSG')\n    try:\n\
      \        # Start transaction for atomic find-and-update\n        async with\
      \ in_transaction(\"default\") as tx:\n            # Find the message by ID *only\
      \ if its status is 'processing'*, lock it, using the transaction\n         \
      \   message = await Message.filter(id=message_id, status='processing') \\\n\
      \                                   .using_connection(tx) \\\n             \
      \                      .select_for_update() \\\n                           \
      \        .get_or_none()\n\n            # Check if the message was found in the\
      \ correct state\n            if not message:\n                # If not found\
      \ in 'processing' state, check if it exists at all or has a different status\n\
      \                existing_msg_status = await Message.filter(id=message_id) \\\
      \n                                                   .using_connection(tx) \\\
      \n                                                   .values_list('status',\
      \ flat=True) \\\n                                                   .first()\n\
      \                if existing_msg_status:\n                    # Message exists\
      \ but is not 'processing'\n                    log_warning(f\"NACK failed for\
      \ message {message_id}: Expected status 'processing', found '{existing_msg_status}'.\"\
      , icon_type='MSG')\n                    raise HTTPException(\n             \
      \           status_code=status.HTTP_409_CONFLICT,\n                        detail=f\"\
      Message {message_id} is in status '{existing_msg_status}', cannot NACK. Only\
      \ 'processing' messages can be negatively acknowledged.\"\n                \
      \    )\n                else:\n                    # Message ID does not exist\n\
      \                    log_warning(f\"NACK failed: Message {message_id} not found.\"\
      , icon_type='MSG')\n                    raise HTTPException(\n             \
      \           status_code=status.HTTP_404_NOT_FOUND,\n                       \
      \ detail=f\"Message with ID {message_id} not found.\"\n                    )\n\
      \n            # Message found and is 'processing'. Determine the new status\
      \ based on 'requeue' flag.\n            new_status = 'pending' if requeue else\
      \ 'failed'\n            message.status = new_status\n            message.updated_at\
      \ = datetime.now(timezone.utc)\n            # Save changes using the transaction\
      \ connection\n            await message.save(using_connection=tx, update_fields=['status',\
      \ 'updated_at'])\n            # Transaction commits automatically here\n\n \
      \       log_success(f\"✅ Message ID {message_id} NACK'd successfully by '{current_user}'\
      \ (status -> {new_status}).\", icon_type='MSG')\n        # Optionally update\
      \ stats\n        # background_tasks.add_task(update_broker_stats)\n        return\
      \ {\"detail\": f\"Message {message_id} successfully {action}.\"}\n\n    except\
      \ HTTPException:\n        raise # Re-raise 404, 409\n    except IntegrityError\
      \ as e:\n         log_warning(f\"DB integrity error during NACK for message\
      \ {message_id}: {e}\", icon_type='DB')\n         raise HTTPException(status_code=status.HTTP_409_CONFLICT,\
      \ detail=\"Database conflict during message NACK operation.\")\n    except Exception\
      \ as e:\n        log_error(f\"Error NACK'ing message {message_id} (action: {action}):\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=f\"Error negatively acknowledging message (action: {action})\")\n\n\
      # --- GraphQL Setup ---\n# This section defines the Strawberry GraphQL schema\
      \ and resolvers, providing an alternative API interface.\nlog_info(\"\U0001F353\
      \ Configuring GraphQL endpoint with Strawberry...\", icon_type='GRAPHQL')\n\n\
      # --- GraphQL Object Types (mirroring Pydantic/ORM models) ---\n@strawberry.type(description=\"\
      Represents a message in a queue\")\nclass MessageGQL:\n    id: strawberry.ID\
      \ # Use strawberry.ID for GraphQL IDs\n    queue_name: str = strawberry.field(description=\"\
      Name of the queue this message belongs to\")\n    content: str\n    status:\
      \ str\n    created_at: datetime\n    updated_at: datetime\n\n    @classmethod\n\
      \    def from_orm(cls, model: Message, queue_name_str: str) -> \"MessageGQL\"\
      :\n         \"\"\"Helper to create MessageGQL from Tortoise Message model.\"\
      \"\"\n         return cls(\n             id=strawberry.ID(str(model.id)), #\
      \ Convert int ID to string for GraphQL ID\n             queue_name=queue_name_str,\n\
      \             content=model.content,\n             status=model.status,\n  \
      \           created_at=model.created_at,\n             updated_at=model.updated_at\n\
      \         )\n\n@strawberry.type(description=\"Represents a message queue\")\n\
      class QueueGQL:\n    id: strawberry.ID\n    name: str\n    created_at: datetime\n\
      \    updated_at: datetime\n\n    @strawberry.field(description=\"Retrieves the\
      \ current count of messages in this queue\")\n    async def message_count(self,\
      \ info: Info) -> int:\n        \"\"\"Resolver for the message count field.\"\
      \"\"\n        log_pipeline(f\"GQL: Resolving message_count for Queue ID {self.id}\"\
      , icon_type='GRAPHQL')\n        try:\n            # Convert Strawberry ID back\
      \ to int for DB query\n            return await Message.filter(queue_id=int(self.id)).count()\n\
      \        except ValueError: # Handle invalid ID format\n             log_error(f\"\
      GQL message_count: Invalid ID format '{self.id}'\", icon_type='GRAPHQL')\n \
      \            return 0\n        except Exception as e:\n            log_error(f\"\
      GQL message_count resolver error for queue ID {self.id}: {e}\", exc_info=True,\
      \ icon_type='GRAPHQL')\n            return 0 # Return 0 on unexpected errors\n\
      \n    @strawberry.field(description=\"Retrieves messages belonging to this queue,\
      \ with filtering and pagination\")\n    async def messages(\n        self, info:\
      \ Info, # Strawberry passes context via info\n        status: Optional[str]\
      \ = strawberry.field(default=None, description=\"Filter by message status (e.g.,\
      \ pending, processing, processed, failed)\"),\n        limit: int = strawberry.field(default=10,\
      \ description=\"Maximum number of messages to return (1-100)\"),\n        offset:\
      \ int = strawberry.field(default=0, description=\"Number of messages to skip\
      \ (for pagination)\")\n    ) -> List[MessageGQL]:\n        \"\"\"Resolver for\
      \ retrieving messages within a queue.\"\"\"\n        log_pipeline(f\"GQL: Resolving\
      \ messages for Queue ID {self.id} (status={status}, limit={limit}, offset={offset})\"\
      , icon_type='GRAPHQL')\n        # Validate status filter\n        valid_statuses\
      \ = ['pending', 'processing', 'processed', 'failed']\n        if status and\
      \ status not in valid_statuses:\n            raise ValueError(f\"Invalid status\
      \ filter: '{status}'. Must be one of {valid_statuses}.\")\n\n        # Clamp\
      \ limit to a reasonable range (prevent excessive data retrieval)\n        limit\
      \ = max(1, min(limit, 100))\n        # Ensure offset is non-negative\n     \
      \   offset = max(0, offset)\n\n        try:\n             queue_id_int = int(self.id)\
      \ # Convert GQL ID to int\n             # Build the query\n             query\
      \ = Message.filter(queue_id=queue_id_int)\n             if status:\n       \
      \          query = query.filter(status=status)\n             # Apply ordering,\
      \ offset, and limit\n             messages_db = await query.order_by('-created_at').offset(offset).limit(limit)\n\
      \n             # Convert ORM models to GraphQL types (Need queue name for MessageGQL)\n\
      \             return [MessageGQL.from_orm(m, queue_name_str=self.name) for m\
      \ in messages_db]\n        except ValueError as ve: # Handles invalid ID or\
      \ status\n             log_warning(f\"GQL messages resolver validation error\
      \ for queue ID {self.id}: {ve}\", icon_type='GRAPHQL')\n             raise ve\
      \ # Let Strawberry handle user input validation errors by raising them\n   \
      \     except Exception as e:\n             log_error(f\"GQL messages resolver\
      \ error for queue ID {self.id}: {e}\", exc_info=True, icon_type='GRAPHQL')\n\
      \             return [] # Return empty list on internal server error\n\n# ---\
      \ GraphQL Root Query Type ---\n@strawberry.type\nclass QueryGQL:\n    @strawberry.field(description=\"\
      Retrieves a list of all available message queues\")\n    async def all_queues(self,\
      \ info: Info) -> List[QueueGQL]:\n        \"\"\"Resolver for the root 'allQueues'\
      \ query.\"\"\"\n        log_info(\"\U0001F353 GraphQL Query: all_queues\", icon_type='GRAPHQL')\n\
      \        try:\n             queues_db = await Queue.all().order_by('name')\n\
      \             # Convert ORM models to GraphQL types\n             # Note: message_count\
      \ resolver for each queue will be called by Strawberry if requested in the GQL\
      \ query\n             return [\n                 QueueGQL(id=strawberry.ID(str(q.id)),\
      \ name=q.name, created_at=q.created_at, updated_at=q.updated_at)\n         \
      \        for q in queues_db\n             ]\n        except Exception as e:\n\
      \            log_error(f\"GraphQL 'all_queues' resolver error: {e}\", icon_type='GRAPHQL',\
      \ exc_info=True)\n            return [] # Return empty list on error\n\n   \
      \ @strawberry.field(description=\"Retrieves a specific message queue by its\
      \ unique name\")\n    async def queue_by_name(self, info: Info, name: str) ->\
      \ Optional[QueueGQL]:\n        \"\"\"Resolver for the root 'queueByName' query.\"\
      \"\"\n        log_info(f\"\U0001F353 GraphQL Query: queue_by_name (name='{name}')\"\
      , icon_type='GRAPHQL')\n        try:\n            queue_db = await Queue.get_or_none(name=name)\n\
      \            if queue_db:\n                # Convert ORM model to GraphQL type\n\
      \                return QueueGQL(id=strawberry.ID(str(queue_db.id)), name=queue_db.name,\
      \ created_at=queue_db.created_at, updated_at=queue_db.updated_at)\n        \
      \    else:\n                log_warning(f\"GraphQL: Queue '{name}' not found\
      \ via queue_by_name.\", icon_type='GRAPHQL')\n                return None #\
      \ Return null if not found\n        except Exception as e:\n            log_error(f\"\
      GraphQL 'queue_by_name' resolver error for name '{name}': {e}\", icon_type='GRAPHQL',\
      \ exc_info=True)\n            return None # Return null on error\n\n    @strawberry.field(description=\"\
      Retrieves a specific message by its unique ID\")\n    async def message_by_id(self,\
      \ info: Info, id: strawberry.ID) -> Optional[MessageGQL]:\n        \"\"\"Resolver\
      \ for the root 'messageById' query.\"\"\"\n        log_info(f\"\U0001F353 GraphQL\
      \ Query: message_by_id (id={id})\", icon_type='GRAPHQL')\n        try:\n   \
      \         message_id_int = int(id) # Convert GQL ID string to int\n        \
      \    # Fetch message and its related queue in one query\n            message_db\
      \ = await Message.get_or_none(id=message_id_int).select_related('queue')\n\n\
      \            if message_db and message_db.queue: # Ensure message and its queue\
      \ exist\n                # Convert ORM model to GraphQL type, passing the queue\
      \ name\n                return MessageGQL.from_orm(message_db, queue_name_str=message_db.queue.name)\n\
      \            else:\n                log_warning(f\"GraphQL: Message ID {id}\
      \ not found or has no associated queue.\", icon_type='GRAPHQL')\n          \
      \      return None # Return null if not found or queue is missing\n        except\
      \ (ValueError, DoesNotExist): # Handle invalid ID format or message not found\n\
      \            log_warning(f\"GraphQL: Message ID {id} not found or invalid format.\"\
      , icon_type='GRAPHQL')\n            return None\n        except Exception as\
      \ e:\n            log_error(f\"GraphQL 'message_by_id' resolver error for ID\
      \ {id}: {e}\", icon_type='GRAPHQL', exc_info=True)\n            return None\n\
      \n# --- GraphQL Root Mutation Type ---\n@strawberry.type\nclass MutationGQL:\n\
      \    @strawberry.mutation(description=\"Creates a new message queue\")\n   \
      \ async def create_queue(self, info: Info, name: str) -> QueueGQL:\n       \
      \  \"\"\"Resolver for the 'createQueue' mutation.\"\"\"\n         log_info(f\"\
      \U0001F353 GraphQL Mutation: create_queue (name='{name}')\", icon_type='GRAPHQL')\n\
      \         # Add authentication check using context if needed\n         # context\
      \ = info.context\n         # if not context.get(\"current_user\"): raise Exception(\"\
      Authentication required\")\n         try:\n             # Validate name format\
      \ (redundant if using Pydantic input type, but good practice here)\n       \
      \      if not re.match(r\"^[a-zA-Z0-9_-]+$\", name):\n                 raise\
      \ ValueError(\"Invalid queue name format. Use alphanumeric, underscore, hyphen.\"\
      )\n             if len(name) > 255:\n                 raise ValueError(\"Queue\
      \ name exceeds maximum length of 255 characters.\")\n\n             # Use get_or_create\
      \ for atomicity\n             new_queue, created = await Queue.get_or_create(name=name)\n\
      \             if not created:\n                 # Raise exception for Strawberry\
      \ to format as a GraphQL error\n                 raise Exception(f\"Queue with\
      \ name '{name}' already exists.\")\n             log_success(f\"GQL: Queue '{name}'\
      \ created (ID: {new_queue.id}).\", icon_type='QUEUE')\n             # Convert\
      \ ORM model to GQL type for the response\n             return QueueGQL(id=strawberry.ID(str(new_queue.id)),\
      \ name=new_queue.name, created_at=new_queue.created_at, updated_at=new_queue.updated_at)\n\
      \         except ValueError as ve: # Catch validation errors\n             \
      \ log_warning(f\"GraphQL 'create_queue' validation error for name '{name}':\
      \ {ve}\", icon_type='GRAPHQL')\n              raise Exception(str(ve)) # Re-raise\
      \ with message\n         except Exception as e:\n             log_error(f\"\
      GraphQL 'create_queue' mutation error for name '{name}': {e}\", icon_type='GRAPHQL',\
      \ exc_info=True)\n             # Re-raise for Strawberry to handle, providing\
      \ a user-friendly message\n             raise Exception(f\"Failed to create\
      \ queue '{name}': {e}\")\n\n    @strawberry.mutation(description=\"Deletes a\
      \ queue and all its associated messages\")\n    async def delete_queue(self,\
      \ info: Info, name: str) -> bool:\n        \"\"\"Resolver for the 'deleteQueue'\
      \ mutation.\"\"\"\n        log_info(f\"\U0001F353 GraphQL Mutation: delete_queue\
      \ (name='{name}')\", icon_type='GRAPHQL')\n        # Add authentication check\
      \ if needed\n        try:\n            queue = await Queue.get_or_none(name=name)\n\
      \            if not queue:\n                raise Exception(f\"Queue with name\
      \ '{name}' not found.\")\n            await queue.delete() # Cascade delete\
      \ handled by ORM relationship\n            log_success(f\"GQL: Queue '{name}'\
      \ deleted successfully.\", icon_type='QUEUE')\n            return True # Return\
      \ true on success\n        except Exception as e:\n            log_error(f\"\
      GraphQL 'delete_queue' mutation error for name '{name}': {e}\", icon_type='GRAPHQL',\
      \ exc_info=True)\n            raise Exception(f\"Failed to delete queue '{name}':\
      \ {e}\") # Re-raise for Strawberry\n\n    @strawberry.mutation(description=\"\
      Publishes a message to a specified queue\")\n    async def publish_message(self,\
      \ info: Info, queue_name: str, content: str) -> MessageGQL:\n        \"\"\"\
      Resolver for the 'publishMessage' mutation.\"\"\"\n        log_info(f\"\U0001F353\
      \ GraphQL Mutation: publish_message (queue='{queue_name}')\", icon_type='GRAPHQL')\n\
      \        # Add authentication check if needed\n        try:\n            # Validate\
      \ content length (example)\n            if not content:\n                 raise\
      \ ValueError(\"Message content cannot be empty.\")\n\n            queue = await\
      \ Queue.get_or_none(name=queue_name)\n            if not queue:\n          \
      \      raise Exception(f\"Queue with name '{queue_name}' not found.\")\n\n \
      \           # Create the message\n            new_message = await Message.create(queue=queue,\
      \ content=content, status='pending')\n            log_success(f\"GQL: Message\
      \ ID {new_message.id} published to queue '{queue_name}'.\", icon_type='MSG')\n\
      \            # Convert ORM model to GQL type for the response\n            return\
      \ MessageGQL.from_orm(new_message, queue_name_str=queue_name)\n        except\
      \ ValueError as ve:\n             log_warning(f\"GraphQL 'publish_message' validation\
      \ error to queue '{queue_name}': {ve}\", icon_type='GRAPHQL')\n            \
      \ raise Exception(str(ve))\n        except Exception as e:\n            log_error(f\"\
      GraphQL 'publish_message' mutation error to queue '{queue_name}': {e}\", icon_type='GRAPHQL',\
      \ exc_info=True)\n            raise Exception(f\"Failed to publish message to\
      \ queue '{queue_name}': {e}\")\n\n# --- GraphQL Context Getter ---\nasync def\
      \ get_graphql_context(\n    request: Request,\n    response: Response,\n   \
      \ background_tasks: BackgroundTasks,\n    # Use Bearer scheme for GraphQL Authorization\
      \ header\n    auth: Optional[HTTPAuthorizationCredentials] = Depends(bearer_scheme)\n\
      ) -> Dict:\n    \"\"\"\n    Provides context dictionary accessible within GraphQL\
      \ resolvers via `info.context`.\n    Includes request/response objects, background\
      \ tasks, and attempts to authenticate the user.\n    \"\"\"\n    context = {\n\
      \        \"request\": request,\n        \"response\": response,\n        \"\
      background_tasks\": background_tasks,\n        \"current_user\": None # Default\
      \ to unauthenticated\n    }\n    if auth:\n        try:\n            # Attempt\
      \ to validate the access token provided in the Authorization: Bearer header\n\
      \            username = await _decode_token(auth.credentials, \"access\")\n\
      \            context[\"current_user\"] = username # Set username in context\
      \ if valid\n            log_debug(f\"\U0001F353 GraphQL request authenticated\
      \ for user: '{username}'\", icon_type='AUTH')\n        except HTTPException\
      \ as auth_exc:\n            # Log failed auth attempts but don't block the request\
      \ here.\n            # Individual resolvers should check `info.context[\"current_user\"\
      ]` if they require auth.\n            log_warning(f\"GraphQL authentication\
      \ failed: {auth_exc.detail} (Status: {auth_exc.status_code})\", icon_type='AUTH')\n\
      \            # Optionally, you could set an error flag in the context: context[\"\
      auth_error\"] = auth_exc.detail\n    else:\n         log_debug(\"\U0001F353\
      \ GraphQL request is unauthenticated (no Bearer token found).\", icon_type='AUTH')\n\
      \n    return context\n\n# --- GraphQL Schema and Router Setup ---\ngql_schema\
      \ = strawberry.Schema(query=QueryGQL, mutation=MutationGQL)\ngraphql_app = GraphQLRouter(\n\
      \    gql_schema,\n    context_getter=get_graphql_context, # Function to create\
      \ the context dict\n    graphiql=False, # Disable default GraphiQL\n    graphql_ide=\"\
      apollo-sandbox\" # Use Apollo Sandbox (provides more features) hosted by Strawberry\n\
      \    # Or set to None to disable the IDE: graphql_ide=None\n)\n# Include the\
      \ GraphQL router in the main FastAPI application\napp.include_router(graphql_app,\
      \ prefix=\"/graphql\", tags=[\"GraphQL\"], include_in_schema=True) # include_in_schema\
      \ adds it to OpenAPI docs\nlog_success(\"\U0001F353 GraphQL endpoint /graphql\
      \ configured with Apollo Sandbox IDE.\", icon_type='GRAPHQL')\n\n# --- Global\
      \ Exception Handlers ---\n# These handlers catch specific exceptions that might\
      \ occur anywhere in the app\n# and return standardized JSON error responses.\n\
      \n@app.exception_handler(DoesNotExist)\nasync def tortoise_does_not_exist_handler(request:\
      \ Request, exc: DoesNotExist):\n    \"\"\"Handles Tortoise ORM's DoesNotExist\
      \ errors globally, returning 404.\"\"\"\n    # Try to extract model name from\
      \ the exception string for better context\n    model_name_match = str(exc).split(\"\
      :\")\n    model_name = model_name_match[0].strip() if len(model_name_match)\
      \ > 0 else \"Resource\"\n    detail = f\"{model_name} not found.\"\n    client_host\
      \ = request.client.host if request.client else \"N/A\"\n    log_warning(f\"\
      Resource Not Found (DB DoesNotExist): {exc} ({request.method} {request.url.path})\"\
      , icon_type='DB', extra={\"client\": client_host})\n    return JSONResponse(\n\
      \        status_code=status.HTTP_404_NOT_FOUND,\n        content={\"detail\"\
      : detail}\n    )\n\n@app.exception_handler(IntegrityError)\nasync def tortoise_integrity_error_handler(request:\
      \ Request, exc: IntegrityError):\n    \"\"\"Handles Tortoise ORM's IntegrityError\
      \ (e.g., unique constraint violations), returning 409.\"\"\"\n    detail = \"\
      Database conflict occurred.\"\n    # Try to get more specific error info from\
      \ the exception arguments (driver-dependent)\n    # Be cautious about leaking\
      \ internal details\n    error_info_str = str(exc) # Get the base error string\n\
      \    if \"UNIQUE constraint failed\" in error_info_str:\n        detail = \"\
      A resource with the same unique identifier already exists.\"\n    elif settings.APP_ENV\
      \ == 'development': # Show more details only in dev\n        detail += f\" Error:\
      \ {error_info_str}\"\n\n    client_host = request.client.host if request.client\
      \ else \"N/A\"\n    log_warning(f\"Database Integrity Conflict: {exc} ({request.method}\
      \ {request.url.path})\", icon_type='DB', extra={\"client\": client_host})\n\
      \    return JSONResponse(\n        status_code=status.HTTP_409_CONFLICT,\n \
      \       content={\"detail\": detail}\n    )\n\n@app.exception_handler(ValidationError)\n\
      async def pydantic_validation_exception_handler(request: Request, exc: ValidationError):\n\
      \    \"\"\"Handles Pydantic validation errors (e.g., invalid request body/params),\
      \ returning 422.\"\"\"\n    client_host = request.client.host if request.client\
      \ else \"N/A\"\n    try:\n        # Use Pydantic's json() method for standardized\
      \ error output\n        error_content = {\"detail\": \"Request validation failed\"\
      , \"errors\": json.loads(exc.json())}\n        log_warning(f\"Request Validation\
      \ Error (Pydantic): {error_content['errors']} ({request.method} {request.url.path})\"\
      , icon_type='HTTP', extra={\"client\": client_host})\n    except Exception as\
      \ json_err: # Fallback if json.loads fails for some reason\n        log_error(f\"\
      Error parsing Pydantic validation errors: {json_err}\", icon_type=\"ERROR\"\
      )\n        error_content = {\"detail\": \"Request validation failed\", \"errors\"\
      : str(exc)} # Simple string representation\n        log_warning(f\"Request Validation\
      \ Error (Pydantic - raw): {str(exc)} ({request.method} {request.url.path})\"\
      , icon_type='HTTP', extra={\"client\": client_host})\n\n    return JSONResponse(\n\
      \        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n        content=error_content\n\
      \    )\n\n@app.exception_handler(HTTPException)\nasync def http_exception_handler(request:\
      \ Request, exc: HTTPException):\n    \"\"\"Handles FastAPI's built-in HTTPExceptions,\
      \ ensuring consistent logging and response format.\"\"\"\n    # Determine log\
      \ level based on status code (warnings for 4xx, errors for 5xx)\n    log_level\
      \ = log_warning if 400 <= exc.status_code < 500 else log_error\n    icon = 'HTTP'\
      \ if 400 <= exc.status_code < 500 else 'ERROR'\n    client_host = request.client.host\
      \ if request.client else \"N/A\"\n    log_level(\n        f\"HTTP Error Handled:\
      \ Status={exc.status_code}, Detail='{exc.detail}' ({request.method} {request.url.path})\"\
      ,\n        icon_type=icon,\n        extra={\"client\": client_host, \"headers\"\
      : exc.headers} # Log associated headers (like WWW-Authenticate)\n    )\n   \
      \ # Return the standard JSON response using details and headers from the exception\n\
      \    return JSONResponse(\n        status_code=exc.status_code,\n        content={\"\
      detail\": exc.detail},\n        headers=getattr(exc, \"headers\", None) # Include\
      \ headers if the exception has them\n    )\n\n@app.exception_handler(Exception)\n\
      async def generic_exception_handler(request: Request, exc: Exception):\n   \
      \ \"\"\"\n    Handles any other unhandled exceptions as a generic 500 Internal\
      \ Server Error.\n    Logs the error critically and returns a safe error message\
      \ to the client.\n    \"\"\"\n    # Format traceback for logging\n    tb_str\
      \ = \"\".join(traceback.format_exception(type(exc), exc, exc.__traceback__))\n\
      \    client_host = request.client.host if request.client else \"N/A\"\n    error_time\
      \ = datetime.now(timezone.utc)\n\n    # Log critically, including a traceback\
      \ summary\n    log_critical(\n        f\"Unhandled Internal Server Error: {type(exc).__name__}:\
      \ {exc} ({request.method} {request.url.path})\",\n        icon_type='CRITICAL',\n\
      \        exc_info=False, # Avoid duplicating full traceback if JsonFormatter\
      \ logs it\n        extra={\n            \"client\": client_host,\n         \
      \   # Log full traceback only in development for security/verbosity reasons\n\
      \            \"full_traceback\": tb_str if settings.APP_ENV == 'development'\
      \ else \"Traceback hidden in production\"\n        }\n    )\n    # Update app\
      \ stats to indicate the last error (store datetime object)\n    async with stats_lock:\n\
      \        app_stats[\"last_error\"] = f\"Unhandled {type(exc).__name__} at {request.method}\
      \ {request.url.path}\"\n        app_stats[\"last_error_timestamp\"] = error_time\
      \ # <<< Store datetime object\n\n    # Return a generic 500 response to the\
      \ client\n    return JSONResponse(\n        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n\
      \        content={\"detail\": \"An unexpected internal server error occurred.\
      \ Please contact the administrator or check server logs.\"}\n    )\n\n# ---\
      \ Main Execution Block ---\nif __name__ == '__main__':\n    # Add missing import\
      \ for regex used in GraphQL mutation validation\n    import re\n\n    log_info(\"\
      \U0001F3C1 Main execution block entered...\", icon_type='SETUP')\n\n    # ---\
      \ SSL Certificate Check/Generation ---\n    log_info(\"Checking for SSL certificate\
      \ and key...\", icon_type='SEC')\n    try:\n        # Ensure certificate directory\
      \ exists\n        os.makedirs(settings.CERT_DIR, exist_ok=True)\n        cert_exists\
      \ = os.path.exists(settings.CERT_FILE)\n        key_exists = os.path.exists(settings.KEY_FILE)\n\
      \n        if cert_exists and key_exists:\n            log_success(f\"\U0001F6E1\
      ️ SSL Certificate '{os.path.basename(settings.CERT_FILE)}' and Key '{os.path.basename(settings.KEY_FILE)}'\
      \ found in '{settings.CERT_DIR}'.\", icon_type='SEC')\n            # Optional:\
      \ Add check for certificate expiry here if needed\n        else:\n         \
      \   missing = [f for f, exists in [(os.path.basename(settings.CERT_FILE), cert_exists),\
      \ (os.path.basename(settings.KEY_FILE), key_exists)] if not exists]\n      \
      \      log_warning(f\"SSL file(s) not found: {', '.join(missing)}. Attempting\
      \ to generate new self-signed certificate for 'localhost'...\", icon_type='SEC')\n\
      \            try:\n                if not generate_self_signed_cert(settings.CERT_FILE,\
      \ settings.KEY_FILE, common_name=\"localhost\"):\n                    log_critical(\"\
      Critical failure generating self-signed SSL certificates. Cannot start server\
      \ with HTTPS.\", icon_type='CRITICAL')\n                    sys.exit(1) # Exit\
      \ if generation fails\n                else:\n                     log_success(\"\
      ✅ Successfully generated new self-signed SSL certificate and key.\", icon_type='SEC')\n\
      \            except Exception as cert_gen_e:\n                log_critical(f\"\
      Unexpected error during certificate generation: {cert_gen_e}\", icon_type='CRITICAL',\
      \ exc_info=True)\n                sys.exit(1)\n    except Exception as setup_e:\n\
      \        log_critical(f\"Unexpected error during initial certificate setup check:\
      \ {setup_e}\", icon_type='CRITICAL', exc_info=True)\n        sys.exit(1)\n\n\
      \    # --- Log Final Configuration Summary ---\n    log_info(\"=== Configuration\
      \ Summary ===\", icon_type='SETUP')\n    log_info(f\"  Project: {settings.PROJECT_NAME}\
      \ v{settings.VERSION}\", icon_type='INFO')\n    log_info(f\"  Environment: {settings.APP_ENV}\"\
      , icon_type='INFO')\n    log_info(f\"  Log Level: {settings.LOG_LEVEL_STR}\"\
      , icon_type='LOGS')\n    log_info(f\"  JWT Secret: {'Set via Env Var' if 'JWT_SECRET_KEY'\
      \ in os.environ and 'CHANGE_ME' not in settings.JWT_SECRET_KEY else 'Using Generated/Default\
      \ (INSECURE FOR PROD)'}\", icon_type='AUTH')\n    log_info(f\"  DB Path: {settings.DB_PATH}\"\
      , icon_type='DB')\n    log_info(f\"  Rate Limit (Default): {settings.DEFAULT_RATE_LIMIT}\"\
      , icon_type='RATELIMIT')\n    log_info(f\"  Rate Limit (High Traffic): {settings.HIGH_TRAFFIC_RATE_LIMIT}\"\
      , icon_type='RATELIMIT')\n    log_info(f\"  CORS Origins: {settings.ALLOWED_ORIGINS}\"\
      , icon_type='HTTP')\n    log_info(f\"  Log Dir: {settings.LOG_DIR} (Current\
      \ File: {os.path.basename(LOG_FILENAME)})\", icon_type='LOGS')\n    log_info(f\"\
      \  Cert Dir: {settings.CERT_DIR}\", icon_type='SEC')\n    log_info(f\"============================\"\
      , icon_type='SETUP')\n\n    # --- Determine Uvicorn settings ---\n    # Enable\
      \ auto-reload only in development environment\n    reload_enabled = settings.APP_ENV\
      \ == \"development\"\n    if reload_enabled:\n        log_warning(\"Running\
      \ in DEVELOPMENT mode with auto-reload enabled.\", icon_type='SETUP')\n\n  \
      \  # Map FastAPI log level to Uvicorn log level string\n    # Uvicorn levels:\
      \ 'critical', 'error', 'warning', 'info', 'debug', 'trace'\n    log_level_uvicorn\
      \ = settings.LOG_LEVEL_STR.lower()\n    # Adjust if necessary (e.g., FastAPI\
      \ DEBUG might map to uvicorn debug/trace)\n    if log_level_uvicorn == 'debug'\
      \ and reload_enabled:\n        log_level_uvicorn = 'debug' # Keep debug for\
      \ dev reload\n    elif log_level_uvicorn == 'debug':\n         # Avoid overly\
      \ verbose uvicorn logs in non-reloading debug mode unless explicitly desired\n\
      \        log_level_uvicorn = 'info'\n\n    # --- Start Uvicorn Server ---\n\
      \    log_info(f\"\U0001F310\U0001F680 Starting Uvicorn server on https://0.0.0.0:{settings.API_PORT}\"\
      , icon_type='STARTUP', extra={\"reload\": reload_enabled, \"log_level\": log_level_uvicorn})\n\
      \    log_info(f\"   Access API root at: https://localhost:{settings.API_PORT}/\"\
      , icon_type='HTTP')\n    log_info(f\"   Swagger UI docs:  https://localhost:{settings.API_PORT}/docs\"\
      , icon_type='HTTP')\n    log_info(f\"   ReDoc docs:       https://localhost:{settings.API_PORT}/redoc\"\
      , icon_type='HTTP')\n    log_info(f\"   GraphQL endpoint: https://localhost:{settings.API_PORT}/graphql\
      \ (Apollo Sandbox IDE)\", icon_type='GRAPHQL')\n    log_info(\"   Press Ctrl+C\
      \ to stop the server.\", icon_type='INFO')\n\n    try:\n        uvicorn.run(\n\
      \            \"__main__:app\", # Points to the 'app' instance in this file when\
      \ run directly\n            host=\"0.0.0.0\", # Listen on all available network\
      \ interfaces\n            port=settings.API_PORT,\n            log_level=log_level_uvicorn,\
      \ # Set Uvicorn's internal logging level\n            ssl_keyfile=settings.KEY_FILE,\
      \ # Path to SSL private key\n            ssl_certfile=settings.CERT_FILE, #\
      \ Path to SSL certificate\n            reload=reload_enabled, # Enable auto-reload\
      \ if in development\n            use_colors=True, # Use colors in Uvicorn's\
      \ console output if terminal supports it\n            # Disable uvicorn access\
      \ logs if our middleware/logging is sufficient\n            access_log=False\
      \ # Set to True if you want uvicorn's default access logs\n        )\n    except\
      \ KeyboardInterrupt:\n        # Handle Ctrl+C gracefully\n        log_info(\"\
      \\n\U0001F6A6 Server shutdown requested via Keyboard Interrupt (Ctrl+C).\",\
      \ icon_type='SHUTDOWN')\n    except SystemExit as e:\n         # Handle sys.exit()\
      \ calls (e.g., from failed startup checks)\n         log_info(f\"\U0001F6A6\
      \ Server exited with code {e.code}.\", icon_type='SHUTDOWN')\n    except Exception\
      \ as e:\n        # Catch potential errors during Uvicorn startup (e.g., port\
      \ already in use)\n        log_critical(f\"❌ Fatal: Failed to start or run Uvicorn\
      \ server: {e}\", exc_info=True)\n        sys.exit(1) # Exit with error code\
      \ if Uvicorn fails to start\n    finally:\n        # This block runs after Uvicorn\
      \ stops, regardless of the reason\n        log_info(\"\U0001F3C1 Uvicorn server\
      \ process has finished.\", icon_type='SHUTDOWN')"
    tamanho: 0.11 MB
  message-broker-v3-clean.py:
    caminho_completo: .\message-broker-v3-clean.py
    classes:
    - docstring: null
      end_lineno: 86
      lineno: 65
      name: Settings
    - docstring: null
      end_lineno: 117
      lineno: 106
      name: ColoramaFormatter
    - docstring: null
      end_lineno: 137
      lineno: 119
      name: JsonFormatter
    - docstring: null
      end_lineno: 309
      lineno: 307
      name: QueueBase
    - docstring: null
      end_lineno: 311
      lineno: 311
      name: QueueCreatePayload
    - docstring: null
      end_lineno: 318
      lineno: 313
      name: QueueResponse
    - docstring: null
      end_lineno: 321
      lineno: 320
      name: MessageBase
    - docstring: null
      end_lineno: 323
      lineno: 323
      name: MessagePayload
    - docstring: null
      end_lineno: 331
      lineno: 325
      name: MessageResponse
    - docstring: null
      end_lineno: 336
      lineno: 333
      name: MessagePublishResponse
    - docstring: null
      end_lineno: 344
      lineno: 338
      name: MessageConsumeResponse
    - docstring: null
      end_lineno: 350
      lineno: 346
      name: Token
    - docstring: null
      end_lineno: 369
      lineno: 352
      name: StatsResponse
    - docstring: null
      end_lineno: 373
      lineno: 371
      name: LogFileResponse
    - docstring: null
      end_lineno: 387
      lineno: 375
      name: Queue
    - docstring: null
      end_lineno: 407
      lineno: 389
      name: Message
    - docstring: null
      end_lineno: 1162
      lineno: 1145
      name: MessageGQL
    - docstring: null
      end_lineno: 1211
      lineno: 1165
      name: QueueGQL
    - docstring: null
      end_lineno: 1259
      lineno: 1214
      name: QueryGQL
    - docstring: null
      end_lineno: 1317
      lineno: 1262
      name: MutationGQL
    - docstring: null
      end_lineno: 384
      lineno: 382
      name: Meta
    - docstring: null
      end_lineno: 404
      lineno: 401
      name: Meta
    functions:
    - docstring: null
      end_lineno: 160
      lineno: 160
      name: log_debug
    - docstring: null
      end_lineno: 161
      lineno: 161
      name: log_info
    - docstring: null
      end_lineno: 162
      lineno: 162
      name: log_success
    - docstring: null
      end_lineno: 163
      lineno: 163
      name: log_warning
    - docstring: null
      end_lineno: 164
      lineno: 164
      name: log_error
    - docstring: null
      end_lineno: 165
      lineno: 165
      name: log_critical
    - docstring: null
      end_lineno: 166
      lineno: 166
      name: log_pipeline
    - docstring: null
      end_lineno: 216
      lineno: 168
      name: generate_self_signed_cert
    - docstring: null
      end_lineno: 117
      lineno: 110
      name: format
    - docstring: null
      end_lineno: 121
      lineno: 120
      name: formatTime
    - docstring: null
      end_lineno: 137
      lineno: 123
      name: format
    - docstring: null
      end_lineno: 387
      lineno: 386
      name: __str__
    - docstring: null
      end_lineno: 407
      lineno: 406
      name: __str__
    - docstring: null
      end_lineno: 838
      lineno: 789
      name: read_and_parse_log_sync
    - docstring: null
      end_lineno: 1162
      lineno: 1154
      name: from_orm
    - docstring: null
      end_lineno: 701
      lineno: 646
      name: _get_psutil_data_sync
    - docstring: null
      end_lineno: 755
      lineno: 754
      name: list_dir_sync
    imports:
    - asname: null
      name: asyncio
    - asname: null
      name: json
    - asname: null
      name: logging
    - asname: null
      name: os
    - asname: null
      name: platform
    - asname: null
      name: secrets
    - asname: null
      name: sys
    - asname: null
      name: time
    - asname: null
      name: traceback
    - asname: null
      name: re
    - module: contextlib
      names:
      - asynccontextmanager
    - module: datetime
      names:
      - datetime
      - timezone
      - timedelta
    - module: typing
      names:
      - Dict
      - Any
      - Optional
      - List
      - AsyncGenerator
      - Union
    - module: collections
      names:
      - deque
    - asname: null
      name: hashlib
    - asname: null
      name: ipaddress
    - module: tortoise
      names:
      - Tortoise
      - fields
      - models
    - module: tortoise.exceptions
      names:
      - DoesNotExist
      - IntegrityError
    - module: tortoise.transactions
      names:
      - in_transaction
    - module: fastapi
      names:
      - FastAPI
      - Request
      - Response
      - Depends
      - HTTPException
      - status
      - BackgroundTasks
      - Path
      - Query
    - module: fastapi.middleware.cors
      names:
      - CORSMiddleware
    - module: fastapi.security
      names:
      - OAuth2PasswordBearer
      - OAuth2PasswordRequestForm
      - HTTPBearer
      - HTTPAuthorizationCredentials
    - module: fastapi.responses
      names:
      - JSONResponse
    - asname: null
      name: uvicorn
    - module: jose
      names:
      - JWTError
      - jwt
    - module: pydantic
      names:
      - BaseModel
      - ValidationError
      - Field
      - EmailStr
      - ConfigDict
      - field_validator
    - module: colorama
      names:
      - init
      - Fore
      - Style
    - module: cryptography
      names:
      - x509
    - module: cryptography.x509.oid
      names:
      - NameOID
    - module: cryptography.hazmat.primitives
      names:
      - hashes
    - module: cryptography.hazmat.backends
      names:
      - default_backend
    - module: cryptography.hazmat.primitives
      names:
      - serialization
    - module: cryptography.hazmat.primitives.asymmetric
      names:
      - rsa
    - asname: null
      name: psutil
    - module: werkzeug.utils
      names:
      - secure_filename
    - module: slowapi
      names:
      - Limiter
      - _rate_limit_exceeded_handler
    - module: slowapi.util
      names:
      - get_remote_address
    - module: slowapi.errors
      names:
      - RateLimitExceeded
    - module: slowapi.middleware
      names:
      - SlowAPIMiddleware
    - asname: null
      name: strawberry
    - module: strawberry.fastapi
      names:
      - GraphQLRouter
    - module: strawberry.types
      names:
      - Info
    - asname: null
      name: re
    numero_de_linhas: 1515
    source_code: "# -*- coding: utf-8 -*-\nimport asyncio\nimport json\nimport logging\n\
      import os\nimport platform\nimport secrets\nimport sys\nimport time\nimport\
      \ traceback\nimport re\nfrom contextlib import asynccontextmanager\nfrom datetime\
      \ import datetime, timezone, timedelta\nfrom typing import Dict, Any, Optional,\
      \ List, AsyncGenerator, Union\nfrom collections import deque\nimport hashlib\n\
      import ipaddress\n\nfrom tortoise import Tortoise, fields, models\nfrom tortoise.exceptions\
      \ import DoesNotExist, IntegrityError\nfrom tortoise.transactions import in_transaction\n\
      \ntry:\n    from fastapi import (FastAPI, Request, Response, Depends, HTTPException,\
      \ status,\n                         BackgroundTasks, Path, Query as FastQuery)\n\
      \    from fastapi.middleware.cors import CORSMiddleware\n    from fastapi.security\
      \ import (OAuth2PasswordBearer, OAuth2PasswordRequestForm,\n               \
      \                   HTTPBearer, HTTPAuthorizationCredentials)\n    from fastapi.responses\
      \ import JSONResponse\n    import uvicorn\n\n    from jose import JWTError,\
      \ jwt\n    from pydantic import BaseModel, ValidationError, Field, EmailStr,\
      \ ConfigDict, field_validator\n\n    from colorama import init, Fore, Style\n\
      \n    from cryptography import x509\n    from cryptography.x509.oid import NameOID\n\
      \    from cryptography.hazmat.primitives import hashes\n    from cryptography.hazmat.backends\
      \ import default_backend\n    from cryptography.hazmat.primitives import serialization\n\
      \    from cryptography.hazmat.primitives.asymmetric import rsa\n\n    import\
      \ psutil\n    from werkzeug.utils import secure_filename\n\n    from slowapi\
      \ import Limiter, _rate_limit_exceeded_handler\n    from slowapi.util import\
      \ get_remote_address\n    from slowapi.errors import RateLimitExceeded\n   \
      \ from slowapi.middleware import SlowAPIMiddleware\n\n    import strawberry\n\
      \    from strawberry.fastapi import GraphQLRouter\n    from strawberry.types\
      \ import Info\n\nexcept ImportError as e:\n    missing_pkg = str(e).split(\"\
      '\")[-2]\n    print(f\"\\nERROR: Missing dependency '{missing_pkg}'.\")\n  \
      \  print(\"Please install all required packages by running:\")\n    print(\"\
      \\n  pip install fastapi uvicorn[standard] tortoise-orm aiosqlite pydantic[email]\
      \ python-jose[cryptography] colorama cryptography psutil Werkzeug slowapi strawberry-graphql[fastapi]\
      \ Jinja2 ipaddress passlib Werkzeug\\n\")\n    sys.exit(1)\n\ninit(autoreset=True)\n\
      \nclass Settings:\n    PROJECT_NAME: str = \"Message Broker API V3.1.5 (FastAPI/Tortoise/Fixes)\"\
      \n    VERSION: str = \"0.3.1.5-fastapi-tortoise-fixes\"\n    API_PORT: int =\
      \ 8777\n    JWT_SECRET_KEY: str = os.environ.get('JWT_SECRET_KEY', '!!_CHANGE_ME_IN_PRODUCTION_'\
      \ + secrets.token_hex(16) + '_!!')\n    ALGORITHM: str = \"HS256\"\n    ACCESS_TOKEN_EXPIRE_MINUTES:\
      \ int = 60 * 1\n    REFRESH_TOKEN_EXPIRE_DAYS: int = 30\n    DB_DIR: str = 'databases'\n\
      \    DB_FILENAME: str = 'message_broker_v3.db'\n    DB_PATH: str = os.path.abspath(os.path.join(DB_DIR,\
      \ DB_FILENAME))\n    DATABASE_URL: str = f\"sqlite:///{DB_PATH}\"\n    LOG_DIR:\
      \ str = 'logs_v3'\n    CERT_DIR: str = 'certs_v3'\n    CERT_FILE: str = os.path.join(CERT_DIR,\
      \ 'cert.pem')\n    KEY_FILE: str = os.path.join(CERT_DIR, 'key_nopass.pem')\n\
      \    ALLOWED_ORIGINS: List[str] = [\"*\"]\n    DEFAULT_RATE_LIMIT: str = \"\
      200/minute\"\n    HIGH_TRAFFIC_RATE_LIMIT: str = \"200/second\"\n    LOG_LEVEL_STR:\
      \ str = os.environ.get(\"LOG_LEVEL\", \"INFO\").upper()\n    LOG_LEVEL: int\
      \ = getattr(logging, LOG_LEVEL_STR, logging.INFO)\n    APP_ENV: str = os.environ.get(\"\
      APP_ENV\", \"production\").lower()\n\nsettings = Settings()\n\nif \"CHANGE_ME_IN_PRODUCTION\"\
      \ in settings.JWT_SECRET_KEY and settings.APP_ENV == \"production\":\n    print(f\"\
      {Fore.RED}{Style.BRIGHT}\U0001F6A8 CRITICAL SECURITY WARNING: Running in PRODUCTION\
      \ environment with a DEFAULT JWT_SECRET_KEY! Generate a strong secret and set\
      \ the JWT_SECRET_KEY environment variable.{Style.RESET_ALL}\")\nelif \"CHANGE_ME_IN_PRODUCTION\"\
      \ in settings.JWT_SECRET_KEY:\n     print(f\"{Fore.YELLOW}⚠️ SECURITY WARNING:\
      \ Using a generated default JWT_SECRET_KEY. Set the JWT_SECRET_KEY environment\
      \ variable for persistent sessions between restarts.{Style.RESET_ALL}\")\n\n\
      if settings.ALLOWED_ORIGINS == [\"*\"] and settings.APP_ENV == \"production\"\
      :\n    print(f\"{Fore.YELLOW}⚠️ SECURITY WARNING: CORS ALLOWED_ORIGINS is set\
      \ to '*' in production. This is insecure. Specify allowed origins explicitly.{Style.RESET_ALL}\"\
      )\n\nos.makedirs(settings.LOG_DIR, exist_ok=True)\nos.makedirs(settings.CERT_DIR,\
      \ exist_ok=True)\nos.makedirs(settings.DB_DIR, exist_ok=True)\n\ntimestamp =\
      \ datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nunique_hash = hashlib.sha1(str(os.getpid()).encode()).hexdigest()[:8]\n\
      LOG_FILENAME = os.path.join(settings.LOG_DIR, f\"broker_log_{timestamp}_{unique_hash}.json\"\
      )\n\nclass ColoramaFormatter(logging.Formatter):\n    LEVEL_COLORS = { logging.DEBUG:\
      \ Fore.CYAN, logging.INFO: Fore.GREEN, logging.WARNING: Fore.YELLOW, logging.ERROR:\
      \ Fore.RED, logging.CRITICAL: Fore.MAGENTA }\n    LEVEL_ICONS = { logging.DEBUG:\
      \ \"⚙️ \", logging.INFO: \"ℹ️ \", logging.WARNING: \"⚠️ \", logging.ERROR: \"\
      ❌ \", logging.CRITICAL: \"\U0001F525 \", 'SUCCESS': \"✅ \", 'PIPELINE': \"➡️\
      \ \", 'DB': \"\U0001F4BE \", 'AUTH': \"\U0001F511 \", 'QUEUE': \"\U0001F4E5\
      \ \", 'MSG': \"✉️ \", 'HTTP': \"\U0001F310 \", 'STATS': \"\U0001F4CA \", 'LOGS':\
      \ \"\U0001F4C4 \", 'SEC': \"\U0001F6E1️ \", 'ASYNC': \"⚡ \", 'GRAPHQL': \"\U0001F353\
      \ \", 'RATELIMIT': \"⏱️ \", 'STARTUP': '\U0001F680', 'SHUTDOWN': '\U0001F6D1\
      ', 'GEN': '✨', 'SETUP': '\U0001F527'}\n\n    def format(self, record):\n   \
      \     level_color = self.LEVEL_COLORS.get(record.levelno, Fore.WHITE)\n    \
      \    icon_type = getattr(record, 'icon_type', record.levelname)\n        icon\
      \ = self.LEVEL_ICONS.get(icon_type, \"\")\n        formatted_time = self.formatTime(record,\
      \ self.datefmt)\n        log_message_content = f\"[{record.levelname}] {icon}{record.getMessage()}\"\
      \n        log_line = f\"{formatted_time} - {record.name} - {level_color}{Style.BRIGHT}{log_message_content}{Style.RESET_ALL}\"\
      \n        return log_line\n\nclass JsonFormatter(logging.Formatter):\n    def\
      \ formatTime(self, record, datefmt=None):\n        return datetime.fromtimestamp(record.created,\
      \ tz=timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n\
      \n    def format(self, record):\n        log_record = {\n            'timestamp':\
      \ self.formatTime(record), 'level': record.levelname, 'name': record.name,\n\
      \            'pid': record.process, 'thread': record.threadName, 'message':\
      \ record.getMessage(),\n            'pathname': record.pathname, 'lineno': record.lineno,\n\
      \        }\n        if hasattr(record, 'icon_type'): log_record['icon_type']\
      \ = record.icon_type\n        if hasattr(record, 'extra_data') and isinstance(record.extra_data,\
      \ dict): log_record.update(record.extra_data)\n        if record.exc_info:\n\
      \            traceback_str = \"\".join(traceback.format_exception(*record.exc_info))\
      \ if settings.APP_ENV == 'development' else 'Traceback hidden in production'\n\
      \            log_record['exception'] = {\n                'type': record.exc_info[0].__name__,\
      \ 'value': str(record.exc_info[1]),\n                'traceback': traceback_str\n\
      \            }\n        return json.dumps(log_record, ensure_ascii=False, default=str)\n\
      \nlogger = logging.getLogger(\"MessageBroker\")\nlogger.setLevel(settings.LOG_LEVEL)\n\
      logger.propagate = False\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\nif not logger.handlers:\n\
      \    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(settings.LOG_LEVEL)\n\
      \    console_formatter = ColoramaFormatter(datefmt=DATE_FORMAT)\n    console_handler.setFormatter(console_formatter)\n\
      \    logger.addHandler(console_handler)\n\n    try:\n        file_handler =\
      \ logging.FileHandler(LOG_FILENAME, mode='a', encoding='utf-8')\n        file_handler.setLevel(settings.LOG_LEVEL)\n\
      \        file_formatter = JsonFormatter()\n        file_handler.setFormatter(file_formatter)\n\
      \        logger.addHandler(file_handler)\n    except Exception as e:\n     \
      \    logger.error(f\"❌ CRITICAL: Failed to initialize file logging ({LOG_FILENAME}):\
      \ {e}\", exc_info=True)\n\ndef log_debug(message: str, icon_type: str = 'DEBUG',\
      \ extra: Optional[Dict[str, Any]] = None): logger.debug(message, extra={'icon_type':\
      \ icon_type, 'extra_data': extra or {}})\ndef log_info(message: str, icon_type:\
      \ str = 'INFO', extra: Optional[Dict[str, Any]] = None): logger.info(message,\
      \ extra={'icon_type': icon_type, 'extra_data': extra or {}})\ndef log_success(message:\
      \ str, icon_type: str = 'SUCCESS', extra: Optional[Dict[str, Any]] = None):\
      \ logger.info(message, extra={'icon_type': icon_type, 'extra_data': extra or\
      \ {}})\ndef log_warning(message: str, icon_type: str = 'WARNING', extra: Optional[Dict[str,\
      \ Any]] = None): logger.warning(message, extra={'icon_type': icon_type, 'extra_data':\
      \ extra or {}})\ndef log_error(message: str, exc_info: bool = False, icon_type:\
      \ str = 'ERROR', extra: Optional[Dict[str, Any]] = None): logger.error(message,\
      \ exc_info=exc_info, extra={'icon_type': icon_type, 'extra_data': extra or {}})\n\
      def log_critical(message: str, exc_info: bool = False, icon_type: str = 'CRITICAL',\
      \ extra: Optional[Dict[str, Any]] = None): logger.critical(message, exc_info=exc_info,\
      \ extra={'icon_type': icon_type, 'extra_data': extra or {}})\ndef log_pipeline(message:\
      \ str, icon_type: str = 'PIPELINE', extra: Optional[Dict[str, Any]] = None):\
      \ logger.info(message, extra={'icon_type': icon_type, 'extra_data': extra or\
      \ {}})\n\ndef generate_self_signed_cert(cert_path: str, key_path: str, key_password:\
      \ Optional[bytes] = None, common_name: str = \"localhost\"):\n    log_info(f\"\
      \U0001F6E1️ Generating new RSA private key and self-signed certificate for CN='{common_name}'...\"\
      , icon_type='GEN')\n    try:\n        private_key = rsa.generate_private_key(public_exponent=65537,\
      \ key_size=2048, backend=default_backend())\n        subject = issuer = x509.Name([\n\
      \            x509.NameAttribute(NameOID.COUNTRY_NAME, u\"XX\"),\n          \
      \  x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, u\"DefaultState\"),\n\
      \            x509.NameAttribute(NameOID.LOCALITY_NAME, u\"DefaultCity\"),\n\
      \            x509.NameAttribute(NameOID.ORGANIZATION_NAME, u\"Message Broker\
      \ SelfSigned\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, common_name),\n\
      \        ])\n        san_extension = x509.SubjectAlternativeName([\n       \
      \     x509.DNSName(common_name),\n            x509.IPAddress(ipaddress.ip_address(\"\
      127.0.0.1\")),\n        ])\n        cert_builder = x509.CertificateBuilder().subject_name(subject).issuer_name(issuer).public_key(private_key.public_key())\
      \ \\\n            .serial_number(x509.random_serial_number()).not_valid_before(datetime.now(timezone.utc)\
      \ - timedelta(days=1)) \\\n            .not_valid_after(datetime.now(timezone.utc)\
      \ + timedelta(days=365*2)) \\\n            .add_extension(san_extension, critical=False)\n\
      \n        cert_builder = cert_builder.add_extension(\n            x509.BasicConstraints(ca=False,\
      \ path_length=None), critical=True,\n        )\n\n        certificate = cert_builder.sign(private_key,\
      \ hashes.SHA256(), default_backend())\n\n        key_pem_encryption = serialization.NoEncryption()\n\
      \        if key_password:\n             log_info(\"\U0001F511 Encrypting private\
      \ key with provided password.\", icon_type='SEC')\n             key_pem_encryption\
      \ = serialization.BestAvailableEncryption(key_password)\n\n        with open(key_path,\
      \ \"wb\") as f:\n             f.write(private_key.private_bytes(\n         \
      \        encoding=serialization.Encoding.PEM,\n                 format=serialization.PrivateFormat.PKCS8,\n\
      \                 encryption_algorithm=key_pem_encryption\n             ))\n\
      \        log_success(f\"\U0001F511 Private key saved: {key_path}\", icon_type='SEC')\n\
      \n        with open(cert_path, \"wb\") as f:\n             f.write(certificate.public_bytes(serialization.Encoding.PEM))\n\
      \        log_success(f\"\U0001F4DC Self-signed certificate saved: {cert_path}\"\
      , icon_type='SEC')\n        return True\n    except ImportError:\n        log_critical(\"\
      The 'ipaddress' module is required for certificate generation. Please install\
      \ it (`pip install ipaddress`).\", icon_type='CRITICAL')\n        return False\n\
      \    except Exception as e:\n        log_critical(f\"Failed to generate certificates/key:\
      \ {e}\", exc_info=True, icon_type='CRITICAL')\n        return False\n\napp_stats:\
      \ Dict[str, Any] = {\n    \"start_time\": datetime.now(timezone.utc),\n    \"\
      requests_total\": 0,\n    \"requests_by_route\": {},\n    \"requests_by_status\"\
      : {},\n    \"queues_total\": 0,\n    \"messages_total\": 0,\n    \"messages_pending\"\
      : 0,\n    \"messages_processing\": 0,\n    \"messages_processed\": 0,\n    \"\
      messages_failed\": 0,\n    \"last_error\": None,\n    \"last_error_timestamp\"\
      : None,\n    \"system\": {\n        \"python_version\": platform.python_version(),\
      \ \"platform\": platform.system(),\n        \"platform_release\": platform.release(),\
      \ \"architecture\": platform.machine(),\n    },\n    \"broker_specific\": {\n\
      \        \"framework\": \"FastAPI\", \"version\": settings.VERSION, \"db_engine\"\
      : \"sqlite (tortoise-orm)\",\n        \"auth_method\": \"jwt (access+refresh,\
      \ python-jose)\",\n        \"notification\": \"None\", \"rate_limit\": \"In-Memory\
      \ (slowapi)\",\n        \"graphql\": \"strawberry-graphql\"\n    }\n}\nstats_lock\
      \ = asyncio.Lock()\n\nasync def update_request_stats(route_template: str, method:\
      \ str, status_code: int):\n    async with stats_lock:\n        app_stats[\"\
      requests_total\"] += 1\n        route_stats = app_stats[\"requests_by_route\"\
      ].setdefault(route_template, {})\n        route_stats[method] = route_stats.get(method,\
      \ 0) + 1\n        status_code_str = str(status_code)\n        app_stats[\"requests_by_status\"\
      ][status_code_str] = app_stats[\"requests_by_status\"].get(status_code_str,\
      \ 0) + 1\n        log_debug(f\"Stats Update: route='{route_template}', method='{method}',\
      \ status={status_code}. New totals: route={route_stats[method]}, status={app_stats['requests_by_status'][status_code_str]}\"\
      , icon_type='STATS')\n\nasync def update_broker_stats():\n    log_pipeline(\"\
      \U0001F4CA Fetching broker stats from DB...\", icon_type='STATS')\n    try:\n\
      \        if not Tortoise.apps:\n             log_warning(\"DB not initialized,\
      \ cannot update broker stats.\", icon_type='DB')\n             return\n\n  \
      \      q_count_task = Queue.all().count()\n        m_pending_task = Message.filter(status='pending').count()\n\
      \        m_processing_task = Message.filter(status='processing').count()\n \
      \       m_processed_task = Message.filter(status='processed').count()\n    \
      \    m_failed_task = Message.filter(status='failed').count()\n\n        q_count,\
      \ pending, processing, processed, failed = await asyncio.gather(\n         \
      \   q_count_task, m_pending_task, m_processing_task, m_processed_task, m_failed_task\n\
      \        )\n        total = pending + processing + processed + failed\n\n  \
      \      async with stats_lock:\n            app_stats[\"queues_total\"] = q_count\n\
      \            app_stats[\"messages_pending\"] = pending\n            app_stats[\"\
      messages_processing\"] = processing\n            app_stats[\"messages_processed\"\
      ] = processed\n            app_stats[\"messages_failed\"] = failed\n       \
      \     app_stats[\"messages_total\"] = total\n            if app_stats[\"last_error\"\
      ] and \"Broker Stats Update Failed\" in app_stats[\"last_error\"]:\n       \
      \          app_stats[\"last_error\"] = None\n                 app_stats[\"last_error_timestamp\"\
      ] = None\n        log_success(\"\U0001F4CA Broker stats updated.\", icon_type='STATS',\
      \ extra={'counts': {'queues': q_count, 'pending': pending, 'processing': processing,\
      \ 'processed': processed, 'failed': failed}})\n    except Exception as e:\n\
      \        error_time = datetime.now(timezone.utc)\n        error_msg = f\"Broker\
      \ Stats Update Failed at {error_time.isoformat()}: {type(e).__name__}\"\n  \
      \      log_error(f\"Error updating broker stats: {e}\", icon_type='STATS', exc_info=True)\n\
      \        async with stats_lock:\n            app_stats[\"last_error\"] = error_msg\n\
      \            app_stats[\"last_error_timestamp\"] = error_time\n\nasync def init_tortoise():\n\
      \    log_info(f\"\U0001F4BE Configuring Tortoise ORM for SQLite: {settings.DATABASE_URL}\"\
      , icon_type='DB')\n    try:\n        await Tortoise.init(\n            db_url=settings.DATABASE_URL,\n\
      \            modules={'models': ['__main__']}\n        )\n        log_info(\"\
      \U0001F4BE Generating DB schemas if necessary...\", icon_type='DB')\n      \
      \  await Tortoise.generate_schemas(safe=True)\n        log_success(\"\U0001F4BE\
      \ ORM tables verified/created successfully.\", icon_type='DB')\n        await\
      \ update_broker_stats()\n    except Exception as e:\n        log_critical(f\"\
      Fatal: Failed to initialize Tortoise ORM: {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        sys.exit(1)\n\nPYDANTIC_CONFIG = ConfigDict(populate_by_name=True,\
      \ from_attributes=True)\n\nclass QueueBase(BaseModel):\n    name: str = Field(...,\
      \ min_length=1, max_length=255, pattern=r\"^[a-zA-Z0-9_-]+$\",\n           \
      \           description=\"Unique queue name (alphanumeric, underscore, hyphen).\"\
      )\n\nclass QueueCreatePayload(QueueBase): pass\n\nclass QueueResponse(QueueBase):\n\
      \    id: int\n    created_at: datetime\n    updated_at: datetime\n    message_count:\
      \ int = Field(default=0, description=\"Current number of messages in the queue\"\
      )\n    model_config = PYDANTIC_CONFIG\n\nclass MessageBase(BaseModel):\n   \
      \ content: str = Field(..., min_length=1, description=\"The content/payload\
      \ of the message (arbitrary string)\")\n\nclass MessagePayload(MessageBase):\
      \ pass\n\nclass MessageResponse(MessageBase):\n    id: int\n    queue_id: int\n\
      \    status: str = Field(description=\"Current status: pending, processing,\
      \ processed, failed\")\n    created_at: datetime\n    updated_at: datetime\n\
      \    model_config = PYDANTIC_CONFIG\n\nclass MessagePublishResponse(BaseModel):\n\
      \    message: str = Field(default=\"Message published successfully\")\n    message_id:\
      \ int\n    model_config = PYDANTIC_CONFIG\n\nclass MessageConsumeResponse(BaseModel):\n\
      \    message_id: int\n    queue: str\n    content: str\n    status: str = Field(default='processing',\
      \ description=\"Should always be 'processing' on successful consume\")\n   \
      \ retrieved_at: datetime\n    model_config = PYDANTIC_CONFIG\n\nclass Token(BaseModel):\n\
      \    access_token: str\n    refresh_token: str\n    token_type: str = \"bearer\"\
      \n    model_config = PYDANTIC_CONFIG\n\nclass StatsResponse(BaseModel):\n  \
      \  start_time: datetime\n    uptime_seconds: float\n    uptime_human: str\n\
      \    requests_total: int\n    requests_by_route: Dict[str, Dict[str, int]] =\
      \ Field(description=\"Count of requests per route template and HTTP method\"\
      )\n    requests_by_status: Dict[str, int] = Field(description=\"Count of requests\
      \ per HTTP status code\")\n    queues_total: int\n    messages_total: int\n\
      \    messages_pending: int\n    messages_processing: int\n    messages_processed:\
      \ int\n    messages_failed: int\n    last_error: Optional[str]\n    last_error_timestamp:\
      \ Optional[datetime]\n    system: Dict[str, Any]\n    broker_specific: Dict[str,\
      \ Any]\n    model_config = PYDANTIC_CONFIG\n\nclass LogFileResponse(BaseModel):\n\
      \    log_files: List[str]\n    model_config = PYDANTIC_CONFIG\n\nclass Queue(models.Model):\n\
      \    id = fields.IntField(pk=True)\n    name = fields.CharField(max_length=255,\
      \ unique=True, index=True, description=\"Unique queue name\")\n    created_at\
      \ = fields.DatetimeField(auto_now_add=True)\n    updated_at = fields.DatetimeField(auto_now=True)\n\
      \    messages: fields.ReverseRelation[\"Message\"]\n\n    class Meta:\n    \
      \    table = \"queues\"\n        ordering = [\"name\"]\n\n    def __str__(self):\n\
      \        return self.name\n\nclass Message(models.Model):\n    id = fields.IntField(pk=True)\n\
      \    queue: fields.ForeignKeyRelation[Queue] = fields.ForeignKeyField(\n   \
      \     'models.Queue', related_name='messages', on_delete=fields.CASCADE,\n \
      \       description=\"The queue this message belongs to\"\n    )\n    content\
      \ = fields.TextField(description=\"Message payload\")\n    status = fields.CharField(max_length=20,\
      \ default='pending', index=True,\n                              description=\"\
      Status: pending, processing, processed, failed\")\n    created_at = fields.DatetimeField(auto_now_add=True,\
      \ index=True)\n    updated_at = fields.DatetimeField(auto_now=True)\n\n    class\
      \ Meta:\n        table = \"messages\"\n        indexes = [(\"queue_id\", \"\
      status\", \"created_at\")]\n        ordering = [\"created_at\"]\n\n    def __str__(self):\n\
      \        return f\"Message {self.id} (Queue: {self.queue_id}, Status: {self.status})\"\
      \n\n@asynccontextmanager\nasync def lifespan(app_ref: FastAPI):\n    log_info(\"\
      \U0001F680 Application Startup Initiated...\", icon_type='STARTUP')\n    await\
      \ init_tortoise()\n    log_success(\"\U0001F680 Application Startup Complete.\
      \ Ready to accept connections.\", icon_type='STARTUP')\n    yield\n    log_info(\"\
      \U0001F6D1 Application Shutdown Initiated...\", icon_type='SHUTDOWN')\n    try:\n\
      \        log_info(\"\U0001F4BE Closing database connections...\", icon_type='DB')\n\
      \        await Tortoise.close_connections()\n        log_success(\"\U0001F4BE\
      \ Database connections closed gracefully.\", icon_type='DB')\n    except Exception\
      \ as e:\n         log_warning(f\"⚠️ Error closing Tortoise connections during\
      \ shutdown: {e}\", icon_type='DB')\n    log_success(\"\U0001F6D1 Application\
      \ Shutdown Complete.\", icon_type='SHUTDOWN')\n\nlog_info(f\"\U0001F680 Initializing\
      \ FastAPI Application ({settings.PROJECT_NAME} v{settings.VERSION})...\", icon_type='SETUP')\n\
      app = FastAPI(\n    title=settings.PROJECT_NAME, version=settings.VERSION,\n\
      \    description=\"Asynchronous Message Broker API using FastAPI, Tortoise ORM,\
      \ and SQLite.\",\n    lifespan=lifespan,\n    docs_url=\"/docs\",\n    redoc_url=\"\
      /redoc\",\n    openapi_tags=[\n        {\"name\": \"General\", \"description\"\
      : \"Basic health and info endpoints\"},\n        {\"name\": \"Authentication\"\
      , \"description\": \"User login and token management (JWT)\"},\n        {\"\
      name\": \"Monitoring\", \"description\": \"System statistics and log viewing\"\
      },\n        {\"name\": \"Queues\", \"description\": \"Operations for managing\
      \ message queues\"},\n        {\"name\": \"Messages\", \"description\": \"Publishing,\
      \ consuming, and managing messages\"},\n        {\"name\": \"GraphQL\", \"description\"\
      : \"GraphQL API endpoint (alternative to REST)\"},\n    ]\n)\n\nlimiter = Limiter(key_func=get_remote_address,\
      \ default_limits=[settings.DEFAULT_RATE_LIMIT])\napp.state.limiter = limiter\n\
      app.add_middleware(SlowAPIMiddleware)\napp.add_exception_handler(RateLimitExceeded,\
      \ _rate_limit_exceeded_handler)\nlog_info(f\"⏱️ Rate Limiter configured (Default:\
      \ {settings.DEFAULT_RATE_LIMIT}, High Traffic: {settings.HIGH_TRAFFIC_RATE_LIMIT}).\"\
      , icon_type='RATELIMIT')\n\napp.add_middleware(\n    CORSMiddleware, allow_origins=settings.ALLOWED_ORIGINS,\
      \ allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"\
      *\"],\n)\nlog_info(f\"\U0001F6E1️ CORS configured for origins: {settings.ALLOWED_ORIGINS}\"\
      , icon_type='SEC')\n\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"login\"\
      , auto_error=False)\nbearer_scheme = HTTPBearer(auto_error=False)\n\nasync def\
      \ create_jwt_token(data: dict, expires_delta: timedelta) -> str:\n    to_encode\
      \ = data.copy()\n    issue_time = datetime.now(timezone.utc)\n    expire = issue_time\
      \ + expires_delta\n    to_encode.update({\"exp\": expire, \"iat\": issue_time})\n\
      \    encoded_jwt = jwt.encode(to_encode, settings.JWT_SECRET_KEY, algorithm=settings.ALGORITHM)\n\
      \    return encoded_jwt\n\nasync def create_access_token(username: str) -> str:\n\
      \    return await create_jwt_token(\n        {\"sub\": username, \"type\": \"\
      access\"},\n        timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n\
      \    )\n\nasync def create_refresh_token(username: str) -> str:\n    return\
      \ await create_jwt_token(\n        {\"sub\": username, \"type\": \"refresh\"\
      },\n        timedelta(days=settings.REFRESH_TOKEN_EXPIRE_DAYS)\n    )\n\nasync\
      \ def _decode_token(token: str, expected_type: str) -> str:\n    credentials_exception\
      \ = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED, detail=f\"\
      Could not validate {expected_type} token\",\n        headers={\"WWW-Authenticate\"\
      : f\"Bearer error=\\\"invalid_token\\\", error_description=\\\"Invalid {expected_type}\
      \ token\\\"\"},\n    )\n    if not token:\n        log_warning(f\"Token decode\
      \ attempt failed: No token provided (expected type: {expected_type}).\", icon_type='AUTH')\n\
      \        raise credentials_exception\n\n    try:\n        payload = jwt.decode(\n\
      \            token,\n            settings.JWT_SECRET_KEY,\n            algorithms=[settings.ALGORITHM],\n\
      \            options={\"verify_aud\": False}\n        )\n        username: Optional[str]\
      \ = payload.get(\"sub\")\n        token_type: Optional[str] = payload.get(\"\
      type\")\n\n        if username is None or token_type != expected_type:\n   \
      \         log_warning(f\"{expected_type.capitalize()} token validation failed:\
      \ 'sub' missing or type mismatch (Got '{token_type}', Expected '{expected_type}').\"\
      , icon_type='AUTH', extra={\"payload_keys\": list(payload.keys())})\n      \
      \      raise credentials_exception\n\n        return username\n\n    except\
      \ JWTError as e:\n        log_warning(f\"{expected_type.capitalize()} token\
      \ validation JWTError: {e}\", icon_type='AUTH', extra={\"token_preview\": token[:10]\
      \ + \"...\"})\n        detail = f\"Invalid {expected_type} token: {e}\"\n  \
      \      if \"expired\" in str(e).lower():\n             detail = f\"{expected_type.capitalize()}\
      \ token has expired\"\n             credentials_exception.headers[\"WWW-Authenticate\"\
      ] = f\"Bearer error=\\\"invalid_token\\\", error_description=\\\"Token expired\\\
      \"\"\n        credentials_exception.detail = detail\n        raise credentials_exception\n\
      \    except Exception as e:\n         log_error(f\"Unexpected error during {expected_type}\
      \ token decode: {e}\", icon_type='AUTH', exc_info=True)\n         raise credentials_exception\n\
      \nasync def get_current_user(token: Optional[str] = Depends(oauth2_scheme))\
      \ -> str:\n    if token is None:\n        raise HTTPException(\n           \
      \ status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Not authenticated\"\
      ,\n            headers={\"WWW-Authenticate\": \"Bearer\"}\n        )\n    return\
      \ await _decode_token(token, \"access\")\n\nasync def validate_refresh_token(credentials:\
      \ Optional[HTTPAuthorizationCredentials] = Depends(bearer_scheme)) -> str:\n\
      \    if credentials is None:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n\
      \            detail=\"Refresh token missing or invalid Authorization header\
      \ format\",\n            headers={\"WWW-Authenticate\": \"Bearer error=\\\"\
      invalid_request\\\", error_description=\\\"Refresh token required\\\"\"}\n \
      \       )\n    return await _decode_token(credentials.credentials, \"refresh\"\
      )\n\n@app.middleware(\"http\")\nasync def update_stats_middleware(request: Request,\
      \ call_next):\n    start_time_mw = time.perf_counter()\n    response = None\n\
      \    status_code = 500\n    try:\n        response = await call_next(request)\n\
      \        process_time_mw = time.perf_counter() - start_time_mw\n        response.headers[\"\
      X-Process-Time\"] = f\"{process_time_mw:.4f}s\"\n        status_code = response.status_code\n\
      \n    except Exception as e:\n         process_time_mw = time.perf_counter()\
      \ - start_time_mw\n         log_error(\n             f\"Unhandled exception\
      \ propagated to stats middleware ({request.method} {request.url.path}) after\
      \ {process_time_mw:.4f}s: {type(e).__name__}: {e}\",\n             exc_info=True,\n\
      \             icon_type='ERROR'\n         )\n         raise e\n    finally:\n\
      \        route = request.scope.get(\"route\")\n        if route and hasattr(route,\
      \ 'path'):\n            route_template = route.path\n            ignored_prefixes\
      \ = ('/docs', '/redoc', '/openapi.json', '/graphql', '/favicon.ico')\n     \
      \       ignored_paths = ('/', '/stats', '/logs')\n\n            should_ignore\
      \ = False\n            if route_template:\n                if any(route_template.startswith(prefix)\
      \ for prefix in ignored_prefixes):\n                    should_ignore = True\n\
      \                    log_debug(f\"Ignoring stats update for route (prefix match):\
      \ {route_template}\", icon_type='STATS')\n                elif route_template\
      \ in ignored_paths:\n                     should_ignore = True\n           \
      \          log_debug(f\"Ignoring stats update for route (path match): {route_template}\"\
      , icon_type='STATS')\n\n            if route_template and not should_ignore:\n\
      \                try:\n                    await update_request_stats(route_template,\
      \ request.method, status_code)\n                except Exception as stats_e:\n\
      \                     log_error(f\"Failed to update request stats: {stats_e}\"\
      , icon_type='STATS', exc_info=True)\n\n    if response:\n        return response\n\
      \    else:\n        log_critical(\"Middleware finished without a response object\
      \ (likely due to early exception). Returning 500.\", icon_type=\"CRITICAL\"\
      )\n        return JSONResponse(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n\
      \            content={\"detail\": \"Internal server error occurred during request\
      \ processing.\"},\n        )\n\nasync def _get_queue_or_404(queue_name: str)\
      \ -> Queue:\n    try:\n        queue = await Queue.get(name=queue_name)\n  \
      \      return queue\n    except DoesNotExist:\n        log_warning(f\"Queue\
      \ '{queue_name}' not found in database.\", icon_type='DB')\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=f\"Queue '{queue_name}' not found\")\n    except Exception as e:\n\
      \        log_error(f\"Database error fetching queue '{queue_name}': {e}\", icon_type='DB',\
      \ exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Database error retrieving queue\")\n\n@app.get(\"/\", tags=[\"General\"\
      ], summary=\"Health Check\")\n@limiter.limit(\"5/second\")\nasync def index(request:\
      \ Request):\n    client_host = request.client.host if request.client else 'N/A'\n\
      \    log_info(\"\U0001F310 GET / request\", icon_type='HTTP', extra={\"client\"\
      : client_host})\n    return {\n        \"message\": f\"Welcome to {settings.PROJECT_NAME}\"\
      ,\n        \"status\": \"ok\",\n        \"version\": settings.VERSION,\n   \
      \     \"timestamp\": datetime.now(timezone.utc).isoformat()\n    }\n\n@app.post(\"\
      /login\", response_model=Token, tags=[\"Authentication\"], summary=\"User Login\"\
      )\n@limiter.limit(\"10/minute\")\nasync def login_for_access_token(request:\
      \ Request, form_data: OAuth2PasswordRequestForm = Depends()):\n    client_host\
      \ = request.client.host if request.client else 'N/A'\n    log_info(f\"\U0001F511\
      \ POST /login attempt for user: '{form_data.username}'\", icon_type='AUTH',\
      \ extra={\"client\": client_host})\n\n    if form_data.username == 'admin' and\
      \ form_data.password == 'admin':\n        log_warning(\"\U0001F6A8 Using hardcoded\
      \ 'admin'/'admin' credentials for login. This is insecure!\", icon_type='AUTH')\n\
      \        access_token = await create_access_token(username=form_data.username)\n\
      \        refresh_token = await create_refresh_token(username=form_data.username)\n\
      \        log_success(f\"Tokens generated for '{form_data.username}'.\", icon_type='AUTH')\n\
      \        return Token(access_token=access_token, refresh_token=refresh_token)\n\
      \    else:\n        log_warning(f\"Login failed for '{form_data.username}':\
      \ Invalid credentials.\", icon_type='AUTH')\n        raise HTTPException(\n\
      \            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"\
      Incorrect username or password\",\n            headers={\"WWW-Authenticate\"\
      : \"Bearer error=\\\"invalid_grant\\\"\"},\n        )\n\n@app.post(\"/refresh\"\
      , response_model=Token, tags=[\"Authentication\"], summary=\"Refresh Access\
      \ Token\")\n@limiter.limit(\"20/minute\")\nasync def refresh_access_token(request:\
      \ Request, username: str = Depends(validate_refresh_token)):\n    client_host\
      \ = request.client.host if request.client else 'N/A'\n    log_info(f\"\U0001F511\
      \ POST /refresh request validated for user '{username}'\", icon_type='AUTH',\
      \ extra={\"client\": client_host})\n    new_access_token = await create_access_token(username=username)\n\
      \    new_refresh_token = await create_refresh_token(username=username)\n   \
      \ log_success(f\"New access/refresh tokens generated for '{username}' via refresh.\"\
      , icon_type='AUTH')\n    return Token(access_token=new_access_token, refresh_token=new_refresh_token)\n\
      \n@app.get(\"/stats\", response_model=StatsResponse, tags=[\"Monitoring\"],\
      \ summary=\"Get System Statistics\")\n@limiter.limit(\"30/minute\")\nasync def\
      \ get_stats(request: Request, current_user: str = Depends(get_current_user))\
      \ -> StatsResponse:\n    client_host = request.client.host if request.client\
      \ else 'N/A'\n    log_info(f\"\U0001F4CA GET /stats request by user '{current_user}'\"\
      , icon_type='STATS', extra={\"client\": client_host})\n\n    await update_broker_stats()\n\
      \n    system_metrics = {}\n    try:\n        process = psutil.Process(os.getpid())\n\
      \        def _get_psutil_data_sync():\n            mem_info = process.memory_info()\n\
      \            proc_cpu = process.cpu_percent(interval=0.05)\n            sys_cpu\
      \ = psutil.cpu_percent(interval=0.05)\n            virt_mem = psutil.virtual_memory()\n\
      \n            disk_usage_data = {}\n            try:\n                partitions\
      \ = psutil.disk_partitions(all=False)\n            except Exception as disk_e:\n\
      \                log_warning(f\"Could not get disk partitions: {disk_e}\", icon_type='STATS')\n\
      \                partitions = []\n\n            for part in partitions:\n  \
      \              unwanted_fstypes = ['squashfs', 'tmpfs', 'devtmpfs', 'fuse.gvfsd-fuse',\
      \ 'overlay', 'autofs']\n                mountpoint = getattr(part, 'mountpoint',\
      \ None)\n                if not mountpoint or 'loop' in part.device or 'snap'\
      \ in part.device or part.fstype in unwanted_fstypes:\n                    continue\n\
      \                try:\n                    if os.path.exists(mountpoint):\n\
      \                       usage = psutil.disk_usage(mountpoint)\n            \
      \           disk_usage_data[mountpoint] = {\n                           \"total_gb\"\
      : round(usage.total / (1024**3), 2),\n                           \"used_gb\"\
      : round(usage.used / (1024**3), 2),\n                           \"free_gb\"\
      : round(usage.free / (1024**3), 2),\n                           \"percent\"\
      : usage.percent\n                       }\n                except (FileNotFoundError,\
      \ PermissionError, OSError) as part_e:\n                    log_warning(f\"\
      Could not get disk usage for {mountpoint}: {part_e}\", icon_type='STATS')\n\n\
      \            load_avg = os.getloadavg() if hasattr(os, 'getloadavg') else \"\
      N/A\"\n\n            open_fds = \"N/A\"\n            thread_count = \"N/A\"\n\
      \            try: open_fds = len(process.open_files())\n            except (psutil.AccessDenied,\
      \ NotImplementedError, Exception) as fd_e: log_warning(f\"Could not get open\
      \ file descriptors: {fd_e}\", icon_type=\"STATS\")\n            try: thread_count\
      \ = process.num_threads()\n            except (psutil.AccessDenied, NotImplementedError,\
      \ Exception) as th_e: log_warning(f\"Could not get thread count: {th_e}\", icon_type=\"\
      STATS\")\n\n            return {\n                \"cpu_percent\": sys_cpu,\n\
      \                \"memory_total_gb\": round(virt_mem.total / (1024**3), 2),\n\
      \                \"memory_available_gb\": round(virt_mem.available / (1024**3),\
      \ 2),\n                \"memory_used_gb\": round(virt_mem.used / (1024**3),\
      \ 2),\n                \"memory_percent\": virt_mem.percent,\n             \
      \   \"disk_usage\": disk_usage_data or {\"info\": \"No valid partitions found\
      \ or error reading usage.\"},\n                \"process_memory_rss_mb\": round(mem_info.rss\
      \ / (1024**2), 2),\n                \"process_memory_vms_mb\": round(mem_info.vms\
      \ / (1024**2), 2),\n                \"process_cpu_percent\": proc_cpu,\n   \
      \             \"load_average\": load_avg,\n                \"cpu_count_logical\"\
      : psutil.cpu_count(logical=True),\n                \"cpu_count_physical\": psutil.cpu_count(logical=False),\n\
      \                \"open_file_descriptors\": open_fds,\n                \"thread_count\"\
      : thread_count,\n                \"process_memory_mb\": round(mem_info.rss /\
      \ (1024**2), 2)\n            }\n        system_metrics = await asyncio.to_thread(_get_psutil_data_sync)\n\
      \n    except ImportError:\n        system_metrics[\"error\"] = \"psutil package\
      \ not installed. Cannot provide detailed system metrics.\"\n        log_warning(\"\
      psutil package not found. Install with `pip install psutil` for detailed system\
      \ stats.\", icon_type='STATS')\n    except Exception as e:\n        log_warning(f\"\
      Error collecting system stats with psutil: {e}\", icon_type='STATS', exc_info=True)\n\
      \        system_metrics[\"error\"] = f\"psutil data collection failed: {type(e).__name__}\"\
      \n\n    response_data = {}\n    async with stats_lock:\n        current_stats_copy\
      \ = app_stats.copy()\n\n        if \"system\" not in current_stats_copy:\n \
      \           current_stats_copy[\"system\"] = {}\n        current_stats_copy[\"\
      system\"].update(system_metrics)\n\n        start_time_dt = current_stats_copy[\"\
      start_time\"]\n        uptime_delta = datetime.now(timezone.utc) - start_time_dt\n\
      \        uptime_seconds = uptime_delta.total_seconds()\n        current_stats_copy[\"\
      uptime_seconds\"] = round(uptime_seconds, 2)\n\n        days, rem = divmod(int(uptime_seconds),\
      \ 86400)\n        hours, rem = divmod(rem, 3600)\n        minutes, seconds =\
      \ divmod(rem, 60)\n        parts = []\n        if days: parts.append(f\"{days}d\"\
      )\n        if hours: parts.append(f\"{hours}h\")\n        if minutes: parts.append(f\"\
      {minutes}m\")\n        if seconds or not parts: parts.append(f\"{seconds}s\"\
      )\n        current_stats_copy[\"uptime_human\"] = \" \".join(parts)\n\n    \
      \    current_stats_copy.setdefault(\"requests_by_route\", {})\n        current_stats_copy.setdefault(\"\
      requests_by_status\", {})\n\n        response_data = current_stats_copy\n  \
      \      log_debug(f\"Data before Pydantic validation in /stats: {response_data}\"\
      , icon_type=\"STATS\")\n\n    log_success(f\"Stats returned for user '{current_user}'.\"\
      , icon_type='STATS')\n    try:\n        validated_response = StatsResponse.model_validate(response_data)\n\
      \        return validated_response\n    except ValidationError as e:\n     \
      \   log_critical(f\"Stats data failed Pydantic validation: {e.errors()}\", icon_type='CRITICAL',\
      \ extra={\"invalid_stats_data\": response_data})\n        raise HTTPException(status_code=500,\
      \ detail=\"Internal Server Error: Failed to generate valid stats data.\")\n\n\
      @app.get(\"/logs\", response_model=LogFileResponse, tags=[\"Monitoring\"], summary=\"\
      List Log Files\")\n@limiter.limit(\"10/minute\")\nasync def list_log_files(request:\
      \ Request, current_user: str = Depends(get_current_user)):\n    client_host\
      \ = request.client.host if request.client else 'N/A'\n    log_info(f\"\U0001F4C4\
      \ GET /logs request by user '{current_user}'\", icon_type='LOGS', extra={\"\
      client\": client_host})\n    try:\n        def list_dir_sync():\n          \
      \  return os.listdir(settings.LOG_DIR)\n\n        log_files_all = await asyncio.to_thread(list_dir_sync)\n\
      \        log_files_json = sorted(\n            [f for f in log_files_all if\
      \ f.endswith('.json') and os.path.isfile(os.path.join(settings.LOG_DIR, f))],\n\
      \            reverse=True\n        )\n        log_success(f\"Found {len(log_files_json)}\
      \ JSON log files in '{settings.LOG_DIR}'.\", icon_type='LOGS')\n        return\
      \ LogFileResponse(log_files=log_files_json)\n    except FileNotFoundError:\n\
      \        log_error(f\"Log directory '{settings.LOG_DIR}' configured but not\
      \ found.\", icon_type='LOGS')\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=\"Log directory not found on server\")\n    except OSError as e:\n\
      \        log_error(f\"Error listing log files in '{settings.LOG_DIR}': {e}\"\
      , exc_info=True, icon_type='LOGS')\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error accessing log directory\")\n\n@app.get(\"/logs/{filename:path}\"\
      , response_model=List[Dict[str, Any]], tags=[\"Monitoring\"], summary=\"Get\
      \ Log File Content\")\n@limiter.limit(\"60/minute\")\nasync def get_log_file(\n\
      \    request: Request,\n    filename: str = Path(..., description=\"The name\
      \ of the JSON log file to retrieve (e.g., broker_log_YYYYMMDD_HHMMSS_hash.json).\"\
      ),\n    start: Optional[int] = FastQuery(None, ge=1, description=\"Start reading\
      \ from this line number (1-based index).\"),\n    end: Optional[int] = FastQuery(None,\
      \ ge=1, description=\"Stop reading at this line number (inclusive, 1-based index).\"\
      ),\n    tail: Optional[int] = FastQuery(None, ge=1, le=10000, description=\"\
      Retrieve only the last N lines (max 10000). Overrides start/end if provided.\"\
      ),\n    current_user: str = Depends(get_current_user)\n) -> List[Dict]:\n  \
      \  safe_filename = secure_filename(filename)\n    if not safe_filename or safe_filename\
      \ != filename or not safe_filename.startswith('broker_log_') or not safe_filename.endswith('.json'):\n\
      \        log_warning(f\"Invalid log file access attempt: '{filename}' by user\
      \ '{current_user}'\", icon_type='SEC')\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\
      \ detail=\"Invalid or potentially unsafe log filename provided.\")\n\n    log_path\
      \ = os.path.join(settings.LOG_DIR, safe_filename)\n    log_info(f\"\U0001F4C4\
      \ GET /logs/{safe_filename} request by '{current_user}' (start={start}, end={end},\
      \ tail={tail})\", icon_type='LOGS')\n\n    def read_and_parse_log_sync() ->\
      \ Optional[List[Dict]]:\n        if not os.path.isfile(log_path):\n        \
      \    log_warning(f\"Log file not found at path: {log_path}\", icon_type='LOGS')\n\
      \            return None\n\n        lines_to_process: Union[deque, List[str]]\
      \ = []\n        try:\n            with open(log_path, 'r', encoding='utf-8')\
      \ as f:\n                if tail is not None and tail > 0:\n               \
      \     lines_to_process = deque(f, maxlen=tail)\n                else:\n    \
      \                lines_to_process = []\n                    line_count_read\
      \ = 0\n                    for line_num_0based, line in enumerate(f):\n    \
      \                    line_num_1based = line_num_0based + 1\n               \
      \         if start is not None and line_num_1based < start:\n              \
      \              continue\n                        if end is not None and line_num_1based\
      \ > end:\n                            break\n                        stripped_line\
      \ = line.strip()\n                        if stripped_line:\n              \
      \              lines_to_process.append(stripped_line)\n                    \
      \        line_count_read += 1\n                        if start is not None\
      \ and end is None and line_count_read >= 10000:\n                          \
      \  log_warning(f\"Log read for {safe_filename} truncated at 10000 lines due\
      \ to missing 'end' parameter.\", icon_type='LOGS')\n                       \
      \     lines_to_process.append(json.dumps({\"_warning\": \"Result set truncated\
      \ at 10000 lines (specify 'end' for more)\", \"_limit\": 10000}))\n        \
      \                    break\n        except FileNotFoundError:\n            \
      \ log_warning(f\"Log file disappeared during read: {log_path}\", icon_type='LOGS')\n\
      \             return None\n        except Exception as read_exc:\n         \
      \   log_error(f\"Error reading log file '{safe_filename}': {read_exc}\", exc_info=True,\
      \ icon_type='LOGS')\n            return [{\"_error\": f\"Failed to read file:\
      \ {type(read_exc).__name__}. Check server logs for details.\"}]\n\n        parsed_lines:\
      \ List[Dict[str, Any]] = []\n        for i, line in enumerate(lines_to_process):\n\
      \            if not line: continue\n\n            line_num_info = f\"tail_{i+1}\"\
      \ if tail else (start or 1) + i\n            try:\n                parsed_line_data\
      \ = json.loads(line)\n                if isinstance(parsed_line_data, dict):\n\
      \                     parsed_lines.append(parsed_line_data)\n              \
      \  else:\n                     parsed_lines.append({\"_warning\": \"Line parsed\
      \ but is not a JSON object\", \"_line\": line_num_info, \"_type\": type(parsed_line_data).__name__,\
      \ \"_raw\": line[:250]})\n            except json.JSONDecodeError:\n       \
      \         parsed_lines.append({\"_error\": \"Invalid JSON format\", \"_line\"\
      : line_num_info, \"_raw\": line[:250] + ('...' if len(line)>250 else '')})\n\
      \            except Exception as parse_exc:\n                 parsed_lines.append({\"\
      _error\": f\"Parsing error: {parse_exc}\", \"_line\": line_num_info, \"_raw\"\
      : line[:250] + ('...' if len(line)>250 else '')})\n        return parsed_lines\n\
      \n    try:\n        result_lines = await asyncio.to_thread(read_and_parse_log_sync)\n\
      \n        if result_lines is None:\n            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\
      \ detail=f\"Log file '{safe_filename}' not found.\")\n\n        log_success(f\"\
      {len(result_lines)} log entries returned from '{safe_filename}'.\", icon_type='LOGS')\n\
      \        return result_lines\n    except HTTPException:\n        raise\n   \
      \ except Exception as e:\n        log_error(f\"Unexpected error processing log\
      \ file '{safe_filename}': {e}\", exc_info=True, icon_type='LOGS')\n        raise\
      \ HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"\
      Unexpected error processing log file. Check server logs.\")\n\n@app.get(\"/queues\"\
      , response_model=List[QueueResponse], tags=[\"Queues\"], summary=\"List All\
      \ Queues\")\n@limiter.limit(\"60/minute\")\nasync def list_queues(request: Request,\
      \ current_user: str = Depends(get_current_user)) -> List[QueueResponse]:\n \
      \   log_info(f\"\U0001F4CB GET /queues request by user '{current_user}'\", icon_type='QUEUE')\n\
      \    try:\n        queues = await Queue.all().order_by('name')\n        if not\
      \ queues:\n            log_info(\"No queues found in the database.\", icon_type='QUEUE')\n\
      \            return []\n\n        count_tasks = {q.id: Message.filter(queue_id=q.id).count()\
      \ for q in queues}\n        message_counts_results = await asyncio.gather(*count_tasks.values())\n\
      \        counts_dict = dict(zip(count_tasks.keys(), message_counts_results))\n\
      \n        response_list = []\n        for q in queues:\n            try:\n \
      \                response_item = QueueResponse(\n                     id=q.id,\
      \ name=q.name, created_at=q.created_at, updated_at=q.updated_at,\n         \
      \            message_count=counts_dict.get(q.id, 0)\n                 )\n  \
      \               response_list.append(response_item)\n            except ValidationError\
      \ as e:\n                 log_error(f\"Queue data validation failed for queue\
      \ ID {q.id} ('{q.name}'): {e.errors()}\", icon_type='QUEUE')\n\n        log_success(f\"\
      Returned {len(response_list)} queues.\", icon_type='QUEUE')\n        return\
      \ response_list\n    except Exception as e:\n        log_error(f\"Error listing\
      \ queues: {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error retrieving queue list from database\")\n\n@app.post(\"/queues\"\
      , response_model=QueueResponse, status_code=status.HTTP_201_CREATED, tags=[\"\
      Queues\"], summary=\"Create New Queue\")\n@limiter.limit(\"30/minute\")\nasync\
      \ def create_queue(request: Request, payload: QueueCreatePayload, current_user:\
      \ str = Depends(get_current_user)) -> QueueResponse:\n    queue_name = payload.name\n\
      \    log_info(f\"➕ POST /queues request by '{current_user}' to create queue\
      \ '{queue_name}'\", icon_type='QUEUE')\n    try:\n        new_queue, created\
      \ = await Queue.get_or_create(name=queue_name)\n\n        if not created:\n\
      \            log_warning(f\"Queue '{queue_name}' already exists. Creation request\
      \ denied (409).\", icon_type='QUEUE')\n            raise HTTPException(\n  \
      \              status_code=status.HTTP_409_CONFLICT,\n                detail=f\"\
      Queue with name '{queue_name}' already exists.\"\n            )\n\n        log_success(f\"\
      ✅ Queue '{queue_name}' created successfully (ID: {new_queue.id}).\", icon_type='QUEUE')\n\
      \        response = QueueResponse.model_validate(new_queue)\n        response.message_count\
      \ = 0\n        return response\n\n    except IntegrityError:\n        log_warning(f\"\
      IntegrityError during queue creation for '{queue_name}'. Likely already exists\
      \ (concurrent request?).\", icon_type='DB')\n        raise HTTPException(status_code=status.HTTP_409_CONFLICT,\
      \ detail=f\"Queue with name '{queue_name}' already exists (database constraint\
      \ violation).\")\n    except ValidationError as e:\n        log_warning(f\"\
      Queue creation validation error for '{queue_name}': {e.errors()}\", icon_type='QUEUE')\n\
      \        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\
      \ detail=e.errors())\n    except Exception as e:\n        log_error(f\"Error\
      \ creating queue '{queue_name}': {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Unexpected error creating queue\")\n\n@app.get(\"/queues/{queue_name}\"\
      , response_model=QueueResponse, tags=[\"Queues\"], summary=\"Get Queue Details\"\
      )\n@limiter.limit(\"60/minute\")\nasync def get_queue(request: Request, queue_name:\
      \ str = Path(..., description=\"The name of the queue to retrieve.\"), current_user:\
      \ str = Depends(get_current_user)) -> QueueResponse:\n    log_info(f\"\U0001F4E5\
      \ GET /queues/{queue_name} request by user '{current_user}'\", icon_type='QUEUE')\n\
      \    try:\n        queue = await _get_queue_or_404(queue_name)\n        message_count\
      \ = await Message.filter(queue_id=queue.id).count()\n        log_success(f\"\
      Details for queue '{queue_name}' (ID: {queue.id}) returned.\", icon_type='QUEUE')\n\
      \        response = QueueResponse.model_validate(queue)\n        response.message_count\
      \ = message_count\n        return response\n    except HTTPException:\n    \
      \    raise\n    except Exception as e:\n        log_error(f\"Unexpected error\
      \ getting queue details for '{queue_name}': {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error retrieving queue details\")\n\n@app.delete(\"/queues/{queue_name}\"\
      , status_code=status.HTTP_204_NO_CONTENT, tags=[\"Queues\"], summary=\"Delete\
      \ Queue\")\n@limiter.limit(\"10/minute\")\nasync def delete_queue(request: Request,\
      \ queue_name: str = Path(..., description=\"The name of the queue to delete.\"\
      ), current_user: str = Depends(get_current_user)) -> Response:\n    log_info(f\"\
      \U0001F5D1️ DELETE /queues/{queue_name} request by user '{current_user}'\",\
      \ icon_type='QUEUE')\n    try:\n        queue = await _get_queue_or_404(queue_name)\n\
      \        queue_id = queue.id\n        log_pipeline(f\"Queue '{queue_name}' (ID:\
      \ {queue_id}) found. Proceeding with deletion...\")\n\n        await queue.delete()\n\
      \n        log_success(f\"✅ Queue '{queue_name}' (ID: {queue_id}) and associated\
      \ messages deleted successfully.\", icon_type='QUEUE')\n        return Response(status_code=status.HTTP_204_NO_CONTENT)\n\
      \    except HTTPException:\n        raise\n    except Exception as e:\n    \
      \    log_error(f\"Error deleting queue '{queue_name}': {e}\", icon_type='CRITICAL',\
      \ exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error deleting queue\")\n\n@app.post(\"/queues/{queue_name}/messages\"\
      , response_model=MessagePublishResponse, status_code=status.HTTP_201_CREATED,\
      \ tags=[\"Messages\"], summary=\"Publish Message\")\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT)\n\
      async def publish_message(\n    request: Request,\n    payload: MessagePayload,\n\
      \    queue_name: str = Path(..., description=\"The name of the target queue.\"\
      ),\n    current_user: str = Depends(get_current_user)\n) -> MessagePublishResponse:\n\
      \    content_preview = payload.content[:80] + ('...' if len(payload.content)\
      \ > 80 else '')\n    log_info(f\"\U0001F4E4 POST /queues/{queue_name}/messages\
      \ request by '{current_user}'\", icon_type='MSG', extra={\"content_preview\"\
      : content_preview})\n    try:\n        queue = await _get_queue_or_404(queue_name)\n\
      \        log_pipeline(f\"Queue '{queue_name}' (ID: {queue.id}) found. Creating\
      \ message...\")\n\n        new_message = await Message.create(queue=queue, content=payload.content,\
      \ status='pending')\n\n        log_success(f\"✅ Message ID {new_message.id}\
      \ published to queue '{queue_name}'.\", icon_type='MSG')\n        return MessagePublishResponse(message_id=new_message.id)\n\
      \    except HTTPException:\n        raise\n    except ValidationError as e:\n\
      \        log_warning(f\"Message publish validation error to '{queue_name}':\
      \ {e.errors()}\", icon_type='MSG')\n        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\
      \ detail=e.errors())\n    except Exception as e:\n        log_error(f\"Error\
      \ publishing message to queue '{queue_name}': {e}\", icon_type='CRITICAL', exc_info=True)\n\
      \        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error publishing message\")\n\n# --- CORRECTED consume_message FUNCTION\
      \ (NO COMMENTS, no using_connection) ---\n@app.get(\"/queues/{queue_name}/messages/consume\"\
      ,\n         response_model=MessageResponse,\n         tags=[\"Messages\"],\n\
      \         summary=\"Consume Message from Queue\",\n         responses={\n  \
      \           200: {\"description\": \"Message consumed successfully\", \"model\"\
      : MessageResponse},\n             204: {\"description\": \"No pending messages\
      \ in the queue\"},\n             404: {\"description\": \"Queue not found\"\
      },\n             500: {\"description\": \"Internal server error during consumption\"\
      }\n         })\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT)\nasync def\
      \ consume_message(\n    request: Request,\n    queue_name: str = Path(..., description=\"\
      The name of the queue to consume a message from.\"),\n    current_user: str\
      \ = Depends(get_current_user)\n) -> Union[MessageResponse, Response]:\n    log_info(f\"\
      \U0001F504 GET /queues/{queue_name}/messages/consume request by '{current_user}'\"\
      , icon_type='MSG')\n    try:\n        queue = await _get_queue_or_404(queue_name)\n\
      \        async with in_transaction(\"default\"): # Context manager handles connection\n\
      \            message = await Message.filter(queue_id=queue.id, status='pending')\
      \ \\\n                                   .select_for_update() \\\n         \
      \                          .order_by('created_at') \\\n                    \
      \               .first()\n\n            if not message:\n                log_info(f\"\
      No pending messages available in queue '{queue_name}'. Returning 204.\", icon_type='MSG')\n\
      \                return Response(status_code=status.HTTP_204_NO_CONTENT)\n\n\
      \            message.status = 'processing'\n            message.updated_at =\
      \ datetime.now(timezone.utc)\n            # Remove using_connection=tx from\
      \ save()\n            await message.save(update_fields=['status', 'updated_at'])\n\
      \n            log_success(f\"✉️ Message ID {message.id} consumed from queue\
      \ '{queue_name}' (status -> processing).\", icon_type='MSG')\n\n           \
      \ return MessageResponse(\n                id=message.id,\n                queue_id=message.queue_id,\n\
      \                content=message.content,\n                status=message.status,\n\
      \                created_at=message.created_at,\n                updated_at=message.updated_at\n\
      \            )\n\n    except HTTPException as http_exc:\n        raise http_exc\n\
      \    except Exception as e:\n        log_error(f\"Error consuming message from\
      \ queue '{queue_name}': {type(e).__name__} - {e}\", exc_info=True, icon_type='ERROR')\n\
      \        detail = f\"Error consuming message from queue: {type(e).__name__}\"\
      \n        if settings.APP_ENV == 'development':\n             try:\n       \
      \          detail += f\" - {str(e)}\"\n             except Exception:\n    \
      \             detail += \" (Error details could not be stringified)\"\n    \
      \    raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n\
      \            detail=detail\n        )\n# --- END OF CORRECTED consume_message\
      \ FUNCTION ---\n\n\n@app.post(\"/messages/{message_id}/ack\", status_code=status.HTTP_200_OK,\
      \ response_model=Dict[str, str], tags=[\"Messages\"], summary=\"Acknowledge\
      \ Message\")\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT)\nasync def acknowledge_message(\n\
      \    request: Request,\n    background_tasks: BackgroundTasks,\n    message_id:\
      \ int = Path(..., ge=1, description=\"The ID of the message to acknowledge.\"\
      ),\n    current_user: str = Depends(get_current_user)\n) -> Dict[str, str]:\n\
      \    log_info(f\"✅ POST /messages/{message_id}/ack request by '{current_user}'\"\
      , icon_type='MSG')\n    try:\n        async with in_transaction(\"default\"\
      ): # Context manager handles connection\n            message = await Message.filter(id=message_id,\
      \ status='processing') \\\n                                   .select_for_update()\
      \ \\\n                                   .get_or_none()\n\n            if not\
      \ message:\n                existing_msg_status = await Message.filter(id=message_id)\
      \ \\\n                                                   .values_list('status',\
      \ flat=True) \\\n                                                   .first()\n\
      \                if existing_msg_status:\n                    log_warning(f\"\
      ACK failed for message {message_id}: Expected status 'processing', found '{existing_msg_status}'.\"\
      , icon_type='MSG')\n                    raise HTTPException(\n             \
      \           status_code=status.HTTP_409_CONFLICT,\n                        detail=f\"\
      Message {message_id} is in status '{existing_msg_status}', cannot ACK. Only\
      \ 'processing' messages can be acknowledged.\"\n                    )\n    \
      \            else:\n                    log_warning(f\"ACK failed: Message {message_id}\
      \ not found.\", icon_type='MSG')\n                    raise HTTPException(\n\
      \                        status_code=status.HTTP_404_NOT_FOUND,\n          \
      \              detail=f\"Message with ID {message_id} not found.\"\n       \
      \             )\n\n            message.status = 'processed'\n            message.updated_at\
      \ = datetime.now(timezone.utc)\n            # Remove using_connection=tx from\
      \ save()\n            await message.save(update_fields=['status', 'updated_at'])\n\
      \n        log_success(f\"✅ Message ID {message_id} acknowledged successfully\
      \ by '{current_user}' (status -> processed).\", icon_type='MSG')\n        return\
      \ {\"detail\": f\"Message {message_id} acknowledged successfully.\"}\n\n   \
      \ except HTTPException:\n        raise\n    except IntegrityError as e:\n  \
      \       log_warning(f\"DB integrity error during ACK for message {message_id}:\
      \ {e}\", icon_type='DB')\n         raise HTTPException(status_code=status.HTTP_409_CONFLICT,\
      \ detail=\"Database conflict during message acknowledgement.\")\n    except\
      \ Exception as e:\n        log_error(f\"Error acknowledging message {message_id}:\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=\"Error acknowledging message\")\n\n@app.post(\"/messages/{message_id}/nack\"\
      , status_code=status.HTTP_200_OK, response_model=Dict[str, str], tags=[\"Messages\"\
      ], summary=\"Negative Acknowledge Message\")\n@limiter.limit(settings.HIGH_TRAFFIC_RATE_LIMIT)\n\
      async def negative_acknowledge_message(\n    request: Request,\n    background_tasks:\
      \ BackgroundTasks,\n    message_id: int = Path(..., ge=1, description=\"The\
      \ ID of the message to NACK.\"),\n    requeue: bool = FastQuery(False, description=\"\
      If true, set status back to 'pending' for reprocessing. If false, set status\
      \ to 'failed'.\"),\n    current_user: str = Depends(get_current_user)\n) ->\
      \ Dict[str, str]:\n    action = \"requeued (pending)\" if requeue else \"marked\
      \ as failed\"\n    log_info(f\"❌ POST /messages/{message_id}/nack request by\
      \ '{current_user}' (requeue={requeue})\", icon_type='MSG')\n    try:\n     \
      \   async with in_transaction(\"default\"): # Context manager handles connection\n\
      \            message = await Message.filter(id=message_id, status='processing')\
      \ \\\n                                   .select_for_update() \\\n         \
      \                          .get_or_none()\n\n            if not message:\n \
      \               existing_msg_status = await Message.filter(id=message_id) \\\
      \n                                                   .values_list('status',\
      \ flat=True) \\\n                                                   .first()\n\
      \                if existing_msg_status:\n                    log_warning(f\"\
      NACK failed for message {message_id}: Expected status 'processing', found '{existing_msg_status}'.\"\
      , icon_type='MSG')\n                    raise HTTPException(\n             \
      \           status_code=status.HTTP_409_CONFLICT,\n                        detail=f\"\
      Message {message_id} is in status '{existing_msg_status}', cannot NACK. Only\
      \ 'processing' messages can be negatively acknowledged.\"\n                \
      \    )\n                else:\n                    log_warning(f\"NACK failed:\
      \ Message {message_id} not found.\", icon_type='MSG')\n                    raise\
      \ HTTPException(\n                        status_code=status.HTTP_404_NOT_FOUND,\n\
      \                        detail=f\"Message with ID {message_id} not found.\"\
      \n                    )\n\n            new_status = 'pending' if requeue else\
      \ 'failed'\n            message.status = new_status\n            message.updated_at\
      \ = datetime.now(timezone.utc)\n            # Remove using_connection=tx from\
      \ save()\n            await message.save(update_fields=['status', 'updated_at'])\n\
      \n        log_success(f\"✅ Message ID {message_id} NACK'd successfully by '{current_user}'\
      \ (status -> {new_status}).\", icon_type='MSG')\n        return {\"detail\"\
      : f\"Message {message_id} successfully {action}.\"}\n\n    except HTTPException:\n\
      \        raise\n    except IntegrityError as e:\n         log_warning(f\"DB\
      \ integrity error during NACK for message {message_id}: {e}\", icon_type='DB')\n\
      \         raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=\"\
      Database conflict during message NACK operation.\")\n    except Exception as\
      \ e:\n        log_error(f\"Error NACK'ing message {message_id} (action: {action}):\
      \ {e}\", icon_type='CRITICAL', exc_info=True)\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\
      \ detail=f\"Error negatively acknowledging message (action: {action})\")\n\n\
      log_info(\"\U0001F353 Configuring GraphQL endpoint with Strawberry...\", icon_type='GRAPHQL')\n\
      \n@strawberry.type\nclass MessageGQL:\n    id: strawberry.ID\n    queue_name:\
      \ str = strawberry.field(description=\"Name of the queue this message belongs\
      \ to\")\n    content: str\n    status: str\n    created_at: datetime\n    updated_at:\
      \ datetime\n\n    @classmethod\n    def from_orm(cls, model: Message, queue_name_str:\
      \ str) -> \"MessageGQL\":\n         return cls(\n             id=strawberry.ID(str(model.id)),\n\
      \             queue_name=queue_name_str,\n             content=model.content,\n\
      \             status=model.status,\n             created_at=model.created_at,\n\
      \             updated_at=model.updated_at\n         )\n\n@strawberry.type\n\
      class QueueGQL:\n    id: strawberry.ID\n    name: str\n    created_at: datetime\n\
      \    updated_at: datetime\n\n    @strawberry.field\n    async def message_count(self,\
      \ info: Info) -> int:\n        log_pipeline(f\"GQL: Resolving message_count\
      \ for Queue ID {self.id}\", icon_type='GRAPHQL')\n        try:\n           \
      \ return await Message.filter(queue_id=int(self.id)).count()\n        except\
      \ ValueError:\n             log_error(f\"GQL message_count: Invalid ID format\
      \ '{self.id}'\", icon_type='GRAPHQL')\n             return 0\n        except\
      \ Exception as e:\n            log_error(f\"GQL message_count resolver error\
      \ for queue ID {self.id}: {e}\", exc_info=True, icon_type='GRAPHQL')\n     \
      \       return 0\n\n    @strawberry.field\n    async def messages(\n       \
      \ self, info: Info,\n        status: Optional[str] = strawberry.field(default=None,\
      \ description=\"Filter by message status (e.g., pending, processing, processed,\
      \ failed)\"),\n        limit: int = strawberry.field(default=10, description=\"\
      Maximum number of messages to return (1-100)\"),\n        offset: int = strawberry.field(default=0,\
      \ description=\"Number of messages to skip (for pagination)\")\n    ) -> List[MessageGQL]:\n\
      \        log_pipeline(f\"GQL: Resolving messages for Queue ID {self.id} (status={status},\
      \ limit={limit}, offset={offset})\", icon_type='GRAPHQL')\n        valid_statuses\
      \ = ['pending', 'processing', 'processed', 'failed']\n        if status and\
      \ status not in valid_statuses:\n            raise ValueError(f\"Invalid status\
      \ filter: '{status}'. Must be one of {valid_statuses}.\")\n\n        limit =\
      \ max(1, min(limit, 100))\n        offset = max(0, offset)\n\n        try:\n\
      \             queue_id_int = int(self.id)\n             query = Message.filter(queue_id=queue_id_int)\n\
      \             if status:\n                 query = query.filter(status=status)\n\
      \             messages_db = await query.order_by('-created_at').offset(offset).limit(limit)\n\
      \n             return [MessageGQL.from_orm(m, queue_name_str=self.name) for\
      \ m in messages_db]\n        except ValueError as ve:\n             log_warning(f\"\
      GQL messages resolver validation error for queue ID {self.id}: {ve}\", icon_type='GRAPHQL')\n\
      \             raise ve\n        except Exception as e:\n             log_error(f\"\
      GQL messages resolver error for queue ID {self.id}: {e}\", exc_info=True, icon_type='GRAPHQL')\n\
      \             return []\n\n@strawberry.type\nclass QueryGQL:\n    @strawberry.field\n\
      \    async def all_queues(self, info: Info) -> List[QueueGQL]:\n        log_info(\"\
      \U0001F353 GraphQL Query: all_queues\", icon_type='GRAPHQL')\n        try:\n\
      \             queues_db = await Queue.all().order_by('name')\n             return\
      \ [\n                 QueueGQL(id=strawberry.ID(str(q.id)), name=q.name, created_at=q.created_at,\
      \ updated_at=q.updated_at)\n                 for q in queues_db\n          \
      \   ]\n        except Exception as e:\n            log_error(f\"GraphQL 'all_queues'\
      \ resolver error: {e}\", icon_type='GRAPHQL', exc_info=True)\n            return\
      \ []\n\n    @strawberry.field\n    async def queue_by_name(self, info: Info,\
      \ name: str) -> Optional[QueueGQL]:\n        log_info(f\"\U0001F353 GraphQL\
      \ Query: queue_by_name (name='{name}')\", icon_type='GRAPHQL')\n        try:\n\
      \            queue_db = await Queue.get_or_none(name=name)\n            if queue_db:\n\
      \                return QueueGQL(id=strawberry.ID(str(queue_db.id)), name=queue_db.name,\
      \ created_at=queue_db.created_at, updated_at=queue_db.updated_at)\n        \
      \    else:\n                log_warning(f\"GraphQL: Queue '{name}' not found\
      \ via queue_by_name.\", icon_type='GRAPHQL')\n                return None\n\
      \        except Exception as e:\n            log_error(f\"GraphQL 'queue_by_name'\
      \ resolver error for name '{name}': {e}\", icon_type='GRAPHQL', exc_info=True)\n\
      \            return None\n\n    @strawberry.field\n    async def message_by_id(self,\
      \ info: Info, id: strawberry.ID) -> Optional[MessageGQL]:\n        log_info(f\"\
      \U0001F353 GraphQL Query: message_by_id (id={id})\", icon_type='GRAPHQL')\n\
      \        try:\n            message_id_int = int(id)\n            message_db\
      \ = await Message.get_or_none(id=message_id_int).select_related('queue')\n\n\
      \            if message_db and message_db.queue:\n                return MessageGQL.from_orm(message_db,\
      \ queue_name_str=message_db.queue.name)\n            else:\n               \
      \ log_warning(f\"GraphQL: Message ID {id} not found or has no associated queue.\"\
      , icon_type='GRAPHQL')\n                return None\n        except (ValueError,\
      \ DoesNotExist):\n            log_warning(f\"GraphQL: Message ID {id} not found\
      \ or invalid format.\", icon_type='GRAPHQL')\n            return None\n    \
      \    except Exception as e:\n            log_error(f\"GraphQL 'message_by_id'\
      \ resolver error for ID {id}: {e}\", icon_type='GRAPHQL', exc_info=True)\n \
      \           return None\n\n@strawberry.type\nclass MutationGQL:\n    @strawberry.mutation\n\
      \    async def create_queue(self, info: Info, name: str) -> QueueGQL:\n    \
      \     log_info(f\"\U0001F353 GraphQL Mutation: create_queue (name='{name}')\"\
      , icon_type='GRAPHQL')\n         try:\n             if not re.match(r\"^[a-zA-Z0-9_-]+$\"\
      , name):\n                 raise ValueError(\"Invalid queue name format. Use\
      \ alphanumeric, underscore, hyphen.\")\n             if len(name) > 255:\n \
      \                raise ValueError(\"Queue name exceeds maximum length of 255\
      \ characters.\")\n\n             new_queue, created = await Queue.get_or_create(name=name)\n\
      \             if not created:\n                 raise Exception(f\"Queue with\
      \ name '{name}' already exists.\")\n             log_success(f\"GQL: Queue '{name}'\
      \ created (ID: {new_queue.id}).\", icon_type='QUEUE')\n             return QueueGQL(id=strawberry.ID(str(new_queue.id)),\
      \ name=new_queue.name, created_at=new_queue.created_at, updated_at=new_queue.updated_at)\n\
      \         except ValueError as ve:\n              log_warning(f\"GraphQL 'create_queue'\
      \ validation error for name '{name}': {ve}\", icon_type='GRAPHQL')\n       \
      \       raise Exception(str(ve))\n         except Exception as e:\n        \
      \     log_error(f\"GraphQL 'create_queue' mutation error for name '{name}':\
      \ {e}\", icon_type='GRAPHQL', exc_info=True)\n             raise Exception(f\"\
      Failed to create queue '{name}': {e}\")\n\n    @strawberry.mutation\n    async\
      \ def delete_queue(self, info: Info, name: str) -> bool:\n        log_info(f\"\
      \U0001F353 GraphQL Mutation: delete_queue (name='{name}')\", icon_type='GRAPHQL')\n\
      \        try:\n            queue = await Queue.get_or_none(name=name)\n    \
      \        if not queue:\n                raise Exception(f\"Queue with name '{name}'\
      \ not found.\")\n            await queue.delete()\n            log_success(f\"\
      GQL: Queue '{name}' deleted successfully.\", icon_type='QUEUE')\n          \
      \  return True\n        except Exception as e:\n            log_error(f\"GraphQL\
      \ 'delete_queue' mutation error for name '{name}': {e}\", icon_type='GRAPHQL',\
      \ exc_info=True)\n            raise Exception(f\"Failed to delete queue '{name}':\
      \ {e}\")\n\n    @strawberry.mutation\n    async def publish_message(self, info:\
      \ Info, queue_name: str, content: str) -> MessageGQL:\n        log_info(f\"\U0001F353\
      \ GraphQL Mutation: publish_message (queue='{queue_name}')\", icon_type='GRAPHQL')\n\
      \        try:\n            if not content:\n                 raise ValueError(\"\
      Message content cannot be empty.\")\n\n            queue = await Queue.get_or_none(name=queue_name)\n\
      \            if not queue:\n                raise Exception(f\"Queue with name\
      \ '{queue_name}' not found.\")\n\n            new_message = await Message.create(queue=queue,\
      \ content=content, status='pending')\n            log_success(f\"GQL: Message\
      \ ID {new_message.id} published to queue '{queue_name}'.\", icon_type='MSG')\n\
      \            return MessageGQL.from_orm(new_message, queue_name_str=queue_name)\n\
      \        except ValueError as ve:\n             log_warning(f\"GraphQL 'publish_message'\
      \ validation error to queue '{queue_name}': {ve}\", icon_type='GRAPHQL')\n \
      \            raise Exception(str(ve))\n        except Exception as e:\n    \
      \        log_error(f\"GraphQL 'publish_message' mutation error to queue '{queue_name}':\
      \ {e}\", icon_type='GRAPHQL', exc_info=True)\n            raise Exception(f\"\
      Failed to publish message to queue '{queue_name}': {e}\")\n\nasync def get_graphql_context(\n\
      \    request: Request,\n    response: Response,\n    background_tasks: BackgroundTasks,\n\
      \    auth: Optional[HTTPAuthorizationCredentials] = Depends(bearer_scheme)\n\
      ) -> Dict:\n    context = {\n        \"request\": request,\n        \"response\"\
      : response,\n        \"background_tasks\": background_tasks,\n        \"current_user\"\
      : None\n    }\n    if auth:\n        try:\n            username = await _decode_token(auth.credentials,\
      \ \"access\")\n            context[\"current_user\"] = username\n          \
      \  log_debug(f\"\U0001F353 GraphQL request authenticated for user: '{username}'\"\
      , icon_type='AUTH')\n        except HTTPException as auth_exc:\n           \
      \ log_warning(f\"GraphQL authentication failed: {auth_exc.detail} (Status: {auth_exc.status_code})\"\
      , icon_type='AUTH')\n    else:\n         log_debug(\"\U0001F353 GraphQL request\
      \ is unauthenticated (no Bearer token found).\", icon_type='AUTH')\n\n    return\
      \ context\n\ngql_schema = strawberry.Schema(query=QueryGQL, mutation=MutationGQL)\n\
      graphql_app = GraphQLRouter(\n    gql_schema,\n    context_getter=get_graphql_context,\n\
      \    graphiql=False,\n    graphql_ide=\"apollo-sandbox\"\n)\napp.include_router(graphql_app,\
      \ prefix=\"/graphql\", tags=[\"GraphQL\"], include_in_schema=True)\nlog_success(\"\
      \U0001F353 GraphQL endpoint /graphql configured with Apollo Sandbox IDE.\",\
      \ icon_type='GRAPHQL')\n\n@app.exception_handler(DoesNotExist)\nasync def tortoise_does_not_exist_handler(request:\
      \ Request, exc: DoesNotExist):\n    model_name_match = str(exc).split(\":\"\
      )\n    model_name = model_name_match[0].strip() if len(model_name_match) > 0\
      \ else \"Resource\"\n    detail = f\"{model_name} not found.\"\n    client_host\
      \ = request.client.host if request.client else \"N/A\"\n    log_warning(f\"\
      Resource Not Found (DB DoesNotExist): {exc} ({request.method} {request.url.path})\"\
      , icon_type='DB', extra={\"client\": client_host})\n    return JSONResponse(\n\
      \        status_code=status.HTTP_404_NOT_FOUND,\n        content={\"detail\"\
      : detail}\n    )\n\n@app.exception_handler(IntegrityError)\nasync def tortoise_integrity_error_handler(request:\
      \ Request, exc: IntegrityError):\n    detail = \"Database conflict occurred.\"\
      \n    error_info_str = str(exc)\n    if \"UNIQUE constraint failed\" in error_info_str:\n\
      \        detail = \"A resource with the same unique identifier already exists.\"\
      \n    elif settings.APP_ENV == 'development':\n        detail += f\" Error:\
      \ {error_info_str}\"\n\n    client_host = request.client.host if request.client\
      \ else \"N/A\"\n    log_warning(f\"Database Integrity Conflict: {exc} ({request.method}\
      \ {request.url.path})\", icon_type='DB', extra={\"client\": client_host})\n\
      \    return JSONResponse(\n        status_code=status.HTTP_409_CONFLICT,\n \
      \       content={\"detail\": detail}\n    )\n\n@app.exception_handler(ValidationError)\n\
      async def pydantic_validation_exception_handler(request: Request, exc: ValidationError):\n\
      \    client_host = request.client.host if request.client else \"N/A\"\n    try:\n\
      \        error_content = {\"detail\": \"Request validation failed\", \"errors\"\
      : json.loads(exc.json())}\n        log_warning(f\"Request Validation Error (Pydantic):\
      \ {error_content['errors']} ({request.method} {request.url.path})\", icon_type='HTTP',\
      \ extra={\"client\": client_host})\n    except Exception as json_err:\n    \
      \    log_error(f\"Error parsing Pydantic validation errors: {json_err}\", icon_type=\"\
      ERROR\")\n        error_content = {\"detail\": \"Request validation failed\"\
      , \"errors\": str(exc)}\n        log_warning(f\"Request Validation Error (Pydantic\
      \ - raw): {str(exc)} ({request.method} {request.url.path})\", icon_type='HTTP',\
      \ extra={\"client\": client_host})\n\n    return JSONResponse(\n        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n\
      \        content=error_content\n    )\n\n@app.exception_handler(HTTPException)\n\
      async def http_exception_handler(request: Request, exc: HTTPException):\n  \
      \  log_level = log_warning if 400 <= exc.status_code < 500 else log_error\n\
      \    icon = 'HTTP' if 400 <= exc.status_code < 500 else 'ERROR'\n    client_host\
      \ = request.client.host if request.client else \"N/A\"\n    log_level(\n   \
      \     f\"HTTP Error Handled: Status={exc.status_code}, Detail='{exc.detail}'\
      \ ({request.method} {request.url.path})\",\n        icon_type=icon,\n      \
      \  extra={\"client\": client_host, \"headers\": exc.headers}\n    )\n    return\
      \ JSONResponse(\n        status_code=exc.status_code,\n        content={\"detail\"\
      : exc.detail},\n        headers=getattr(exc, \"headers\", None)\n    )\n\n@app.exception_handler(Exception)\n\
      async def generic_exception_handler(request: Request, exc: Exception):\n   \
      \ tb_str = \"\".join(traceback.format_exception(type(exc), exc, exc.__traceback__))\n\
      \    client_host = request.client.host if request.client else \"N/A\"\n    error_time\
      \ = datetime.now(timezone.utc)\n\n    log_critical(\n        f\"Unhandled Internal\
      \ Server Error: {type(exc).__name__}: {exc} ({request.method} {request.url.path})\"\
      ,\n        icon_type='CRITICAL',\n        exc_info=False,\n        extra={\n\
      \            \"client\": client_host,\n            \"full_traceback\": tb_str\
      \ if settings.APP_ENV == 'development' else \"Traceback hidden in production\"\
      \n        }\n    )\n    async with stats_lock:\n        app_stats[\"last_error\"\
      ] = f\"Unhandled {type(exc).__name__} at {request.method} {request.url.path}\"\
      \n        app_stats[\"last_error_timestamp\"] = error_time\n\n    return JSONResponse(\n\
      \        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n        content={\"\
      detail\": \"An unexpected internal server error occurred. Please contact the\
      \ administrator or check server logs.\"}\n    )\n\nif __name__ == '__main__':\n\
      \    import re\n    log_info(\"\U0001F3C1 Main execution block entered...\"\
      , icon_type='SETUP')\n\n    log_info(\"Checking for SSL certificate and key...\"\
      , icon_type='SEC')\n    try:\n        os.makedirs(settings.CERT_DIR, exist_ok=True)\n\
      \        cert_exists = os.path.exists(settings.CERT_FILE)\n        key_exists\
      \ = os.path.exists(settings.KEY_FILE)\n\n        if cert_exists and key_exists:\n\
      \            log_success(f\"\U0001F6E1️ SSL Certificate '{os.path.basename(settings.CERT_FILE)}'\
      \ and Key '{os.path.basename(settings.KEY_FILE)}' found in '{settings.CERT_DIR}'.\"\
      , icon_type='SEC')\n        else:\n            missing = [f for f, exists in\
      \ [(os.path.basename(settings.CERT_FILE), cert_exists), (os.path.basename(settings.KEY_FILE),\
      \ key_exists)] if not exists]\n            log_warning(f\"SSL file(s) not found:\
      \ {', '.join(missing)}. Attempting to generate new self-signed certificate for\
      \ 'localhost'...\", icon_type='SEC')\n            try:\n                if not\
      \ generate_self_signed_cert(settings.CERT_FILE, settings.KEY_FILE, common_name=\"\
      localhost\"):\n                    log_critical(\"Critical failure generating\
      \ self-signed SSL certificates. Cannot start server with HTTPS.\", icon_type='CRITICAL')\n\
      \                    sys.exit(1)\n                else:\n                  \
      \   log_success(\"✅ Successfully generated new self-signed SSL certificate and\
      \ key.\", icon_type='SEC')\n            except Exception as cert_gen_e:\n  \
      \              log_critical(f\"Unexpected error during certificate generation:\
      \ {cert_gen_e}\", icon_type='CRITICAL', exc_info=True)\n                sys.exit(1)\n\
      \    except Exception as setup_e:\n        log_critical(f\"Unexpected error\
      \ during initial certificate setup check: {setup_e}\", icon_type='CRITICAL',\
      \ exc_info=True)\n        sys.exit(1)\n\n    log_info(\"=== Configuration Summary\
      \ ===\", icon_type='SETUP')\n    log_info(f\"  Project: {settings.PROJECT_NAME}\
      \ v{settings.VERSION}\", icon_type='INFO')\n    log_info(f\"  Environment: {settings.APP_ENV}\"\
      , icon_type='INFO')\n    log_info(f\"  Log Level: {settings.LOG_LEVEL_STR}\"\
      , icon_type='LOGS')\n    log_info(f\"  JWT Secret: {'Set via Env Var' if 'JWT_SECRET_KEY'\
      \ in os.environ and 'CHANGE_ME' not in settings.JWT_SECRET_KEY else 'Using Generated/Default\
      \ (INSECURE FOR PROD)'}\", icon_type='AUTH')\n    log_info(f\"  DB Path: {settings.DB_PATH}\"\
      , icon_type='DB')\n    log_info(f\"  Rate Limit (Default): {settings.DEFAULT_RATE_LIMIT}\"\
      , icon_type='RATELIMIT')\n    log_info(f\"  Rate Limit (High Traffic): {settings.HIGH_TRAFFIC_RATE_LIMIT}\"\
      , icon_type='RATELIMIT')\n    log_info(f\"  CORS Origins: {settings.ALLOWED_ORIGINS}\"\
      , icon_type='HTTP')\n    log_info(f\"  Log Dir: {settings.LOG_DIR} (Current\
      \ File: {os.path.basename(LOG_FILENAME)})\", icon_type='LOGS')\n    log_info(f\"\
      \  Cert Dir: {settings.CERT_DIR}\", icon_type='SEC')\n    log_info(f\"============================\"\
      , icon_type='SETUP')\n\n    reload_enabled = settings.APP_ENV == \"development\"\
      \n    if reload_enabled:\n        log_warning(\"Running in DEVELOPMENT mode\
      \ with auto-reload enabled.\", icon_type='SETUP')\n\n    log_level_uvicorn =\
      \ settings.LOG_LEVEL_STR.lower()\n    if log_level_uvicorn == 'debug' and reload_enabled:\n\
      \        log_level_uvicorn = 'debug'\n    elif log_level_uvicorn == 'debug':\n\
      \        log_level_uvicorn = 'info'\n\n    log_info(f\"\U0001F310\U0001F680\
      \ Starting Uvicorn server on https://0.0.0.0:{settings.API_PORT}\", icon_type='STARTUP',\
      \ extra={\"reload\": reload_enabled, \"log_level\": log_level_uvicorn})\n  \
      \  log_info(f\"   Access API root at: https://localhost:{settings.API_PORT}/\"\
      , icon_type='HTTP')\n    log_info(f\"   Swagger UI docs:  https://localhost:{settings.API_PORT}/docs\"\
      , icon_type='HTTP')\n    log_info(f\"   ReDoc docs:       https://localhost:{settings.API_PORT}/redoc\"\
      , icon_type='HTTP')\n    log_info(f\"   GraphQL endpoint: https://localhost:{settings.API_PORT}/graphql\
      \ (Apollo Sandbox IDE)\", icon_type='GRAPHQL')\n    log_info(\"   Press Ctrl+C\
      \ to stop the server.\", icon_type='INFO')\n\n    try:\n        uvicorn.run(\n\
      \            \"__main__:app\",\n            host=\"0.0.0.0\",\n            port=settings.API_PORT,\n\
      \            log_level=log_level_uvicorn,\n            ssl_keyfile=settings.KEY_FILE,\n\
      \            ssl_certfile=settings.CERT_FILE,\n            reload=reload_enabled,\n\
      \            use_colors=True,\n            access_log=False\n        )\n   \
      \ except KeyboardInterrupt:\n        log_info(\"\\n\U0001F6A6 Server shutdown\
      \ requested via Keyboard Interrupt (Ctrl+C).\", icon_type='SHUTDOWN')\n    except\
      \ SystemExit as e:\n         log_info(f\"\U0001F6A6 Server exited with code\
      \ {e.code}.\", icon_type='SHUTDOWN')\n    except Exception as e:\n        log_critical(f\"\
      ❌ Fatal: Failed to start or run Uvicorn server: {e}\", exc_info=True)\n    \
      \    sys.exit(1)\n    finally:\n        log_info(\"\U0001F3C1 Uvicorn server\
      \ process has finished.\", icon_type='SHUTDOWN')"
    tamanho: 0.08 MB
  meu_bloco.json:
    caminho_completo: .\meu_bloco.json
    json_info:
      numero_de_linhas: 5
      tamanho: 0.00 MB
    numero_de_linhas: 5
    tamanho: 0.00 MB
  mypy.ini:
    caminho_completo: .\mypy.ini
    numero_de_linhas: 54
    tamanho: 0.00 MB
  pyproject.toml:
    caminho_completo: .\pyproject.toml
    numero_de_linhas: 62
    tamanho: 0.00 MB
  pytest.ini:
    caminho_completo: .\pytest.ini
    numero_de_linhas: 33
    tamanho: 0.00 MB
  readmev1.md:
    caminho_completo: .\readmev1.md
    numero_de_linhas: 439
    tamanho: 0.02 MB
  requirements.txt:
    caminho_completo: .\requirements.txt
    numero_de_linhas: 12
    tamanho: 0.00 MB
  tortoise_config.py:
    caminho_completo: .\tortoise_config.py
    classes: []
    functions: []
    imports:
    - module: typing
      names:
      - List
    numero_de_linhas: 28
    source_code: "\"\"\"\nConfiguração do Tortoise ORM para o Message Broker.\nAutor:\
      \ Elias Andrade\nData: 2024-03-19\nVersão: 1.0.0\n\"\"\"\n\nfrom typing import\
      \ List\n\nTORTOISE_ORM = {\n    \"connections\": {\n        \"default\": \"\
      sqlite://db.sqlite3\"\n    },\n    \"apps\": {\n        \"models\": {\n    \
      \        \"models\": [\"message_broker_v1\"],  # Nome do módulo onde estão os\
      \ modelos\n            \"default_connection\": \"default\",\n        }\n   \
      \ },\n    \"use_tz\": False,\n    \"timezone\": \"America/Sao_Paulo\"\n}\n\n\
      # Lista de modelos para migração automática\nMODELS: List[str] = [\n    \"message_broker_v1.Queue\"\
      ,\n    \"message_broker_v1.Message\"\n] "
    tamanho: 0.00 MB
  webdash3-clean.py:
    caminho_completo: .\webdash3-clean.py
    classes:
    - docstring: null
      end_lineno: 291
      lineno: 57
      name: DashboardState
    functions:
    - docstring: Safely convert value to float.
      end_lineno: 300
      lineno: 297
      name: safe_float
    - docstring: Converts seconds into a human-readable string like 1d 2h 3m 4s.
      end_lineno: 315
      lineno: 302
      name: format_timedelta_human
    - docstring: Converts bytes to a human-readable string (KB, MB, GB...).
      end_lineno: 325
      lineno: 317
      name: bytes_to_human
    - docstring: null
      end_lineno: 414
      lineno: 328
      name: handle_api_errors
    - docstring: Attempts to login and sets the token in the state.
      end_lineno: 465
      lineno: 418
      name: login_to_api
    - docstring: Fetches stats data from the API.
      end_lineno: 505
      lineno: 468
      name: fetch_stats_data
    - docstring: Fetches queue data from the API.
      end_lineno: 537
      lineno: 508
      name: fetch_queues_data
    - docstring: Fetches the list of available log files.
      end_lineno: 591
      lineno: 540
      name: fetch_log_list
    - docstring: Fetches log content chunks. Handles fetching newer or older lines.
      end_lineno: 722
      lineno: 594
      name: fetch_log_content
    - docstring: null
      end_lineno: 728
      lineno: 726
      name: fetch_stats_job
    - docstring: null
      end_lineno: 732
      lineno: 730
      name: fetch_queues_job
    - docstring: null
      end_lineno: 736
      lineno: 734
      name: fetch_loglist_job
    - docstring: Scheduled job to fetch log content (latest or older).
      end_lineno: 771
      lineno: 738
      name: fetch_log_content_job
    - docstring: Runs the background scheduler thread.
      end_lineno: 803
      lineno: 773
      name: run_scheduler
    - docstring: Serves the main dashboard HTML page.
      end_lineno: 2352
      lineno: 2338
      name: serve_dashboard
    - docstring: API endpoint to provide the current state snapshot for the dashboard.
      end_lineno: 2366
      lineno: 2355
      name: get_dashboard_data
    - docstring: API endpoint to get the latest log data chunk.
      end_lineno: 2380
      lineno: 2369
      name: get_log_data
    - docstring: API endpoint triggered by user to fetch older log entries.
      end_lineno: 2396
      lineno: 2383
      name: get_older_logs
    - docstring: API endpoint to enable/disable log auto-refresh.
      end_lineno: 2414
      lineno: 2399
      name: toggle_log_refresh
    - docstring: null
      end_lineno: 110
      lineno: 58
      name: __init__
    - docstring: null
      end_lineno: 118
      lineno: 112
      name: _update_rate_history
    - docstring: null
      end_lineno: 146
      lineno: 120
      name: _update_http_error_rate
    - docstring: null
      end_lineno: 179
      lineno: 148
      name: update_stats_history
    - docstring: null
      end_lineno: 185
      lineno: 181
      name: update_error
    - docstring: null
      end_lineno: 192
      lineno: 187
      name: clear_error
    - docstring: null
      end_lineno: 195
      lineno: 194
      name: needs_login
    - docstring: null
      end_lineno: 197
      lineno: 196
      name: get_token
    - docstring: null
      end_lineno: 203
      lineno: 198
      name: set_token
    - docstring: null
      end_lineno: 209
      lineno: 204
      name: invalidate_token
    - docstring: null
      end_lineno: 235
      lineno: 211
      name: get_snapshot_for_dashboard
    - docstring: null
      end_lineno: 246
      lineno: 237
      name: get_log_data_for_request
    - docstring: Updates log lines, handling duplicates and max lines.
      end_lineno: 283
      lineno: 248
      name: update_log_lines
    - docstring: null
      end_lineno: 291
      lineno: 287
      name: set_log_auto_refresh
    - docstring: null
      end_lineno: 413
      lineno: 329
      name: decorator
    - docstring: null
      end_lineno: 412
      lineno: 331
      name: wrapper
    imports:
    - asname: null
      name: os
    - asname: null
      name: time
    - asname: null
      name: threading
    - asname: null
      name: logging
    - module: collections
      names:
      - deque
    - module: threading
      names:
      - Lock
    - module: datetime
      names:
      - datetime
      - timezone
      - timedelta
    - asname: null
      name: json
    - asname: null
      name: math
    - module: functools
      names:
      - wraps
    - asname: null
      name: re
    - asname: null
      name: random
    - asname: null
      name: traceback
    - asname: null
      name: requests
    - asname: null
      name: schedule
    - module: flask
      names:
      - Flask
      - Response
      - jsonify
      - render_template_string
      - request
    - module: flask_cors
      names:
      - CORS
    - module: markupsafe
      names:
      - Markup
    - asname: null
      name: urllib3
    - module: waitress
      names:
      - serve
    numero_de_linhas: 2460
    source_code: "# dashboard_server_pro_enhanced.py\nimport os\nimport time\nimport\
      \ threading\nimport logging\nfrom collections import deque\nfrom threading import\
      \ Lock\nfrom datetime import datetime, timezone, timedelta\nimport json\nimport\
      \ math\nfrom functools import wraps\nimport re\nimport random # For potential\
      \ mock data if API isn't fully featured yet\nimport traceback # For detailed\
      \ error logging\n\nimport requests\nimport schedule\nfrom flask import Flask,\
      \ Response, jsonify, render_template_string, request\nfrom flask_cors import\
      \ CORS\nfrom markupsafe import Markup # For rendering HTML in info tables safely\n\
      \n# --- Configuration ---\nDASHBOARD_PORT = 8333\nAPI_BASE_URL = os.environ.get(\"\
      API_BASE_URL\", \"https://127.0.0.1:8777\").rstrip('/')\nAPI_STATS_URL = f\"\
      {API_BASE_URL}/stats\"\nAPI_LOGIN_URL = f\"{API_BASE_URL}/login\"\nAPI_QUEUES_URL\
      \ = f\"{API_BASE_URL}/queues\"\nAPI_LOGS_LIST_URL = f\"{API_BASE_URL}/logs\"\
      \nAPI_LOG_CONTENT_URL = f\"{API_BASE_URL}/logs\" # Endpoint like /logs/{filename}\n\
      \nAPI_USERNAME = os.environ.get(\"API_USER\", \"admin\")\nAPI_PASSWORD = os.environ.get(\"\
      API_PASS\", \"admin\")\n\nFETCH_STATS_INTERVAL_SECONDS = 5\nFETCH_QUEUES_INTERVAL_SECONDS\
      \ = 15\nFETCH_LOGLIST_INTERVAL_SECONDS = 60\nFETCH_LOGCONTENT_INTERVAL_SECONDS\
      \ = 30 # Default auto-refresh\n\nMAX_CHART_HISTORY = 360 # ~30 mins at 5s interval\
      \ (adjust as needed for performance/memory)\nLOG_CHUNK_SIZE = 250 # Lines per\
      \ log fetch (adjust based on typical line length/performance)\nREQUESTS_TIMEOUT\
      \ = 15 # Slightly longer timeout for potentially slower APIs\nMAX_LOG_LINES_MEMORY\
      \ = 5000 # Limit memory usage for logs deque\n\n# --- Logging ---\nlogging.basicConfig(\n\
      \    level=logging.INFO,\n    format='%(asctime)s - %(threadName)s - %(name)s\
      \ - %(levelname)s - %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\nlogger\
      \ = logging.getLogger('BrokerDashPro')\nlogging.getLogger(\"requests\").setLevel(logging.WARNING)\n\
      logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\nlogging.getLogger(\"\
      schedule\").setLevel(logging.WARNING)\nlogging.getLogger('werkzeug').setLevel(logging.WARNING)\
      \ # Quieter Flask dev server logs\n\n# --- Global State ---\nclass DashboardState:\n\
      \    def __init__(self, max_history, log_chunk_size):\n        self.lock = Lock()\n\
      \        self.latest_stats = {}\n        self.latest_queues = []\n        self.last_api_error\
      \ = None\n        self.last_successful_stats_fetch = None\n        self.last_successful_queues_fetch\
      \ = None\n        self.last_successful_loglist_fetch = None\n        self.last_successful_logcontent_fetch\
      \ = None\n        self.api_access_token = None\n        self.login_needed =\
      \ True\n        self.server_start_time = datetime.now(timezone.utc)\n\n    \
      \    self.is_fetching_stats = False\n        self.is_fetching_queues = False\n\
      \        self.is_fetching_loglist = False\n        self.is_fetching_logcontent\
      \ = False\n\n        # History Deques\n        self.max_history = max_history\n\
      \        self.time_labels = deque(maxlen=max_history)\n        self.request_rate_history\
      \ = deque(maxlen=max_history)\n        self.processed_rate_history = deque(maxlen=max_history)\n\
      \        self.failed_rate_history = deque(maxlen=max_history)\n        self.message_status_history\
      \ = {\n            \"pending\": deque(maxlen=max_history),\n            \"processing\"\
      : deque(maxlen=max_history),\n            \"failed\": deque(maxlen=max_history),\n\
      \            \"processed\": deque(maxlen=max_history)\n        }\n        self.performance_history\
      \ = {\n            \"process_cpu\": deque(maxlen=max_history),\n           \
      \ \"process_memory\": deque(maxlen=max_history),\n            \"system_cpu\"\
      : deque(maxlen=max_history),\n            \"system_memory\": deque(maxlen=max_history)\n\
      \        }\n        self.http_error_rate_history = deque(maxlen=max_history)\
      \ # % 4xx/5xx\n\n        # Rate Calculation State\n        self.previous_total_requests\
      \ = 0\n        self.previous_total_processed = 0\n        self.previous_total_failed\
      \ = 0\n        self.previous_req_by_status = {}\n        self.last_calc_timestamp\
      \ = None\n\n        # Log State\n        self.log_chunk_size = log_chunk_size\n\
      \        self.available_log_files = []\n        self.current_log_filename =\
      \ None\n        self.log_lines = deque(maxlen=MAX_LOG_LINES_MEMORY) # Apply\
      \ memory limit directly\n        self.log_next_fetch_start_line = None # For\
      \ fetching older lines (line number *after* the last fetched older block)\n\
      \        self.log_fetch_error = None\n        self.log_auto_refresh_enabled\
      \ = True\n\n    def _update_rate_history(self, history_deque, current_total,\
      \ previous_total_attr, interval_seconds):\n        current_val = current_total\
      \ if isinstance(current_total, (int, float)) else 0\n        prev_val = getattr(self,\
      \ previous_total_attr, 0)\n        delta = max(0, current_val - prev_val)\n\
      \        rate = delta / interval_seconds if interval_seconds > 0 else 0\n  \
      \      history_deque.append(round(rate, 2)) # Store rate per second\n      \
      \  setattr(self, previous_total_attr, current_val)\n\n    def _update_http_error_rate(self,\
      \ current_req_by_status, interval_seconds):\n        current_total = 0\n   \
      \     current_errors = 0\n        # Ensure counts are integers\n        safe_current_req_by_status\
      \ = {}\n        for status, count in current_req_by_status.items():\n      \
      \      try:\n                code_str = str(status)\n                count_val\
      \ = int(count)\n                safe_current_req_by_status[code_str] = count_val\n\
      \                current_total += count_val\n                if int(code_str)\
      \ >= 400:\n                    current_errors += count_val\n            except\
      \ (ValueError, TypeError):\n                logger.warning(f\"Invalid status/count\
      \ in requests_by_status: {status}={count}\")\n                continue # Skip\
      \ invalid entries\n\n        prev_total = sum(self.previous_req_by_status.values())\n\
      \        prev_errors = sum(count for status, count in self.previous_req_by_status.items()\
      \ if int(status) >= 400)\n\n        delta_total = max(0, current_total - prev_total)\n\
      \        delta_errors = max(0, current_errors - prev_errors)\n\n        # Calculate\
      \ rate as percentage over the interval\n        rate = (delta_errors / delta_total\
      \ * 100) if delta_total > 0 else 0\n        self.http_error_rate_history.append(round(rate,\
      \ 2))\n        self.previous_req_by_status = safe_current_req_by_status # Store\
      \ the cleaned dictionary\n\n    def update_stats_history(self, stats):\n   \
      \     now = datetime.now(timezone.utc)\n        now_label = now.strftime(\"\
      %H:%M:%S\")\n\n        # Calculate actual interval for rate calculation\n  \
      \      interval = 0\n        if self.last_calc_timestamp:\n            interval\
      \ = (now - self.last_calc_timestamp).total_seconds()\n        self.last_calc_timestamp\
      \ = now\n\n        # Only add history if interval is reasonable (avoid spikes\
      \ on startup/gaps)\n        if interval > 0.1:\n            self.time_labels.append(now_label)\n\
      \n            # Calculate rates (requests/sec)\n            self._update_rate_history(self.request_rate_history,\
      \ stats.get(\"requests_total\"), \"previous_total_requests\", interval)\n  \
      \          self._update_rate_history(self.processed_rate_history, stats.get(\"\
      messages_processed\"), \"previous_total_processed\", interval)\n           \
      \ self._update_rate_history(self.failed_rate_history, stats.get(\"messages_failed\"\
      ), \"previous_total_failed\", interval)\n\n            # Message Counts (absolute\
      \ values)\n            for status in [\"pending\", \"processing\", \"failed\"\
      , \"processed\"]:\n                self.message_status_history[status].append(stats.get(f\"\
      messages_{status}\", 0))\n\n            # Performance Metrics (%)\n        \
      \    sys_stats = stats.get(\"system\", {})\n            self.performance_history[\"\
      process_cpu\"].append(round(safe_float(sys_stats.get(\"process_cpu_percent\"\
      )), 2))\n            self.performance_history[\"process_memory\"].append(round(safe_float(sys_stats.get(\"\
      process_memory_mb\")), 2)) # Keep as MB for card, but use % for chart if available\n\
      \            self.performance_history[\"system_cpu\"].append(round(safe_float(sys_stats.get(\"\
      cpu_percent\")), 2))\n            self.performance_history[\"system_memory\"\
      ].append(round(safe_float(sys_stats.get(\"memory_percent\")), 2))\n\n      \
      \      # HTTP Error Rate (%)\n            self._update_http_error_rate(stats.get(\"\
      requests_by_status\", {}), interval)\n\n    def update_error(self, error_message,\
      \ error_type=\"generic\"):\n        with self.lock:\n            timestamp =\
      \ datetime.now(timezone.utc).isoformat()\n            self.last_api_error =\
      \ {\"message\": str(error_message), \"type\": error_type, \"timestamp\": timestamp}\n\
      \            logger.error(f\"API Error ({error_type}): {error_message}\")\n\n\
      \    def clear_error(self, error_type=\"generic\"):\n        with self.lock:\n\
      \            # Clear only if the *current* error matches the type being cleared\n\
      \            if self.last_api_error and self.last_api_error.get(\"type\") ==\
      \ error_type:\n                self.last_api_error = None\n                logger.info(f\"\
      Cleared API error of type: {error_type}\")\n\n    def needs_login(self):\n \
      \       with self.lock: return self.login_needed or not self.api_access_token\n\
      \    def get_token(self):\n        with self.lock: return self.api_access_token\n\
      \    def set_token(self, token):\n        with self.lock:\n            self.api_access_token\
      \ = token\n            self.login_needed = False\n            self.clear_error(\"\
      auth\") # Clear auth errors on successful login/token set\n            logger.info(\"\
      API token set successfully.\")\n    def invalidate_token(self, reason=\"Authentication\
      \ failed\"):\n        with self.lock:\n            self.api_access_token = None\n\
      \            self.login_needed = True\n            self.update_error(reason,\
      \ \"auth\") # Log auth error when invalidating\n            logger.warning(f\"\
      API token invalidated: {reason}\")\n\n    def get_snapshot_for_dashboard(self):\n\
      \        with self.lock:\n            # Create copies to avoid race conditions\
      \ during JSON serialization\n            return {\n                \"latest_stats\"\
      : self.latest_stats.copy(),\n                \"latest_queues\": self.latest_queues[:],\n\
      \                \"history\": {\n                    \"time_labels\": list(self.time_labels),\n\
      \                    \"request_rate_history\": list(self.request_rate_history),\n\
      \                    \"processed_rate_history\": list(self.processed_rate_history),\n\
      \                    \"failed_rate_history\": list(self.failed_rate_history),\n\
      \                    \"message_status\": {k: list(v) for k, v in self.message_status_history.items()},\n\
      \                    \"performance\": {k: list(v) for k, v in self.performance_history.items()},\n\
      \                    \"http_error_rate_history\": list(self.http_error_rate_history)\n\
      \                },\n                \"current_log_filename\": self.current_log_filename,\n\
      \                \"log_fetch_error\": self.log_fetch_error,\n              \
      \  \"last_successful_stats_fetch\": self.last_successful_stats_fetch,\n    \
      \            \"last_successful_queues_fetch\": self.last_successful_queues_fetch,\n\
      \                \"last_api_error\": self.last_api_error.copy() if self.last_api_error\
      \ else None,\n                \"log_auto_refresh_enabled\": self.log_auto_refresh_enabled,\n\
      \                \"available_log_files\": self.available_log_files[:], # Send\
      \ available logs list\n                \"log_next_fetch_start_line\": self.log_next_fetch_start_line,\
      \ # Let frontend know if \"Load Older\" is possible\n                \"server_start_time\"\
      : self.server_start_time.isoformat()\n            }\n\n    def get_log_data_for_request(self):\n\
      \         with self.lock:\n             return {\n                 \"filename\"\
      : self.current_log_filename,\n                 \"lines\": list(self.log_lines),\
      \ # Return current buffer\n                 \"next_fetch_start_line\": self.log_next_fetch_start_line,\n\
      \                 \"log_fetch_error\": self.log_fetch_error,\n             \
      \    \"last_successful_logcontent_fetch\": self.last_successful_logcontent_fetch,\n\
      \                 \"log_auto_refresh_enabled\": self.log_auto_refresh_enabled\n\
      \             }\n\n    def update_log_lines(self, new_lines, is_prepend=False,\
      \ next_start_for_older=None):\n         \"\"\"Updates log lines, handling duplicates\
      \ and max lines.\"\"\"\n         with self.lock:\n            self.log_fetch_error\
      \ = None # Clear error on successful fetch *before* processing\n           \
      \ self.last_successful_logcontent_fetch = datetime.now(timezone.utc).isoformat()\n\
      \            self.log_next_fetch_start_line = next_start_for_older\n\n     \
      \       if not isinstance(new_lines, list):\n                logger.warning(\"\
      update_log_lines received non-list input.\")\n                return\n\n   \
      \         processed_count = 0\n            if is_prepend: # Fetching older logs,\
      \ append to the *end* of deque\n                for line in new_lines: # Assume\
      \ API returns older lines first\n                    # Basic check if line already\
      \ exists (heuristic based on message/timestamp)\n                    # This\
      \ isn't perfect but prevents obvious duplicates from overlapping fetches\n \
      \                   exists = any(l.get('message') == line.get('message') and\
      \ l.get('timestamp') == line.get('timestamp') for l in self.log_lines)\n   \
      \                 if not exists:\n                        self.log_lines.append(line)\n\
      \                        processed_count += 1\n                logger.debug(f\"\
      Appended {processed_count}/{len(new_lines)} older unique log lines.\")\n   \
      \         else: # Fetching latest logs, prepend to the *start* of deque\n  \
      \              # More robust duplicate check for recent lines\n            \
      \    existing_recent_hashes = set(hash(f\"{l.get('timestamp')}_{l.get('message')}\"\
      ) for l in list(self.log_lines)[:LOG_CHUNK_SIZE*2]) # Check recent ~2 chunks\n\
      \                unique_lines_to_add = []\n\n                for line in new_lines:\
      \ # Assume API returns newest lines first (e.g., from tail)\n              \
      \      line_hash = hash(f\"{line.get('timestamp')}_{line.get('message')}\")\n\
      \                    if line_hash not in existing_recent_hashes:\n         \
      \               unique_lines_to_add.append(line)\n                        existing_recent_hashes.add(line_hash)\
      \ # Add new one to check against incoming batch\n\n                for line\
      \ in reversed(unique_lines_to_add): # Add unique lines newest first\n      \
      \                self.log_lines.appendleft(line)\n                      processed_count\
      \ += 1\n                logger.debug(f\"Prepended {processed_count}/{len(new_lines)}\
      \ new unique log lines.\")\n\n            # Max line limit is handled automatically\
      \ by deque's maxlen\n\n    def set_log_auto_refresh(self, enabled: bool):\n\
      \        with self.lock:\n            if self.log_auto_refresh_enabled != enabled:\n\
      \                self.log_auto_refresh_enabled = enabled\n                logger.info(f\"\
      Log auto-refresh set to: {enabled}\")\n\n# Initialize Global State\nstate =\
      \ DashboardState(MAX_CHART_HISTORY, LOG_CHUNK_SIZE)\n\n# --- Utilities ---\n\
      def safe_float(value, default=0.0):\n    \"\"\"Safely convert value to float.\"\
      \"\"\n    try: return float(value) if value is not None else default\n    except\
      \ (ValueError, TypeError): return default\n\ndef format_timedelta_human(seconds):\n\
      \    \"\"\"Converts seconds into a human-readable string like 1d 2h 3m 4s.\"\
      \"\"\n    if seconds is None or not isinstance(seconds, (int, float)) or seconds\
      \ < 0: return \"--\"\n    seconds = int(seconds)\n    if seconds < 1: return\
      \ \"< 1 sec\"\n    days, rem = divmod(seconds, 86400)\n    hours, rem = divmod(rem,\
      \ 3600)\n    minutes, secs = divmod(rem, 60)\n    parts = []\n    if days >\
      \ 0: parts.append(f\"{days}d\")\n    if hours > 0: parts.append(f\"{hours}h\"\
      )\n    if minutes > 0: parts.append(f\"{minutes}m\")\n    if secs > 0 or not\
      \ parts: parts.append(f\"{secs}s\")\n    return \" \".join(parts)\n\ndef bytes_to_human(n_bytes,\
      \ precision=1):\n    \"\"\"Converts bytes to a human-readable string (KB, MB,\
      \ GB...).\"\"\"\n    if n_bytes is None or not isinstance(n_bytes, (int, float))\
      \ or n_bytes < 0: return \"--\"\n    n_bytes = int(n_bytes)\n    if n_bytes\
      \ == 0: return \"0 B\"\n    units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n  \
      \  power = min(int(math.log(n_bytes, 1024)), len(units) - 1) if n_bytes > 0\
      \ else 0\n    value = n_bytes / (1024 ** power)\n    return f\"{value:.{precision}f}\
      \ {units[power]}\"\n\n# --- API Error Handling Decorator ---\ndef handle_api_errors(error_scope=\"\
      generic\"):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args,\
      \ **kwargs):\n            global state\n            token = None # Define token\
      \ outside the conditional block\n\n            # --- Authentication Check ---\n\
      \            if state.needs_login():\n                logger.info(f\"Login required\
      \ for {func.__name__}, attempting login...\")\n                if not login_to_api():\n\
      \                    logger.error(f\"Aborting {func.__name__}: login failed.\"\
      )\n                    # Ensure an error is set if login fails\n           \
      \         if not state.last_api_error or state.last_api_error.get(\"type\")\
      \ != \"auth\":\n                       state.update_error(\"API login failed\
      \ or credentials incorrect.\", \"auth\")\n                    return False #\
      \ Indicate failure\n                # After successful login, get the token\n\
      \                token = state.get_token()\n                if not token:\n\
      \                    # This case should ideally not happen if login_to_api sets\
      \ token correctly\n                    logger.error(f\"Internal dashboard error:\
      \ Token missing after successful login attempt for {func.__name__}.\")\n   \
      \                 state.update_error(\"Internal error: Token lost after login.\"\
      , \"internal\")\n                    return False\n            else:\n     \
      \           token = state.get_token()\n                if not token:\n     \
      \                logger.error(f\"Internal dashboard error: Token is unexpectedly\
      \ None for {func.__name__} despite not needing login.\")\n                 \
      \    state.update_error(\"Internal error: Token unexpectedly missing.\", \"\
      internal\")\n                     state.invalidate_token(\"Token missing unexpectedly\"\
      ) # Force re-login next time\n                     return False\n\n        \
      \    # --- Prepare Request ---\n            headers = {'Authorization': f'Bearer\
      \ {token}', 'Accept': 'application/json'}\n            # Disable SSL verification\
      \ only for local addresses\n            verify_ssl = not (\"127.0.0.1\" in API_BASE_URL\
      \ or \"localhost\" in API_BASE_URL)\n\n            # --- Execute API Call ---\n\
      \            try:\n                # Inject headers and verify_ssl into the\
      \ decorated function's kwargs\n                kwargs['headers'] = headers\n\
      \                kwargs['verify_ssl'] = verify_ssl\n                result =\
      \ func(*args, **kwargs)\n\n                # If the function executed and didn't\
      \ raise an exception that implies success\n                # Clear the specific\
      \ error scope *if* the result indicates success (e.g., returns True or data)\n\
      \                # The called function should return False or raise an exception\
      \ on *logical* failure (e.g., 404 handled internally)\n                if result\
      \ is not False: # Check against explicit False return\n                    \
      \ state.clear_error(error_scope)\n                return result # Pass back\
      \ the result (could be data, True, False)\n\n            # --- Error Handling\
      \ ---\n            except requests.exceptions.Timeout as e:\n              \
      \  state.update_error(f\"API request timed out calling {func.__name__}\", error_scope)\n\
      \                logger.warning(f\"Timeout during {func.__name__}: {e}\")\n\
      \            except requests.exceptions.SSLError as e:\n                state.update_error(f\"\
      API SSL Error in {func.__name__}: {e}. Check certs/URL.\", error_scope)\n  \
      \              logger.error(f\"SSL Error during {func.__name__}: {e}\")\n  \
      \          except requests.exceptions.ConnectionError as e:\n              \
      \  state.update_error(f\"API Connection Error in {func.__name__}: {e}. Cannot\
      \ reach {API_BASE_URL}\", error_scope)\n                logger.error(f\"Connection\
      \ Error during {func.__name__}: {e}\")\n            except requests.exceptions.HTTPError\
      \ as e:\n                status_code = getattr(e.response, 'status_code', 'N/A')\n\
      \                response_text = \"\"\n                try: response_text =\
      \ e.response.text[:200] if e.response is not None else \"N/A\"\n           \
      \     except Exception: pass\n                error_detail = f\"API HTTP Error\
      \ ({status_code}) in {func.__name__}: {e}. Response: {response_text}\"\n\n \
      \               if status_code in [401, 403]:\n                    logger.warning(f\"\
      API auth error ({status_code}) calling {func.__name__}. Invalidating token.\"\
      )\n                    state.invalidate_token(f\"API Auth error ({status_code})\
      \ calling {func.__name__}\")\n                else:\n                    # Log\
      \ other HTTP errors without invalidating token immediately\n               \
      \     state.update_error(error_detail, error_scope)\n                    logger.warning(error_detail)\
      \ # Log as warning, might be transient\n            except requests.exceptions.RequestException\
      \ as e:\n                state.update_error(f\"General API Request Failed in\
      \ {func.__name__}: {e}\", error_scope)\n                logger.error(f\"RequestException\
      \ during {func.__name__}: {e}\")\n            except json.JSONDecodeError as\
      \ e:\n                state.update_error(f\"API response is not valid JSON in\
      \ {func.__name__}. Error: {e}\", error_scope)\n                logger.error(f\"\
      JSONDecodeError during {func.__name__}: {e}\")\n            except Exception\
      \ as e:\n                logger.exception(f\"Unexpected error during API call\
      \ in {func.__name__}\") # Log full traceback\n                state.update_error(f\"\
      Unexpected error in {func.__name__}: {type(e).__name__} - {e}\", \"internal\"\
      )\n\n            return False # Indicate failure if any exception occurred\n\
      \        return wrapper\n    return decorator\n\n\n# --- API Interaction ---\n\
      def login_to_api():\n    \"\"\"Attempts to login and sets the token in the state.\"\
      \"\"\n    global state\n    logger.info(f\"Attempting login to API at {API_LOGIN_URL}...\"\
      )\n    verify_ssl = not (\"127.0.0.1\" in API_BASE_URL or \"localhost\" in API_BASE_URL)\n\
      \    login_success = False\n    try:\n        response = requests.post(\n  \
      \          API_LOGIN_URL,\n            data={'username': API_USERNAME, 'password':\
      \ API_PASSWORD},\n            verify=verify_ssl,\n            timeout=REQUESTS_TIMEOUT\n\
      \        )\n        response.raise_for_status() # Raise HTTPError for bad status\
      \ codes\n        token_data = response.json()\n\n        if \"access_token\"\
      \ in token_data:\n            state.set_token(token_data[\"access_token\"])\
      \ # set_token handles logging and state change\n            login_success =\
      \ True\n        else:\n            logger.error(\"Login response received, but\
      \ 'access_token' field is missing.\")\n            state.update_error(\"Login\
      \ response missing 'access_token'\", \"auth\")\n\n    except requests.exceptions.HTTPError\
      \ as e:\n         status_code = getattr(e.response, 'status_code', 'N/A')\n\
      \         detail = f\"Status Code: {status_code}\"\n         try:\n        \
      \     if e.response is not None: detail += f\" - Response: {e.response.json().get('detail',\
      \ e.response.text[:100])}\"\n         except (json.JSONDecodeError, AttributeError):\n\
      \             try: detail += f\" - Response: {e.response.text[:100]}\"\n   \
      \          except AttributeError: pass # No response object\n         logger.error(f\"\
      API login HTTP error ({detail}): {e}\")\n         state.update_error(f\"API\
      \ login failed ({detail})\", \"auth\")\n    except requests.exceptions.RequestException\
      \ as e:\n        logger.error(f\"API login request failed: {e}\")\n        state.update_error(f\"\
      API login failed: {e}\", \"auth\")\n    except json.JSONDecodeError as e:\n\
      \        logger.error(f\"Failed to decode API login response: {e}\")\n     \
      \   state.update_error(\"Invalid JSON response during login\", \"auth\")\n \
      \   except Exception as e:\n        logger.exception(\"Unexpected error during\
      \ API login\")\n        state.update_error(f\"Unexpected login error: {e}\"\
      , \"internal\")\n\n    # Explicitly invalidate token if login wasn't successful\n\
      \    if not login_success:\n        state.invalidate_token(\"Login attempt failed\"\
      )\n\n    return login_success\n\n@handle_api_errors(error_scope=\"stats\")\n\
      def fetch_stats_data(headers, verify_ssl):\n    \"\"\"Fetches stats data from\
      \ the API.\"\"\"\n    global state\n    # Use a flag to prevent concurrent fetches\
      \ of the same data\n    with state.lock:\n        if state.is_fetching_stats:\n\
      \            logger.debug(\"Stats fetch skipped, already in progress.\")\n \
      \           return True # Not an error, just busy\n        state.is_fetching_stats\
      \ = True\n\n    logger.debug(\"Fetching stats data...\")\n    success = False\n\
      \    try:\n        response = requests.get(API_STATS_URL, headers=headers, verify=verify_ssl,\
      \ timeout=REQUESTS_TIMEOUT)\n        response.raise_for_status() # Check for\
      \ HTTP errors\n        stats = response.json()\n\n        # Basic validation\
      \ of received stats\n        if not isinstance(stats, dict) or not stats:\n\
      \             logger.warning(\"Received empty or invalid stats data structure\
      \ from API.\")\n             state.update_error(\"Received empty/invalid stats\
      \ data\", \"stats\")\n             # Don't update history with bad data\n  \
      \      else:\n            with state.lock:\n                state.latest_stats\
      \ = stats\n                state.last_successful_stats_fetch = datetime.now(timezone.utc).isoformat()\n\
      \                # Update history *after* successful fetch and storing latest_stats\n\
      \                state.update_stats_history(stats)\n            logger.info(f\"\
      Stats data updated successfully at {state.last_successful_stats_fetch}\")\n\
      \            success = True\n\n    # Specific handling within the 'try' is now\
      \ done by the decorator\n    finally:\n        # CRITICAL: Ensure the flag is\
      \ reset regardless of success or failure\n        with state.lock:\n       \
      \     state.is_fetching_stats = False\n\n    return success # Decorator will\
      \ return False if exceptions occurred\n\n@handle_api_errors(error_scope=\"queues\"\
      )\ndef fetch_queues_data(headers, verify_ssl):\n    \"\"\"Fetches queue data\
      \ from the API.\"\"\"\n    global state\n    with state.lock:\n         if state.is_fetching_queues:\n\
      \             logger.debug(\"Queues fetch skipped, already in progress.\")\n\
      \             return True\n         state.is_fetching_queues = True\n\n    logger.debug(\"\
      Fetching queues data...\")\n    success = False\n    try:\n        response\
      \ = requests.get(API_QUEUES_URL, headers=headers, verify=verify_ssl, timeout=REQUESTS_TIMEOUT)\n\
      \        response.raise_for_status()\n        queues = response.json()\n\n \
      \       if not isinstance(queues, list):\n            logger.warning(\"Received\
      \ non-list data structure for queues from API.\")\n            state.update_error(\"\
      Received invalid queues data format\", \"queues\")\n        else:\n        \
      \    with state.lock:\n                # Sort queues alphabetically by name\
      \ for consistent display\n                state.latest_queues = sorted(queues,\
      \ key=lambda q: q.get('name', ''))\n                state.last_successful_queues_fetch\
      \ = datetime.now(timezone.utc).isoformat()\n            logger.info(f\"Queues\
      \ data updated successfully at {state.last_successful_queues_fetch} ({len(queues)}\
      \ queues)\")\n            success = True\n    finally:\n        with state.lock:\n\
      \            state.is_fetching_queues = False\n    return success\n\n@handle_api_errors(error_scope=\"\
      loglist\")\ndef fetch_log_list(headers, verify_ssl):\n    \"\"\"Fetches the\
      \ list of available log files.\"\"\"\n    global state\n    with state.lock:\n\
      \        if state.is_fetching_loglist:\n            logger.debug(\"Log list\
      \ fetch skipped, already in progress.\")\n            return True\n        state.is_fetching_loglist\
      \ = True\n\n    logger.debug(\"Fetching log file list...\")\n    success = False\n\
      \    try:\n        response = requests.get(API_LOGS_LIST_URL, headers=headers,\
      \ verify=verify_ssl, timeout=REQUESTS_TIMEOUT)\n        response.raise_for_status()\n\
      \        log_data = response.json()\n\n        # Expecting a dictionary with\
      \ a 'log_files' key containing a list of strings\n        if not isinstance(log_data,\
      \ dict) or \"log_files\" not in log_data or not isinstance(log_data[\"log_files\"\
      ], list):\n            logger.warning(\"Received invalid log list data structure\
      \ from API.\")\n            state.update_error(\"Invalid log list format from\
      \ API\", \"loglist\")\n        else:\n            files = sorted(log_data[\"\
      log_files\"], reverse=True) # Assume newest first is desirable\n           \
      \ with state.lock:\n                state.available_log_files = files\n    \
      \            state.last_successful_loglist_fetch = datetime.now(timezone.utc).isoformat()\n\
      \                logger.info(f\"Log list updated at {state.last_successful_loglist_fetch}:\
      \ {len(files)} files.\")\n\n                # Check if the currently viewed\
      \ log file still exists\n                current_file = state.current_log_filename\n\
      \                if current_file and current_file not in files:\n          \
      \          logger.warning(f\"Current log file '{current_file}' no longer available\
      \ in list. Clearing view.\")\n                    state.current_log_filename\
      \ = None\n                    state.log_lines.clear()\n                    state.log_next_fetch_start_line\
      \ = None\n                    state.log_fetch_error = \"Log file disappeared\
      \ or was rotated.\" # Inform user\n\n                # If no log file is selected\
      \ and logs are available, select the newest one\n                if not state.current_log_filename\
      \ and files:\n                    newest_log = files[0]\n                  \
      \  logger.info(f\"No log selected, automatically selecting newest: '{newest_log}'\"\
      )\n                    state.current_log_filename = newest_log\n           \
      \         state.log_lines.clear() # Clear old lines\n                    state.log_next_fetch_start_line\
      \ = None # Reset pagination\n                    state.log_fetch_error = None\
      \ # Clear previous errors\n                    # Trigger an initial content\
      \ fetch shortly after selecting the new file\n                    schedule.clear('initial-log-content')\
      \ # Clear previous one-time jobs if any\n                    schedule.every(1).second.do(fetch_log_content_job,\
      \ fetch_older=False).tag('initial-log-content')\n            success = True\n\
      \    finally:\n        with state.lock:\n            state.is_fetching_loglist\
      \ = False\n    return success\n\n@handle_api_errors(error_scope=\"logcontent\"\
      )\ndef fetch_log_content(filename, fetch_older=False, headers=None, verify_ssl=None):\n\
      \    \"\"\"Fetches log content chunks. Handles fetching newer or older lines.\"\
      \"\"\n    global state\n    if not filename:\n        logger.warning(\"Log content\
      \ fetch skipped: no filename specified.\")\n        # Don't set an error here,\
      \ it's expected if no file is selected\n        return False # Indicate skipped\n\
      \n    with state.lock:\n        if state.is_fetching_logcontent:\n         \
      \   logger.debug(f\"Log content fetch for '{filename}' skipped, already fetching.\"\
      )\n            return True # Not an error, just busy\n\n        # --- Determine\
      \ parameters ---\n        params = {'limit': state.log_chunk_size} # Use limit\
      \ for simplicity if API supports it\n        start_line_for_older_request =\
      \ None # Track the start line *requested* for older logs\n\n        if fetch_older:\n\
      \            older_start_num = state.log_next_fetch_start_line\n           \
      \ if older_start_num and older_start_num > 0:\n                params['start']\
      \ = older_start_num\n                params['end'] = older_start_num + state.log_chunk_size\
      \ - 1\n                del params['limit'] # Don't use limit if using start/end\n\
      \                start_line_for_older_request = older_start_num\n          \
      \      logger.debug(f\"Configured to fetch older logs for '{filename}' from\
      \ line {older_start_num}\")\n            else:\n                logger.info(f\"\
      Fetch older logs for '{filename}' skipped: No valid 'next_fetch_start_line'\
      \ ({state.log_next_fetch_start_line}). Assuming beginning reached.\")\n    \
      \            return True # Not an error, just nothing more to fetch older\n\
      \        else: # Fetch latest using tail (or limit if API doesn't support tail)\n\
      \            # Assuming API supports 'tail' or defaults to newest if no start/end\n\
      \            params['tail'] = state.log_chunk_size\n            if 'limit' in\
      \ params: del params['limit'] # Prefer tail if available\n            logger.debug(f\"\
      Configured to fetch latest logs for '{filename}' using tail/limit.\")\n\n  \
      \      # --- Mark as fetching ---\n        state.is_fetching_logcontent = True\n\
      \        state.log_fetch_error = None # Clear previous fetch error before attempting\n\
      \n    logger.info(f\"Fetching log content from API for '{filename}' with params:\
      \ {params}\")\n    success = False\n    try:\n        # Construct URL: Ensure\
      \ filename is URL-encoded\n        # Simple encoding for basic cases, use urllib.parse.quote\
      \ for robustness if needed\n        safe_filename = filename.replace('/', '%2F')\n\
      \        url = f\"{API_LOG_CONTENT_URL}/{safe_filename}\"\n\n        response\
      \ = requests.get(\n            url,\n            headers=headers,\n        \
      \    params=params,\n            verify=verify_ssl,\n            timeout=REQUESTS_TIMEOUT\
      \ + 10 # Slightly longer timeout for log requests\n        )\n        response.raise_for_status()\
      \ # Raises HTTPError for 4xx/5xx\n        log_lines_received = response.json()\
      \ # Assume API returns a list of log line objects/strings\n\n        # --- Validate\
      \ response ---\n        if not isinstance(log_lines_received, list):\n     \
      \       logger.error(f\"Invalid log content response for '{filename}': Expected\
      \ list, got {type(log_lines_received)}.\")\n            state.update_error(f\"\
      Invalid log content format for {filename}\", \"logcontent\")\n            #\
      \ Return False here as the fetch failed logically\n            return False\n\
      \n        logger.debug(f\"Received {len(log_lines_received)} log lines for '{filename}'.\"\
      )\n\n        # --- Process received lines ---\n        with state.lock:\n  \
      \          next_start_line_calc = None\n            if fetch_older and start_line_for_older_request:\n\
      \                 # If we received lines *and* it was an 'older' request:\n\
      \                 # If we received a full chunk, assume more older logs might\
      \ exist\n                 # The *next* older block starts *after* the current\
      \ block\n                 if len(log_lines_received) >= state.log_chunk_size:\n\
      \                     next_start_line_calc = start_line_for_older_request +\
      \ state.log_chunk_size\n                 else:\n                     # Received\
      \ less than a full chunk, assume we hit the beginning\n                    \
      \ next_start_line_calc = None # Signal no more older logs known\n          \
      \  elif not fetch_older:\n                 # When fetching latest via 'tail',\
      \ determine if older logs *might* exist\n                 # This is heuristic.\
      \ If we received a full chunk, enable \"Load Older\".\n                 # The\
      \ *next* request for older should start *after* this initial chunk.\n      \
      \           if len(log_lines_received) >= state.log_chunk_size:\n          \
      \           # Start numbering from 1. If first chunk is 0-249, next older starts\
      \ at 250.\n                     next_start_line_calc = state.log_chunk_size\
      \ + 1\n                 elif state.log_next_fetch_start_line is None and len(self.log_lines)\
      \ < state.log_chunk_size:\n                     # If it's the very first fetch\
      \ (no next_start set yet) and we got less than a chunk,\n                  \
      \   # it's likely there are no older logs either.\n                     next_start_line_calc\
      \ = None\n                 else:\n                     # Otherwise (e.g., refreshing\
      \ latest when older logs already loaded),\n                     # don't change\
      \ the existing next_start_line pointer.\n                      next_start_line_calc\
      \ = state.log_next_fetch_start_line\n\n            # Update the log lines deque\
      \ and the pointer for the *next* older fetch\n            state.update_log_lines(\n\
      \                new_lines=log_lines_received,\n                is_prepend=fetch_older,\
      \ # Prepend=True means append to our deque (older logs)\n                next_start_for_older=next_start_line_calc\n\
      \            )\n        success = True\n\n    except requests.exceptions.HTTPError\
      \ as e:\n        # Handle 404 specifically - file might have rotated JUST before\
      \ fetch\n        if e.response is not None and e.response.status_code == 404:\n\
      \            logger.warning(f\"Log file '{filename}' not found (404). It might\
      \ have been rotated or deleted.\")\n            with state.lock:\n         \
      \       state.log_fetch_error = f\"Log file '{filename}' not found (404).\"\n\
      \                # If it was the *currently viewed* file that disappeared\n\
      \                if state.current_log_filename == filename:\n              \
      \      logger.info(\"Clearing log view because the current file was not found.\"\
      )\n                    state.log_lines.clear()\n                    state.current_log_filename\
      \ = None # No longer valid\n                    state.log_next_fetch_start_line\
      \ = None\n                    # Don't automatically select a new one here, let\
      \ log list fetch handle it\n        else:\n            # Re-raise other HTTP\
      \ errors to be caught by the decorator\n            logger.error(f\"HTTPError\
      \ fetching log content for {filename}: {e}\")\n            raise e # Let decorator\
      \ handle generic HTTP errors\n    # Other exceptions (Timeout, ConnectionError,\
      \ JSONDecodeError, etc.) are handled by the decorator\n\n    finally:\n    \
      \    # CRITICAL: Ensure the flag is always reset\n        with state.lock:\n\
      \            state.is_fetching_logcontent = False\n\n    # Decorator handles\
      \ converting exceptions to False return\n    # We return success explicitly\
      \ if the try block completed without error\n    # We return False if we handled\
      \ a specific logical failure (like 404 for current file)\n    return success\n\
      \n\n# --- Scheduler Jobs ---\ndef fetch_stats_job():\n    logger.debug(\"Executing\
      \ scheduled stats fetch job.\")\n    fetch_stats_data() # Decorator handles\
      \ auth and errors\n\ndef fetch_queues_job():\n    logger.debug(\"Executing scheduled\
      \ queues fetch job.\")\n    fetch_queues_data()\n\ndef fetch_loglist_job():\n\
      \    logger.debug(\"Executing scheduled log list fetch job.\")\n    fetch_log_list()\n\
      \ndef fetch_log_content_job(fetch_older=False):\n    \"\"\"Scheduled job to\
      \ fetch log content (latest or older).\"\"\"\n    global state\n    with state.lock:\n\
      \        filename = state.current_log_filename\n        auto_refresh = state.log_auto_refresh_enabled\n\
      \        is_fetching = state.is_fetching_logcontent\n\n    # Conditions to fetch:\n\
      \    # 1. We have a filename selected.\n    # 2. EITHER it's an auto-refresh\
      \ (fetch_older=False and auto_refresh=True)\n    #    OR it's a forced fetch\
      \ (fetch_older=True, typically user-initiated).\n    # 3. We are not already\
      \ fetching log content.\n    should_fetch = filename and (fetch_older or auto_refresh)\
      \ and not is_fetching\n\n    if should_fetch:\n        logger.debug(f\"Executing\
      \ scheduled log content fetch job for '{filename}', fetch_older={fetch_older}.\"\
      )\n        fetch_log_content(filename, fetch_older=fetch_older)\n    elif not\
      \ filename:\n        logger.debug(\"Skipping log content fetch: No current log\
      \ file selected.\")\n    elif not auto_refresh and not fetch_older:\n      \
      \  logger.debug(\"Skipping log content auto-refresh: Disabled by user.\")\n\
      \    elif is_fetching:\n         logger.debug(f\"Skipping log content fetch\
      \ job for '{filename}': Already fetching.\")\n\n    # Remove one-time 'initial-log-content'\
      \ tag after its first execution attempt\n    # schedule.get_jobs() might include\
      \ jobs that failed, check the tag directly\n    jobs_to_cancel = [j for j in\
      \ schedule.get_jobs() if 'initial-log-content' in j.tags]\n    if jobs_to_cancel:\n\
      \        for job in jobs_to_cancel:\n           schedule.cancel_job(job)\n \
      \          logger.debug(f\"Cancelled one-time job: {job}\")\n    # Return None\
      \ explicitly as schedule doesn't need a return value here\n    return None\n\
      \ndef run_scheduler():\n    \"\"\"Runs the background scheduler thread.\"\"\"\
      \n    logger.info(\"Scheduler thread started.\")\n    logger.info(\"Performing\
      \ initial data fetch...\")\n    # Perform initial fetches sequentially to ensure\
      \ login happens first if needed\n    try:\n        fetch_stats_job()\n     \
      \   fetch_queues_job()\n        fetch_loglist_job()\n        # Initial log content\
      \ fetch is triggered by fetch_log_list if needed\n    except Exception as e:\n\
      \        logger.exception(\"Error during initial data fetch in scheduler startup.\"\
      )\n    logger.info(\"Initial data fetch sequence complete.\")\n\n    # --- Schedule\
      \ recurring jobs ---\n    schedule.every(FETCH_STATS_INTERVAL_SECONDS).seconds.do(fetch_stats_job).tag('stats',\
      \ 'data')\n    schedule.every(FETCH_QUEUES_INTERVAL_SECONDS).seconds.do(fetch_queues_job).tag('queues',\
      \ 'data')\n    schedule.every(FETCH_LOGLIST_INTERVAL_SECONDS).seconds.do(fetch_loglist_job).tag('loglist',\
      \ 'logs')\n    # Auto-refresh log content job - runs conditionally based on\
      \ state inside the job function\n    schedule.every(FETCH_LOGCONTENT_INTERVAL_SECONDS).seconds.do(fetch_log_content_job,\
      \ fetch_older=False).tag('logcontent-auto', 'logs')\n\n    logger.info(f\"Scheduled\
      \ jobs: Stats ({FETCH_STATS_INTERVAL_SECONDS}s), Queues ({FETCH_QUEUES_INTERVAL_SECONDS}s),\
      \ LogList ({FETCH_LOGLIST_INTERVAL_SECONDS}s), LogContent ({FETCH_LOGCONTENT_INTERVAL_SECONDS}s\
      \ auto)\")\n\n    # --- Scheduler Loop ---\n    while True:\n        try:\n\
      \            schedule.run_pending()\n        except Exception as e:\n      \
      \      # Log errors in the scheduler loop itself, but keep running\n       \
      \     logger.error(f\"Error in scheduler run_pending() loop: {e}\", exc_info=True)\n\
      \        time.sleep(0.5) # Check for pending jobs twice per second\n\n\n# ---\
      \ Flask App & Routes ---\napp = Flask(__name__)\napp.logger.handlers = logger.handlers\
      \ # Use the configured logger\napp.logger.setLevel(logger.level)\nCORS(app)\
      \ # Allow Cross-Origin Requests for development/flexible deployment\n\n# ---\
      \ HTML Template (Embedded) ---\n# This will be a very long string. Ensure it's\
      \ correctly formatted.\nHTML_TEMPLATE = \"\"\"\n<!DOCTYPE html>\n<html lang=\"\
      en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"\
      width=device-width, initial-scale=1.0\">\n    <title>BrokerDash Pro - API Dashboard</title>\n\
      \    <script src=\"https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js\"\
      ></script>\n    <script src=\"https://cdn.jsdelivr.net/npm/luxon@3.0.1/build/global/luxon.min.js\"\
      ></script>\n    <link rel=\"icon\" href=\"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22\
      \ viewBox=%220 0 100 100%22><path d=%22M8.3 25L41.7 8.3L75 25L41.7 41.7L8.3\
      \ 25Z%22 stroke=%22%23ff9800%22 stroke-width=%2210%22 fill=%22none%22/><path\
      \ d=%22M8.3 75L41.7 58.3L75 75L41.7 91.7L8.3 75Z%22 stroke=%22%23ff5722%22 stroke-width=%2210%22\
      \ fill=%22none%22/><path d=%22M8.3 50H75%22 stroke=%22%23ffc107%22 stroke-width=%2210%22\
      \ fill=%22none%22/></svg>\">\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\"\
      >\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n\
      \    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\"\
      \ rel=\"stylesheet\">\n\n    {# ***** START RAW BLOCK FOR CSS ***** #}\n   \
      \ {% raw %}\n    <style>\n        /* --- CSS Variables (Theme) --- */\n    \
      \    :root {\n            --font-family-base: 'Inter', -apple-system, BlinkMacSystemFont,\
      \ \"Segoe UI\", Roboto, Helvetica, Arial, sans-serif;\n            --font-family-mono:\
      \ 'Consolas', 'Monaco', 'Courier New', monospace;\n\n            --bg-dark:\
      \ #121417;\n            --bg-medium: #1a1d21;\n            --bg-light: #23272f;\n\
      \            --bg-card: #1f2329; /* Slightly different card background */\n\
      \            --bg-tooltip: rgba(15, 17, 20, 0.95);\n\n            --text-light:\
      \ #e8eaf6; /* Brighter light text */\n            --text-medium: #a0a8b8; /*\
      \ Adjusted medium text */\n            --text-dark: #6a7386; /* Adjusted dark\
      \ text */\n            --text-heading: #ffffff;\n            --text-inverse:\
      \ #121417; /* For light backgrounds if needed */\n\n            --border-color-strong:\
      \ rgba(255, 255, 255, 0.12);\n            --border-color-medium: rgba(255, 255,\
      \ 255, 0.08);\n            --border-color-light: rgba(255, 255, 255, 0.05);\n\
      \n            --accent-orange: #ff9800;\n            --accent-deep-orange: #ff5722;\n\
      \            --accent-yellow: #ffc107;\n            --accent-green: #4caf50;\n\
      \            --accent-red: #f44336;\n            --accent-blue: #2196f3;\n \
      \           --accent-cyan: #00bcd4;\n            --accent-purple: #9c27b0;\n\
      \            --accent-indigo: #5c6bc0; /* Softer indigo */\n            --accent-teal:\
      \ #26a69a; /* Teal */\n\n            --status-success: var(--accent-green);\n\
      \            --status-error: var(--accent-red);\n            --status-warning:\
      \ var(--accent-orange);\n            --status-info: var(--accent-blue);\n  \
      \          --status-processing: var(--accent-indigo);\n            --status-debug:\
      \ var(--accent-cyan);\n            --status-critical: #d32f2f; /* Darker red\
      \ for critical */\n\n            --gradient-red: linear-gradient(135deg, #f44336,\
      \ #d32f2f);\n            --gradient-orange: linear-gradient(135deg, #ffa726,\
      \ #fb8c00);\n            --gradient-yellow: linear-gradient(135deg, #ffeb3b,\
      \ #fbc02d);\n            --gradient-green: linear-gradient(135deg, #66bb6a,\
      \ #388e3c);\n            --gradient-blue: linear-gradient(135deg, #42a5f5, #1976d2);\n\
      \            --gradient-cyan: linear-gradient(135deg, #26c6da, #0097a7);\n \
      \           --gradient-purple: linear-gradient(135deg, #ab47bc, #7b1fa2);\n\
      \            --gradient-indigo: linear-gradient(135deg, #7986cb, #303f9f);\n\
      \            --gradient-grey: linear-gradient(135deg, #78909c, #546e7a);\n \
      \           --gradient-teal: linear-gradient(135deg, #4db6ac, #00897b);\n\n\
      \            --shadow-color: rgba(0, 0, 0, 0.3);\n            --card-shadow:\
      \ 0 3px 8px var(--shadow-color);\n            --card-hover-shadow: 0 6px 16px\
      \ var(--shadow-color);\n            --border-radius-sm: 4px;\n            --border-radius-md:\
      \ 8px;\n            --border-radius-lg: 12px;\n\n            --transition-speed:\
      \ 0.25s;\n            --transition-ease: ease-in-out;\n        }\n\n       \
      \ /* --- Base & Resets --- */\n        *, *::before, *::after { box-sizing:\
      \ border-box; margin: 0; padding: 0; }\n        html { scroll-behavior: smooth;\
      \ }\n        body {\n            font-family: var(--font-family-base);\n   \
      \         background: var(--bg-dark);\n            color: var(--text-medium);\n\
      \            line-height: 1.6;\n            display: flex;\n            flex-direction:\
      \ column;\n            min-height: 100vh;\n            font-size: 14px;\n  \
      \          -webkit-font-smoothing: antialiased;\n            -moz-osx-font-smoothing:\
      \ grayscale;\n        }\n        .container { width: 100%; max-width: 1800px;\
      \ margin: 0 auto; padding: 0 25px; }\n\n        /* --- Animations --- */\n \
      \       @keyframes fadeIn { from { opacity: 0; transform: translateY(8px); }\
      \ to { opacity: 1; transform: translateY(0); } }\n        @keyframes pulse {\
      \ 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }\n        @keyframes highlight-value\
      \ { 0% { transform: scale(1); } 50% { transform: scale(1.08); color: var(--accent-yellow);\
      \ } 100% { transform: scale(1); }}\n        @keyframes blinkCritical { 50% {\
      \ background-color: rgba(244, 67, 54, 0.3); color: #fff; } }\n\n        /* ---\
      \ Header --- */\n        .app-header {\n            background: rgba(26, 29,\
      \ 33, 0.85); /* bg-medium with opacity */\n            backdrop-filter: blur(10px);\n\
      \            padding: 15px 0;\n            border-bottom: 1px solid var(--border-color-medium);\n\
      \            position: sticky; top: 0; z-index: 1000;\n        }\n        .header-content\
      \ { display: flex; align-items: center; justify-content: space-between; gap:\
      \ 15px; }\n        .logo { display: flex; align-items: center; color: var(--accent-orange);\
      \ text-decoration: none; gap: 12px; }\n        .logo svg { width: 30px; height:\
      \ 30px; transition: transform var(--transition-speed) var(--transition-ease);\
      \ }\n        .logo:hover svg { transform: rotate(-10deg); }\n        .logo-text-main\
      \ { font-weight: 700; font-size: 1.5em; color: var(--text-heading); letter-spacing:\
      \ -0.5px; }\n        .status-indicator {\n            font-size: 0.9em; font-weight:\
      \ 500; text-align: right; min-width: 180px;\n            transition: all var(--transition-speed)\
      \ var(--transition-ease);\n            padding: 8px 15px; border-radius: var(--border-radius-md);\n\
      \            white-space: nowrap; overflow: hidden; text-overflow: ellipsis;\n\
      \            max-width: 350px; border: 1px solid transparent;\n            cursor:\
      \ default; /* Indicate it's read-only */\n        }\n        .status-indicator.live\
      \ { color: var(--status-success); background-color: rgba(76, 175, 80, 0.1);\
      \ border-color: rgba(76, 175, 80, 0.4); }\n        .status-indicator.error {\
      \ color: var(--status-error); background-color: rgba(244, 67, 54, 0.1); border-color:\
      \ rgba(244, 67, 54, 0.4); font-weight: 600; }\n        .status-indicator.stale\
      \ { color: var(--status-warning); background-color: rgba(255, 152, 0, 0.1);\
      \ border-color: rgba(255, 152, 0, 0.4); }\n        .status-indicator.fetching\
      \ { color: var(--status-info); background-color: rgba(33, 150, 243, 0.1); border-color:\
      \ rgba(33, 150, 243, 0.4); animation: pulse 1.5s infinite ease-in-out; }\n \
      \       .status-indicator.init { color: var(--text-dark); background-color:\
      \ rgba(106, 115, 134, 0.1); border-color: rgba(106, 115, 134, 0.3); }\n\n  \
      \      /* --- Main Layout --- */\n        .main-layout {\n            display:\
      \ grid;\n            grid-template-columns: repeat(12, 1fr);\n            gap:\
      \ 25px; padding: 35px 0; flex-grow: 1;\n        }\n        .section { display:\
      \ contents; } /* Makes the section act like its children are direct grid items\
      \ */\n        .section-title {\n            font-size: 1.5em; font-weight: 600;\
      \ color: var(--text-heading);\n            margin-bottom: 10px; /* Reduced margin\
      \ */ padding-bottom: 15px;\n            border-bottom: 1px solid var(--border-color-medium);\n\
      \            grid-column: 1 / -1; /* Span full width */\n            margin-top:\
      \ 30px; /* Space between sections */\n        }\n        .section-title:first-of-type\
      \ { margin-top: 0; } /* No top margin for the first title */\n\n        /* ---\
      \ Status Cards --- */\n        .status-card {\n            grid-column: span\
      \ 2; /* Default: 6 cards per row */\n            border-radius: var(--border-radius-lg);\
      \ /* Larger radius */\n            box-shadow: var(--card-shadow);\n       \
      \     overflow: hidden; display: flex; flex-direction: column;\n           \
      \ border: 1px solid var(--border-color-light);\n            animation: fadeIn\
      \ 0.5s ease-out forwards;\n            background: var(--bg-card);\n       \
      \     transition: transform var(--transition-speed) var(--transition-ease),\
      \ box-shadow var(--transition-speed) var(--transition-ease);\n            position:\
      \ relative;\n            color: var(--text-heading); /* White text on gradients\
      \ */\n            aspect-ratio: 5 / 4; /* Slightly wider than square */\n  \
      \          padding: 20px 25px; /* More padding */\n            background-image:\
      \ var(--gradient-grey); /* Default */\n        }\n        .status-card:hover\
      \ { transform: translateY(-5px) scale(1.02); box-shadow: var(--card-hover-shadow);\
      \ }\n        .card-content { z-index: 1; display: flex; flex-direction: column;\
      \ justify-content: space-between; height: 100%;}\n        .card-title { font-size:\
      \ 0.9em; font-weight: 500; color: rgba(255,255,255,0.8); margin-bottom: 10px;\
      \ text-transform: uppercase; letter-spacing: 0.8px; }\n        .card-value {\
      \ font-size: 2.5em; font-weight: 700; line-height: 1.1; color: #fff; display:\
      \ block; margin-top: auto; text-shadow: 0 2px 4px rgba(0,0,0,0.4); transition:\
      \ color 0.3s ease, transform 0.3s ease; }\n        .card-value.small { font-size:\
      \ 1.9em; }\n        .value-changed .card-value { animation: highlight-value\
      \ 0.4s ease-out; }\n        .card-icon { position: absolute; bottom: 15px; right:\
      \ 20px; font-size: 3.5em; opacity: 0.15; user-select: none; line-height: 1;\
      \ color: #fff;}\n\n        /* Card Backgrounds */\n        .card-bg-pending\
      \ { background-image: var(--gradient-orange); }\n        .card-bg-processing\
      \ { background-image: var(--gradient-blue); }\n        .card-bg-failed { background-image:\
      \ var(--gradient-red); }\n        .card-bg-processed { background-image: var(--gradient-green);\
      \ }\n        .card-bg-total-msgs { background-image: var(--gradient-cyan); }\n\
      \        .card-bg-total-queues { background-image: var(--gradient-purple); }\n\
      \        .card-bg-total-reqs { background-image: var(--gradient-indigo); }\n\
      \        .card-bg-uptime { background-image: var(--gradient-grey); }\n     \
      \   .card-bg-cpu { background-image: var(--gradient-indigo); } /* Reuse */\n\
      \        .card-bg-mem { background-image: var(--gradient-teal); }\n        .card-bg-error-rate\
      \ { background-image: var(--gradient-red); } /* Reuse */\n        .card-bg-files-threads\
      \ { background-image: var(--gradient-grey); } /* Reuse */\n\n        /* API\
      \ Error Card */\n        .last-error-card {\n            grid-column: 1 / -1;\
      \ /* Span full width */\n            background: linear-gradient(135deg, rgba(244,\
      \ 67, 54, 0.2), rgba(211, 47, 47, 0.3));\n            border: 1px solid rgba(244,\
      \ 67, 54, 0.4);\n            color: #ffcdd2; /* Light red text */\n        \
      \    backdrop-filter: blur(4px);\n            aspect-ratio: auto; /* Allow height\
      \ to adjust */\n            padding: 20px 30px;\n        }\n        .last-error-card\
      \ .card-title { color: #ff8a80; font-weight: 600;}\n        .last-error-card\
      \ .card-value { font-size: 1em; line-height: 1.5; color: #ffcdd2; font-weight:\
      \ 400; white-space: pre-wrap; word-break: break-word; text-shadow: none; }\n\
      \        .error-timestamp { font-size: 0.8em; color: var(--text-dark); margin-top:\
      \ 10px; display: block; }\n\n        /* --- Chart Cards --- */\n        .chart-card\
      \ {\n            grid-column: span 4; /* Default: 3 charts per row */\n    \
      \        background: var(--bg-card); border-radius: var(--border-radius-lg);\
      \ padding: 25px 30px 30px 30px;\n            box-shadow: var(--card-shadow);\
      \ border: 1px solid var(--border-color-light);\n            animation: fadeIn\
      \ 0.6s ease-out forwards; display: flex; flex-direction: column;\n        }\n\
      \        .chart-title { font-size: 1.05em; font-weight: 500; color: var(--text-light);\
      \ margin-bottom: 25px; text-align: center; }\n        .chart-container { min-height:\
      \ 320px; height: 100%; position: relative; flex-grow: 1; }\n        .chart-container\
      \ canvas { display: block; width: 100%; height: 100%; }\n\n        /* --- Info/Table\
      \ Cards --- */\n        .info-card {\n             grid-column: span 6; /* Default:\
      \ 2 info cards per row */\n             background: var(--bg-card); border-radius:\
      \ var(--border-radius-lg); padding: 30px;\n             box-shadow: var(--card-shadow);\
      \ border: 1px solid var(--border-color-light);\n             animation: fadeIn\
      \ 0.7s ease-out forwards; display: flex; flex-direction: column;\n         \
      \    font-size: 0.95em;\n        }\n        .info-title { font-size: 1.2em;\
      \ font-weight: 600; color: var(--text-heading); margin-bottom: 20px; }\n   \
      \     .info-table { width: 100%; border-collapse: collapse; }\n        .info-table\
      \ th, .info-table td { padding: 12px 8px; text-align: left; border-bottom: 1px\
      \ solid var(--border-color-medium); vertical-align: top; }\n        .info-table\
      \ th { font-weight: 500; color: var(--text-medium); white-space: nowrap; padding-right:\
      \ 25px; width: 35%; }\n        .info-table td { color: var(--text-light); word-break:\
      \ break-word; }\n        .info-table tr:last-child th, .info-table tr:last-child\
      \ td { border-bottom: none; }\n        .info-table code { background-color:\
      \ var(--bg-medium); padding: 3px 7px; border-radius: var(--border-radius-sm);\
      \ font-size: 0.95em; font-family: var(--font-family-mono); color: var(--accent-cyan);}\n\
      \        .no-data { text-align: center; color: var(--text-dark); padding: 20px;\
      \ font-style: italic; }\n\n        /* Disk Usage Bar */\n        .disk-usage-bar-container\
      \ { display: flex; align-items: center; gap: 10px; }\n        .disk-usage-text\
      \ { white-space: nowrap; font-size: 0.95em; color: var(--text-light); }\n  \
      \      .disk-usage-bar { flex-grow: 1; background-color: rgba(0,0,0,0.3); height:\
      \ 12px; border-radius: 6px; overflow: hidden; border: 1px solid var(--border-color-light);}\n\
      \        .disk-usage-fill { height: 100%; background-image: var(--gradient-green);\
      \ transition: width 0.4s ease; border-radius: 5px; }\n        .disk-usage-fill.warn\
      \ { background-image: var(--gradient-orange); }\n        .disk-usage-fill.crit\
      \ { background-image: var(--gradient-red); }\n\n        /* Queues Table Specific\
      \ */\n        .queues-table-wrapper { max-height: 380px; overflow-y: auto; margin:\
      \ -10px; padding: 10px; /* Offset padding */ scrollbar-width: thin; scrollbar-color:\
      \ var(--text-dark) var(--bg-light); }\n        .queues-table-wrapper::-webkit-scrollbar\
      \ { width: 8px; }\n        .queues-table-wrapper::-webkit-scrollbar-track {\
      \ background: var(--bg-light); border-radius: 4px; }\n        .queues-table-wrapper::-webkit-scrollbar-thumb\
      \ { background-color: var(--text-dark); border-radius: 4px; border: 2px solid\
      \ var(--bg-light); }\n        #queue-count { font-weight: 600; color: var(--accent-purple);\
      \ }\n\n        /* --- Log Viewer --- */\n        .log-viewer-card {\n      \
      \      grid-column: 1 / -1; background: var(--bg-card); border-radius: var(--border-radius-lg);\n\
      \            padding: 25px 30px; box-shadow: var(--card-shadow); border: 1px\
      \ solid var(--border-color-light);\n            display: flex; flex-direction:\
      \ column; margin-top: 10px;\n        }\n        .log-header { display: flex;\
      \ justify-content: space-between; align-items: center; margin-bottom: 25px;\
      \ flex-wrap: wrap; gap: 20px;}\n        .log-title-section { display: flex;\
      \ align-items: baseline; gap: 15px; }\n        .log-title { font-size: 1.2em;\
      \ font-weight: 600; color: var(--text-heading); }\n        .log-filename { font-family:\
      \ var(--font-family-mono); font-size: 1em; color: var(--text-light); background-color:\
      \ var(--bg-medium); padding: 5px 12px; border-radius: var(--border-radius-sm);\
      \ border: 1px solid var(--border-color-light); }\n        .log-filename.na {\
      \ color: var(--text-dark); font-style: italic; }\n\n        /* Log Controls\
      \ */\n        .log-controls { display: flex; align-items: center; gap: 15px;\
      \ flex-wrap: wrap; }\n        .log-controls .control-group { display: flex;\
      \ align-items: center; gap: 10px;}\n        .log-controls label { font-size:\
      \ 0.9em; color: var(--text-medium); cursor: pointer; }\n        .log-controls\
      \ input[type=\"checkbox\"] { cursor: pointer; accent-color: var(--accent-orange);\
      \ width: 16px; height: 16px; transform: translateY(2px); }\n        .log-controls\
      \ input[type=\"text\"], .log-controls select {\n            background-color:\
      \ var(--bg-light); border: 1px solid var(--border-color-medium);\n         \
      \   color: var(--text-light); padding: 8px 12px; border-radius: var(--border-radius-sm);\n\
      \            font-size: 0.9em; transition: border-color var(--transition-speed);\n\
      \        }\n        .log-controls input[type=\"text\"]:focus, .log-controls\
      \ select:focus { outline: none; border-color: var(--accent-blue); box-shadow:\
      \ 0 0 0 2px rgba(33, 150, 243, 0.3); }\n        .log-controls input[type=\"\
      text\"] { font-family: var(--font-family-mono); width: 180px; }\n        .log-controls\
      \ select { cursor: pointer; appearance: none; background-image: url(\"data:image/svg+xml,%3Csvg\
      \ xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' fill='%23a0a8b8'%3E%3Cpath\
      \ fill-rule='evenodd' d='M8 11.5a.5.5 0 0 1-.354-.146l-4-4a.5.5 0 0 1 .708-.708L8\
      \ 10.293l3.646-3.647a.5.5 0 0 1 .708.708l-4 4A.5.5 0 0 1 8 11.5z'/%3E%3C/svg%3E\"\
      ); background-repeat: no-repeat; background-position: right 10px center; background-size:\
      \ 16px; padding-right: 30px; }\n        .log-controls button {\n           \
      \ background: var(--bg-light); color: var(--text-medium); border: 1px solid\
      \ var(--border-color-medium);\n            padding: 8px 18px; border-radius:\
      \ var(--border-radius-sm); cursor: pointer; font-size: 0.9em; font-weight: 500;\n\
      \            transition: all var(--transition-speed) var(--transition-ease);\n\
      \        }\n        .log-controls button:hover:not(:disabled) { background-color:\
      \ var(--bg-medium); color: var(--text-light); border-color: var(--text-medium);\
      \ }\n        .log-controls button:active:not(:disabled) { transform: scale(0.97);\
      \ }\n        .log-controls button:disabled { opacity: 0.5; cursor: not-allowed;\
      \ background-color: var(--bg-light); border-color: var(--border-color-light);\
      \ color: var(--text-dark);}\n\n        /* Log Content Area */\n        .log-content-wrapper\
      \ {\n            background-color: #15171a; /* Slightly darker than card */\n\
      \            border: 1px solid var(--border-color-strong); border-radius: var(--border-radius-md);\n\
      \            flex-grow: 1; overflow: auto; max-height: 650px; /* Increased height\
      \ */\n            font-family: var(--font-family-mono); font-size: 0.88em; line-height:\
      \ 1.7;\n            margin-top: 10px; /* Space below controls */\n         \
      \   position: relative; /* For absolute positioning of status */\n         \
      \   scrollbar-width: thin; scrollbar-color: var(--text-dark) var(--bg-light);\n\
      \        }\n        .log-content-wrapper::-webkit-scrollbar { width: 10px; }\n\
      \        .log-content-wrapper::-webkit-scrollbar-track { background: var(--bg-light);\
      \ border-radius: 5px; }\n        .log-content-wrapper::-webkit-scrollbar-thumb\
      \ { background-color: var(--text-dark); border-radius: 5px; border: 2px solid\
      \ var(--bg-light); }\n        .log-line { display: flex; padding: 2px 15px;\
      \ border-bottom: 1px solid var(--border-color-light); white-space: pre-wrap;\
      \ word-break: break-word; transition: background-color 0.15s ease; }\n     \
      \   .log-line:hover { background-color: rgba(255, 255, 255, 0.03); }\n     \
      \   .log-line.hidden { display: none; } /* For filtering */\n        .log-line-timestamp\
      \ { color: var(--text-dark); margin-right: 15px; user-select: none; min-width:\
      \ 75px; padding-top: 1px;}\n        .log-line-level { font-weight: 600; margin-right:\
      \ 12px; min-width: 80px; display: inline-block; text-transform: uppercase; text-align:\
      \ right; }\n        .log-line-level.critical { color: var(--status-critical);\
      \ animation: blinkCritical 1.2s infinite ease-in-out; }\n        .log-line-level.error\
      \ { color: var(--status-error); }\n        .log-line-level.warning { color:\
      \ var(--status-warning); }\n        .log-line-level.info { color: var(--status-info);\
      \ }\n        .log-line-level.debug { color: var(--status-debug); }\n       \
      \ .log-line-message { flex-grow: 1; color: var(--text-light); }\n        .log-highlight\
      \ { background-color: rgba(255, 193, 7, 0.25); border-radius: 2px; box-shadow:\
      \ 0 0 0 1px rgba(255, 193, 7, 0.4); } /* Search highlight */\n        .log-status-overlay\
      \ { /* To show messages like 'Loading...' or 'No logs' */\n            position:\
      \ absolute; top: 0; left: 0; right: 0; bottom: 0;\n            display: flex;\
      \ align-items: center; justify-content: center;\n            background-color:\
      \ rgba(21, 23, 26, 0.8); /* Semi-transparent overlay */\n            color:\
      \ var(--text-medium); font-size: 1.1em; font-style: italic;\n            z-index:\
      \ 10; pointer-events: none; /* Allow clicking through if needed */\n       \
      \     opacity: 0; transition: opacity var(--transition-speed) ease;\n      \
      \  }\n         .log-status-overlay.visible { opacity: 1; pointer-events: auto;\
      \ }\n\n        /* Log Status Text (Below Controls) */\n        .log-status-display\
      \ { font-size: 0.85em; color: var(--text-dark); text-align: right; min-height:\
      \ 1.5em; }\n\n        /* --- Footer --- */\n        .app-footer {\n        \
      \    text-align: center; padding: 35px 0; margin-top: auto;\n            font-size:\
      \ 0.9em; color: var(--text-dark);\n            border-top: 1px solid var(--border-color-medium);\
      \ background: var(--bg-medium);\n        }\n        .footer-status { font-weight:\
      \ 500; display: block; margin-top: 10px; transition: color 0.3s ease;}\n   \
      \     .footer-status .status-icon { margin-right: 5px; }\n        .footer-status.error\
      \ { color: var(--status-error); font-weight: 600; }\n        .footer-status.success\
      \ { color: var(--text-medium); }\n        .footer-status.stale { color: var(--status-warning);\
      \ }\n\n        /* --- Responsive Design --- */\n        @media (max-width: 1600px)\
      \ {\n            .status-card { grid-column: span 3; /* 4 cards row */ aspect-ratio:\
      \ 4 / 3; }\n            .chart-card { grid-column: span 6; /* 2 charts row */\
      \ }\n            .info-card { grid-column: span 6; }\n        }\n        @media\
      \ (max-width: 1200px) {\n            .status-card { grid-column: span 4; /*\
      \ 3 cards row */ }\n            .chart-card { grid-column: span 6; }\n     \
      \       .info-card { grid-column: span 6; }\n             .log-controls { justify-content:\
      \ flex-start; }\n        }\n        @media (max-width: 992px) {\n          \
      \  .container { padding: 0 15px; }\n            .main-layout { gap: 20px; padding:\
      \ 25px 0; }\n            .status-card { grid-column: span 6; /* 2 cards row\
      \ */ aspect-ratio: 16 / 9; }\n            .chart-card { grid-column: span 12;\
      \ /* 1 chart row */ }\n            .info-card { grid-column: span 12; }\n  \
      \          .section-title { font-size: 1.3em; }\n            .log-header { flex-direction:\
      \ column; align-items: stretch; gap: 15px;}\n            .log-title-section\
      \ { justify-content: space-between; }\n            .log-controls { gap: 10px;\
      \ }\n        }\n         @media (max-width: 768px) {\n             body { font-size:\
      \ 13px; }\n             .app-header { padding: 12px 0; }\n             .header-content\
      \ { flex-direction: column; align-items: center; gap: 12px;}\n             .status-indicator\
      \ { max-width: 90%; }\n             .status-card { grid-column: span 6; aspect-ratio:\
      \ auto; min-height: 130px;}\n             .card-value { font-size: 2.1em; }\
      \ .card-value.small { font-size: 1.7em; }\n             .log-controls .control-group\
      \ { width: 100%; justify-content: space-between; }\n             .log-controls\
      \ input[type=\"text\"] { width: calc(100% - 110px); } /* Adjust width */\n \
      \            .log-controls select { width: 100px; }\n             .log-controls\
      \ button { flex-grow: 1; text-align: center; }\n             .log-content-wrapper\
      \ { max-height: 500px; }\n             .info-table th { width: auto; } /* Let\
      \ table layout decide */\n             .info-table th, .info-table td { padding:\
      \ 10px 5px; }\n         }\n        @media (max-width: 576px) {\n           \
      \ .status-card { grid-column: span 12; } /* 1 card row */\n            .card-value\
      \ { font-size: 2.3em; }\n            .chart-container { min-height: 280px; }\n\
      \            .log-controls { flex-direction: column; align-items: stretch; }\n\
      \             .log-controls .control-group { flex-direction: column; align-items:\
      \ stretch; gap: 8px; }\n             .log-controls input[type=\"text\"], .log-controls\
      \ select, .log-controls button { width: 100%; }\n        }\n    </style>\n \
      \   {% endraw %}\n    {# ***** END RAW BLOCK FOR CSS ***** #}\n</head>\n<body>\n\
      \    <header class=\"app-header\">\n        <div class=\"container\">\n    \
      \        <div class=\"header-content\">\n                <a href=\"/\" class=\"\
      logo\" title=\"BrokerDash Pro Home\">\n                     <svg viewBox=\"\
      0 0 100 100\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"\
      M8.3 25L41.7 8.3L75 25L41.7 41.7L8.3 25Z\" stroke=\"currentColor\" stroke-width=\"\
      10\"/><path d=\"M8.3 75L41.7 58.3L75 75L41.7 91.7L8.3 75Z\" stroke=\"var(--accent-deep-orange)\"\
      \ stroke-width=\"10\"/><path d=\"M8.3 50H75\" stroke=\"var(--accent-yellow)\"\
      \ stroke-width=\"10\"/></svg>\n                    <span class=\"logo-text-main\"\
      >BrokerDash Pro</span>\n                </a>\n                <div id=\"status-indicator\"\
      \ class=\"status-indicator init\" title=\"Status of connection to API\">Initializing...</div>\n\
      \            </div>\n        </div>\n    </header>\n\n    <div class=\"container\"\
      >\n        <main class=\"main-layout\">\n            <!-- API Error Display\
      \ -->\n            <div class=\"status-card last-error-card\" id=\"card-last-error\"\
      \ style=\"display: none;\">\n                 <div class=\"card-content\">\n\
      \                     <div class=\"card-title\">\U0001F6A8 API Communication\
      \ Error</div>\n                     <div class=\"card-value small\" id=\"last-error-message\"\
      >--</div>\n                     <div class=\"error-timestamp\" id=\"last-error-timestamp\"\
      ></div>\n                 </div>\n            </div>\n\n             <!-- Broker\
      \ Status Section -->\n             <div class=\"section\">\n               \
      \  <h2 class=\"section-title\">Broker Message Status</h2>\n                \
      \ <div class=\"status-card card-bg-pending\"><div class=\"card-content\"><div\
      \ class=\"card-title\">Pending</div><div class=\"card-value\" id=\"value-pending-msgs\"\
      >--</div></div><div class=\"card-icon\">\U0001F4E5</div></div>\n           \
      \      <div class=\"status-card card-bg-processing\"><div class=\"card-content\"\
      ><div class=\"card-title\">Processing</div><div class=\"card-value\" id=\"value-processing-msgs\"\
      >--</div></div><div class=\"card-icon\">⚙️</div></div>\n                 <div\
      \ class=\"status-card card-bg-failed\"><div class=\"card-content\"><div class=\"\
      card-title\">Failed</div><div class=\"card-value\" id=\"value-failed-msgs\"\
      >--</div></div><div class=\"card-icon\">❌</div></div>\n                 <div\
      \ class=\"status-card card-bg-processed\"><div class=\"card-content\"><div class=\"\
      card-title\">Processed</div><div class=\"card-value\" id=\"value-processed-msgs\"\
      >--</div></div><div class=\"card-icon\">✅</div></div>\n                 <div\
      \ class=\"status-card card-bg-total-msgs\"><div class=\"card-content\"><div\
      \ class=\"card-title\">Total Msgs</div><div class=\"card-value\" id=\"value-total-msgs\"\
      >--</div></div><div class=\"card-icon\">✉️</div></div>\n                 <div\
      \ class=\"status-card card-bg-total-queues\"><div class=\"card-content\"><div\
      \ class=\"card-title\">Active Queues</div><div class=\"card-value\" id=\"value-total-queues\"\
      >--</div></div><div class=\"card-icon\">\U0001F4C1</div></div>\n           \
      \ </div>\n\n            <!-- API & System Performance Section -->\n        \
      \     <div class=\"section\">\n                 <h2 class=\"section-title\"\
      >API Performance & System Health</h2>\n                 <div class=\"status-card\
      \ card-bg-total-reqs\"><div class=\"card-content\"><div class=\"card-title\"\
      >Total Requests</div><div class=\"card-value\" id=\"value-total-requests\">--</div></div><div\
      \ class=\"card-icon\">\U0001F4C8</div></div>\n                 <div class=\"\
      status-card card-bg-error-rate\"><div class=\"card-content\"><div class=\"card-title\"\
      >HTTP Err Rate % (Interval)</div><div class=\"card-value small\" id=\"value-http-error-rate\"\
      >--</div></div><div class=\"card-icon\">\U0001F6A6</div></div>\n           \
      \      <div class=\"status-card card-bg-cpu\"><div class=\"card-content\"><div\
      \ class=\"card-title\">API Process CPU %</div><div class=\"card-value small\"\
      \ id=\"value-process-cpu\">--</div></div><div class=\"card-icon\">⚙️</div></div>\n\
      \                 <div class=\"status-card card-bg-mem\"><div class=\"card-content\"\
      ><div class=\"card-title\">API Process Mem</div><div class=\"card-value small\"\
      \ id=\"value-process-mem\">--</div></div><div class=\"card-icon\">\U0001F9E0\
      </div></div>\n                 <div class=\"status-card card-bg-cpu\"><div class=\"\
      card-content\"><div class=\"card-title\">System CPU %</div><div class=\"card-value\
      \ small\" id=\"value-system-cpu\">--</div></div><div class=\"card-icon\">\U0001F4BB\
      </div></div>\n                 <div class=\"status-card card-bg-mem\"><div class=\"\
      card-content\"><div class=\"card-title\">System Mem %</div><div class=\"card-value\
      \ small\" id=\"value-system-mem\">--</div></div><div class=\"card-icon\">\U0001F4BE\
      </div></div>\n                 <div class=\"status-card card-bg-uptime\"><div\
      \ class=\"card-content\"><div class=\"card-title\">API Uptime</div><div class=\"\
      card-value small\" id=\"value-uptime\">--</div></div><div class=\"card-icon\"\
      >⏳</div></div>\n                 <div class=\"status-card card-bg-files-threads\"\
      ><div class=\"card-content\"><div class=\"card-title\">Open Files / Threads</div><div\
      \ class=\"card-value small\" id=\"value-files-threads\">-- / --</div></div><div\
      \ class=\"card-icon\">\U0001F4C4</div></div>\n            </div>\n\n       \
      \     <!-- Historical Trends Section -->\n            <div class=\"section\"\
      >\n                 <h2 class=\"section-title\">Historical Trends</h2>\n   \
      \              <div class=\"chart-card\">\n                     <div class=\"\
      chart-title\">Message Throughput & Failures (Events/sec)</div>\n           \
      \          <div class=\"chart-container\"><canvas id=\"ratesChart\"></canvas></div>\n\
      \                 </div>\n                 <div class=\"chart-card\">\n    \
      \                 <div class=\"chart-title\">Message Status Queue Size</div>\n\
      \                     <div class=\"chart-container\"><canvas id=\"messageStatusChart\"\
      ></canvas></div>\n                 </div>\n                 <div class=\"chart-card\"\
      >\n                     <div class=\"chart-title\">Resource Utilization (%)</div>\n\
      \                     <div class=\"chart-container\"><canvas id=\"performanceChart\"\
      ></canvas></div>\n                 </div>\n            </div>\n\n          \
      \  <!-- Request Analysis Section -->\n            <div class=\"section\">\n\
      \                 <h2 class=\"section-title\">Request Analysis</h2>\n      \
      \           <div class=\"chart-card\">\n                     <div class=\"chart-title\"\
      >HTTP Status Code Distribution (Total)</div>\n                     <div class=\"\
      chart-container\"><canvas id=\"requestsByStatusChart\"></canvas></div>\n   \
      \              </div>\n                 <div class=\"chart-card\">\n       \
      \              <div class=\"chart-title\">Top 15 API Routes by Request Count\
      \ (Total)</div>\n                     <div class=\"chart-container\"><canvas\
      \ id=\"requestsByRouteChart\"></canvas></div>\n                 </div>\n   \
      \               <div class=\"chart-card\">\n                     <div class=\"\
      chart-title\">HTTP Error Rate (% over time)</div>\n                     <div\
      \ class=\"chart-container\"><canvas id=\"httpErrorRateChart\"></canvas></div>\n\
      \                 </div>\n            </div>\n\n            <!-- System & Config\
      \ Details Section -->\n             <div class=\"section\">\n              \
      \   <h2 class=\"section-title\">System & Configuration Details</h2>\n      \
      \           <div class=\"info-card\" id=\"system-info-card\">\n            \
      \         <div class=\"info-title\">\U0001F4BB System Information</div>\n  \
      \                   <table class=\"info-table\" id=\"system-info-table\"><tbody><tr><td\
      \ colspan=\"2\" class=\"no-data\">Loading...</td></tr></tbody></table>\n   \
      \              </div>\n                 <div class=\"info-card\" id=\"broker-info-card\"\
      >\n                     <div class=\"info-title\">\U0001F6E0️ Broker Configuration</div>\n\
      \                     <table class=\"info-table\" id=\"broker-info-table\"><tbody><tr><td\
      \ colspan=\"2\" class=\"no-data\">Loading...</td></tr></tbody></table>\n   \
      \              </div>\n                 <div class=\"info-card\" id=\"queues-info-card\"\
      >\n                     <div class=\"info-title\">\U0001F4C1 Queue Details (<span\
      \ id=\"queue-count\">0</span>)</div>\n                     <div class=\"queues-table-wrapper\"\
      >\n                        <table class=\"info-table\" id=\"queues-info-table\"\
      >\n                           <thead><tr><th>Name</th><th>Total Msgs</th><th>Created</th></tr></thead>\n\
      \                           <tbody><tr><td colspan=\"3\" class=\"no-data\">Loading...</td></tr></tbody>\n\
      \                        </table>\n                     </div>\n           \
      \      </div>\n                 <div class=\"info-card\" id=\"disk-info-card\"\
      >\n                      <div class=\"info-title\">\U0001F4BE Disk Usage</div>\n\
      \                      <table class=\"info-table\" id=\"disk-info-table\">\n\
      \                          <thead><tr><th>Mountpoint</th><th>Usage</th><th>Free\
      \ Space</th></tr></thead>\n                          <tbody><tr><td colspan=\"\
      3\" class=\"no-data\">Loading...</td></tr></tbody>\n                      </table>\n\
      \                 </div>\n            </div>\n\n            <!-- Log Viewer\
      \ Section -->\n             <div class=\"section\">\n                 <h2 class=\"\
      section-title\">Log Viewer</h2>\n                 <div class=\"log-viewer-card\"\
      >\n                      <div class=\"log-header\">\n                      \
      \   <div class=\"log-title-section\">\n                             <span class=\"\
      log-title\">Current File:</span>\n                             <span class=\"\
      log-filename na\" id=\"log-filename-display\">N/A</span>\n                 \
      \        </div>\n                         <div class=\"log-controls\">\n   \
      \                         <div class=\"control-group\">\n                  \
      \             <input type=\"text\" id=\"log-search-input\" placeholder=\"Search\
      \ logs...\" aria-label=\"Search logs\">\n                               <label\
      \ for=\"log-filter-level\">Level:</label>\n                               <select\
      \ id=\"log-filter-level\" aria-label=\"Filter logs by level\">\n           \
      \                        <option value=\"\">All</option>\n                 \
      \                  <option value=\"critical\">Critical</option>\n          \
      \                         <option value=\"error\">Error</option>\n         \
      \                          <option value=\"warning\">Warning</option>\n    \
      \                               <option value=\"info\">Info</option>\n     \
      \                              <option value=\"debug\">Debug</option>\n    \
      \                           </select>\n                           </div>\n \
      \                           <div class=\"control-group\">\n                \
      \                <label for=\"log-auto-refresh-toggle\" title=\"Toggle automatic\
      \ log refreshing every {{ FETCH_LOGCONTENT_INTERVAL_SECONDS }} seconds\">Auto-Refresh:</label>\n\
      \                                <input type=\"checkbox\" id=\"log-auto-refresh-toggle\"\
      \ checked>\n                           </div>\n                           <div\
      \ class=\"control-group\">\n                                <button id=\"load-older-logs-btn\"\
      \ title=\"Load older log entries\" disabled>Load Older</button>\n          \
      \                      <button id=\"refresh-logs-btn\" title=\"Fetch latest\
      \ log entries now\">Refresh Now</button>\n                           </div>\n\
      \                         </div>\n                     </div>\n            \
      \         <div class=\"log-status-display\" id=\"log-status-text\"></div>\n\
      \                      <div class=\"log-content-wrapper\" id=\"log-content-area\"\
      >\n                          <div class=\"log-line no-data\" id=\"log-initial-message\"\
      >(Initializing log viewer...)</div>\n                          <div class=\"\
      log-status-overlay\" id=\"log-status-overlay\"></div>\n                    \
      \ </div>\n                 </div>\n            </div>\n\n        </main>\n \
      \   </div>\n\n    <footer class=\"app-footer\">\n        BrokerDash Pro - Real-time\
      \ API Metrics Dashboard\n        <div class=\"footer-status success\" id=\"\
      footer-backend-status\"><span class=\"status-icon\"></span>Initializing connection...</div>\n\
      \    </footer>\n\n    {# ***** START RAW BLOCK FOR JS ***** #}\n    {% raw %}\n\
      \    <script>\n        // --- Injected Config ---\n        const CONFIG = {\n\
      \            API_DASHBOARD_DATA_URL: '/api/dashboard_data',\n            API_LOG_DATA_URL:\
      \ '/api/log_data',\n            API_FETCH_OLDER_LOGS_URL: '/api/fetch_older_logs',\n\
      \            API_TOGGLE_LOG_REFRESH_URL: '/api/toggle_log_refresh',\n      \
      \      POLLING_INTERVAL_MS: {{ FETCH_STATS_INTERVAL_SECONDS * 1000 }},\n   \
      \         LOG_REFRESH_INTERVAL_MS: {{ FETCH_LOGCONTENT_INTERVAL_SECONDS * 1000\
      \ }},\n            MAX_CHART_HISTORY: {{ MAX_CHART_HISTORY }},\n           \
      \ LOG_CHUNK_SIZE: {{ LOG_CHUNK_SIZE }},\n            FETCH_STATS_INTERVAL_SECONDS:\
      \ {{ FETCH_STATS_INTERVAL_SECONDS }} // For chart label\n        };\n\n    \
      \    // --- Global JS State ---\n        const DateTime = luxon.DateTime;\n\
      \        let chartInstances = {};\n        let fetchDataIntervalId = null;\n\
      \        let fetchLogIntervalId = null;\n        let lastKnownApiError = null;\n\
      \        let lastSuccessfulDataFetch = null;\n        let logAutoRefreshEnabled\
      \ = true; // Default, synced with backend\n        let currentLogFilename =\
      \ null; // Keep track locally\n        let canLoadOlderLogs = false;\n     \
      \   let isFetchingLogs = false; // Prevent concurrent log fetches\n        let\
      \ logSearchTerm = '';\n        let logFilterLevel = '';\n        let logSearchDebounceTimeout\
      \ = null;\n        let initialLoadComplete = false;\n\n        // --- DOM Element\
      \ Cache ---\n        let dom = {}; // Initialized in cacheDOMElements\n\n  \
      \      // --- Initialization ---\n        document.addEventListener('DOMContentLoaded',\
      \ () => {\n            console.info(\"BrokerDash Pro: DOM Loaded. Initializing...\"\
      );\n            cacheDOMElements();\n            initializeCharts();\n     \
      \       setupEventListeners();\n            clearUI(); // Set initial state\n\
      \            updateStatusIndicator('init', 'Initializing...'); // Initial status\n\
      \n            // Start fetching data\n            fetchDashboardData(); // Initial\
      \ high-level data fetch\n            // Log data fetch is triggered by fetchDashboardData\
      \ based on state\n\n            // Setup polling intervals\n            if (fetchDataIntervalId)\
      \ clearInterval(fetchDataIntervalId);\n            fetchDataIntervalId = setInterval(fetchDashboardData,\
      \ CONFIG.POLLING_INTERVAL_MS);\n            startLogAutoRefreshTimer(); // Start\
      \ conditional log auto-refresh timer\n\n            console.info(`Polling dashboard\
      \ data every ${CONFIG.POLLING_INTERVAL_MS / 1000}s.`);\n            console.info(`Log\
      \ auto-refresh interval: ${CONFIG.LOG_REFRESH_INTERVAL_MS / 1000}s (will enable/disable\
      \ based on state).`);\n        });\n\n        function cacheDOMElements() {\n\
      \            dom = {\n                statusIndicator: document.getElementById('status-indicator'),\n\
      \                footerStatus: document.getElementById('footer-backend-status'),\n\
      \                lastErrorCard: document.getElementById('card-last-error'),\n\
      \                lastErrorMessage: document.getElementById('last-error-message'),\n\
      \                lastErrorTimestamp: document.getElementById('last-error-timestamp'),\n\
      \                // Cards\n                pendingMsgs: document.getElementById('value-pending-msgs'),\n\
      \                processingMsgs: document.getElementById('value-processing-msgs'),\n\
      \                failedMsgs: document.getElementById('value-failed-msgs'),\n\
      \                processedMsgs: document.getElementById('value-processed-msgs'),\n\
      \                totalMsgs: document.getElementById('value-total-msgs'),\n \
      \               totalQueues: document.getElementById('value-total-queues'),\n\
      \                totalRequests: document.getElementById('value-total-requests'),\n\
      \                httpErrorRate: document.getElementById('value-http-error-rate'),\n\
      \                uptime: document.getElementById('value-uptime'),\n        \
      \        processCpu: document.getElementById('value-process-cpu'),\n       \
      \         processMem: document.getElementById('value-process-mem'),\n      \
      \          systemCpu: document.getElementById('value-system-cpu'),\n       \
      \         systemMem: document.getElementById('value-system-mem'),\n        \
      \        filesThreads: document.getElementById('value-files-threads'),\n   \
      \             // Tables & Info\n                systemInfoTableBody: document.querySelector('#system-info-table\
      \ tbody'),\n                brokerInfoTableBody: document.querySelector('#broker-info-table\
      \ tbody'),\n                queuesInfoTableBody: document.querySelector('#queues-info-table\
      \ tbody'),\n                diskInfoTableBody: document.querySelector('#disk-info-table\
      \ tbody'),\n                queueCountSpan: document.getElementById('queue-count'),\n\
      \                // Charts (Canvas elements)\n                ratesChartCanvas:\
      \ document.getElementById('ratesChart'),\n                messageStatusChartCanvas:\
      \ document.getElementById('messageStatusChart'),\n                performanceChartCanvas:\
      \ document.getElementById('performanceChart'),\n                requestsByRouteChartCanvas:\
      \ document.getElementById('requestsByRouteChart'),\n                requestsByStatusChartCanvas:\
      \ document.getElementById('requestsByStatusChart'),\n                httpErrorRateChartCanvas:\
      \ document.getElementById('httpErrorRateChart'),\n                // Log Viewer\n\
      \                logFilenameDisplay: document.getElementById('log-filename-display'),\n\
      \                logContentArea: document.getElementById('log-content-area'),\n\
      \                logStatusText: document.getElementById('log-status-text'),\n\
      \                logStatusOverlay: document.getElementById('log-status-overlay'),\n\
      \                logInitialMessage: document.getElementById('log-initial-message'),\n\
      \                loadOlderLogsBtn: document.getElementById('load-older-logs-btn'),\n\
      \                refreshLogsBtn: document.getElementById('refresh-logs-btn'),\n\
      \                logAutoRefreshToggle: document.getElementById('log-auto-refresh-toggle'),\n\
      \                logSearchInput: document.getElementById('log-search-input'),\n\
      \                logFilterLevel: document.getElementById('log-filter-level'),\n\
      \            };\n            // Get contexts for charts\n             dom.ratesChartCtx\
      \ = dom.ratesChartCanvas?.getContext('2d');\n             dom.messageStatusChartCtx\
      \ = dom.messageStatusChartCanvas?.getContext('2d');\n             dom.performanceChartCtx\
      \ = dom.performanceChartCanvas?.getContext('2d');\n             dom.requestsByRouteChartCtx\
      \ = dom.requestsByRouteChartCanvas?.getContext('2d');\n             dom.requestsByStatusChartCtx\
      \ = dom.requestsByStatusChartCanvas?.getContext('2d');\n             dom.httpErrorRateChartCtx\
      \ = dom.httpErrorRateChartCanvas?.getContext('2d');\n             console.debug(\"\
      DOM elements cached.\");\n        }\n\n        function startLogAutoRefreshTimer()\
      \ {\n             if (fetchLogIntervalId) clearInterval(fetchLogIntervalId);\
      \ // Clear existing timer\n             if (logAutoRefreshEnabled && currentLogFilename)\
      \ { // Only run if enabled AND a file is selected\n                 fetchLogIntervalId\
      \ = setInterval(() => fetchLogData(false), CONFIG.LOG_REFRESH_INTERVAL_MS);\n\
      \                 console.info(\"Log auto-refresh timer started.\");\n     \
      \        } else {\n                 console.info(`Log auto-refresh timer ${currentLogFilename\
      \ ? 'disabled' : 'inactive (no log file selected)'}.`);\n             }\n  \
      \      }\n\n        // --- Formatters & Helpers ---\n        function safeGet(obj,\
      \ path, defaultValue = null) { if (!obj || typeof path !== 'string') return\
      \ defaultValue; try { return path.split('.').reduce((acc, key) => (acc && acc[key]\
      \ !== undefined && acc[key] !== null) ? acc[key] : defaultValue, obj); } catch\
      \ (e) { return defaultValue; } }\n        function formatNumber(num) { const\
      \ n = parseFloat(num); return (n === null || n === undefined || isNaN(n)) ?\
      \ '--' : n.toLocaleString(undefined, { maximumFractionDigits: 0 }); }\n    \
      \    function formatDecimal(num, digits = 1) { const n = parseFloat(num); return\
      \ (n === null || n === undefined || isNaN(n)) ? '--' : n.toLocaleString(undefined,\
      \ { minimumFractionDigits: digits, maximumFractionDigits: digits }); }\n   \
      \     function formatPercentage(num) { const n = parseFloat(num); return (n\
      \ === null || n === undefined || isNaN(n)) ? '--' : formatDecimal(n, 1) + '%';\
      \ }\n        function formatMemory(num, unit = 'MB') { return (num === null\
      \ || num === undefined || isNaN(parseFloat(num))) ? '--' : `${formatDecimal(num,\
      \ 1)} ${unit}`; }\n        function formatBytes(num) { const n = parseInt(num,\
      \ 10); if (n === null || n === undefined || isNaN(n)) return '--'; const sizes\
      \ = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']; if (n === 0) return '0 B'; const i\
      \ = parseInt(Math.floor(Math.log(n) / Math.log(1024)), 10); if (i < 0 || i >=\
      \ sizes.length) return `${n} B`; /* Handle very small or large */ if (i ===\
      \ 0) return `${n} ${sizes[i]}`; return `${formatDecimal(n / (1024 ** i), 1)}\
      \ ${sizes[i]}`; }\n        function formatDateTime(isoString, format = DateTime.DATETIME_SHORT_WITH_SECONDS)\
      \ { if (!isoString) return '--'; try { const dt = DateTime.fromISO(isoString);\
      \ return dt.isValid ? dt.toLocaleString(format) : isoString; } catch (e) { return\
      \ isoString; } }\n        function formatRelativeTime(isoString) { if (!isoString)\
      \ return '--'; try { const dt = DateTime.fromISO(isoString); return dt.isValid\
      \ ? dt.toRelative() : 'invalid date'; } catch (e) { return 'invalid date'; }\
      \ }\n        function formatUptime(uptimeStr) { return uptimeStr || '--'; }\
      \ // Assuming backend sends pre-formatted string\n        function formatLoadAvg(loadTuple)\
      \ { if (!Array.isArray(loadTuple) || loadTuple.length < 3) return '--'; return\
      \ loadTuple.map(n => (n === null || n === undefined || isNaN(parseFloat(n)))\
      \ ? '?' : parseFloat(n).toFixed(2)).join(', '); }\n        function formatFilesThreads(files,\
      \ threads) { const f = formatNumber(files); const t = formatNumber(threads);\
      \ return `${f} / ${t}`; }\n        function generateColors(count) { const base\
      \ = ['#64b5f6','#81c784','#ffb74d','#e57373','#ba68c8','#4dd0e1','#fff176','#7986cb','#a1887f','#90a4ae','#ff8a65','#4db6ac','#9575cd','#f06292','#69f0ae'];\
      \ return Array.from({ length: count }, (_, i) => base[i % base.length]); }\n\
      \        function getHttpStatusColor(code) { code = parseInt(code); if (code\
      \ >= 500) return 'var(--status-error)'; if (code >= 400) return 'var(--status-warning)';\
      \ if (code >= 300) return 'var(--status-info)'; if (code >= 200) return 'var(--status-success)';\
      \ return 'var(--text-dark)'; }\n        function escapeHtml(unsafe) { return\
      \ unsafe.replace(/&/g, \"&amp;\").replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\"\
      ).replace(/\"/g, \"&quot;\").replace(/'/g, \"&#039;\"); }\n\n        // ---\
      \ UI Update Functions ---\n        function updateCardValue(element, newValue,\
      \ formatter = formatNumber) {\n            if (!element) return;\n         \
      \   try {\n                const formattedValue = formatter(newValue);\n   \
      \             if (element.textContent !== formattedValue) {\n              \
      \      element.textContent = formattedValue;\n                    const card\
      \ = element.closest('.status-card');\n                    if (card && card.classList.contains('value-changed'))\
      \ {\n                       // If animation is already running, reset it quickly\
      \ to restart\n                       card.classList.remove('value-changed');\n\
      \                       void card.offsetWidth; // Trigger reflow\n         \
      \           }\n                    if (card) card.classList.add('value-changed');\n\
      \                    setTimeout(() => card?.classList.remove('value-changed'),\
      \ 450);\n                }\n            } catch (e) {\n                console.error(`Error\
      \ formatting/updating card value: ${e}`, element, newValue);\n             \
      \   element.textContent = 'ERR';\n            }\n        }\n\n        function\
      \ updateChartData(chartInstance, newLabels = [], newDatasetsData = []) {\n \
      \            if (!chartInstance?.config?._config) { console.warn(\"Attempted\
      \ to update non-existent chart\"); return; }\n             chartInstance.data.labels\
      \ = newLabels;\n             chartInstance.data.datasets.forEach((dataset, index)\
      \ => {\n                 const dataForDataset = (Array.isArray(newDatasetsData)\
      \ && index < newDatasetsData.length && Array.isArray(newDatasetsData[index]))\
      \ ? newDatasetsData[index] : [];\n                 dataset.data = dataForDataset;\n\
      \n                 // Dynamically update colors for categorical charts if needed\n\
      \                  if ((chartInstance.config.type === 'doughnut' || chartInstance.config.type\
      \ === 'pie' || chartInstance.config.type === 'bar') && dataset.backgroundColor)\
      \ {\n                     if (chartInstance.canvas.id === 'requestsByStatusChart')\
      \ {\n                         dataset.backgroundColor = newLabels.map(label\
      \ => getHttpStatusColor(label));\n                         dataset.hoverBackgroundColor\
      \ = dataset.backgroundColor; // Keep hover same\n                     } else\
      \ if (chartInstance.canvas.id === 'requestsByRouteChart') {\n              \
      \           // Consistent color for route bars\n                          dataset.backgroundColor\
      \ = 'var(--accent-indigo)';\n                          dataset.hoverBackgroundColor\
      \ = 'var(--accent-blue)';\n                     } else {\n                 \
      \        dataset.backgroundColor = generateColors(dataForDataset.length);\n\
      \                         dataset.hoverBackgroundColor = dataset.backgroundColor;\n\
      \                     }\n                 }\n             });\n            \
      \ chartInstance.update('none'); // 'none' for no animation on update\n     \
      \   }\n\n        function clearUI() {\n             console.log(\"Clearing UI\
      \ to initial state.\");\n             Object.values(dom).forEach(el => {\n \
      \               if (!el) return;\n                if (el.classList?.contains('card-value'))\
      \ el.textContent = '--';\n                if (el.tagName === 'TBODY') el.innerHTML\
      \ = `<tr><td colspan=\"${el.closest('table')?.querySelector('thead tr')?.children.length\
      \ || 2}\" class=\"no-data\">(Waiting for data...)</td></tr>`;\n            \
      \    if (el.id === 'queue-count') el.textContent = '0';\n             });\n\
      \             if (dom.logFilenameDisplay) { dom.logFilenameDisplay.textContent\
      \ = 'N/A'; dom.logFilenameDisplay.classList.add('na'); }\n             if (dom.logContentArea\
      \ && dom.logInitialMessage) { dom.logContentArea.innerHTML = ''; dom.logContentArea.appendChild(dom.logInitialMessage);\
      \ dom.logInitialMessage.textContent = \"(Waiting for data...)\"; dom.logInitialMessage.style.display\
      \ = 'block'; }\n             if (dom.logStatusText) dom.logStatusText.textContent\
      \ = '';\n             if (dom.logStatusOverlay) { dom.logStatusOverlay.textContent\
      \ = ''; dom.logStatusOverlay.classList.remove('visible'); }\n             if\
      \ (dom.loadOlderLogsBtn) dom.loadOlderLogsBtn.disabled = true;\n           \
      \  if (dom.refreshLogsBtn) dom.refreshLogsBtn.disabled = true; // Disable initially\n\
      \             if (dom.lastErrorCard) dom.lastErrorCard.style.display = 'none';\n\
      \             Object.values(chartInstances).forEach(chart => { if(chart) updateChartData(chart);\
      \ });\n             lastKnownApiError = null; // Reset error state\n       \
      \      lastSuccessfulDataFetch = null; // Reset fetch time\n             currentLogFilename\
      \ = null;\n             canLoadOlderLogs = false;\n        }\n\n        function\
      \ setLogOverlay(message, isVisible) {\n            if (!dom.logStatusOverlay)\
      \ return;\n            dom.logStatusOverlay.textContent = message;\n       \
      \     if (isVisible) {\n                dom.logStatusOverlay.classList.add('visible');\n\
      \            } else {\n                dom.logStatusOverlay.classList.remove('visible');\n\
      \            }\n        }\n\n        // --- Chart Initialization ---\n     \
      \   function initializeCharts() {\n             console.log(\"Initializing charts...\"\
      );\n             if (!dom.ratesChartCtx || !dom.messageStatusChartCtx || !dom.performanceChartCtx\
      \ || !dom.requestsByRouteChartCtx || !dom.requestsByStatusChartCtx || !dom.httpErrorRateChartCtx)\
      \ { console.error(\"One or more chart canvas elements not found.\"); return;\
      \ }\n\n             Chart.defaults.color = 'var(--text-medium)';\n         \
      \    Chart.defaults.borderColor = 'var(--border-color-medium)';\n          \
      \   Chart.defaults.font.family = \"var(--font-family-base)\";\n            \
      \ Chart.defaults.font.size = 11; // Smaller default font\n\n             const\
      \ commonTooltipOptions = {\n                 backgroundColor: 'var(--bg-tooltip)',\n\
      \                 titleFont: { weight: '600', size: 13 },\n                \
      \ bodyFont: { size: 11 },\n                 padding: 12, boxPadding: 6, cornerRadius:\
      \ var(--border-radius-sm),\n                 borderColor: 'var(--border-color-strong)',\
      \ borderWidth: 1,\n                 displayColors: true, usePointStyle: true,\n\
      \             };\n             const commonLegendOptions = {\n             \
      \    position: 'bottom',\n                 labels: { padding: 18, boxWidth:\
      \ 10, font: { size: 11 }, usePointStyle: true }\n             };\n         \
      \    const commonXAxisOptions = {\n                 ticks: { maxRotation: 0,\
      \ autoSkip: true, maxTicksLimit: 15, font: { size: 10 }, color: 'var(--text-dark)'\
      \ },\n                 grid: { display: false }\n             };\n         \
      \    const commonYAxisOptions = {\n                 ticks: { beginAtZero: true,\
      \ font: { size: 10 }, precision: 0, color: 'var(--text-medium)' },\n       \
      \          grid: { color: 'var(--border-color-medium)', drawTicks: false, borderDash:\
      \ [3, 4] }\n             };\n\n             // --- Rates Chart (Line) ---\n\
      \             const ratesOpts = { responsive: true, maintainAspectRatio: false,\
      \ animation: { duration: 200 }, plugins: { legend: commonLegendOptions, tooltip:\
      \ { ...commonTooltipOptions, mode: 'index', intersect: false } }, scales: {\
      \ x: commonXAxisOptions, yReq: { ...commonYAxisOptions, type: 'linear', position:\
      \ 'left', title: { display: false }, ticks:{color:'var(--accent-indigo)'} },\
      \ yProcFail: { ...commonYAxisOptions, type: 'linear', position: 'right', title:\
      \ { display: false }, grid: { drawOnChartArea: false }, ticks:{color:'var(--accent-green)'}\
      \ } }, elements: { line: { tension: 0.3, borderWidth: 2 }, point: { radius:\
      \ 0, hitRadius: 10, hoverRadius: 5 } }, interaction: { mode: 'nearest', axis:\
      \ 'x', intersect: false } };\n             chartInstances.rates = new Chart(dom.ratesChartCtx,\
      \ { type: 'line', data: { labels: [], datasets: [ { label: 'Reqs/sec', data:\
      \ [], borderColor: 'var(--accent-indigo)', backgroundColor: 'rgba(92, 107, 192,\
      \ 0.1)', fill: false, yAxisID: 'yReq' }, { label: 'Proc/sec', data: [], borderColor:\
      \ 'var(--accent-green)', backgroundColor: 'rgba(76, 175, 80, 0.1)', fill: false,\
      \ yAxisID: 'yProcFail' }, { label: 'Fail/sec', data: [], borderColor: 'var(--accent-red)',\
      \ backgroundColor: 'rgba(244, 67, 54, 0.1)', fill: false, yAxisID: 'yProcFail'\
      \ } ] }, options: ratesOpts });\n\n             // --- Message Status Chart\
      \ (Stacked Area) ---\n             const msgStatusOpts = { responsive: true,\
      \ maintainAspectRatio: false, animation: { duration: 200 }, plugins: { legend:\
      \ commonLegendOptions, tooltip: { ...commonTooltipOptions, mode: 'index', intersect:\
      \ false } }, scales: { x: commonXAxisOptions, y: { ...commonYAxisOptions, stacked:\
      \ true, title: { display: false } } }, elements: { line: { tension: 0.1, borderWidth:\
      \ 1.5, fill: 'start' }, point: { radius: 0, hitRadius: 10, hoverRadius: 5 }\
      \ }, interaction: { mode: 'index', axis: 'x', intersect: false } };\n      \
      \       chartInstances.messageStatus = new Chart(dom.messageStatusChartCtx,\
      \ { type: 'line', data: { labels: [], datasets: [ { label: 'Failed', data: [],\
      \ borderColor: 'var(--status-error)', backgroundColor: 'rgba(244, 67, 54, 0.5)',\
      \ order: 3 }, { label: 'Processing', data: [], borderColor: 'var(--status-processing)',\
      \ backgroundColor: 'rgba(92, 107, 192, 0.5)', order: 2 }, { label: 'Pending',\
      \ data: [], borderColor: 'var(--status-warning)', backgroundColor: 'rgba(255,\
      \ 152, 0, 0.5)', order: 1 }, /* Exclude 'Processed' from stack as it grows too\
      \ large, keep if needed: { label: 'Processed', data: [], borderColor: 'var(--status-success)',\
      \ backgroundColor: 'rgba(76, 175, 80, 0.3)', order: 0 } */ ] }, options: msgStatusOpts\
      \ });\n\n             // --- Performance Chart (Line, Multi-Axis) ---\n    \
      \         const perfOpts = { responsive: true, maintainAspectRatio: false, animation:\
      \ { duration: 200 }, plugins: { legend: commonLegendOptions, tooltip: { ...commonTooltipOptions,\
      \ mode: 'index', intersect: false } }, scales: { x: commonXAxisOptions, yCpu:\
      \ { ...commonYAxisOptions, type: 'linear', position: 'left', title: { display:\
      \ true, text: 'CPU (%)', color: 'var(--accent-cyan)', font:{size:10, weight:'500'}\
      \ }, ticks: { color: 'var(--accent-cyan)', precision: 1 }, grid: { color: 'rgba(0,\
      \ 188, 212, 0.1)' } }, yMem: { ...commonYAxisOptions, type: 'linear', position:\
      \ 'right', title: { display: true, text: 'Memory (%)', color: 'var(--accent-teal)',\
      \ font:{size:10, weight:'500'} }, ticks: { color: 'var(--accent-teal)', precision:\
      \ 1 }, grid: { drawOnChartArea: false } } }, elements: { line: { tension: 0.3,\
      \ borderWidth: 2 }, point: { radius: 0, hitRadius: 10, hoverRadius: 5 } }, interaction:\
      \ { mode: 'index', axis: 'x', intersect: false } };\n             chartInstances.performance\
      \ = new Chart(dom.performanceChartCtx, { type: 'line', data: { labels: [], datasets:\
      \ [ { label: 'API Process CPU %', data: [], borderColor: 'var(--accent-cyan)',\
      \ yAxisID: 'yCpu', backgroundColor: 'rgba(0, 188, 212, 0.1)', fill: 'start'\
      \ }, { label: 'System CPU %', data: [], borderColor: 'var(--accent-blue)', yAxisID:\
      \ 'yCpu', backgroundColor: 'rgba(33, 150, 243, 0.1)', fill: 'start' }, { label:\
      \ 'System Memory %', data: [], borderColor: 'var(--accent-teal)', yAxisID: 'yMem',\
      \ backgroundColor: 'rgba(38, 166, 154, 0.1)', fill: 'start' } ] }, options:\
      \ perfOpts });\n\n             // --- Requests by Route (Horizontal Bar) ---\n\
      \             const routeOpts = { responsive: true, maintainAspectRatio: false,\
      \ indexAxis: 'y', animation: { duration: 300 }, plugins: { legend: { display:\
      \ false }, tooltip: { ...commonTooltipOptions, mode: 'index', intersect: true,\
      \ callbacks: { label: (context) => ` Count: ${formatNumber(context.parsed.x)}`\
      \ } } }, scales: { x: { ...commonYAxisOptions, title:{ display: true, text:\
      \ 'Total Requests', font:{size: 10} } }, y: { ...commonXAxisOptions, ticks:\
      \ { font: { size: 10 }, color:'var(--text-medium)' }, grid: { display: false\
      \ } } } };\n             chartInstances.requestsByRoute = new Chart(dom.requestsByRouteChartCtx,\
      \ { type: 'bar', data: { labels: [], datasets: [{ label: 'Count', data: [],\
      \ backgroundColor: 'var(--accent-indigo)', hoverBackgroundColor: 'var(--accent-blue)',\
      \ borderRadius: 3, barPercentage: 0.8, categoryPercentage: 0.7 }] }, options:\
      \ routeOpts });\n\n             // --- Requests by Status (Doughnut) ---\n \
      \            const statusOpts = { responsive: true, maintainAspectRatio: false,\
      \ animation: { duration: 300, animateRotate: true, animateScale: true }, cutout:\
      \ '65%', plugins: { legend: { position: 'right', labels: { padding: 15, boxWidth:\
      \ 12, font: { size: 11 } } }, tooltip: { ...commonTooltipOptions, callbacks:\
      \ { label: (context) => ` ${context.label}: ${formatNumber(context.parsed)}\
      \ (${((context.parsed / context.chart.getDatasetMeta(0).total) * 100).toFixed(1)}%)`\
      \ } } } };\n             chartInstances.requestsByStatus = new Chart(dom.requestsByStatusChartCtx,\
      \ { type: 'doughnut', data: { labels: [], datasets: [{ label: 'Count', data:\
      \ [], backgroundColor: [], // Set dynamically\n                 borderWidth:\
      \ 2, borderColor: 'var(--bg-card)', hoverOffset: 12, hoverBorderColor: 'var(--text-light)'\
      \ }] }, options: statusOpts });\n\n             // --- HTTP Error Rate Chart\
      \ (Line) ---\n             const errRateOpts = { responsive: true, maintainAspectRatio:\
      \ false, animation: { duration: 200 }, plugins: { legend: { display: false },\
      \ tooltip: { ...commonTooltipOptions, mode: 'index', intersect: false, callbacks:\
      \ { label: (context) => ` ${context.dataset.label}: ${formatDecimal(context.parsed.y,\
      \ 1)}%` } } }, scales: { x: commonXAxisOptions, y: { ...commonYAxisOptions,\
      \ suggestedMax: 10, title: { display: true, text: 'Error Rate (%)', font:{size:\
      \ 10}}, ticks: { callback: (value) => value + '%' } } }, elements: { line: {\
      \ tension: 0.2, borderWidth: 2 }, point: { radius: 0, hitRadius: 10, hoverRadius:\
      \ 5 } }, interaction: { mode: 'index', axis: 'x', intersect: false } };\n  \
      \           chartInstances.httpErrorRate = new Chart(dom.httpErrorRateChartCtx,\
      \ { type: 'line', data: { labels: [], datasets: [{ label: 'HTTP Err % (4xx+)',\
      \ data: [], borderColor: 'var(--accent-red)', backgroundColor: 'rgba(244, 67,\
      \ 54, 0.2)', fill: true }] }, options: errRateOpts });\n\n             console.info(\"\
      All charts initialized.\");\n        }\n\n        // --- Data Fetching & Processing\
      \ ---\n        async function fetchDashboardData() {\n             if (!initialLoadComplete\
      \ && dom.statusIndicator) { updateStatusIndicator('fetching', 'Fetching initial\
      \ data...'); }\n             else if (dom.statusIndicator && !dom.statusIndicator.classList.contains('error'))\
      \ { updateStatusIndicator('fetching', 'Fetching stats...'); }\n\n          \
      \   console.debug(`[${DateTime.now().toFormat('HH:mm:ss')}] Fetching ${CONFIG.API_DASHBOARD_DATA_URL}`);\n\
      \             try {\n                 const response = await fetch(CONFIG.API_DASHBOARD_DATA_URL);\n\
      \                 const data = await response.json(); // Assume JSON response\n\
      \n                 if (!response.ok) {\n                     // Try to get error\
      \ message from response, fallback to statusText\n                     const\
      \ errorMsg = data?.error || data?.detail || `Server returned status ${response.status}`;\n\
      \                     throw new Error(errorMsg);\n                 }\n\n   \
      \              // Check for API-level error reported within the data\n     \
      \            if (data.last_api_error) {\n                     console.warn(\"\
      API reported an error:\", data.last_api_error);\n                     updateApiErrorUI(data.last_api_error);\n\
      \                     // Don't necessarily stop UI updates, some data might\
      \ still be valid\n                 } else {\n                      // Clear\
      \ previous error if current fetch is successful and no error reported\n    \
      \                  if (lastKnownApiError) updateApiErrorUI(null);\n        \
      \         }\n\n                 // Validate core data presence\n           \
      \      if (!data.latest_stats || Object.keys(data.latest_stats).length === 0)\
      \ {\n                     console.warn(\"Dashboard data received, but 'latest_stats'\
      \ is missing or empty.\");\n                     // Handle this gracefully,\
      \ maybe show a specific message?\n                     // For now, update UI\
      \ with available data, cards might show '--'\n                 }\n\n       \
      \          // Update UI with the received data\n                 updateDashboardUI(data);\n\
      \                 lastSuccessfulDataFetch = data.last_successful_stats_fetch\
      \ || data.last_successful_queues_fetch || DateTime.now().toISO(); // Use server\
      \ time if available\n                 updateStatusIndicator(); // Update based\
      \ on success and timestamps\n\n                 // Handle log viewer state based\
      \ on dashboard data\n                 handleLogStateFromDashboard(data);\n\n\
      \                 if (!initialLoadComplete) {\n                     initialLoadComplete\
      \ = true;\n                     console.info(\"Initial dashboard data load complete.\"\
      );\n                     // Fetch initial log content *after* dashboard data\
      \ sets the filename\n                     if (currentLogFilename) {\n      \
      \                    fetchLogData(false, true); // Force initial log fetch\n\
      \                     }\n                 }\n\n             } catch (error)\
      \ {\n                 console.error(`Dashboard data fetch failed: ${error.message}`);\n\
      \                 // Update UI to show a dashboard-level connection error\n\
      \                 updateApiErrorUI({ message: `Dashboard connection error: ${error.message}`,\
      \ type: \"dashboard_fetch\", timestamp: DateTime.now().toISO() });\n       \
      \          updateStatusIndicator(); // Update status based on error\n      \
      \           // Potentially clear parts of the UI or show stale data indicators?\n\
      \                 // clearUI(); // Optionally clear everything on fetch failure\n\
      \             }\n        }\n\n        function handleLogStateFromDashboard(data)\
      \ {\n            // Sync log auto-refresh toggle state\n            if (dom.logAutoRefreshToggle\
      \ && data.log_auto_refresh_enabled !== undefined) {\n                logAutoRefreshEnabled\
      \ = data.log_auto_refresh_enabled;\n                dom.logAutoRefreshToggle.checked\
      \ = logAutoRefreshEnabled;\n                // Restart timer based on potentially\
      \ changed state\n                 startLogAutoRefreshTimer();\n            }\n\
      \n            // Update current filename and \"Load Older\" capability\n   \
      \          currentLogFilename = data.current_log_filename || null;\n       \
      \      canLoadOlderLogs = !!data.log_next_fetch_start_line; // Convert to boolean\n\
      \n             if (dom.logFilenameDisplay) {\n                 dom.logFilenameDisplay.textContent\
      \ = currentLogFilename || 'N/A';\n                 if (currentLogFilename) dom.logFilenameDisplay.classList.remove('na');\n\
      \                 else dom.logFilenameDisplay.classList.add('na');\n       \
      \      }\n             if (dom.loadOlderLogsBtn) {\n                 dom.loadOlderLogsBtn.disabled\
      \ = !canLoadOlderLogs || isFetchingLogs;\n             }\n              if (dom.refreshLogsBtn)\
      \ {\n                 dom.refreshLogsBtn.disabled = !currentLogFilename || isFetchingLogs;\n\
      \              }\n\n            // If the backend reports a log fetch error,\
      \ display it\n            if (data.log_fetch_error && !lastKnownApiError?.message.includes('Log\
      \ file')) { // Avoid duplicate error display\n                 setLogOverlay(`Log\
      \ Error: ${data.log_fetch_error}`, true);\n                 if (dom.logStatusText)\
      \ dom.logStatusText.textContent = `Error: ${data.log_fetch_error}`;\n      \
      \      }\n        }\n\n        async function fetchLogData(fetchOlder = false,\
      \ isInitialFetch = false) {\n             if (!currentLogFilename) {\n     \
      \            console.debug(\"fetchLogData skipped: No log file selected.\");\n\
      \                 updateLogViewerUI({ lines: [], filename: null }, false); //\
      \ Clear UI if no file\n                 return;\n             }\n          \
      \   if (isFetchingLogs) {\n                 console.debug(`fetchLogData skipped\
      \ (${fetchOlder ? 'older' : 'latest'}): Already fetching.`);\n             \
      \    return;\n             }\n\n             isFetchingLogs = true;\n      \
      \       const userAction = fetchOlder || !logAutoRefreshEnabled; // Was this\
      \ likely triggered by user?\n             if (userAction || isInitialFetch)\
      \ { // Show visual cue for user actions or first load\n                setLogOverlay(fetchOlder\
      \ ? 'Loading older entries...' : 'Fetching latest logs...', true);\n       \
      \      }\n             if(dom.logStatusText) dom.logStatusText.textContent =\
      \ fetchOlder ? 'Loading older...' : 'Refreshing...';\n             if(dom.loadOlderLogsBtn)\
      \ dom.loadOlderLogsBtn.disabled = true;\n             if(dom.refreshLogsBtn)\
      \ dom.refreshLogsBtn.disabled = true;\n\n             const url = fetchOlder\
      \ ? CONFIG.API_FETCH_OLDER_LOGS_URL : CONFIG.API_LOG_DATA_URL;\n           \
      \  console.debug(`[${DateTime.now().toFormat('HH:mm:ss')}] Fetching ${url}${fetchOlder\
      \ ? ' (older)' : ' (latest)'}`);\n\n             try {\n                 const\
      \ response = await fetch(url);\n                 const logData = await response.json();\n\
      \n                 if (!response.ok) {\n                      const errorMsg\
      \ = logData?.error || logData?.detail || `Server returned status ${response.status}`;\n\
      \                      throw new Error(errorMsg);\n                 }\n\n  \
      \               // Check for specific log fetch error from backend response\n\
      \                 if (logData.log_fetch_error) {\n                      console.warn(`Log\
      \ fetch for ${logData.filename} reported error: ${logData.log_fetch_error}`);\n\
      \                      setLogOverlay(`Error: ${logData.log_fetch_error}`, true);\
      \ // Show error in overlay\n                 } else {\n                    \
      \  setLogOverlay('', false); // Clear overlay on success\n                 }\n\
      \n                 updateLogViewerUI(logData, fetchOlder); // Update UI with\
      \ new lines/state\n\n                 // Update state based on response\n  \
      \                currentLogFilename = logData.filename || null; // Update filename\
      \ just in case\n                  canLoadOlderLogs = !!logData.next_fetch_start_line;\n\
      \n             } catch (error) {\n                 console.error(`Log data fetch\
      \ failed (${fetchOlder ? 'older' : 'latest'}): ${error.message}`);\n       \
      \          setLogOverlay(`Error fetching logs: ${error.message}`, true);\n \
      \                if(dom.logStatusText) dom.logStatusText.textContent = `Error:\
      \ ${error.message.substring(0, 100)}`;\n                 // Don't clear existing\
      \ logs on error, just show message\n             } finally {\n             \
      \    isFetchingLogs = false;\n                 // Re-enable buttons based on\
      \ latest state\n                 if(dom.loadOlderLogsBtn) dom.loadOlderLogsBtn.disabled\
      \ = !canLoadOlderLogs;\n                 if(dom.refreshLogsBtn) dom.refreshLogsBtn.disabled\
      \ = !currentLogFilename; // Re-enable if a file is selected\n              \
      \    // Clear status text if it was just 'Loading' or 'Refreshing'\n       \
      \          if(dom.logStatusText && (dom.logStatusText.textContent.startsWith('Loading')\
      \ || dom.logStatusText.textContent.startsWith('Refreshing'))) {\n          \
      \          dom.logStatusText.textContent = `Last updated: ${DateTime.now().toFormat('HH:mm:ss')}`;\n\
      \                 }\n             }\n        }\n\n        // --- Core UI Update\
      \ Function ---\n        function updateDashboardUI(data) {\n            console.debug(\"\
      Updating dashboard UI with data:\", data);\n\n            // --- Cards Update\
      \ ---\n            if (data.latest_stats) {\n                const stats = data.latest_stats;\n\
      \                const sys = stats.system || {};\n\n                // Message\
      \ Stats\n                updateCardValue(dom.pendingMsgs, safeGet(stats, 'messages_pending'));\n\
      \                updateCardValue(dom.processingMsgs, safeGet(stats, 'messages_processing'));\n\
      \                updateCardValue(dom.failedMsgs, safeGet(stats, 'messages_failed'));\n\
      \                updateCardValue(dom.processedMsgs, safeGet(stats, 'messages_processed'));\n\
      \                updateCardValue(dom.totalMsgs, safeGet(stats, 'messages_total'));\
      \ // Assuming API provides this\n\n                // Request & System Stats\n\
      \                updateCardValue(dom.totalRequests, safeGet(stats, 'requests_total'));\n\
      \                updateCardValue(dom.uptime, safeGet(stats, 'uptime_str'), formatUptime);\n\
      \                updateCardValue(dom.processCpu, safeGet(sys, 'process_cpu_percent'),\
      \ formatPercentage);\n                updateCardValue(dom.processMem, safeGet(sys,\
      \ 'process_memory_mb'), (v) => formatMemory(v, 'MB'));\n                updateCardValue(dom.systemCpu,\
      \ safeGet(sys, 'cpu_percent'), formatPercentage);\n                updateCardValue(dom.systemMem,\
      \ safeGet(sys, 'memory_percent'), formatPercentage);\n                updateCardValue(dom.filesThreads,\
      \ formatFilesThreads(safeGet(sys, 'process_num_fds'), safeGet(sys, 'process_num_threads')),\
      \ v => v); // Pass raw string\n\n                // HTTP Error Rate Card (uses\
      \ history)\n                const errorRateHistory = safeGet(data, 'history.http_error_rate_history',\
      \ []);\n                updateCardValue(dom.httpErrorRate, errorRateHistory[errorRateHistory.length\
      \ - 1], formatPercentage);\n            } else {\n                 console.warn(\"\
      No 'latest_stats' data found in response. Cards may not update.\");\n      \
      \           // Optionally clear specific cards if stats are missing\n      \
      \      }\n\n            // Queue Count Card\n            updateCardValue(dom.totalQueues,\
      \ data.latest_queues?.length);\n\n            // --- Info Tables Update ---\n\
      \            updateSystemInfoTable(safeGet(data, 'latest_stats.system', {}));\n\
      \            updateBrokerInfoTable(safeGet(data, 'latest_stats.broker_config',\
      \ {})); // Assuming this key exists\n            updateQueuesTable(data.latest_queues\
      \ || []);\n            updateDiskInfoTable(safeGet(data, 'latest_stats.system.disk_usage',\
      \ []));\n\n            // --- Charts Update ---\n            if (data.history)\
      \ {\n                 const hist = data.history;\n                 updateChartData(chartInstances.rates,\
      \ hist.time_labels, [hist.request_rate_history, hist.processed_rate_history,\
      \ hist.failed_rate_history]);\n                 updateChartData(chartInstances.messageStatus,\
      \ hist.time_labels, [\n                     safeGet(hist, 'message_status.failed',\
      \ []),\n                     safeGet(hist, 'message_status.processing', []),\n\
      \                     safeGet(hist, 'message_status.pending', []),\n       \
      \          ]);\n                  updateChartData(chartInstances.performance,\
      \ hist.time_labels, [\n                     safeGet(hist, 'performance.process_cpu',\
      \ []),\n                     safeGet(hist, 'performance.system_cpu', []),\n\
      \                     safeGet(hist, 'performance.system_memory', []), // Matching\
      \ dataset order in init\n                 ]);\n                 updateChartData(chartInstances.httpErrorRate,\
      \ hist.time_labels, [hist.http_error_rate_history]);\n\n                // Update\
      \ categorical charts (which use totals from latest_stats)\n                if(data.latest_stats)\
      \ {\n                    updateRequestsByStatusChart(safeGet(data.latest_stats,\
      \ 'requests_by_status', {}));\n                    updateRequestsByRouteChart(safeGet(data.latest_stats,\
      \ 'requests_by_route', {}));\n                }\n            } else {\n    \
      \             console.warn(\"No 'history' data found in response. Time-series\
      \ charts may not update.\");\n            }\n        }\n\n        // --- Table\
      \ Population Functions ---\n        function populateTable(tbodyElement, dataRows,\
      \ columns) {\n             if (!tbodyElement) return;\n             tbodyElement.innerHTML\
      \ = ''; // Clear existing rows\n             if (!dataRows || dataRows.length\
      \ === 0) {\n                 tbodyElement.innerHTML = `<tr><td colspan=\"${columns.length}\"\
      \ class=\"no-data\">(No data available)</td></tr>`;\n                 return;\n\
      \             }\n             dataRows.forEach(rowData => {\n              \
      \   const tr = tbodyElement.insertRow();\n                 columns.forEach(col\
      \ => {\n                     const td = tr.insertCell();\n                 \
      \    let value = safeGet(rowData, col.key, '--');\n                     if (col.formatter)\
      \ {\n                         value = col.formatter(value, rowData); // Pass\
      \ full row data if needed\n                     }\n                      //\
      \ Safely render HTML if formatter returns it\n                     if (typeof\
      \ value === 'string' && (value.includes('<') || value.includes('&'))) {\n  \
      \                       // Basic check for HTML, consider a more robust check\
      \ or explicit flag\n                         // Use DOMPurify here if complex\
      \ HTML is possible and security is paramount\n                          td.innerHTML\
      \ = value; // Assume simple/safe HTML from formatters\n                    \
      \ } else {\n                          td.textContent = value;\n            \
      \         }\n\n                     if(col.class) td.classList.add(col.class);\n\
      \                 });\n             });\n        }\n\n        function createDiskUsageBar(usageData)\
      \ {\n             const percent = parseFloat(safeGet(usageData, 'percent', 0));\n\
      \             const used = formatBytes(safeGet(usageData, 'used'));\n      \
      \       const free = formatBytes(safeGet(usageData, 'free'));\n            \
      \ let barClass = '';\n             if (percent > 90) barClass = 'crit';\n  \
      \           else if (percent > 75) barClass = 'warn';\n             // Use markupsafe.Markup\
      \ equivalent in JS (or just raw HTML string for simple cases)\n            \
      \ return `\n                 <div class=\"disk-usage-bar-container\">\n    \
      \                 <span class=\"disk-usage-text\">${formatDecimal(percent, 1)}%\
      \ Used</span>\n                     <div class=\"disk-usage-bar\">\n       \
      \                  <div class=\"disk-usage-fill ${barClass}\" style=\"width:\
      \ ${percent}%;\"></div>\n                     </div>\n                 </div>\n\
      \                 <div class=\"disk-usage-text\" style=\"font-size: 0.85em;\
      \ color: var(--text-dark);\">${used} used / ${free} free</div>\n           \
      \  `;\n        }\n\n        function updateSystemInfoTable(sysData) {\n    \
      \        populateTable(dom.systemInfoTableBody, [sysData], [ // Wrap sysData\
      \ in array as it's one row conceptually\n                { key: 'hostname',\
      \ label: 'Hostname' },\n                { key: 'os_platform', label: 'OS' },\n\
      \                { key: 'cpu_cores', label: 'CPU Cores' },\n               \
      \ { key: 'load_average', label: 'Load Avg (1m, 5m, 15m)', formatter: formatLoadAvg\
      \ },\n                { key: 'memory_total', label: 'Total Memory', formatter:\
      \ formatBytes },\n                { key: 'memory_available', label: 'Available\
      \ Memory', formatter: formatBytes },\n                 // Add Python version\
      \ if available\n                { key: 'python_version', label: 'Python Version'\
      \ },\n            ].map(c => ({ key: c.key, formatter: c.formatter })) // Extract\
      \ needed info for populateTable\n            .filter(c => safeGet(sysData, c.key)\
      \ !== null) // Only show rows with data\n            .map(c => { // Rebuild\
      \ for display labels\n                 const labels = { hostname: 'Hostname',\
      \ os_platform: 'OS', cpu_cores: 'CPU Cores', load_average: 'Load Avg', memory_total:\
      \ 'Total Memory', memory_available: 'Available Memory', python_version: 'Python\
      \ Ver.' };\n                 return { key: c.key, label: labels[c.key] || c.key,\
      \ formatter: c.formatter };\n            }));\n\n            // Manually create\
      \ rows for table structure if needed\n             if (dom.systemInfoTableBody)\
      \ {\n                 dom.systemInfoTableBody.innerHTML = ''; // Clear first\n\
      \                 const info = [\n                      { label: 'Hostname',\
      \ value: safeGet(sysData, 'hostname', '--') },\n                      { label:\
      \ 'Operating System', value: safeGet(sysData, 'os_platform', '--') },\n    \
      \                  { label: 'CPU Cores', value: safeGet(sysData, 'cpu_cores',\
      \ '--') },\n                      { label: 'Load Average', value: formatLoadAvg(safeGet(sysData,\
      \ 'load_average')) },\n                      { label: 'Total Memory', value:\
      \ formatBytes(safeGet(sysData, 'memory_total')) },\n                      {\
      \ label: 'Available Memory', value: formatBytes(safeGet(sysData, 'memory_available'))\
      \ },\n                      { label: 'Python Version', value: safeGet(sysData,\
      \ 'python_version', '--') },\n                      // Add Dashboard Uptime\n\
      \                      { label: 'Dashboard Uptime', value: formatRelativeTime(safeGet(sysData,\
      \ 'dashboard_start_time')) } // Requires backend to add this\n             \
      \    ];\n                 info.forEach(item => {\n                     if (item.value\
      \ !== '--' && item.value !== null && item.value !== undefined) {\n         \
      \                 const tr = dom.systemInfoTableBody.insertRow();\n        \
      \                  const th = document.createElement('th');\n              \
      \            th.textContent = item.label;\n                          tr.appendChild(th);\n\
      \                          const td = tr.insertCell();\n                   \
      \       td.textContent = item.value;\n                     }\n             \
      \    });\n                  if (dom.systemInfoTableBody.rows.length === 0) {\n\
      \                      dom.systemInfoTableBody.innerHTML = `<tr><td colspan=\"\
      2\" class=\"no-data\">(No system info)</td></tr>`;\n                  }\n  \
      \           }\n        }\n\n        function updateBrokerInfoTable(brokerData)\
      \ {\n             // Similar manual row creation as updateSystemInfoTable\n\
      \             if (dom.brokerInfoTableBody) {\n                  dom.brokerInfoTableBody.innerHTML\
      \ = '';\n                  const info = Object.entries(brokerData || {}).map(([key,\
      \ value]) => ({ label: key.replace(/_/g, ' ').replace(/\\b\\w/g, l => l.toUpperCase()),\
      \ value: value }));\n\n                  info.forEach(item => {\n          \
      \           const tr = dom.brokerInfoTableBody.insertRow();\n              \
      \       const th = document.createElement('th');\n                     th.textContent\
      \ = item.label;\n                     tr.appendChild(th);\n                \
      \     const td = tr.insertCell();\n                     // Display complex values\
      \ (like lists/dicts) as JSON string\n                     if (typeof item.value\
      \ === 'object' && item.value !== null) {\n                         td.innerHTML\
      \ = `<code>${escapeHtml(JSON.stringify(item.value))}</code>`;\n            \
      \         } else {\n                          td.textContent = String(item.value);\n\
      \                     }\n                 });\n                 if (dom.brokerInfoTableBody.rows.length\
      \ === 0) {\n                      dom.brokerInfoTableBody.innerHTML = `<tr><td\
      \ colspan=\"2\" class=\"no-data\">(No broker config)</td></tr>`;\n         \
      \         }\n             }\n        }\n\n        function updateQueuesTable(queuesData)\
      \ {\n            if(dom.queueCountSpan) dom.queueCountSpan.textContent = queuesData.length;\n\
      \            populateTable(dom.queuesInfoTableBody, queuesData, [\n        \
      \        { key: 'name', label: 'Name', formatter: (val) => `<code>${escapeHtml(val)}</code>`\
      \ },\n                { key: 'messages_total', label: 'Total Msgs', formatter:\
      \ formatNumber }, // Use appropriate key from API\n                { key: 'created_at',\
      \ label: 'Created', formatter: formatRelativeTime } // Use appropriate key from\
      \ API\n            ]);\n        }\n\n        function updateDiskInfoTable(diskData)\
      \ {\n            populateTable(dom.diskInfoTableBody, diskData, [\n        \
      \        { key: 'mountpoint', label: 'Mountpoint', formatter: (val) => `<code>${escapeHtml(val)}</code>`\
      \ },\n                { key: 'percent', label: 'Usage', formatter: (val, row)\
      \ => createDiskUsageBar(row) }, // Use custom formatter\n                { key:\
      \ 'free', label: 'Free Space', formatter: formatBytes }\n            ]);\n \
      \       }\n\n        // --- Chart Specific Update Functions ---\n        function\
      \ updateRequestsByStatusChart(reqByStatus) {\n            if (!chartInstances.requestsByStatus\
      \ || !reqByStatus) return;\n            const labels = Object.keys(reqByStatus).sort((a,b)\
      \ => parseInt(a) - parseInt(b)); // Sort by status code\n            const data\
      \ = labels.map(status => reqByStatus[status]);\n            updateChartData(chartInstances.requestsByStatus,\
      \ labels, [data]);\n        }\n\n        function updateRequestsByRouteChart(reqByRoute)\
      \ {\n            if (!chartInstances.requestsByRoute || !reqByRoute) return;\n\
      \            // Sort routes by count descending, take top 15\n            const\
      \ sortedRoutes = Object.entries(reqByRoute)\n                              \
      \       .sort(([, countA], [, countB]) => countB - countA)\n               \
      \                      .slice(0, 15);\n            const labels = sortedRoutes.map(([route])\
      \ => route);\n            const data = sortedRoutes.map(([, count]) => count);\n\
      \            updateChartData(chartInstances.requestsByRoute, labels, [data]);\n\
      \        }\n\n\n        // --- Log Viewer Functions ---\n        function updateLogViewerUI(logData,\
      \ wasPrepended) { // wasPrepended means older logs were loaded\n           \
      \  if (!dom.logContentArea) return;\n\n             const { lines = [], filename\
      \ = null } = logData;\n             const shouldPreserveScroll = !wasPrepended\
      \ && isScrolledToBottom(dom.logContentArea);\n\n             if (filename !==\
      \ currentLogFilename && !isInitialFetch) { // filename changed from backend,\
      \ likely cleared\n                 dom.logContentArea.innerHTML = ''; // Clear\
      \ existing content\n                 if (dom.logInitialMessage) {\n        \
      \             dom.logInitialMessage.textContent = filename ? \"(Loading new\
      \ log file...)\" : \"(No log file selected)\";\n                     dom.logContentArea.appendChild(dom.logInitialMessage);\n\
      \                     dom.logInitialMessage.style.display = 'block';\n     \
      \            }\n                 currentLogFilename = filename; // Update local\
      \ cache\n                 // Fetch new file content immediately? Maybe wait\
      \ for next cycle or user action.\n             }\n\n             // Remove the\
      \ initial message if it exists and we have lines\n             if (dom.logInitialMessage\
      \ && lines.length > 0) {\n                 dom.logInitialMessage.style.display\
      \ = 'none';\n             }\n\n             if (lines.length > 0) {\n      \
      \           const fragment = document.createDocumentFragment();\n          \
      \       lines.forEach(lineData => {\n                     const lineElement\
      \ = createLogLineElement(lineData);\n                     if (lineElement) {\n\
      \                         fragment.appendChild(lineElement);\n             \
      \        }\n                 });\n\n                 if (wasPrepended) { //\
      \ Appending older logs to the end of view (top of content area)\n          \
      \           dom.logContentArea.insertBefore(fragment, dom.logContentArea.firstChild);\n\
      \                     // Try to maintain scroll position relative to the old\
      \ top element\n                     // This is tricky, might need more sophisticated\
      \ logic if jarring\n                 } else { // Prepending newer logs to the\
      \ start of view (bottom of content area)\n                     dom.logContentArea.appendChild(fragment);\n\
      \                 }\n\n                  // Apply filtering/search to newly\
      \ added lines (and potentially existing ones)\n                  applyLogFilterAndSearch();\n\
      \             } else if (!wasPrepended && dom.logContentArea.children.length\
      \ === 0) {\n                 // No new lines received, and log area is empty\
      \ (and not loading older)\n                 if (dom.logInitialMessage) {\n \
      \                    dom.logInitialMessage.textContent = currentLogFilename\
      \ ? \"(Log file appears empty or filter matches no lines)\" : \"(No log file\
      \ selected)\";\n                     dom.logInitialMessage.style.display = 'block';\n\
      \                 }\n             }\n\n             // Trim excess log lines\
      \ from the DOM to prevent performance issues\n             const maxLogLinesInDom\
      \ = CONFIG.LOG_CHUNK_SIZE * 5; // Keep ~5 chunks in DOM\n             while\
      \ (dom.logContentArea.children.length > maxLogLinesInDom) {\n              \
      \   if (wasPrepended) { // Removing oldest lines (from the bottom)\n       \
      \              dom.logContentArea.removeChild(dom.logContentArea.lastElementChild);\n\
      \                 } else { // Removing oldest lines (from the top)\n       \
      \               if (dom.logContentArea.firstChild && dom.logContentArea.firstChild\
      \ !== dom.logInitialMessage) {\n                         dom.logContentArea.removeChild(dom.logContentArea.firstChild);\n\
      \                      } else {\n                          break; // Avoid removing\
      \ initial message\n                      }\n                 }\n           \
      \  }\n\n             // Scroll to bottom if it was previously scrolled to bottom\
      \ (for auto-refresh)\n             if (shouldPreserveScroll && !wasPrepended)\
      \ {\n                 scrollToBottom(dom.logContentArea);\n             }\n\n\
      \              // Update status text (e.g., last updated time)\n           \
      \   if (dom.logStatusText && !logData.log_fetch_error) {\n                 \
      \ dom.logStatusText.textContent = `Last updated: ${DateTime.now().toFormat('HH:mm:ss')}`;\n\
      \              }\n        }\n\n        function createLogLineElement(lineData)\
      \ {\n             if (!lineData || typeof lineData !== 'object') {\n       \
      \          console.warn(\"Invalid lineData received:\", lineData);\n       \
      \          return null; // Skip invalid lines\n             }\n            \
      \ const { timestamp, level = 'info', message = '' } = lineData;\n          \
      \   const lineDiv = document.createElement('div');\n             lineDiv.classList.add('log-line');\n\
      \             lineDiv.dataset.level = level.toLowerCase(); // Store level for\
      \ filtering\n\n             const timeSpan = document.createElement('span');\n\
      \             timeSpan.classList.add('log-line-timestamp');\n             //\
      \ Format time only, date is usually implied by file\n             timeSpan.textContent\
      \ = timestamp ? DateTime.fromISO(timestamp).toFormat('HH:mm:ss.SSS') : '??:??:??';\n\
      \             lineDiv.appendChild(timeSpan);\n\n             const levelSpan\
      \ = document.createElement('span');\n             levelSpan.classList.add('log-line-level',\
      \ level.toLowerCase());\n             levelSpan.textContent = level.toUpperCase();\n\
      \             lineDiv.appendChild(levelSpan);\n\n             const msgSpan\
      \ = document.createElement('span');\n             msgSpan.classList.add('log-line-message');\n\
      \             // IMPORTANT: Escape message content to prevent XSS if logs contain\
      \ HTML/JS\n             // Use textContent for safety. If highlighting is needed,\
      \ do it carefully.\n              msgSpan.textContent = message; // Safe default\n\
      \              // Apply highlighting if needed *after* setting textContent\n\
      \              applyHighlighting(msgSpan, message, logSearchTerm);\n\n     \
      \        lineDiv.appendChild(msgSpan);\n             return lineDiv;\n     \
      \   }\n\n         function applyLogFilterAndSearch() {\n             if (!dom.logContentArea)\
      \ return;\n             const searchTerm = logSearchTerm.toLowerCase();\n  \
      \           const filterLevel = logFilterLevel;\n             let visibleCount\
      \ = 0;\n\n             // Iterate through existing log lines\n             const\
      \ lines = dom.logContentArea.querySelectorAll('.log-line');\n             lines.forEach(line\
      \ => {\n                 const lineLevel = line.dataset.level || 'info';\n \
      \                const lineMessageElement = line.querySelector('.log-line-message');\n\
      \                 const lineMessage = lineMessageElement ? lineMessageElement.textContent.toLowerCase()\
      \ : ''; // Use textContent for search\n\n                 // Check level filter\n\
      \                 const levelMatch = !filterLevel || (filterLevel === lineLevel);\n\
      \n                 // Check search term filter\n                 const searchMatch\
      \ = !searchTerm || lineMessage.includes(searchTerm);\n\n                 //\
      \ Show/hide line\n                 if (levelMatch && searchMatch) {\n      \
      \               line.classList.remove('hidden');\n                     visibleCount++;\n\
      \                     // Apply/remove highlighting based *only* on search term\
      \ match\n                     if (lineMessageElement) {\n                  \
      \       applyHighlighting(lineMessageElement, lineMessageElement.textContent,\
      \ searchTerm);\n                     }\n                 } else {\n        \
      \             line.classList.add('hidden');\n                     // Remove\
      \ highlighting if hidden\n                      if (lineMessageElement) {\n\
      \                         applyHighlighting(lineMessageElement, lineMessageElement.textContent,\
      \ ''); // Clear highlighting\n                      }\n                 }\n\
      \             });\n              console.debug(`Log filter applied. Visible\
      \ lines: ${visibleCount}/${lines.length}. Filter: level='${filterLevel}', search='${searchTerm}'`);\n\
      \              // Update status if needed (e.g., \"Showing X of Y lines\")\n\
      \               if (dom.logInitialMessage && visibleCount === 0 && lines.length\
      \ > 0) {\n                   dom.logInitialMessage.textContent = \"(Filter matches\
      \ no log lines)\";\n                   dom.logInitialMessage.style.display =\
      \ 'block';\n               } else if (dom.logInitialMessage && visibleCount\
      \ > 0) {\n                   dom.logInitialMessage.style.display = 'none';\n\
      \               }\n         }\n\n         function applyHighlighting(element,\
      \ originalText, searchTerm) {\n             // Simple text highlighting. For\
      \ complex cases, use libraries or more robust regex.\n             if (!element)\
      \ return;\n             if (!searchTerm || searchTerm.length < 1) {\n      \
      \           element.textContent = originalText; // Restore original if no search\
      \ term\n                 return;\n             }\n             const lowerText\
      \ = originalText.toLowerCase();\n             const lowerSearchTerm = searchTerm.toLowerCase();\n\
      \             let startIndex = 0;\n             let resultHtml = '';\n     \
      \        let index = lowerText.indexOf(lowerSearchTerm, startIndex);\n\n   \
      \          while (index !== -1) {\n                 // Append text before the\
      \ match (escaped)\n                 resultHtml += escapeHtml(originalText.substring(startIndex,\
      \ index));\n                 // Append the highlighted match (escaped)\n   \
      \              resultHtml += `<span class=\"log-highlight\">${escapeHtml(originalText.substring(index,\
      \ index + searchTerm.length))}</span>`;\n                 startIndex = index\
      \ + searchTerm.length;\n                 index = lowerText.indexOf(lowerSearchTerm,\
      \ startIndex);\n             }\n             // Append remaining text (escaped)\n\
      \             resultHtml += escapeHtml(originalText.substring(startIndex));\n\
      \             element.innerHTML = resultHtml;\n         }\n\n        function\
      \ isScrolledToBottom(element) {\n            if (!element) return false;\n \
      \           // Check if scroll position is close to the bottom\n           \
      \ const threshold = 5; // Pixels threshold\n            return element.scrollHeight\
      \ - element.scrollTop - element.clientHeight < threshold;\n        }\n\n   \
      \     function scrollToBottom(element) {\n            if (!element) return;\n\
      \            element.scrollTop = element.scrollHeight;\n        }\n\n      \
      \  // --- Status & Error Handling ---\n        function updateApiErrorUI(errorData)\
      \ {\n             lastKnownApiError = errorData; // Store the latest error globally\n\
      \             if (!dom.lastErrorCard || !dom.lastErrorMessage || !dom.lastErrorTimestamp)\
      \ return;\n\n             if (errorData) {\n                 dom.lastErrorMessage.textContent\
      \ = errorData.message || 'Unknown error';\n                 dom.lastErrorTimestamp.textContent\
      \ = `Type: ${errorData.type || 'generic'} | Time: ${formatDateTime(errorData.timestamp)}`;\n\
      \                 dom.lastErrorCard.style.display = 'flex'; // Show the card\n\
      \             } else {\n                 dom.lastErrorCard.style.display = 'none';\
      \ // Hide the card\n             }\n             // Also update the main status\
      \ indicators\n             updateStatusIndicator();\n        }\n\n        function\
      \ updateStatusIndicator(forceState = null, forceText = null) {\n           \
      \  let status = 'init'; // 'init', 'live', 'stale', 'error', 'fetching'\n  \
      \           let statusText = 'Initializing...';\n             const now = DateTime.now();\n\
      \n             if (forceState) {\n                 status = forceState;\n  \
      \               statusText = forceText || status.charAt(0).toUpperCase() + status.slice(1);\n\
      \             } else if (lastKnownApiError) {\n                 status = 'error';\n\
      \                 statusText = `API Error (${lastKnownApiError.type || 'generic'})`;\n\
      \                 // Add more detail on hover/title?\n             } else if\
      \ (lastSuccessfulDataFetch) {\n                 const lastFetchTime = DateTime.fromISO(lastSuccessfulDataFetch);\n\
      \                 if (lastFetchTime.isValid) {\n                    const diffSeconds\
      \ = now.diff(lastFetchTime, 'seconds').seconds;\n                    // Consider\
      \ live if updated within 2.5x the polling interval\n                    if (diffSeconds\
      \ < (CONFIG.POLLING_INTERVAL_MS / 1000) * 2.5) {\n                        status\
      \ = 'live';\n                        statusText = `Live (Updated ${lastFetchTime.toRelative()})`;\n\
      \                    } else {\n                        status = 'stale';\n \
      \                       statusText = `Stale (Last update ${lastFetchTime.toRelative()})`;\n\
      \                    }\n                 } else {\n                      status\
      \ = 'stale'; // Invalid timestamp\n                      statusText = 'Stale\
      \ (Timestamp issue)';\n                 }\n             } else {\n         \
      \         // Still initializing, no successful fetch yet\n                 \
      \ status = 'init';\n                  statusText = 'Waiting for first data...';\n\
      \             }\n\n             // Update Header Indicator\n             if\
      \ (dom.statusIndicator) {\n                 dom.statusIndicator.textContent\
      \ = statusText;\n                 dom.statusIndicator.className = `status-indicator\
      \ ${status}`;\n                 dom.statusIndicator.title = `Status: ${status}\
      \ | Last Fetch: ${lastSuccessfulDataFetch || 'N/A'} | Error: ${lastKnownApiError?.message\
      \ || 'None'}`;\n             }\n\n             // Update Footer Indicator\n\
      \             if (dom.footerStatus) {\n                  const icons = { init:\
      \ '⏳', live: '✅', stale: '⚠️', error: '❌', fetching: '⏳' };\n              \
      \    const footerClasses = { init: 'stale', live: 'success', stale: 'stale',\
      \ error: 'error', fetching: 'stale' };\n                  dom.footerStatus.innerHTML\
      \ = `<span class=\"status-icon\">${icons[status] || ''}</span>${statusText}`;\n\
      \                  dom.footerStatus.className = `footer-status ${footerClasses[status]\
      \ || 'stale'}`;\n             }\n        }\n\n\n        // --- Event Listeners\
      \ ---\n        function setupEventListeners() {\n            // Log Viewer Controls\n\
      \            if (dom.refreshLogsBtn) {\n                dom.refreshLogsBtn.addEventListener('click',\
      \ () => {\n                     console.log(\"Manual log refresh triggered.\"\
      );\n                     fetchLogData(false); // Fetch latest\n            \
      \    });\n            }\n            if (dom.loadOlderLogsBtn) {\n         \
      \       dom.loadOlderLogsBtn.addEventListener('click', () => {\n           \
      \          console.log(\"Load older logs triggered.\");\n                  \
      \   fetchLogData(true); // Fetch older\n                });\n            }\n\
      \            if (dom.logAutoRefreshToggle) {\n                 dom.logAutoRefreshToggle.addEventListener('change',\
      \ async (e) => {\n                     const enabled = e.target.checked;\n \
      \                    console.log(`Toggling log auto-refresh to: ${enabled}`);\n\
      \                     try {\n                         const response = await\
      \ fetch(CONFIG.API_TOGGLE_LOG_REFRESH_URL, {\n                             method:\
      \ 'POST',\n                             headers: {'Content-Type': 'application/json'},\n\
      \                             body: JSON.stringify({enabled: enabled})\n   \
      \                      });\n                         if (!response.ok) {\n \
      \                            const errorData = await response.json();\n    \
      \                         throw new Error(errorData.error || `Server error ${response.status}`);\n\
      \                         }\n                         const result = await response.json();\n\
      \                         if (result.success) {\n                          \
      \   logAutoRefreshEnabled = result.enabled;\n                             dom.logAutoRefreshToggle.checked\
      \ = logAutoRefreshEnabled; // Ensure UI matches state\n                    \
      \         startLogAutoRefreshTimer(); // Restart timer with new setting\n  \
      \                           console.info(`Log auto-refresh successfully set\
      \ to: ${logAutoRefreshEnabled}`);\n                         } else { throw new\
      \ Error(\"Toggle command rejected by server.\"); }\n                     } catch\
      \ (err) {\n                         console.error(\"Failed to toggle log auto-refresh:\"\
      , err);\n                         // Revert checkbox on error to reflect actual\
      \ state\n                         e.target.checked = !enabled;\n           \
      \              // Optionally show user feedback\n                         if(dom.logStatusText)\
      \ dom.logStatusText.textContent = \"Error toggling refresh.\";\n           \
      \          }\n                 });\n            }\n            if (dom.logSearchInput)\
      \ {\n                 dom.logSearchInput.addEventListener('input', () => {\n\
      \                     clearTimeout(logSearchDebounceTimeout);\n            \
      \         logSearchDebounceTimeout = setTimeout(() => {\n                  \
      \       logSearchTerm = dom.logSearchInput.value.trim();\n                 \
      \        console.debug(`Log search term changed: \"${logSearchTerm}\"`);\n \
      \                        applyLogFilterAndSearch();\n                     },\
      \ 300); // 300ms debounce\n                 });\n            }\n           \
      \ if (dom.logFilterLevel) {\n                 dom.logFilterLevel.addEventListener('change',\
      \ () => {\n                     logFilterLevel = dom.logFilterLevel.value;\n\
      \                     console.debug(`Log filter level changed: \"${logFilterLevel}\"\
      `);\n                     applyLogFilterAndSearch();\n                 });\n\
      \            }\n            console.debug(\"Event listeners set up.\");\n  \
      \      }\n\n    </script>\n     {% endraw %}\n     {# ***** END RAW BLOCK FOR\
      \ JS ***** #}\n</body>\n</html>\n\"\"\"\n\n# --- Flask Routes ---\n@app.route('/')\n\
      def serve_dashboard():\n    \"\"\"Serves the main dashboard HTML page.\"\"\"\
      \n    logger.info(f\"Request for dashboard page from {request.remote_addr}\"\
      )\n    try:\n        # Inject necessary config variables into the template\n\
      \        return render_template_string( HTML_TEMPLATE,\n            FETCH_STATS_INTERVAL_SECONDS=FETCH_STATS_INTERVAL_SECONDS,\n\
      \            FETCH_LOGCONTENT_INTERVAL_SECONDS=FETCH_LOGCONTENT_INTERVAL_SECONDS,\n\
      \            MAX_CHART_HISTORY=MAX_CHART_HISTORY,\n            LOG_CHUNK_SIZE=LOG_CHUNK_SIZE\n\
      \        )\n    except Exception as e:\n        logger.exception(\"Error rendering\
      \ dashboard template\")\n        # Provide a minimal error page if template\
      \ rendering fails\n        return f\"<h1>Internal Server Error</h1><p>Failed\
      \ to render dashboard template: {e}</p>\", 500\n\n@app.route('/api/dashboard_data')\n\
      def get_dashboard_data():\n    \"\"\"API endpoint to provide the current state\
      \ snapshot for the dashboard.\"\"\"\n    logger.debug(\"Request received for\
      \ /api/dashboard_data\")\n    try:\n        data = state.get_snapshot_for_dashboard()\n\
      \        # Add dashboard start time to system info if available\n        if\
      \ data.get('latest_stats') and data['latest_stats'].get('system'):\n       \
      \     data['latest_stats']['system']['dashboard_start_time'] = state.server_start_time.isoformat()\n\
      \        return jsonify(data)\n    except Exception as e:\n        logger.exception(\"\
      Error preparing data for /api/dashboard_data\")\n        return jsonify({\"\
      error\": \"Failed to prepare dashboard data\", \"detail\": str(e)}), 500\n\n\
      @app.route('/api/log_data')\ndef get_log_data():\n    \"\"\"API endpoint to\
      \ get the latest log data chunk.\"\"\"\n    logger.debug(\"Request received\
      \ for /api/log_data (latest)\")\n    # Note: Actual fetching is handled by the\
      \ scheduled job or triggered elsewhere.\n    # This endpoint just returns the\
      \ current state of the log buffer.\n    try:\n        # Optionally trigger an\
      \ immediate refresh if desired, but might conflict with scheduler\n        #\
      \ fetch_log_content_job(fetch_older=False)\n        return jsonify(state.get_log_data_for_request())\n\
      \    except Exception as e:\n        logger.exception(\"Error preparing data\
      \ for /api/log_data\")\n        return jsonify({\"error\": \"Failed to prepare\
      \ log data\", \"detail\": str(e)}), 500\n\n@app.route('/api/fetch_older_logs')\n\
      def get_older_logs():\n    \"\"\"API endpoint triggered by user to fetch older\
      \ log entries.\"\"\"\n    logger.debug(\"Request received for /api/fetch_older_logs\"\
      )\n    # Trigger the job to fetch older logs. It runs async via the decorator/thread\
      \ pool.\n    # We return the *current* state immediately. The UI will update\
      \ when the fetch completes.\n    thread = threading.Thread(target=fetch_log_content_job,\
      \ args=(True,), name=\"FetchOlderLogsThread\")\n    thread.start()\n    logger.info(\"\
      Dispatched background thread to fetch older logs.\")\n    try:\n        # Return\
      \ current state, UI will poll or update based on subsequent fetches\n      \
      \  return jsonify(state.get_log_data_for_request())\n    except Exception as\
      \ e:\n        logger.exception(\"Error preparing data after triggering older\
      \ log fetch\")\n        return jsonify({\"error\": \"Failed to get log state\
      \ after triggering fetch\", \"detail\": str(e)}), 500\n\n@app.route('/api/toggle_log_refresh',\
      \ methods=['POST'])\ndef toggle_log_refresh():\n    \"\"\"API endpoint to enable/disable\
      \ log auto-refresh.\"\"\"\n    logger.debug(\"Request received for /api/toggle_log_refresh\"\
      )\n    try:\n        data = request.get_json()\n        if data is None or 'enabled'\
      \ not in data:\n            return jsonify({\"error\": \"Missing 'enabled' field\
      \ in request body\"}), 400\n\n        enabled = bool(data.get('enabled', False))\n\
      \        state.set_log_auto_refresh(enabled) # Update state\n        # No need\
      \ to restart scheduler here, the job checks the flag\n\n        return jsonify({\"\
      success\": True, \"enabled\": enabled})\n    except Exception as e:\n      \
      \  logger.exception(\"Error toggling log refresh state\")\n        return jsonify({\"\
      error\": \"Failed to toggle log refresh\", \"detail\": str(e)}), 500\n\n# ---\
      \ Main Execution ---\nif __name__ == '__main__':\n    # Disable SSL warnings\
      \ if running against local API with self-signed cert\n    is_local_api = \"\
      127.0.0.1\" in API_BASE_URL or \"localhost\" in API_BASE_URL\n    if is_local_api:\n\
      \        try:\n            import urllib3\n            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\
      \            logger.warning(\"SSL certificate verification disabled for API\
      \ requests (local dev).\")\n        except ImportError:\n            logger.warning(\"\
      urllib3 not found, cannot disable SSL warnings.\")\n        except Exception\
      \ as e:\n            logger.warning(f\"Could not disable urllib3 warnings: {e}\"\
      )\n\n    # Start the background scheduler thread\n    scheduler_thread = threading.Thread(target=run_scheduler,\
      \ name=\"SchedulerThread\", daemon=True)\n    scheduler_thread.start()\n\n \
      \   logger.info(f\" --- BrokerDash Pro Starting --- \")\n    logger.info(f\"\
      \ Dashboard server running on http://0.0.0.0:{DASHBOARD_PORT}\")\n    logger.info(f\"\
      \ Connecting to API at: {API_BASE_URL}\")\n    logger.info(f\" API Username:\
      \ {API_USERNAME}\")\n    logger.info(f\" Using SSL Verification for API: {not\
      \ is_local_api}\")\n    logger.info(f\" Fetch Intervals: Stats={FETCH_STATS_INTERVAL_SECONDS}s,\
      \ Queues={FETCH_QUEUES_INTERVAL_SECONDS}s, LogList={FETCH_LOGLIST_INTERVAL_SECONDS}s\"\
      )\n    logger.info(f\" Log Auto-Refresh Interval: {FETCH_LOGCONTENT_INTERVAL_SECONDS}s\"\
      )\n    logger.info(f\" Max Chart History: {MAX_CHART_HISTORY} points\")\n  \
      \  logger.info(f\" Log Chunk Size: {LOG_CHUNK_SIZE} lines\")\n    logger.info(f\"\
      \ ----------------------------- \")\n\n    try:\n        # Use Waitress for\
      \ a more production-ready server than Flask's dev server\n        try:\n   \
      \         from waitress import serve\n            logger.info(\"Starting server\
      \ with Waitress...\")\n            serve(app, host='0.0.0.0', port=DASHBOARD_PORT,\
      \ threads=12) # Increased threads\n        except ImportError:\n           \
      \ logger.warning(\"Waitress not found. Falling back to Flask's development server\
      \ (not recommended for production).\")\n            app.run(host='0.0.0.0',\
      \ port=DASHBOARD_PORT, debug=False, use_reloader=False)\n    except KeyboardInterrupt:\n\
      \        logger.info(\"Dashboard server stopped by user (KeyboardInterrupt).\"\
      )\n    except Exception as e:\n        logger.critical(f\"Dashboard server failed\
      \ to start or crashed: {e}\", exc_info=True)\n        logger.critical(\"Check\
      \ configuration, network connectivity, and permissions.\")\n\n    logger.info(\"\
      BrokerDash Pro server exiting.\")"
    tamanho: 0.14 MB
  webdashv1.py:
    caminho_completo: .\webdashv1.py
    classes: []
    functions:
    - docstring: Tenta fazer login na API principal e armazena os tokens.
      end_lineno: 137
      lineno: 67
      name: login_to_api
    - docstring: Busca dados de /stats da API principal, handling authentication.
      end_lineno: 286
      lineno: 140
      name: fetch_api_data
    - docstring: Executa o loop do agendador em uma thread separada.
      end_lineno: 310
      lineno: 289
      name: run_scheduler
    - docstring: Serve the main dashboard HTML page, rendering the template string.
      end_lineno: 978
      lineno: 964
      name: serve_dashboard
    - docstring: Endpoint for the frontend JavaScript to fetch the collected data.
      end_lineno: 1013
      lineno: 981
      name: get_dashboard_data
    imports:
    - asname: null
      name: os
    - asname: null
      name: time
    - asname: null
      name: threading
    - asname: null
      name: logging
    - module: collections
      names:
      - deque
    - module: threading
      names:
      - Lock
    - module: datetime
      names:
      - datetime
      - timezone
    - asname: null
      name: json
    - asname: null
      name: requests
    - asname: null
      name: schedule
    - module: flask
      names:
      - Flask
      - Response
      - jsonify
      - render_template_string
    - module: flask_cors
      names:
      - CORS
    - asname: null
      name: urllib3
    numero_de_linhas: 1049
    source_code: "# dashboard_server.py\nimport os\nimport time\nimport threading\n\
      import logging\nfrom collections import deque\nfrom threading import Lock\n\
      from datetime import datetime, timezone\nimport json # Import json for potential\
      \ decoding errors\n\nimport requests # Para fazer requisições à API principal\n\
      import schedule # Para agendar a coleta de dados\nfrom flask import Flask, Response,\
      \ jsonify, render_template_string\nfrom flask_cors import CORS\n\n# --- Configuração\
      \ ---\nDASHBOARD_PORT = 8333\nAPI_BASE_URL = os.environ.get(\"API_BASE_URL\"\
      , \"https://127.0.0.1:8777\") # Use HTTPS for the API\nAPI_STATS_URL = f\"{API_BASE_URL}/stats\"\
      \nAPI_LOGIN_URL = f\"{API_BASE_URL}/login\"\n\n# Credentials for the dashboard\
      \ to access the main API\n# !!! Use environment variables in production !!!\n\
      API_USERNAME = os.environ.get(\"API_USER\", \"admin\")\nAPI_PASSWORD = os.environ.get(\"\
      API_PASS\", \"admin\")\n\nFETCH_INTERVAL_SECONDS = 5 # Intervalo de coleta de\
      \ dados\nMAX_CHART_HISTORY = 60 # Pontos no histórico para gráficos de linha\n\
      \n# --- Configuração de Logging ---\n# Use basicConfig or integrate with Flask's\
      \ logger\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s\
      \ - %(name)s - %(levelname)s - %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n\
      )\nlogger = logging.getLogger('webdashv1') # Use a specific name for the dashboard\
      \ logger\n\n# --- Estado Global e Controle ---\napp_state = {\n    \"latest_stats\"\
      : {},\n    \"last_error\": None,\n    \"last_successful_fetch\": None,\n   \
      \ \"api_token\": None, # Store only the access token\n    \"refresh_token\"\
      : None, # Store refresh token if API supports refresh logic\n    \"login_needed\"\
      : True,\n    \"is_fetching\": False, # Flag to prevent concurrent fetches\n\
      \    # Histórico para gráficos\n    \"time_labels\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \    \"request_history\": deque(maxlen=MAX_CHART_HISTORY), # Deltas por intervalo\n\
      \    \"message_status_history\": {\n        \"pending\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \        \"processing\": deque(maxlen=MAX_CHART_HISTORY),\n        \"failed\"\
      : deque(maxlen=MAX_CHART_HISTORY),\n        \"processed\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \    },\n    \"performance_history\": {\n        \"cpu\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \        \"memory\": deque(maxlen=MAX_CHART_HISTORY),\n    },\n    \"previous_total_requests\"\
      : 0 # Para calcular delta\n}\ndata_lock = Lock() # Para proteger o acesso concorrente\
      \ ao app_state\n\n# --- Funções de Coleta e Processamento ---\n\ndef login_to_api():\n\
      \    \"\"\"Tenta fazer login na API principal e armazena os tokens.\"\"\"\n\
      \    global app_state\n    logger.info(f\"Attempting login to API at {API_LOGIN_URL}...\"\
      )\n    try:\n        # Use data payload for standard OAuth2 Password Flow\n\
      \        login_data = {'username': API_USERNAME, 'password': API_PASSWORD}\n\
      \n        # IMPORTANT: Disable SSL verification ONLY for local dev with self-signed\
      \ certs\n        # In production, use verify=True or path to your CA bundle\n\
      \        response = requests.post(API_LOGIN_URL, data=login_data, verify=False,\
      \ timeout=10)\n\n        response.raise_for_status() # Lança exceção para erros\
      \ HTTP 4xx/5xx\n\n        token_data = response.json()\n        if \"access_token\"\
      \ in token_data and \"refresh_token\" in token_data:\n            with data_lock:\n\
      \                app_state[\"api_token\"] = token_data[\"access_token\"]\n \
      \               app_state[\"refresh_token\"] = token_data[\"refresh_token\"\
      ] # Store if needed later\n                app_state[\"login_needed\"] = False\n\
      \                app_state[\"last_error\"] = None # Limpa erro de login anterior\n\
      \            logger.info(\"API login successful.\")\n            return True\n\
      \        else:\n            logger.error(\"API login response missing 'access_token'\
      \ or 'refresh_token'.\")\n            with data_lock:\n                app_state[\"\
      last_error\"] = \"Login response missing tokens\"\n                app_state[\"\
      api_token\"] = None\n                app_state[\"refresh_token\"] = None\n \
      \               app_state[\"login_needed\"] = True\n            return False\n\
      \n    except requests.exceptions.RequestException as e:\n        status_code\
      \ = getattr(e.response, 'status_code', 'N/A')\n        error_detail = f\"Status:\
      \ {status_code}\"\n        try:\n             # Try to get more details from\
      \ response body\n             if e.response is not None:\n                 #\
      \ Check content type before assuming JSON\n                 content_type = e.response.headers.get('Content-Type',\
      \ '')\n                 if 'application/json' in content_type:\n           \
      \         error_json = e.response.json()\n                    error_detail +=\
      \ f\" - Detail: {error_json.get('detail', error_json)}\"\n                 else:\n\
      \                    error_detail += f\" - Response: {e.response.text[:200]}\"\
      \ # Log snippet of non-JSON\n        except Exception: pass # Ignore if can't\
      \ read response body or decode JSON\n        logger.error(f\"API login failed\
      \ ({error_detail}): {e}\")\n        with data_lock:\n            app_state[\"\
      last_error\"] = f\"Login request failed: {e}\" # Store generic error\n     \
      \       app_state[\"api_token\"] = None\n            app_state[\"refresh_token\"\
      ] = None\n            app_state[\"login_needed\"] = True\n        return False\n\
      \    except json.JSONDecodeError as e:\n        # Handle cases where the response\
      \ is not valid JSON\n        response_text = getattr(e, 'doc', '') or getattr(e.response,\
      \ 'text', 'N/A')\n        logger.error(f\"API login failed: Could not decode\
      \ JSON response. Response text: {response_text[:500]}\")\n        with data_lock:\n\
      \            app_state[\"last_error\"] = \"Login response was not valid JSON\"\
      \n            app_state[\"api_token\"] = None\n            app_state[\"refresh_token\"\
      ] = None\n            app_state[\"login_needed\"] = True\n        return False\n\
      \    except Exception as e:\n        logger.error(f\"Unexpected error during\
      \ API login: {e}\", exc_info=True) # Log traceback for unexpected errors\n \
      \       with data_lock:\n            app_state[\"last_error\"] = f\"Unexpected\
      \ login error: {e}\"\n            app_state[\"api_token\"] = None\n        \
      \    app_state[\"refresh_token\"] = None\n            app_state[\"login_needed\"\
      ] = True\n        return False\n\n\ndef fetch_api_data():\n    \"\"\"Busca dados\
      \ de /stats da API principal, handling authentication.\"\"\"\n    global app_state\n\
      \n    # Prevent concurrent fetches\n    with data_lock:\n        if app_state.get(\"\
      is_fetching\", False):\n            logger.debug(\"Fetch cycle skipped, already\
      \ fetching.\")\n            return\n        app_state[\"is_fetching\"] = True\n\
      \        # Get needed state values under lock\n        token = app_state[\"\
      api_token\"]\n        login_needed = app_state[\"login_needed\"]\n\n    # Release\
      \ lock before network I/O\n    logger.debug(\"Starting data fetch cycle...\"\
      )\n\n    try: # Outer try for managing the 'is_fetching' flag\n        # ---\
      \ Handle Authentication ---\n        if login_needed or not token:\n       \
      \     logger.warning(\"Login required or token missing, attempting login...\"\
      )\n            if not login_to_api():\n                logger.error(\"Fetch\
      \ cycle aborted due to login failure.\")\n                # Update state with\
      \ login error if login_to_api didn't already\n                with data_lock:\n\
      \                     if app_state[\"last_error\"] is None:\n              \
      \           app_state[\"last_error\"] = \"Login required but failed\"\n    \
      \            return # Exit fetch cycle\n\n            # Re-fetch the token after\
      \ successful login (under lock)\n            with data_lock:\n             \
      \   token = app_state[\"api_token\"]\n                # If token is *still*\
      \ missing after a successful login_to_api call, something is wrong\n       \
      \         if not token:\n                     logger.error(\"CRITICAL: Token\
      \ still missing after supposedly successful login. Aborting fetch cycle.\")\n\
      \                     app_state[\"last_error\"] = \"Internal dashboard error:\
      \ Token lost after login.\"\n                     return\n\n        # --- Fetch\
      \ Stats Data ---\n        logger.debug(f\"Fetching stats from {API_STATS_URL}...\"\
      )\n        headers = {'Authorization': f'Bearer {token}', 'Accept': 'application/json'}\n\
      \n        try:\n            # Again, disable SSL verification ONLY for local\
      \ dev\n            response = requests.get(API_STATS_URL, headers=headers, verify=False,\
      \ timeout=10)\n\n            # Check for auth errors first\n            if response.status_code\
      \ == 401 or response.status_code == 403:\n                logger.warning(f\"\
      API returned {response.status_code} (Unauthorized/Forbidden) fetching stats.\
      \ Token likely expired. Forcing re-login.\")\n                with data_lock:\n\
      \                    app_state[\"api_token\"] = None\n                    #\
      \ Decide whether to clear refresh token too\n                    # app_state[\"\
      refresh_token\"] = None\n                    app_state[\"login_needed\"] = True\n\
      \                    app_state[\"last_error\"] = f\"API Auth error ({response.status_code}).\
      \ Re-login needed.\"\n                # No need to call login_to_api() here,\
      \ it will happen at the start of the next cycle\n                return # Abort\
      \ this cycle\n\n            # Check for other HTTP errors\n            response.raise_for_status()\n\
      \n            # ---- Process Successful Response ----\n            try:\n  \
      \              stats = response.json()\n                now = datetime.now(timezone.utc)\n\
      \                logger.debug(\"Stats received successfully from API.\")\n\n\
      \                # Process and update the state under lock\n               \
      \ with data_lock:\n                    app_state[\"latest_stats\"] = stats #\
      \ Store the raw stats object\n                    app_state[\"last_successful_fetch\"\
      ] = now.isoformat()\n                    app_state[\"last_error\"] = None #\
      \ Clear errors on success\n\n                    # --- Update history deques\
      \ ---\n                    current_time_label = now.strftime(\"%H:%M:%S\")\n\
      \                    app_state[\"time_labels\"].append(current_time_label)\n\
      \n                    # Calculate request delta safely\n                   \
      \ current_total_requests = stats.get(\"requests_total\")\n                 \
      \   request_delta = 0 # Default if calculation fails\n                    if\
      \ isinstance(current_total_requests, int):\n                        prev_total\
      \ = app_state[\"previous_total_requests\"]\n                        # Ensure\
      \ previous total is also valid before subtracting\n                        request_delta\
      \ = max(0, current_total_requests - (prev_total if isinstance(prev_total, int)\
      \ else 0))\n                        app_state[\"previous_total_requests\"] =\
      \ current_total_requests # Update for next cycle\n                    else:\n\
      \                        logger.warning(f\"`requests_total` missing or not integer\
      \ in stats response: {current_total_requests}. Delta calculation skipped.\"\
      )\n\n                    app_state[\"request_history\"].append(request_delta)\n\
      \n                    # Update message history (use .get with default 0)\n \
      \                   app_state[\"message_status_history\"][\"pending\"].append(stats.get(\"\
      messages_pending\", 0))\n                    app_state[\"message_status_history\"\
      ][\"processing\"].append(stats.get(\"messages_processing\", 0))\n          \
      \          app_state[\"message_status_history\"][\"failed\"].append(stats.get(\"\
      messages_failed\", 0))\n                    app_state[\"message_status_history\"\
      ][\"processed\"].append(stats.get(\"messages_processed\", 0))\n\n          \
      \          # Update performance history (handle potential missing nested keys\
      \ gracefully)\n                    system_stats = stats.get(\"system\", {})\
      \ # Default to empty dict if 'system' is missing\n                    cpu =\
      \ system_stats.get(\"process_cpu_percent\")\n                    mem = system_stats.get(\"\
      process_memory_mb\")\n                    # Ensure values are numeric before\
      \ appending, default to 0\n                    app_state[\"performance_history\"\
      ][\"cpu\"].append(cpu if isinstance(cpu, (int, float)) else 0)\n           \
      \         app_state[\"performance_history\"][\"memory\"].append(mem if isinstance(mem,\
      \ (int, float)) else 0)\n\n                logger.debug(\"Dashboard state updated\
      \ with new stats and history.\")\n\n            except json.JSONDecodeError\
      \ as e:\n                 logger.error(f\"Failed to decode JSON response from\
      \ API /stats: {e}. Response text: {response.text[:500]}\")\n               \
      \  with data_lock:\n                      app_state[\"last_error\"] = \"API\
      \ /stats response is not valid JSON\"\n            except Exception as processing_e:\
      \ # Catch errors during state update/processing\n                logger.error(f\"\
      Error processing received stats: {processing_e}\", exc_info=True)\n        \
      \        with data_lock:\n                    app_state[\"last_error\"] = f\"\
      Error processing stats: {processing_e}\"\n\n\n        # --- Handle Request Errors\
      \ ---\n        except requests.exceptions.Timeout:\n            logger.error(\"\
      API /stats request timed out.\")\n            with data_lock: app_state[\"last_error\"\
      ] = \"API Timeout fetching stats\"\n        except requests.exceptions.ConnectionError\
      \ as e:\n            logger.error(f\"API /stats connection error: {e}\")\n \
      \           with data_lock: app_state[\"last_error\"] = f\"API Connection Error:\
      \ {e}\"\n        except requests.exceptions.RequestException as e:\n       \
      \      # This catches other HTTP errors (like 500, 404 etc.) not handled above\n\
      \            status_code = getattr(e.response, 'status_code', 'N/A')\n     \
      \       logger.error(f\"API /stats request failed (Status: {status_code}): {e}\"\
      )\n            error_detail = f\"API Request Failed: {e}\"\n            try:\
      \ # Attempt to get response details\n                if e.response is not None:\n\
      \                    error_detail += f\" - Response: {e.response.text[:200]}\"\
      \n            except Exception: pass\n            with data_lock:\n        \
      \         # Avoid overwriting a more specific auth error logged earlier in the\
      \ cycle\n                 if app_state.get(\"last_error\") is None or \"Auth\
      \ error\" not in app_state[\"last_error\"]:\n                     app_state[\"\
      last_error\"] = error_detail\n\n    except Exception as outer_e:\n         #\
      \ Catch errors in the logic before the actual request (e.g., token fetching\
      \ issues missed)\n        logger.error(f\"Unexpected error during data fetch\
      \ setup: {outer_e}\", exc_info=True)\n        with data_lock:\n            app_state[\"\
      last_error\"] = f\"Unexpected Fetch Error: {outer_e}\"\n\n    finally:\n   \
      \     # Ensure the fetching flag is reset even if errors occur\n        with\
      \ data_lock:\n            app_state[\"is_fetching\"] = False\n\n\ndef run_scheduler():\n\
      \    \"\"\"Executa o loop do agendador em uma thread separada.\"\"\"\n    logger.info(\"\
      Scheduler thread started.\")\n    # Perform an initial fetch immediately before\
      \ starting the scheduled loop\n    # This helps populate the dashboard faster\
      \ on startup\n    try:\n        fetch_api_data()\n    except Exception as e:\n\
      \         logger.error(f\"Error during initial data fetch: {e}\", exc_info=True)\n\
      \n    # Schedule the regular fetching task\n    schedule.every(FETCH_INTERVAL_SECONDS).seconds.do(fetch_api_data)\n\
      \n    # Keep the scheduler running\n    while True:\n        try:\n        \
      \    schedule.run_pending()\n        except Exception as e:\n             #\
      \ Catch potential errors within the scheduler loop itself or the scheduled job\n\
      \             logger.error(f\"Error in scheduler loop: {e}\", exc_info=True)\n\
      \             # Avoid busy-waiting in case of continuous errors\n        time.sleep(1)\
      \ # Check schedule every second\n\n# --- Flask App ---\napp = Flask(__name__)\n\
      # Configure Flask logger to use our handler setup\napp.logger.handlers = logger.handlers\n\
      app.logger.setLevel(logger.level)\nCORS(app) # Enable CORS for all routes by\
      \ default\n\n# --- HTML Content (CRITICAL FIX: Added {% raw %} blocks) ---\n\
      HTML_CONTENT = \"\"\"\n<!DOCTYPE html>\n<html lang=\"pt-BR\">\n<head>\n    <meta\
      \ charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width,\
      \ initial-scale=1.0\">\n    <title>API Metrics Dashboard</title>\n    <script\
      \ src=\"https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js\"></script>\n\
      \    {# Add a simple Favicon using SVG inline #}\n    <link rel=\"icon\" href=\"\
      data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220\
      \ 0 100 100%22><path d=%22M8.3 25L41.7 8.3L75 25L41.7 41.7L8.3 25Z%22 stroke=%22%2300bcd4%22\
      \ stroke-width=%2210%22 fill=%22none%22/><path d=%22M8.3 75L41.7 58.3L75 75L41.7\
      \ 91.7L8.3 75Z%22 stroke=%22%2300bcd4%22 stroke-width=%2210%22 fill=%22none%22/><path\
      \ d=%22M8.3 50H75%22 stroke=%22%2300bcd4%22 stroke-width=%2210%22 fill=%22none%22/></svg>\"\
      >\n\n    {# ***** START RAW BLOCK FOR CSS ***** #}\n    {% raw %}\n    <style>\n\
      \        /* Reset and Base Styles */\n        * { box-sizing: border-box; margin:\
      \ 0; padding: 0; }\n        @keyframes fadeIn { from { opacity: 0; } to { opacity:\
      \ 1; } }\n        @keyframes highlight-value {\n            0%, 100% { transform:\
      \ scale(1); color: #fff; }\n            50% { transform: scale(1.05); color:\
      \ #80deea; } /* Lighter cyan highlight */\n        }\n        .value-changed\
      \ .card-value { animation: highlight-value 0.4s ease-out; }\n\n        body\
      \ {\n            font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\"\
      , Roboto, Helvetica, Arial, sans-serif;\n            background: #181a1f; color:\
      \ #e0e0e0; line-height: 1.5;\n            display: flex; flex-direction: column;\
      \ min-height: 100vh; overflow-x: hidden;\n        }\n\n        /* Header */\n\
      \        .app-header {\n            background: #21242a; padding: 10px 25px;\
      \ display: flex; align-items: center;\n            border-bottom: 1px solid\
      \ #3a3d4a; position: sticky; top: 0; z-index: 10;\n            box-shadow: 0\
      \ 2px 8px rgba(0, 0, 0, 0.2); flex-wrap: wrap;\n        }\n        .logo { display:\
      \ flex; align-items: center; margin-right: 20px; color: #00bcd4; /* Color for\
      \ SVG */ }\n        .logo svg { margin-right: 8px; }\n        .logo-text-main\
      \ { font-weight: 700; font-size: 1.4em; letter-spacing: 1px; color: #fff;}\n\
      \        .logo-text-sub { font-size: 0.45em; color: #a0a0a0; text-transform:\
      \ uppercase; line-height: 1; display: block; font-weight: normal; letter-spacing:\
      \ 0.5px; margin-top: -2px;}\n        .main-title { flex-grow: 1; text-align:\
      \ center; font-size: 1.2em; font-weight: 500; color: #c5c5c5; margin: 5px 15px;\
      \ }\n        .status-indicator { font-size: 0.95em; font-weight: 500; margin:\
      \ 5px 0; text-align: right; min-width: 150px; transition: color 0.3s ease; }\n\
      \        .status-indicator.live { color: #4caf50; } /* Green */\n        .status-indicator.error\
      \ { color: #f44336; font-weight: bold; } /* Red */\n        .status-indicator.stale\
      \ { color: #ff9800; } /* Orange */\n        .status-indicator.fetching { color:\
      \ #03a9f4; } /* Blue */\n\n        /* Main Content Grid */\n        .main-content\
      \ {\n            display: grid;\n            grid-template-columns: repeat(auto-fit,\
      \ minmax(200px, 1fr)); /* Responsive grid */\n            gap: 20px;\n     \
      \       padding: 25px;\n            flex-grow: 1;\n        }\n\n        /* Card\
      \ Styles */\n        .status-card {\n            border-radius: 8px; box-shadow:\
      \ 0 4px 12px rgba(0, 0, 0, 0.25);\n            overflow: hidden; display: flex;\
      \ flex-direction: column;\n            color: #ffffff; border: 1px solid rgba(255,\
      \ 255, 255, 0.08);\n            animation: fadeIn 0.5s ease-out forwards;\n\
      \            background-color: #2a2d35; /* Default background */\n         \
      \   transition: background-color 0.3s ease, transform 0.2s ease;\n        }\n\
      \        .status-card:hover { transform: translateY(-3px); box-shadow: 0 6px\
      \ 16px rgba(0, 0, 0, 0.3); }\n\n        /* Semantic background colors with gradients\
      \ */\n        .bg-pending { background: linear-gradient(135deg, #ffb74d, #ffa726);\
      \ } /* Orange */\n        .bg-processing { background: linear-gradient(135deg,\
      \ #64b5f6, #42a5f5); } /* Blue */\n        .bg-failed { background: linear-gradient(135deg,\
      \ #e57373, #ef5350); } /* Red */\n        .bg-processed { background: linear-gradient(135deg,\
      \ #81c784, #66bb6a); } /* Green */\n        .bg-requests { background: linear-gradient(135deg,\
      \ #7986cb, #5c6bc0); } /* Indigo */\n        .bg-cpu { background: linear-gradient(135deg,\
      \ #ba68c8, #ab47bc); } /* Purple */\n        .bg-mem { background: linear-gradient(135deg,\
      \ #4dd0e1, #26c6da); } /* Cyan */\n        .bg-uptime { background: linear-gradient(135deg,\
      \ #90a4ae, #78909c); } /* Blue Grey */\n\n        .card-main-content { padding:\
      \ 15px 20px 20px 20px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); text-align:\
      \ center; flex-grow: 1; display: flex; flex-direction: column; justify-content:\
      \ center; }\n        .card-title { font-size: 0.8em; font-weight: 600; color:\
      \ rgba(255, 255, 255, 0.85); margin-bottom: 10px; text-transform: uppercase;\
      \ letter-spacing: 0.5px; }\n        .card-value { font-size: 2.3em; font-weight:\
      \ 700; line-height: 1; color: #ffffff; display: block; transition: transform\
      \ 0.2s ease; }\n\n        /* Chart Section */\n        .charts-section {\n \
      \            display: grid;\n             grid-template-columns: repeat(auto-fit,\
      \ minmax(350px, 1fr)); /* Responsive grid */\n             gap: 20px;\n    \
      \         padding: 0 25px 25px 25px; /* Padding below cards */\n        }\n\
      \        .chart-card {\n            background: #2a2d35; border-radius: 8px;\
      \ padding: 20px;\n            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.25);\n\
      \            border: 1px solid rgba(255, 255, 255, 0.08);\n            animation:\
      \ fadeIn 0.6s ease-out forwards;\n            display: flex; flex-direction:\
      \ column; /* Ensure title and canvas stack */\n        }\n         .chart-title\
      \ {\n            font-size: 1em; font-weight: 600; color: #e0e0e0; margin-bottom:\
      \ 15px; text-align: center;\n         }\n        .chart-container {\n      \
      \      height: 250px; /* Fixed height for charts */\n            position: relative;\n\
      \            flex-grow: 1; /* Allow chart container to fill space */\n     \
      \   }\n        .chart-container canvas { display: block; width: 100%; height:\
      \ 100%; }\n\n        /* Footer */\n        .app-footer { text-align: center;\
      \ padding: 15px; margin-top: auto; font-size: 0.85em; color: #888; border-top:\
      \ 1px solid #3a3d4a; background: #1f2128; }\n        .app-footer #backend-status\
      \ { font-weight: 500; display: block; margin-top: 5px; transition: color 0.3s\
      \ ease;}\n        .app-footer #backend-status.error { color: #f44336; font-weight:\
      \ bold; }\n        .app-footer #backend-status.success { color: #bdc3c7; } /*\
      \ Subtle color for success */\n\n        /* Responsive */\n        @media (max-width:\
      \ 768px) {\n            .main-content, .charts-section { padding: 15px; gap:\
      \ 15px; }\n            .app-header { padding: 8px 15px; flex-direction: column;\
      \ align-items: flex-start; }\n            .main-title { text-align: left; margin:\
      \ 8px 0; }\n            .status-indicator { align-self: flex-end; margin-top:\
      \ -25px; } /* Adjust positioning */\n            .card-value { font-size: 2em;\
      \ }\n            .charts-section { grid-template-columns: 1fr; } /* Single column\
      \ charts */\n        }\n         @media (max-width: 480px) {\n             .card-value\
      \ { font-size: 1.8em; }\n             .main-content { grid-template-columns:\
      \ 1fr 1fr; } /* 2 columns on small */\n         }\n    </style>\n    {% endraw\
      \ %}\n    {# ***** END RAW BLOCK FOR CSS ***** #}\n\n</head>\n<body>\n\n   \
      \ <header class=\"app-header\">\n         <div class=\"logo\">\n           \
      \ <svg width=\"25\" height=\"25\" viewBox=\"0 0 100 100\" fill=\"none\" xmlns=\"\
      http://www.w3.org/2000/svg\">\n                <path d=\"M8.33331 25L41.6666\
      \ 8.33331L75 25L41.6666 41.6666L8.33331 25Z\" stroke=\"currentColor\" stroke-width=\"\
      10\"/>\n                <path d=\"M8.33331 75L41.6666 58.3333L75 75L41.6666\
      \ 91.6666L8.33331 75Z\" stroke=\"currentColor\" stroke-width=\"10\"/>\n    \
      \            <path d=\"M8.33331 50H75\" stroke=\"currentColor\" stroke-width=\"\
      10\"/>\n            </svg>\n            <div>\n                <span class=\"\
      logo-text-main\">API</span>\n                <span class=\"logo-text-sub\">Metrics\
      \ Dashboard</span>\n            </div>\n        </div>\n        <h1 class=\"\
      main-title\">Live System Status</h1>\n        <div id=\"status-indicator\" class=\"\
      status-indicator stale\">Initializing...</div>\n    </header>\n\n    <main class=\"\
      main-content\" id=\"metric-cards\">\n        <!-- Cards dynamically updated\
      \ by JS - add relevant bg class -->\n        <div class=\"status-card bg-pending\"\
      \ id=\"card-pending-msgs\"><div class=\"card-main-content\"><div class=\"card-title\"\
      >Pending Msgs</div><div class=\"card-value\">--</div></div></div>\n        <div\
      \ class=\"status-card bg-processing\" id=\"card-processing-msgs\"><div class=\"\
      card-main-content\"><div class=\"card-title\">Processing Msgs</div><div class=\"\
      card-value\">--</div></div></div>\n        <div class=\"status-card bg-failed\"\
      \ id=\"card-failed-msgs\"><div class=\"card-main-content\"><div class=\"card-title\"\
      >Failed Msgs</div><div class=\"card-value\">--</div></div></div>\n        <div\
      \ class=\"status-card bg-processed\" id=\"card-processed-msgs\"><div class=\"\
      card-main-content\"><div class=\"card-title\">Processed Msgs</div><div class=\"\
      card-value\">--</div></div></div>\n        <div class=\"status-card bg-requests\"\
      \ id=\"card-total-requests\"><div class=\"card-main-content\"><div class=\"\
      card-title\">Total Reqs</div><div class=\"card-value\">--</div></div></div>\n\
      \        <div class=\"status-card bg-cpu\" id=\"card-process-cpu\"><div class=\"\
      card-main-content\"><div class=\"card-title\">Process CPU %</div><div class=\"\
      card-value\">--</div></div></div>\n        <div class=\"status-card bg-mem\"\
      \ id=\"card-process-mem\"><div class=\"card-main-content\"><div class=\"card-title\"\
      >Process Mem (MB)</div><div class=\"card-value\">--</div></div></div>\n    \
      \    <div class=\"status-card bg-uptime\" id=\"card-uptime\"><div class=\"card-main-content\"\
      ><div class=\"card-title\">Uptime</div><div class=\"card-value\">--</div></div></div>\n\
      \    </main>\n\n    <section class=\"charts-section\">\n        <!-- Chart Canvases\
      \ -->\n        <div class=\"chart-card\">\n            <div class=\"chart-title\"\
      >\U0001F4C8 Requests / Interval (Last <span id=\"req-chart-points\">N</span>\
      \ points)</div>\n            <div class=\"chart-container\"><canvas id=\"requestsChart\"\
      ></canvas></div>\n        </div>\n        <div class=\"chart-card\">\n     \
      \       <div class=\"chart-title\">✉️ Message Status (Last <span id=\"msg-chart-points\"\
      >N</span> points)</div>\n            <div class=\"chart-container\"><canvas\
      \ id=\"messageStatusChart\"></canvas></div>\n        </div>\n        <div class=\"\
      chart-card\">\n            <div class=\"chart-title\">⚙️ Performance (Last <span\
      \ id=\"perf-chart-points\">N</span> points)</div>\n            <div class=\"\
      chart-container\"><canvas id=\"performanceChart\"></canvas></div>\n        </div>\n\
      \        <div class=\"chart-card\">\n            <div class=\"chart-title\"\
      >\U0001F6E3️ Requests by Route (Current Totals)</div>\n            <div class=\"\
      chart-container\"><canvas id=\"requestsByRouteChart\"></canvas></div>\n    \
      \    </div>\n         <div class=\"chart-card\">\n            <div class=\"\
      chart-title\">\U0001F6A6 Requests by Status Code (Current Totals)</div>\n  \
      \          <div class=\"chart-container\"><canvas id=\"requestsByStatusChart\"\
      ></canvas></div>\n        </div>\n    </section>\n\n    <footer class=\"app-footer\"\
      >\n        Real-time API Metrics Dashboard\n        <span id=\"backend-status\"\
      \ class=\"success\">Initializing...</span>\n    </footer>\n\n    {# ***** START\
      \ RAW BLOCK FOR JAVASCRIPT ***** #}\n    {% raw %}\n    <script>\n        //\
      \ --- CONFIGURATION (Injected by Flask) ---\n        // Use 'const' for variables\
      \ that don't change after init\n        const DASHBOARD_DATA_URL = '/api/dashboard_data';\n\
      \        const POLLING_INTERVAL_MS = {{ FETCH_INTERVAL_SECONDS * 1000 }};\n\
      \        const MAX_CHART_HISTORY = {{ MAX_CHART_HISTORY }};\n\n        // ---\
      \ GLOBAL STATE ---\n        let chartInstances = {}; // Use let as it's reassigned\
      \ during init\n        let fetchDataIntervalId = null;\n        let lastKnownError\
      \ = null; // Track the last error shown to avoid redundant updates\n\n     \
      \   // --- DOM Elements Cache (Ensure caching happens after DOM is loaded) ---\n\
      \        let statusIndicator = null;\n        let backendStatusSpan = null;\n\
      \        let cardValueElements = {};\n\n        function cacheDOMElements()\
      \ {\n            statusIndicator = document.getElementById('status-indicator');\n\
      \            backendStatusSpan = document.getElementById('backend-status');\n\
      \            cardValueElements = {\n                pendingMsgs: document.querySelector('#card-pending-msgs\
      \ .card-value'),\n                processingMsgs: document.querySelector('#card-processing-msgs\
      \ .card-value'),\n                failedMsgs: document.querySelector('#card-failed-msgs\
      \ .card-value'),\n                processedMsgs: document.querySelector('#card-processed-msgs\
      \ .card-value'),\n                totalRequests: document.querySelector('#card-total-requests\
      \ .card-value'),\n                processCpu: document.querySelector('#card-process-cpu\
      \ .card-value'),\n                processMem: document.querySelector('#card-process-mem\
      \ .card-value'),\n                uptime: document.querySelector('#card-uptime\
      \ .card-value')\n            };\n             // Update chart point display\
      \ spans dynamically based on config\n             try { // Add try-catch for\
      \ robustness if elements don't exist\n                document.getElementById('req-chart-points').textContent\
      \ = MAX_CHART_HISTORY;\n                document.getElementById('msg-chart-points').textContent\
      \ = MAX_CHART_HISTORY;\n                document.getElementById('perf-chart-points').textContent\
      \ = MAX_CHART_HISTORY;\n             } catch (e) {\n                console.warn(\"\
      Could not update chart point labels:\", e);\n             }\n        }\n\n\n\
      \        // --- UTILITY FUNCTIONS ---\n        function formatNumber(num) {\n\
      \            // Ensure input is treated as a number, return '--' if invalid\n\
      \            const number = Number(num);\n            return (num === null ||\
      \ num === undefined || isNaN(number)) ? '--' : number.toLocaleString('pt-BR');\n\
      \        }\n        function formatPercentage(num) {\n            const number\
      \ = Number(num);\n            return (num === null || num === undefined || isNaN(number))\
      \ ? '--' : number.toFixed(1) + '%';\n        }\n        function formatMemory(num)\
      \ {\n            const number = Number(num);\n            return (num === null\
      \ || num === undefined || isNaN(number)) ? '--' : number.toFixed(1) + ' MB';\n\
      \        }\n        // Updates a card's value, formats it, and adds a highlight\
      \ effect\n        function updateCardValue(element, newValue, formatter = formatNumber)\
      \ {\n            if (!element) return; // Guard against null elements\n    \
      \        const formattedValue = formatter(newValue);\n            // Only update\
      \ if the value actually changed or if it's currently '--'\n            if (element.textContent\
      \ !== formattedValue) {\n                element.textContent = formattedValue;\n\
      \                const card = element.closest('.status-card'); // Find the parent\
      \ card\n                if (card) {\n                    // Simple highlight:\
      \ quick class toggle\n                    card.classList.add('value-changed');\n\
      \                    setTimeout(() => card.classList.remove('value-changed'),\
      \ 400); // Remove after animation duration\n                    // // Reflow\
      \ method (more complex, sometimes needed for rapid changes)\n              \
      \      // card.classList.remove('value-changed');\n                    // void\
      \ card.offsetWidth; // Force reflow\n                    // card.classList.add('value-changed');\n\
      \                }\n            }\n        }\n        // Generates colors for\
      \ categorical charts, cycling through a base palette\n        function generateColors(count)\
      \ {\n             // Palette adjusted for better contrast/variety\n        \
      \     const baseColors = ['#64b5f6', '#81c784', '#ffb74d', '#e57373', '#ba68c8',\
      \ '#4dd0e1', '#fff176', '#7986cb', '#a1887f', '#90a4ae'];\n             const\
      \ colors = [];\n             for (let i = 0; i < count; i++) {\n           \
      \      colors.push(baseColors[i % baseColors.length]);\n             }\n   \
      \          return colors;\n         }\n        // Resets card values to '--'\
      \ (e.g., on initial load or error)\n         function clearCards() {\n     \
      \        Object.values(cardValueElements).forEach(el => { if(el) el.textContent\
      \ = '--'; });\n         }\n        // Function to safely update chart data,\
      \ handling potential missing datasets\n        function updateChartData(chartInstance,\
      \ newLabels, newDatasetsData) {\n            // Guard clauses\n            if\
      \ (!chartInstance || !chartInstance.data || !chartInstance.data.datasets) {\n\
      \                console.warn(\"Attempted to update non-existent or invalid\
      \ chart instance.\");\n                return;\n            }\n            if\
      \ (!Array.isArray(newLabels)) newLabels = [];\n            if (!Array.isArray(newDatasetsData))\
      \ newDatasetsData = [];\n\n            chartInstance.data.labels = newLabels;\n\
      \n            // Update each dataset present in the chart instance\n       \
      \     chartInstance.data.datasets.forEach((dataset, index) => {\n          \
      \      // Check if corresponding new data exists\n                if (newDatasetsData[index]\
      \ !== undefined && Array.isArray(newDatasetsData[index])) {\n              \
      \      dataset.data = newDatasetsData[index];\n\n                    // Update\
      \ colors dynamically ONLY for categorical charts needing it (like bar/doughnut)\n\
      \                    // Check if backgroundColor is an array (indicating categorical)\n\
      \                    if (chartInstance.config.type === 'bar' || chartInstance.config.type\
      \ === 'doughnut') {\n                       if(Array.isArray(dataset.backgroundColor))\
      \ {\n                           dataset.backgroundColor = generateColors(newDatasetsData[index].length);\n\
      \                       }\n                       // You might need similar\
      \ logic for borderColor if needed\n                    }\n                }\
      \ else {\n                    // If no new data for this dataset index, clear\
      \ it\n                    dataset.data = [];\n                    console.warn(`No\
      \ data provided for dataset index ${index} in chart. Clearing it.`);\n     \
      \           }\n            });\n\n            // Update the chart without animation\
      \ for smoother live updates\n            chartInstance.update('none');\n   \
      \     }\n\n\n        // --- CHART INITIALIZATION ---\n         function initializeCharts()\
      \ {\n             console.log(\"Initializing charts...\");\n             //\
      \ Set Chart.js defaults for better appearance\n             Chart.defaults.color\
      \ = '#e0e0e0'; // Default font color for scales, legends, tooltips\n       \
      \      Chart.defaults.borderColor = 'rgba(255, 255, 255, 0.1)'; // Default grid\
      \ line color\n\n             const defaultLineOptions = {\n                \
      \ responsive: true, maintainAspectRatio: false, // Essential for resizing\n\
      \                 animation: { duration: 250, easing: 'linear' }, // Subtle\
      \ animation\n                 plugins: {\n                     legend: {\n \
      \                        display: true, position: 'bottom',\n              \
      \           labels: { padding: 10, boxWidth: 12, font: { size: 11 } }\n    \
      \                 },\n                     tooltip: {\n                    \
      \     mode: 'index', intersect: false, // Show tooltips for all datasets at\
      \ that index\n                         backgroundColor: 'rgba(0,0,0,0.8)', titleFont:\
      \ { weight: 'bold' },\n                         bodySpacing: 4, padding: 8,\
      \ boxPadding: 4\n                     }\n                 },\n             \
      \    scales: {\n                     x: {\n                         ticks: {\
      \ maxRotation: 0, autoSkip: true, maxTicksLimit: 10, font: { size: 10 } },\n\
      \                         grid: { display: true } // Keep X grid lines subtle\n\
      \                     },\n                     y: { // Default Y axis (can be\
      \ overridden)\n                         ticks: { beginAtZero: true, font: {\
      \ size: 10 }, precision: 0 }, // Default to whole numbers if possible\n    \
      \                     grid: { display: true, color: 'rgba(255, 255, 255, 0.08)'\
      \ } // Lighter Y grid\n                     }\n                 },\n       \
      \          elements: {\n                     line: { tension: 0.2, borderWidth:\
      \ 1.5 }, // Slight curve, standard width\n                     point: { radius:\
      \ 0, hitRadius: 10, hoverRadius: 4 } // No points normally, larger hit area\n\
      \                 },\n                 interaction: { // Improve hover interaction\n\
      \                     mode: 'nearest', axis: 'x', intersect: false\n       \
      \          }\n             };\n\n             // Requests Chart (Line)\n   \
      \          const reqCtx = document.getElementById('requestsChart')?.getContext('2d');\n\
      \             if (reqCtx) {\n                 const reqOptions = JSON.parse(JSON.stringify(defaultLineOptions));\
      \ // Clone options\n                 chartInstances.requests = new Chart(reqCtx,\
      \ {\n                     type: 'line',\n                     data: { labels:\
      \ [], datasets: [{\n                         label: 'Requests/Interval', data:\
      \ [],\n                         borderColor: '#64b5f6', backgroundColor: 'rgba(100,\
      \ 181, 246, 0.2)', fill: true\n                     }] },\n                \
      \     options: reqOptions\n                 });\n             } else { console.error(\"\
      Canvas element #requestsChart not found\"); }\n\n             // Message Status\
      \ Chart (Line)\n             const msgCtx = document.getElementById('messageStatusChart')?.getContext('2d');\n\
      \              if (msgCtx) {\n                 const msgOptions = JSON.parse(JSON.stringify(defaultLineOptions));\
      \ // Clone options\n                 msgOptions.elements.line.borderWidth =\
      \ 2; // Make lines slightly thicker\n                 chartInstances.messageStatus\
      \ = new Chart(msgCtx, {\n                     type: 'line',\n              \
      \       data: { labels: [], datasets: [\n                         { label: 'Pending',\
      \ data: [], borderColor: '#ffb74d', fill: false }, // Orange\n             \
      \            { label: 'Processing', data: [], borderColor: '#64b5f6', fill:\
      \ false }, // Blue\n                         { label: 'Failed', data: [], borderColor:\
      \ '#e57373', fill: false },    // Red\n                         { label: 'Processed',\
      \ data: [], borderColor: '#81c784', fill: false }  // Green\n              \
      \       ] },\n                     options: msgOptions\n                 });\n\
      \             } else { console.error(\"Canvas element #messageStatusChart not\
      \ found\"); }\n\n             // Performance Chart (Line with Multi-Axis)\n\
      \             const perfCtx = document.getElementById('performanceChart')?.getContext('2d');\n\
      \              if (perfCtx) {\n                 const perfOptions = JSON.parse(JSON.stringify(defaultLineOptions));\
      \ // Clone options\n                 // Define specific Y axes\n           \
      \      perfOptions.scales.yCpu = { // Use unique IDs\n                     type:\
      \ 'linear', position: 'left', title: { display: true, text: 'CPU (%)', color:\
      \ '#ba68c8' },\n                     ticks: { color: '#ba68c8', suggestedMax:\
      \ 100, beginAtZero: true, precision: 1 }, // Allow decimals\n              \
      \       grid: { drawOnChartArea: true } // Primary axis grid\n             \
      \    };\n                 perfOptions.scales.yMem = { // Use unique IDs\n  \
      \                   type: 'linear', position: 'right', title: { display: true,\
      \ text: 'Memory (MB)', color: '#4dd0e1' },\n                     ticks: { color:\
      \ '#4dd0e1', beginAtZero: true, precision: 1 }, // Allow decimals\n        \
      \             grid: { drawOnChartArea: false }, // No grid for secondary axis\n\
      \                 };\n                 delete perfOptions.scales.y; // Remove\
      \ the default 'y' scale\n\n                 chartInstances.performance = new\
      \ Chart(perfCtx, {\n                     type: 'line',\n                   \
      \  data: { labels: [], datasets: [\n                         { label: 'Process\
      \ CPU %', data: [], borderColor: '#ba68c8', fill: false, yAxisID: 'yCpu' },\
      \ // Purple\n                         { label: 'Process Mem (MB)', data: [],\
      \ borderColor: '#4dd0e1', fill: false, yAxisID: 'yMem' } // Cyan\n         \
      \            ] },\n                     options: perfOptions\n             \
      \    });\n             } else { console.error(\"Canvas element #performanceChart\
      \ not found\"); }\n\n             // Default options for Bar/Doughnut\n    \
      \         const defaultCategoricalOptions = {\n                 responsive:\
      \ true, maintainAspectRatio: false,\n                 plugins: {\n         \
      \            legend: { display: true, position: 'bottom', labels: { padding:\
      \ 10, boxWidth: 12, font: { size: 11 } } },\n                     tooltip: {\
      \ backgroundColor: 'rgba(0,0,0,0.8)', titleFont: { weight: 'bold' }, bodySpacing:\
      \ 4, padding: 8, boxPadding: 4 }\n                 }\n             };\n\n  \
      \           // Requests by Route Chart (Horizontal Bar)\n             const\
      \ routeCtx = document.getElementById('requestsByRouteChart')?.getContext('2d');\n\
      \             if (routeCtx) {\n                 const routeOptions = JSON.parse(JSON.stringify(defaultCategoricalOptions));\
      \ // Clone options\n                 routeOptions.indexAxis = 'y'; // Make bars\
      \ horizontal\n                 routeOptions.plugins.legend.display = false;\
      \ // Hide legend (often too many items)\n                 routeOptions.scales\
      \ = {\n                     x: { ticks: { precision: 0, beginAtZero: true },\
      \ grid: { color: 'rgba(255,255,255,0.08)' } }, // X axis = count\n         \
      \            y: { ticks: { font: { size: 10 } }, grid: { display: false } }\
      \ // Y axis = route name\n                 };\n                 chartInstances.requestsByRoute\
      \ = new Chart(routeCtx, {\n                     type: 'bar',\n             \
      \        data: { labels: [], datasets: [{ label: 'Count', data: [], backgroundColor:\
      \ [] }] }, // Colors generated dynamically\n                     options: routeOptions\n\
      \                 });\n             } else { console.error(\"Canvas element\
      \ #requestsByRouteChart not found\"); }\n\n             // Requests by Status\
      \ Chart (Doughnut)\n             const statusCtx = document.getElementById('requestsByStatusChart')?.getContext('2d');\n\
      \              if (statusCtx) {\n                 const statusOptions = JSON.parse(JSON.stringify(defaultCategoricalOptions));\n\
      \                 statusOptions.plugins.legend.position = 'right'; // Position\
      \ legend for doughnut\n                 chartInstances.requestsByStatus = new\
      \ Chart(statusCtx, {\n                     type: 'doughnut',\n             \
      \        data: { labels: [], datasets: [{\n                         label: 'Count',\
      \ data: [], backgroundColor: [], borderWidth: 1, hoverOffset: 8\n          \
      \           }] }, // Colors generated dynamically\n                     options:\
      \ statusOptions\n                 });\n             } else { console.error(\"\
      Canvas element #requestsByStatusChart not found\"); }\n\n             console.log(\"\
      Charts initialized.\");\n         }\n\n\n        // --- DATA FETCHING AND PROCESSING\
      \ ---\n        async function fetchData() {\n            // Indicate fetching\
      \ visually, but only if not already showing an error\n            if (statusIndicator\
      \ && !statusIndicator.classList.contains('error')) {\n                 statusIndicator.textContent\
      \ = 'Fetching...';\n                 statusIndicator.className = 'status-indicator\
      \ fetching';\n            }\n            console.debug(`[${new Date().toLocaleTimeString()}]\
      \ Fetching data from ${DASHBOARD_DATA_URL}`);\n\n            try {\n       \
      \         const response = await fetch(DASHBOARD_DATA_URL);\n\n            \
      \    // Handle HTTP errors from the dashboard server itself\n              \
      \  if (!response.ok) {\n                    let errorMsg = `Error fetching dashboard\
      \ data: ${response.status} ${response.statusText}`;\n                    try\
      \ {\n                        // Attempt to get more detail from the response\
      \ body\n                        const errorData = await response.json();\n \
      \                       errorMsg += ` - ${errorData.error || JSON.stringify(errorData)}`;\n\
      \                    } catch (e) { /* Ignore if response body is not JSON or\
      \ empty */ }\n                    throw new Error(errorMsg); // Throw to be\
      \ caught by the outer catch block\n                }\n\n                const\
      \ data = await response.json();\n                // console.debug(\"Raw dashboard\
      \ data received:\", JSON.stringify(data, null, 2)); // Verbose logging if needed\n\
      \n                // --- Process the received data ---\n                // Check\
      \ if the dashboard backend reported an error *during its API fetch*\n      \
      \          if (data.error) {\n                    if (lastKnownError !== data.error)\
      \ { // Avoid spamming the same error\n                        console.error(\"\
      Dashboard backend reported API fetch error:\", data.error);\n              \
      \          if (statusIndicator) {\n                            statusIndicator.textContent\
      \ = 'API Error';\n                            statusIndicator.className = 'status-indicator\
      \ error';\n                        }\n                        if (backendStatusSpan)\
      \ {\n                            backendStatusSpan.textContent = `API Error:\
      \ ${data.error}`;\n                            backendStatusSpan.className =\
      \ 'error';\n                        }\n                        lastKnownError\
      \ = data.error;\n                        // Decide whether to clear data or\
      \ leave stale data visible\n                        // clearCards(); // Option:\
      \ Clear cards on backend error\n                    }\n                // Check\
      \ if the stats object is missing or empty\n                } else if (!data.latest_stats\
      \ || Object.keys(data.latest_stats).length === 0) {\n                    if\
      \ (lastKnownError !== \"Empty stats data\") { // Avoid spamming\n          \
      \              console.warn(\"Dashboard backend returned empty 'latest_stats'\
      \ data.\");\n                        if (statusIndicator) {\n              \
      \              statusIndicator.textContent = 'No Data';\n                  \
      \          statusIndicator.className = 'status-indicator stale';\n         \
      \               }\n                         const fetchTime = data.last_successful_fetch\
      \ ? new Date(data.last_successful_fetch).toLocaleString('pt-BR') : 'Never';\n\
      \                        if (backendStatusSpan) {\n                        \
      \    backendStatusSpan.textContent = `No stats received. Last API fetch: ${fetchTime}`;\n\
      \                            backendStatusSpan.className = 'error'; // Style\
      \ as error/warning\n                        }\n                        lastKnownError\
      \ = \"Empty stats data\";\n                        clearCards(); // Clear cards\
      \ if no valid data received\n                        // Optionally clear charts\
      \ too\n                        Object.values(chartInstances).forEach(chart =>\
      \ updateChartData(chart, [], []));\n                    }\n                }\
      \ else {\n                    // --- Success Case: Valid data received ---\n\
      \                    if (statusIndicator) {\n                        statusIndicator.textContent\
      \ = 'Live';\n                        statusIndicator.className = 'status-indicator\
      \ live';\n                    }\n                    const fetchTime = data.last_successful_fetch\
      \ ? new Date(data.last_successful_fetch).toLocaleString('pt-BR') : 'Never';\n\
      \                    if (backendStatusSpan) {\n                        backendStatusSpan.textContent\
      \ = `Last API fetch: ${fetchTime}`;\n                        backendStatusSpan.className\
      \ = 'success';\n                    }\n                    updateDashboardUI(data);\
      \ // Update UI with fresh data\n                    lastKnownError = null; //\
      \ Clear the tracked error on success\n                }\n\n            } catch\
      \ (error) {\n                // --- Error fetching data *from the dashboard\
      \ server itself* ---\n                if (lastKnownError !== error.message)\
      \ { // Avoid spamming\n                    console.error(\"Error fetching or\
      \ processing dashboard data from /api/dashboard_data:\", error);\n         \
      \           if (statusIndicator) {\n                        statusIndicator.textContent\
      \ = 'Dashboard Error';\n                        statusIndicator.className =\
      \ 'status-indicator error';\n                    }\n                    if (backendStatusSpan)\
      \ {\n                        backendStatusSpan.textContent = `Dashboard Fetch\
      \ Error: ${error.message}`;\n                        backendStatusSpan.className\
      \ = 'error';\n                    }\n                    lastKnownError = error.message;\n\
      \                    clearCards(); // Clear cards on dashboard fetch error\n\
      \                    // Optionally clear charts too\n                    Object.values(chartInstances).forEach(chart\
      \ => updateChartData(chart, [], []));\n                 }\n            }\n \
      \       }\n\n        // --- UI UPDATE FUNCTION ---\n        function updateDashboardUI(data)\
      \ {\n            // Basic validation already done in fetchData, but double-check\
      \ core objects\n            if (!data?.latest_stats || !data?.history) {\n \
      \                console.warn(\"updateDashboardUI called with incomplete data\
      \ structure. Aborting UI update.\");\n                 return;\n           \
      \ }\n\n            const stats = data.latest_stats;\n            const history\
      \ = data.history;\n            const timeLabels = history.time_labels || [];\
      \ // Use default empty array\n\n            // console.debug(\"Updating UI with\
      \ stats:\", stats); // Uncomment for detailed debug\n\n            // --- Update\
      \ Cards ---\n            updateCardValue(cardValueElements.pendingMsgs, stats.messages_pending);\n\
      \            updateCardValue(cardValueElements.processingMsgs, stats.messages_processing);\n\
      \            updateCardValue(cardValueElements.failedMsgs, stats.messages_failed);\n\
      \            updateCardValue(cardValueElements.processedMsgs, stats.messages_processed);\n\
      \            updateCardValue(cardValueElements.totalRequests, stats.requests_total);\n\
      \            // Use optional chaining (?.) and nullish coalescing (??) for safer\
      \ access\n            updateCardValue(cardValueElements.processCpu, stats.system?.process_cpu_percent\
      \ ?? null, formatPercentage);\n            updateCardValue(cardValueElements.processMem,\
      \ stats.system?.process_memory_mb ?? null, formatMemory);\n            updateCardValue(cardValueElements.uptime,\
      \ stats.uptime_human, (val) => val || '--');\n\n            // --- Update Line\
      \ Charts ---\n            updateChartData(chartInstances.requests, timeLabels,\
      \ [\n                history.request_history || []\n            ]);\n      \
      \      updateChartData(chartInstances.messageStatus, timeLabels, [\n       \
      \         history.message_status?.pending || [],\n                history.message_status?.processing\
      \ || [],\n                history.message_status?.failed || [],\n          \
      \      history.message_status?.processed || []\n            ]);\n          \
      \   updateChartData(chartInstances.performance, timeLabels, [\n            \
      \    history.performance?.cpu || [],\n                history.performance?.memory\
      \ || []\n             ]);\n\n            // --- Update Categorical Charts (Bar\
      \ and Doughnut) ---\n            // Requests by Route (Horizontal Bar)\n   \
      \         if (chartInstances.requestsByRoute) {\n                const routes\
      \ = stats.requests_by_route || {};\n                // Sort routes alphabetically\
      \ for consistent order\n                const routeLabels = Object.keys(routes).sort();\n\
      \                const routeData = routeLabels.map(route => {\n            \
      \        // Sum counts for all methods under this route path\n             \
      \       const methods = routes[route] || {};\n                    return Object.values(methods).reduce((sum,\
      \ count) => sum + (Number(count) || 0), 0);\n                });\n         \
      \        updateChartData(chartInstances.requestsByRoute, routeLabels, [routeData]);\n\
      \            }\n\n             // Requests by Status (Doughnut)\n          \
      \   if (chartInstances.requestsByStatus) {\n                const statuses =\
      \ stats.requests_by_status || {};\n                // Sort status codes numerically\
      \ for logical chart order\n                const statusLabels = Object.keys(statuses).sort((a,\
      \ b) => Number(a) - Number(b));\n                const statusData = statusLabels.map(status\
      \ => statuses[status] || 0);\n                updateChartData(chartInstances.requestsByStatus,\
      \ statusLabels, [statusData]);\n            }\n            // console.debug(\"\
      UI update complete.\"); // Uncomment for detailed debug\n        }\n\n     \
      \   // --- Initialization ---\n        document.addEventListener('DOMContentLoaded',\
      \ () => {\n            console.log(\"DOM Loaded. Initializing dashboard.\");\n\
      \            cacheDOMElements(); // Cache elements now that DOM is ready\n \
      \           initializeCharts(); // Setup chart structures\n            clearCards();\
      \ // Set initial card values to '--'\n            fetchData(); // Perform the\
      \ first data fetch immediately\n\n            // Start polling for new data\
      \ after the first fetch attempt\n            if (fetchDataIntervalId) clearInterval(fetchDataIntervalId);\
      \ // Clear previous interval if any\n            fetchDataIntervalId = setInterval(fetchData,\
      \ POLLING_INTERVAL_MS);\n            console.log(`Started polling data every\
      \ ${POLLING_INTERVAL_MS / 1000} seconds.`);\n        });\n\n    </script>\n\
      \    {% endraw %}\n    {# ***** END RAW BLOCK FOR JAVASCRIPT ***** #}\n\n</body>\n\
      </html>\n\"\"\"\n\n\n# --- Flask Routes ---\n\n@app.route('/')\ndef serve_dashboard():\n\
      \    \"\"\"Serve the main dashboard HTML page, rendering the template string.\"\
      \"\"\n    logger.info(\"Serving dashboard HTML page.\")\n    try:\n        #\
      \ Render the HTML, injecting configuration variables into the JS template sections\n\
      \        return render_template_string(\n            HTML_CONTENT,\n       \
      \     FETCH_INTERVAL_SECONDS=FETCH_INTERVAL_SECONDS,\n            MAX_CHART_HISTORY=MAX_CHART_HISTORY\n\
      \        )\n    except Exception as e:\n        # Catch potential Jinja errors\
      \ during rendering itself\n        logger.error(f\"Error rendering dashboard\
      \ template: {e}\", exc_info=True)\n        # Return a simple error page if template\
      \ rendering fails\n        return f\"<h1>Internal Server Error</h1><p>Failed\
      \ to render dashboard template: {e}</p>\", 500\n\n@app.route('/api/dashboard_data')\n\
      def get_dashboard_data():\n    \"\"\"Endpoint for the frontend JavaScript to\
      \ fetch the collected data.\"\"\"\n    logger.debug(\"Request received for /api/dashboard_data\"\
      )\n    with data_lock:\n        # Create a snapshot of the current state to\
      \ avoid holding the lock during serialization\n        # Ensure all deques are\
      \ converted to lists for JSON compatibility\n        try:\n            data_to_send\
      \ = {\n                # Shallow copy is usually fine for dicts of primitives/strings/numbers\n\
      \                \"latest_stats\": app_state.get(\"latest_stats\", {}).copy(),\n\
      \                \"history\": {\n                    \"time_labels\": list(app_state.get(\"\
      time_labels\", [])),\n                    \"request_history\": list(app_state.get(\"\
      request_history\", [])),\n                    \"message_status\": {\n      \
      \                  \"pending\": list(app_state.get(\"message_status_history\"\
      , {}).get(\"pending\", [])),\n                        \"processing\": list(app_state.get(\"\
      message_status_history\", {}).get(\"processing\", [])),\n                  \
      \      \"failed\": list(app_state.get(\"message_status_history\", {}).get(\"\
      failed\", [])),\n                        \"processed\": list(app_state.get(\"\
      message_status_history\", {}).get(\"processed\", [])),\n                   \
      \ },\n                    \"performance\": {\n                        \"cpu\"\
      : list(app_state.get(\"performance_history\", {}).get(\"cpu\", [])),\n     \
      \                   \"memory\": list(app_state.get(\"performance_history\",\
      \ {}).get(\"memory\", [])),\n                    }\n                },\n   \
      \             \"last_successful_fetch\": app_state.get(\"last_successful_fetch\"\
      ),\n                \"error\": app_state.get(\"last_error\") # Pass the last\
      \ known error (if any)\n            }\n        except Exception as e:\n    \
      \        logger.error(f\"Error preparing data for /api/dashboard_data: {e}\"\
      , exc_info=True)\n            return jsonify({\"error\": \"Failed to prepare\
      \ data\", \"detail\": str(e)}), 500\n\n    # logger.debug(f\"Returning dashboard\
      \ data: {json.dumps(data_to_send)}\") # Be careful logging large data\n    return\
      \ jsonify(data_to_send)\n\n# --- Inicialização ---\nif __name__ == '__main__':\n\
      \    # Disable warnings for insecure HTTPS requests (verify=False) made by this\
      \ script\n    # ONLY use this in development with self-signed certs you trust.\n\
      \    try:\n        import urllib3\n        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\
      \        logger.warning(\"SSL certificate verification is disabled for API requests\
      \ made by this dashboard. THIS IS INSECURE FOR PRODUCTION.\")\n    except ImportError:\n\
      \        logger.warning(\"urllib3 not found, cannot disable InsecureRequestWarning.\"\
      )\n    except Exception as e:\n        logger.warning(f\"Could not disable urllib3\
      \ warnings: {e}\")\n\n    # Start the scheduler thread in the background\n \
      \   # daemon=True ensures the thread exits when the main Flask process exits\n\
      \    scheduler_thread = threading.Thread(target=run_scheduler, name=\"SchedulerThread\"\
      , daemon=True)\n    scheduler_thread.start()\n\n    logger.info(f\"Starting\
      \ Dashboard server on http://0.0.0.0:{DASHBOARD_PORT}\")\n    logger.info(f\"\
      Attempting to fetch data from API at {API_BASE_URL} every {FETCH_INTERVAL_SECONDS}\
      \ seconds.\")\n\n    # Run the Flask app\n    # Use debug=False in production\
      \ to avoid security risks and duplicate scheduler runs\n    # Disable reloader\
      \ when using threads to avoid issues.\n    # Consider using a production-ready\
      \ WSGI server like Gunicorn or Waitress.\n    # Example using Waitress (install\
      \ first: pip install waitress):\n    # from waitress import serve\n    # serve(app,\
      \ host='0.0.0.0', port=DASHBOARD_PORT)\n    try:\n        logger.info(\"Using\
      \ Flask's built-in development server. Not recommended for production.\")\n\
      \        app.run(host='0.0.0.0', port=DASHBOARD_PORT, debug=False, use_reloader=False)\n\
      \    except KeyboardInterrupt:\n        logger.info(\"Dashboard server stopped\
      \ by user (Ctrl+C).\")\n    except Exception as e:\n        logger.critical(f\"\
      Dashboard server failed to start or crashed: {e}\", exc_info=True)"
    tamanho: 0.06 MB
  webdashv2-clean.py:
    caminho_completo: .\webdashv2-clean.py
    classes: []
    functions:
    - docstring: Attempts to log in to the main API and stores the tokens.
      end_lineno: 125
      lineno: 67
      name: login_to_api
    - docstring: Fetches /stats data from the main API, handles authentication.
      end_lineno: 244
      lineno: 127
      name: fetch_api_data
    - docstring: Runs the scheduler loop in a separate thread.
      end_lineno: 258
      lineno: 247
      name: run_scheduler
    - docstring: Serve the main dashboard HTML page.
      end_lineno: 636
      lineno: 624
      name: serve_dashboard
    - docstring: Endpoint for frontend JS to fetch collected data.
      end_lineno: 659
      lineno: 639
      name: get_dashboard_data
    imports:
    - asname: null
      name: os
    - asname: null
      name: time
    - asname: null
      name: threading
    - asname: null
      name: logging
    - module: collections
      names:
      - deque
    - module: threading
      names:
      - Lock
    - module: datetime
      names:
      - datetime
      - timezone
    - asname: null
      name: json
    - asname: null
      name: requests
    - asname: null
      name: schedule
    - module: flask
      names:
      - Flask
      - Response
      - jsonify
      - render_template_string
    - module: flask_cors
      names:
      - CORS
    - asname: null
      name: urllib3
    numero_de_linhas: 687
    source_code: "# dashboard_server.py\nimport os\nimport time\nimport threading\n\
      import logging\nfrom collections import deque\nfrom threading import Lock\n\
      from datetime import datetime, timezone\nimport json # For handling potential\
      \ decoding errors\n\nimport requests # To make requests to the main API\nimport\
      \ schedule # To schedule data collection\nfrom flask import Flask, Response,\
      \ jsonify, render_template_string\nfrom flask_cors import CORS\n\n# --- Configuration\
      \ ---\nDASHBOARD_PORT = 8333\n# Default to HTTPS and the simplified API port\n\
      API_BASE_URL = os.environ.get(\"API_BASE_URL\", \"https://127.0.0.1:8777\")\n\
      API_STATS_URL = f\"{API_BASE_URL}/stats\"\nAPI_LOGIN_URL = f\"{API_BASE_URL}/login\"\
      \n\n# Credentials for the dashboard to access the main API\n# !!! Use environment\
      \ variables in production !!!\nAPI_USERNAME = os.environ.get(\"API_USER\", \"\
      admin\") # Default 'admin'\nAPI_PASSWORD = os.environ.get(\"API_PASS\", \"admin\"\
      ) # Default 'admin'\n\nFETCH_INTERVAL_SECONDS = 5 # Data collection interval\n\
      MAX_CHART_HISTORY = 60 # History points for line charts\n\n# --- Logging Configuration\
      \ ---\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s\
      \ - %(name)s - %(levelname)s - %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n\
      )\nlogger = logging.getLogger('DashboardServer') # Specific name\n\n# --- Global\
      \ State and Control ---\napp_state = {\n    \"latest_stats\": {},\n    \"last_error\"\
      : None,\n    \"last_successful_fetch\": None,\n    \"api_token\": None, # Store\
      \ only the access token\n    \"refresh_token\": None, # Kept for potential future\
      \ use if API adds refresh logic\n    \"login_needed\": True,\n    \"is_fetching\"\
      : False,\n    # History for charts\n    \"time_labels\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \    \"request_history\": deque(maxlen=MAX_CHART_HISTORY), # Deltas per interval\n\
      \    \"message_status_history\": {\n        \"pending\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \        \"processing\": deque(maxlen=MAX_CHART_HISTORY),\n        \"failed\"\
      : deque(maxlen=MAX_CHART_HISTORY),\n        \"processed\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \    },\n    \"performance_history\": {\n        \"cpu\": deque(maxlen=MAX_CHART_HISTORY),\n\
      \        \"memory\": deque(maxlen=MAX_CHART_HISTORY),\n    },\n    \"previous_total_requests\"\
      : 0 # For calculating delta\n}\ndata_lock = Lock() # Protect concurrent access\
      \ to app_state\n\n# --- Collection and Processing Functions ---\n\ndef login_to_api():\n\
      \    \"\"\"Attempts to log in to the main API and stores the tokens.\"\"\"\n\
      \    global app_state\n    logger.info(f\"Attempting login to API at {API_LOGIN_URL}...\"\
      )\n    try:\n        login_data = {'username': API_USERNAME, 'password': API_PASSWORD}\n\
      \        # IMPORTANT: Disable SSL verification ONLY for local dev with self-signed\
      \ certs\n        response = requests.post(API_LOGIN_URL, data=login_data, verify=False,\
      \ timeout=10)\n        response.raise_for_status() # Raise exception for HTTP\
      \ 4xx/5xx errors\n\n        token_data = response.json()\n        if \"access_token\"\
      \ in token_data and \"refresh_token\" in token_data:\n            with data_lock:\n\
      \                app_state[\"api_token\"] = token_data[\"access_token\"]\n \
      \               app_state[\"refresh_token\"] = token_data[\"refresh_token\"\
      ]\n                app_state[\"login_needed\"] = False\n                app_state[\"\
      last_error\"] = None # Clear previous login error\n            logger.info(\"\
      API login successful.\")\n            return True\n        else:\n         \
      \   logger.error(\"API login response missing 'access_token' or 'refresh_token'.\"\
      )\n            with data_lock:\n                app_state[\"last_error\"] =\
      \ \"Login response missing tokens\"\n                app_state[\"api_token\"\
      ] = None\n                app_state[\"refresh_token\"] = None\n            \
      \    app_state[\"login_needed\"] = True\n            return False\n\n    except\
      \ requests.exceptions.RequestException as e:\n        status_code = getattr(e.response,\
      \ 'status_code', 'N/A')\n        error_detail = f\"Status: {status_code}\"\n\
      \        try: # Try to get more details\n            if e.response is not None:\n\
      \                content_type = e.response.headers.get('Content-Type', '')\n\
      \                if 'application/json' in content_type:\n                  \
      \ error_json = e.response.json()\n                   error_detail += f\" - Detail:\
      \ {error_json.get('detail', error_json)}\"\n                else: error_detail\
      \ += f\" - Response: {e.response.text[:200]}\"\n        except Exception: pass\n\
      \        logger.error(f\"API login failed ({error_detail}): {e}\")\n       \
      \ with data_lock:\n            app_state[\"last_error\"] = f\"Login request\
      \ failed: {e}\"\n            app_state[\"api_token\"] = None\n            app_state[\"\
      refresh_token\"] = None\n            app_state[\"login_needed\"] = True\n  \
      \      return False\n    except json.JSONDecodeError as e:\n        response_text\
      \ = getattr(e.response, 'text', 'N/A')\n        logger.error(f\"API login failed:\
      \ Could not decode JSON. Response: {response_text[:500]}\")\n        with data_lock:\n\
      \            app_state[\"last_error\"] = \"Login response not valid JSON\"\n\
      \            app_state[\"api_token\"] = None; app_state[\"refresh_token\"] =\
      \ None; app_state[\"login_needed\"] = True\n        return False\n    except\
      \ Exception as e:\n        logger.error(f\"Unexpected error during API login:\
      \ {e}\", exc_info=True)\n        with data_lock:\n            app_state[\"last_error\"\
      ] = f\"Unexpected login error: {e}\"\n            app_state[\"api_token\"] =\
      \ None; app_state[\"refresh_token\"] = None; app_state[\"login_needed\"] = True\n\
      \        return False\n\ndef fetch_api_data():\n    \"\"\"Fetches /stats data\
      \ from the main API, handles authentication.\"\"\"\n    global app_state\n\n\
      \    with data_lock: # Prevent concurrent fetches\n        if app_state.get(\"\
      is_fetching\", False):\n            logger.debug(\"Fetch skipped, already fetching.\"\
      )\n            return\n        app_state[\"is_fetching\"] = True\n        token\
      \ = app_state[\"api_token\"]\n        login_needed = app_state[\"login_needed\"\
      ]\n\n    logger.debug(\"Starting data fetch cycle...\")\n    try:\n        #\
      \ --- Handle Authentication ---\n        if login_needed or not token:\n   \
      \         logger.warning(\"Login required or token missing, attempting login...\"\
      )\n            if not login_to_api():\n                logger.error(\"Fetch\
      \ cycle aborted: login failed.\")\n                with data_lock:\n       \
      \              if app_state[\"last_error\"] is None: app_state[\"last_error\"\
      ] = \"Login required but failed\"\n                return\n            with\
      \ data_lock: # Re-fetch token after successful login\n                token\
      \ = app_state[\"api_token\"]\n                if not token: # Should not happen\
      \ if login_to_api returned True\n                     logger.error(\"CRITICAL:\
      \ Token missing after successful login. Aborting.\")\n                     app_state[\"\
      last_error\"] = \"Internal dashboard error: Token lost.\"\n                \
      \     return\n\n        # --- Fetch Stats Data ---\n        logger.debug(f\"\
      Fetching stats from {API_STATS_URL}...\")\n        headers = {'Authorization':\
      \ f'Bearer {token}', 'Accept': 'application/json'}\n        try:\n         \
      \   # Disable SSL verification ONLY for local dev\n            response = requests.get(API_STATS_URL,\
      \ headers=headers, verify=False, timeout=10)\n\n            # Check for auth\
      \ errors first -> triggers re-login next cycle\n            if response.status_code\
      \ in [401, 403]:\n                logger.warning(f\"API auth error ({response.status_code})\
      \ fetching stats. Forcing re-login next cycle.\")\n                with data_lock:\n\
      \                    app_state[\"api_token\"] = None\n                    app_state[\"\
      login_needed\"] = True\n                    app_state[\"last_error\"] = f\"\
      API Auth error ({response.status_code}). Re-login needed.\"\n              \
      \  return # Abort this cycle\n\n            response.raise_for_status() # Check\
      \ for other HTTP errors (5xx, 404 etc.)\n\n            # ---- Process Successful\
      \ Response ----\n            try:\n                stats = response.json()\n\
      \                now = datetime.now(timezone.utc)\n                logger.debug(\"\
      Stats received successfully.\")\n\n                with data_lock: # Update\
      \ state under lock\n                    app_state[\"latest_stats\"] = stats\n\
      \                    app_state[\"last_successful_fetch\"] = now.isoformat()\n\
      \                    app_state[\"last_error\"] = None # Clear errors on success\n\
      \n                    # Update history deques\n                    current_time_label\
      \ = now.strftime(\"%H:%M:%S\")\n                    app_state[\"time_labels\"\
      ].append(current_time_label)\n\n                    # Calculate request delta\n\
      \                    current_total = stats.get(\"requests_total\")\n       \
      \             delta = 0\n                    if isinstance(current_total, int):\n\
      \                        prev_total = app_state[\"previous_total_requests\"\
      ]\n                        delta = max(0, current_total - (prev_total if isinstance(prev_total,\
      \ int) else 0))\n                        app_state[\"previous_total_requests\"\
      ] = current_total\n                    else: logger.warning(\"`requests_total`\
      \ missing or invalid in stats.\")\n                    app_state[\"request_history\"\
      ].append(delta)\n\n                    # Message history (safe access with .get)\n\
      \                    app_state[\"message_status_history\"][\"pending\"].append(stats.get(\"\
      messages_pending\", 0))\n                    app_state[\"message_status_history\"\
      ][\"processing\"].append(stats.get(\"messages_processing\", 0))\n          \
      \          app_state[\"message_status_history\"][\"failed\"].append(stats.get(\"\
      messages_failed\", 0))\n                    app_state[\"message_status_history\"\
      ][\"processed\"].append(stats.get(\"messages_processed\", 0))\n\n          \
      \          # Performance history (safe access)\n                    sys_stats\
      \ = stats.get(\"system\", {})\n                    cpu = sys_stats.get(\"process_cpu_percent\"\
      )\n                    mem = sys_stats.get(\"process_memory_mb\")\n        \
      \            app_state[\"performance_history\"][\"cpu\"].append(cpu if isinstance(cpu,\
      \ (int, float)) else 0)\n                    app_state[\"performance_history\"\
      ][\"memory\"].append(mem if isinstance(mem, (int, float)) else 0)\n\n      \
      \          logger.debug(\"Dashboard state updated.\")\n\n            except\
      \ json.JSONDecodeError as e:\n                 logger.error(f\"Failed to decode\
      \ JSON from API /stats: {e}. Response: {response.text[:500]}\")\n          \
      \       with data_lock: app_state[\"last_error\"] = \"API /stats response not\
      \ valid JSON\"\n            except Exception as processing_e:\n            \
      \    logger.error(f\"Error processing received stats: {processing_e}\", exc_info=True)\n\
      \                with data_lock: app_state[\"last_error\"] = f\"Error processing\
      \ stats: {processing_e}\"\n\n        # --- Handle Request Errors ---\n     \
      \   except requests.exceptions.Timeout:\n            logger.error(\"API /stats\
      \ request timed out.\")\n            with data_lock: app_state[\"last_error\"\
      ] = \"API Timeout fetching stats\"\n        except requests.exceptions.ConnectionError\
      \ as e:\n            logger.error(f\"API /stats connection error: {e}\")\n \
      \           with data_lock: app_state[\"last_error\"] = f\"API Connection Error:\
      \ {e}\"\n        except requests.exceptions.RequestException as e:\n       \
      \     status_code = getattr(e.response, 'status_code', 'N/A')\n            logger.error(f\"\
      API /stats request failed (Status: {status_code}): {e}\")\n            error_detail\
      \ = f\"API Request Failed: {e}\"\n            try:\n                if e.response\
      \ is not None: error_detail += f\" - Response: {e.response.text[:200]}\"\n \
      \           except Exception: pass\n            with data_lock:\n          \
      \       # Avoid overwriting a more specific auth error\n                 if\
      \ app_state.get(\"last_error\") is None or \"Auth error\" not in app_state[\"\
      last_error\"]:\n                     app_state[\"last_error\"] = error_detail\n\
      \n    except Exception as outer_e:\n        logger.error(f\"Unexpected error\
      \ during fetch setup: {outer_e}\", exc_info=True)\n        with data_lock: app_state[\"\
      last_error\"] = f\"Unexpected Fetch Error: {outer_e}\"\n    finally:\n     \
      \   with data_lock: app_state[\"is_fetching\"] = False # Ensure flag is reset\n\
      \n\ndef run_scheduler():\n    \"\"\"Runs the scheduler loop in a separate thread.\"\
      \"\"\n    logger.info(\"Scheduler thread started.\")\n    try: # Perform an\
      \ initial fetch immediately\n        fetch_api_data()\n    except Exception\
      \ as e: logger.error(f\"Error during initial fetch: {e}\", exc_info=True)\n\n\
      \    schedule.every(FETCH_INTERVAL_SECONDS).seconds.do(fetch_api_data)\n   \
      \ while True:\n        try: schedule.run_pending()\n        except Exception\
      \ as e: logger.error(f\"Error in scheduler loop: {e}\", exc_info=True)\n   \
      \     time.sleep(1)\n\n# --- Flask App ---\napp = Flask(__name__)\napp.logger.handlers\
      \ = logger.handlers # Use configured logger\napp.logger.setLevel(logger.level)\n\
      CORS(app) # Enable CORS\n\n# --- HTML Content ---\n# Uses Jinja templating for\
      \ configuration injection.\n# IMPORTANT: {% raw %} blocks are critical for CSS\
      \ and JS containing {{ }} syntax.\nHTML_CONTENT = \"\"\"\n<!DOCTYPE html>\n\
      <html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"\
      viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>API\
      \ Metrics Dashboard</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js\"\
      ></script>\n    <link rel=\"icon\" href=\"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22\
      \ viewBox=%220 0 100 100%22><path d=%22M8.3 25L41.7 8.3L75 25L41.7 41.7L8.3\
      \ 25Z%22 stroke=%22%2300bcd4%22 stroke-width=%2210%22 fill=%22none%22/><path\
      \ d=%22M8.3 75L41.7 58.3L75 75L41.7 91.7L8.3 75Z%22 stroke=%22%2300bcd4%22 stroke-width=%2210%22\
      \ fill=%22none%22/><path d=%22M8.3 50H75%22 stroke=%22%2300bcd4%22 stroke-width=%2210%22\
      \ fill=%22none%22/></svg>\">\n\n    {# ***** START RAW BLOCK FOR CSS ***** #}\n\
      \    {% raw %}\n    <style>\n        * { box-sizing: border-box; margin: 0;\
      \ padding: 0; }\n        @keyframes fadeIn { from { opacity: 0; } to { opacity:\
      \ 1; } }\n        @keyframes highlight-value {\n            0%, 100% { transform:\
      \ scale(1); color: #fff; }\n            50% { transform: scale(1.05); color:\
      \ #80deea; }\n        }\n        .value-changed .card-value { animation: highlight-value\
      \ 0.4s ease-out; }\n        body { font-family: system-ui, sans-serif; background:\
      \ #181a1f; color: #e0e0e0; line-height: 1.5; display: flex; flex-direction:\
      \ column; min-height: 100vh; overflow-x: hidden; }\n        .app-header { background:\
      \ #21242a; padding: 10px 25px; display: flex; align-items: center; border-bottom:\
      \ 1px solid #3a3d4a; position: sticky; top: 0; z-index: 10; box-shadow: 0 2px\
      \ 8px rgba(0, 0, 0, 0.2); flex-wrap: wrap; }\n        .logo { display: flex;\
      \ align-items: center; margin-right: 20px; color: #00bcd4; }\n        .logo\
      \ svg { margin-right: 8px; }\n        .logo-text-main { font-weight: 700; font-size:\
      \ 1.4em; letter-spacing: 1px; color: #fff;}\n        .logo-text-sub { font-size:\
      \ 0.45em; color: #a0a0a0; text-transform: uppercase; line-height: 1; display:\
      \ block; font-weight: normal; letter-spacing: 0.5px; margin-top: -2px;}\n  \
      \      .main-title { flex-grow: 1; text-align: center; font-size: 1.2em; font-weight:\
      \ 500; color: #c5c5c5; margin: 5px 15px; }\n        .status-indicator { font-size:\
      \ 0.95em; font-weight: 500; margin: 5px 0; text-align: right; min-width: 150px;\
      \ transition: color 0.3s ease; }\n        .status-indicator.live { color: #4caf50;\
      \ }\n        .status-indicator.error { color: #f44336; font-weight: bold; }\n\
      \        .status-indicator.stale { color: #ff9800; }\n        .status-indicator.fetching\
      \ { color: #03a9f4; }\n        .main-content { display: grid; grid-template-columns:\
      \ repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; padding: 25px; flex-grow:\
      \ 1; }\n        .status-card { border-radius: 8px; box-shadow: 0 4px 12px rgba(0,\
      \ 0, 0, 0.25); overflow: hidden; display: flex; flex-direction: column; color:\
      \ #ffffff; border: 1px solid rgba(255, 255, 255, 0.08); animation: fadeIn 0.5s\
      \ ease-out forwards; background-color: #2a2d35; transition: background-color\
      \ 0.3s ease, transform 0.2s ease; }\n        .status-card:hover { transform:\
      \ translateY(-3px); box-shadow: 0 6px 16px rgba(0, 0, 0, 0.3); }\n        .bg-pending\
      \ { background: linear-gradient(135deg, #ffb74d, #ffa726); }\n        .bg-processing\
      \ { background: linear-gradient(135deg, #64b5f6, #42a5f5); }\n        .bg-failed\
      \ { background: linear-gradient(135deg, #e57373, #ef5350); }\n        .bg-processed\
      \ { background: linear-gradient(135deg, #81c784, #66bb6a); }\n        .bg-requests\
      \ { background: linear-gradient(135deg, #7986cb, #5c6bc0); }\n        .bg-cpu\
      \ { background: linear-gradient(135deg, #ba68c8, #ab47bc); }\n        .bg-mem\
      \ { background: linear-gradient(135deg, #4dd0e1, #26c6da); }\n        .bg-uptime\
      \ { background: linear-gradient(135deg, #90a4ae, #78909c); }\n        .card-main-content\
      \ { padding: 15px 20px 20px 20px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\
      \ text-align: center; flex-grow: 1; display: flex; flex-direction: column; justify-content:\
      \ center; }\n        .card-title { font-size: 0.8em; font-weight: 600; color:\
      \ rgba(255, 255, 255, 0.85); margin-bottom: 10px; text-transform: uppercase;\
      \ letter-spacing: 0.5px; }\n        .card-value { font-size: 2.3em; font-weight:\
      \ 700; line-height: 1; color: #ffffff; display: block; transition: transform\
      \ 0.2s ease; }\n        .charts-section { display: grid; grid-template-columns:\
      \ repeat(auto-fit, minmax(350px, 1fr)); gap: 20px; padding: 0 25px 25px 25px;\
      \ }\n        .chart-card { background: #2a2d35; border-radius: 8px; padding:\
      \ 20px; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.25); border: 1px solid rgba(255,\
      \ 255, 255, 0.08); animation: fadeIn 0.6s ease-out forwards; display: flex;\
      \ flex-direction: column; }\n        .chart-title { font-size: 1em; font-weight:\
      \ 600; color: #e0e0e0; margin-bottom: 15px; text-align: center; }\n        .chart-container\
      \ { height: 250px; position: relative; flex-grow: 1; }\n        .chart-container\
      \ canvas { display: block; width: 100%; height: 100%; }\n        .app-footer\
      \ { text-align: center; padding: 15px; margin-top: auto; font-size: 0.85em;\
      \ color: #888; border-top: 1px solid #3a3d4a; background: #1f2128; }\n     \
      \   .app-footer #backend-status { font-weight: 500; display: block; margin-top:\
      \ 5px; transition: color 0.3s ease;}\n        .app-footer #backend-status.error\
      \ { color: #f44336; font-weight: bold; }\n        .app-footer #backend-status.success\
      \ { color: #bdc3c7; }\n        @media (max-width: 768px) {\n            .main-content,\
      \ .charts-section { padding: 15px; gap: 15px; }\n            .app-header { padding:\
      \ 8px 15px; flex-direction: column; align-items: flex-start; }\n           \
      \ .main-title { text-align: left; margin: 8px 0; }\n            .status-indicator\
      \ { align-self: flex-end; margin-top: -25px; }\n            .card-value { font-size:\
      \ 2em; }\n            .charts-section { grid-template-columns: 1fr; }\n    \
      \    }\n        @media (max-width: 480px) {\n             .card-value { font-size:\
      \ 1.8em; }\n             .main-content { grid-template-columns: 1fr 1fr; }\n\
      \         }\n    </style>\n    {% endraw %}\n    {# ***** END RAW BLOCK FOR\
      \ CSS ***** #}\n</head>\n<body>\n    <header class=\"app-header\">\n       \
      \  <div class=\"logo\">\n            <svg width=\"25\" height=\"25\" viewBox=\"\
      0 0 100 100\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"\
      M8.3 25L41.7 8.3L75 25L41.7 41.7L8.3 25Z\" stroke=\"currentColor\" stroke-width=\"\
      10\"/><path d=\"M8.3 75L41.7 58.3L75 75L41.7 91.7L8.3 75Z\" stroke=\"currentColor\"\
      \ stroke-width=\"10\"/><path d=\"M8.3 50H75\" stroke=\"currentColor\" stroke-width=\"\
      10\"/></svg>\n            <div><span class=\"logo-text-main\">API</span><span\
      \ class=\"logo-text-sub\">Metrics Dashboard</span></div>\n        </div>\n \
      \       <h1 class=\"main-title\">Live System Status</h1>\n        <div id=\"\
      status-indicator\" class=\"status-indicator stale\">Initializing...</div>\n\
      \    </header>\n\n    <main class=\"main-content\" id=\"metric-cards\">\n  \
      \      <div class=\"status-card bg-pending\" id=\"card-pending-msgs\"><div class=\"\
      card-main-content\"><div class=\"card-title\">Pending Msgs</div><div class=\"\
      card-value\">--</div></div></div>\n        <div class=\"status-card bg-processing\"\
      \ id=\"card-processing-msgs\"><div class=\"card-main-content\"><div class=\"\
      card-title\">Processing Msgs</div><div class=\"card-value\">--</div></div></div>\n\
      \        <div class=\"status-card bg-failed\" id=\"card-failed-msgs\"><div class=\"\
      card-main-content\"><div class=\"card-title\">Failed Msgs</div><div class=\"\
      card-value\">--</div></div></div>\n        <div class=\"status-card bg-processed\"\
      \ id=\"card-processed-msgs\"><div class=\"card-main-content\"><div class=\"\
      card-title\">Processed Msgs</div><div class=\"card-value\">--</div></div></div>\n\
      \        <div class=\"status-card bg-requests\" id=\"card-total-requests\"><div\
      \ class=\"card-main-content\"><div class=\"card-title\">Total Reqs</div><div\
      \ class=\"card-value\">--</div></div></div>\n        <div class=\"status-card\
      \ bg-cpu\" id=\"card-process-cpu\"><div class=\"card-main-content\"><div class=\"\
      card-title\">Process CPU %</div><div class=\"card-value\">--</div></div></div>\n\
      \        <div class=\"status-card bg-mem\" id=\"card-process-mem\"><div class=\"\
      card-main-content\"><div class=\"card-title\">Process Mem (MB)</div><div class=\"\
      card-value\">--</div></div></div>\n        <div class=\"status-card bg-uptime\"\
      \ id=\"card-uptime\"><div class=\"card-main-content\"><div class=\"card-title\"\
      >Uptime</div><div class=\"card-value\">--</div></div></div>\n    </main>\n\n\
      \    <section class=\"charts-section\">\n        <div class=\"chart-card\">\n\
      \            <div class=\"chart-title\">\U0001F4C8 Requests / Interval (Last\
      \ <span id=\"req-chart-points\">N</span> points)</div>\n            <div class=\"\
      chart-container\"><canvas id=\"requestsChart\"></canvas></div>\n        </div>\n\
      \        <div class=\"chart-card\">\n            <div class=\"chart-title\"\
      >✉️ Message Status (Last <span id=\"msg-chart-points\">N</span> points)</div>\n\
      \            <div class=\"chart-container\"><canvas id=\"messageStatusChart\"\
      ></canvas></div>\n        </div>\n        <div class=\"chart-card\">\n     \
      \       <div class=\"chart-title\">⚙️ Performance (Last <span id=\"perf-chart-points\"\
      >N</span> points)</div>\n            <div class=\"chart-container\"><canvas\
      \ id=\"performanceChart\"></canvas></div>\n        </div>\n        <div class=\"\
      chart-card\">\n            <div class=\"chart-title\">\U0001F6E3️ Requests by\
      \ Route (Current Totals)</div>\n            <div class=\"chart-container\"><canvas\
      \ id=\"requestsByRouteChart\"></canvas></div>\n        </div>\n         <div\
      \ class=\"chart-card\">\n            <div class=\"chart-title\">\U0001F6A6 Requests\
      \ by Status Code (Current Totals)</div>\n            <div class=\"chart-container\"\
      ><canvas id=\"requestsByStatusChart\"></canvas></div>\n        </div>\n    </section>\n\
      \n    <footer class=\"app-footer\">\n        Real-time API Metrics Dashboard\n\
      \        <span id=\"backend-status\" class=\"success\">Initializing...</span>\n\
      \    </footer>\n\n    <script>\n        // --- Injected Variables (Jinja WILL\
      \ process this part) ---\n        const DASHBOARD_DATA_URL = '/api/dashboard_data';\n\
      \        // Use config values injected by Flask\n        const POLLING_INTERVAL_MS\
      \ = {{ FETCH_INTERVAL_SECONDS * 1000 }}; // NOT in raw\n        const MAX_CHART_HISTORY\
      \ = {{ MAX_CHART_HISTORY }};             // NOT in raw\n\n        // --- Start\
      \ Raw Block (Jinja IGNORES the rest) ---\n        {% raw %}\n\n        // ---\
      \ The rest of your original JavaScript logic ---\n        let chartInstances\
      \ = {};\n        let fetchDataIntervalId = null;\n        let lastKnownError\
      \ = null;\n        let statusIndicator = null;\n        let backendStatusSpan\
      \ = null;\n        let cardValueElements = {};\n\n        function cacheDOMElements()\
      \ {\n            statusIndicator = document.getElementById('status-indicator');\n\
      \            backendStatusSpan = document.getElementById('backend-status');\n\
      \            cardValueElements = {\n                pendingMsgs: document.querySelector('#card-pending-msgs\
      \ .card-value'),\n                processingMsgs: document.querySelector('#card-processing-msgs\
      \ .card-value'),\n                failedMsgs: document.querySelector('#card-failed-msgs\
      \ .card-value'),\n                processedMsgs: document.querySelector('#card-processed-msgs\
      \ .card-value'),\n                totalRequests: document.querySelector('#card-total-requests\
      \ .card-value'),\n                processCpu: document.querySelector('#card-process-cpu\
      \ .card-value'),\n                processMem: document.querySelector('#card-process-mem\
      \ .card-value'),\n                uptime: document.querySelector('#card-uptime\
      \ .card-value')\n            };\n             try {\n                // NOTE:\
      \ MAX_CHART_HISTORY is available here because it was defined above\n       \
      \         document.getElementById('req-chart-points').textContent = MAX_CHART_HISTORY;\n\
      \                document.getElementById('msg-chart-points').textContent = MAX_CHART_HISTORY;\n\
      \                document.getElementById('perf-chart-points').textContent =\
      \ MAX_CHART_HISTORY;\n             } catch (e) { console.warn(\"Could not update\
      \ chart point labels:\", e); }\n        }\n\n        function formatNumber(num)\
      \ { return (num === null || num === undefined || isNaN(Number(num))) ? '--'\
      \ : Number(num).toLocaleString(); }\n        function formatPercentage(num)\
      \ { return (num === null || num === undefined || isNaN(Number(num))) ? '--'\
      \ : Number(num).toFixed(1) + '%'; }\n        function formatMemory(num) { return\
      \ (num === null || num === undefined || isNaN(Number(num))) ? '--' : Number(num).toFixed(1)\
      \ + ' MB'; }\n\n        function updateCardValue(element, newValue, formatter\
      \ = formatNumber) {\n            if (!element) return;\n            const formattedValue\
      \ = formatter(newValue);\n            if (element.textContent !== formattedValue)\
      \ {\n                element.textContent = formattedValue;\n               \
      \ const card = element.closest('.status-card');\n                if (card) {\
      \ card.classList.add('value-changed'); setTimeout(() => card.classList.remove('value-changed'),\
      \ 400); }\n            }\n        }\n\n        function generateColors(count)\
      \ {\n             const baseColors = ['#64b5f6', '#81c784', '#ffb74d', '#e57373',\
      \ '#ba68c8', '#4dd0e1', '#fff176', '#7986cb', '#a1887f', '#90a4ae'];\n     \
      \        return Array.from({ length: count }, (_, i) => baseColors[i % baseColors.length]);\n\
      \         }\n\n         function clearCards() { Object.values(cardValueElements).forEach(el\
      \ => { if(el) el.textContent = '--'; }); }\n\n        function updateChartData(chartInstance,\
      \ newLabels = [], newDatasetsData = []) {\n            if (!chartInstance?.data?.datasets)\
      \ return;\n            chartInstance.data.labels = newLabels;\n            chartInstance.data.datasets.forEach((dataset,\
      \ index) => {\n                // Ensure we have data for this dataset, default\
      \ to empty array if not\n                const dataForDataset = (Array.isArray(newDatasetsData)\
      \ && Array.isArray(newDatasetsData[index]))\n                              \
      \         ? newDatasetsData[index] : [];\n                dataset.data = dataForDataset;\n\
      \n                // Regenerate colors for bar/doughnut if data length changes\n\
      \                if ((chartInstance.config.type === 'bar' || chartInstance.config.type\
      \ === 'doughnut') && Array.isArray(dataset.backgroundColor)) {\n           \
      \        dataset.backgroundColor = generateColors(dataForDataset.length);\n\
      \                   // Also handle potential borderColor array for doughnuts\n\
      \                   if (Array.isArray(dataset.borderColor)) {\n            \
      \           dataset.borderColor = dataset.backgroundColor.map(color => color.replace(')',\
      \ ', 0.7)').replace('rgb', 'rgba')); // Example border adjustment\n        \
      \           }\n                }\n            });\n            chartInstance.update('none');\
      \ // Use 'none' for smoother updates without full re-animation\n        }\n\n\
      \        function initializeCharts() {\n             console.log(\"Initializing\
      \ charts...\");\n             Chart.defaults.color = '#e0e0e0';\n          \
      \   Chart.defaults.borderColor = 'rgba(255, 255, 255, 0.1)';\n\n           \
      \  const defaultLineOptions = { responsive: true, maintainAspectRatio: false,\
      \ animation: { duration: 250 }, plugins: { legend: { position: 'bottom', labels:\
      \ { padding: 10, boxWidth: 12, font: { size: 11 } } }, tooltip: { mode: 'index',\
      \ intersect: false, backgroundColor: 'rgba(0,0,0,0.8)' } }, scales: { x: { ticks:\
      \ { maxRotation: 0, autoSkip: true, maxTicksLimit: 10, font: { size: 10 } }\
      \ }, y: { ticks: { beginAtZero: true, font: { size: 10 }, precision: 0 }, grid:\
      \ { color: 'rgba(255, 255, 255, 0.08)' } } }, elements: { line: { tension: 0.2,\
      \ borderWidth: 1.5 }, point: { radius: 0, hitRadius: 10, hoverRadius: 4 } },\
      \ interaction: { mode: 'nearest', axis: 'x', intersect: false } };\n       \
      \      const defaultCategoricalOptions = { responsive: true, maintainAspectRatio:\
      \ false, plugins: { legend: { position: 'bottom', labels: { padding: 10, boxWidth:\
      \ 12, font: { size: 11 } } }, tooltip: { backgroundColor: 'rgba(0,0,0,0.8)'\
      \ } } };\n\n             // Requests Chart (Line)\n             const reqCtx\
      \ = document.getElementById('requestsChart')?.getContext('2d');\n          \
      \   if (reqCtx) chartInstances.requests = new Chart(reqCtx, { type: 'line',\
      \ data: { labels: [], datasets: [{ label: 'Requests/Interval', data: [], borderColor:\
      \ '#64b5f6', backgroundColor: 'rgba(100, 181, 246, 0.2)', fill: true }] }, options:\
      \ JSON.parse(JSON.stringify(defaultLineOptions)) }); else console.error(\"#requestsChart\
      \ not found\");\n\n             // Message Status Chart (Line)\n           \
      \  const msgCtx = document.getElementById('messageStatusChart')?.getContext('2d');\n\
      \             if (msgCtx) { const opts = JSON.parse(JSON.stringify(defaultLineOptions));\
      \ opts.elements.line.borderWidth = 2; chartInstances.messageStatus = new Chart(msgCtx,\
      \ { type: 'line', data: { labels: [], datasets: [ { label: 'Pending', data:\
      \ [], borderColor: '#ffb74d', fill: false }, { label: 'Processing', data: [],\
      \ borderColor: '#64b5f6', fill: false }, { label: 'Failed', data: [], borderColor:\
      \ '#e57373', fill: false }, { label: 'Processed', data: [], borderColor: '#81c784',\
      \ fill: false } ] }, options: opts }); } else console.error(\"#messageStatusChart\
      \ not found\");\n\n             // Performance Chart (Line, Multi-Axis)\n  \
      \           const perfCtx = document.getElementById('performanceChart')?.getContext('2d');\n\
      \             if (perfCtx) { const opts = JSON.parse(JSON.stringify(defaultLineOptions));\
      \ opts.scales.yCpu = { type: 'linear', position: 'left', title: { display: true,\
      \ text: 'CPU (%)', color: '#ba68c8' }, ticks: { color: '#ba68c8', suggestedMax:\
      \ 100, beginAtZero: true, precision: 1 } }; opts.scales.yMem = { type: 'linear',\
      \ position: 'right', title: { display: true, text: 'Memory (MB)', color: '#4dd0e1'\
      \ }, ticks: { color: '#4dd0e1', beginAtZero: true, precision: 1 }, grid: { drawOnChartArea:\
      \ false } }; delete opts.scales.y; chartInstances.performance = new Chart(perfCtx,\
      \ { type: 'line', data: { labels: [], datasets: [ { label: 'Process CPU %',\
      \ data: [], borderColor: '#ba68c8', fill: false, yAxisID: 'yCpu' }, { label:\
      \ 'Process Mem (MB)', data: [], borderColor: '#4dd0e1', fill: false, yAxisID:\
      \ 'yMem' } ] }, options: opts }); } else console.error(\"#performanceChart not\
      \ found\");\n\n             // Requests by Route (Bar)\n             const routeCtx\
      \ = document.getElementById('requestsByRouteChart')?.getContext('2d');\n   \
      \          if (routeCtx) { const opts = JSON.parse(JSON.stringify(defaultCategoricalOptions));\
      \ opts.indexAxis = 'y'; opts.plugins.legend.display = false; opts.scales = {\
      \ x: { ticks: { precision: 0, beginAtZero: true }, grid: { color: 'rgba(255,255,255,0.08)'\
      \ } }, y: { ticks: { font: { size: 10 } }, grid: { display: false } } }; chartInstances.requestsByRoute\
      \ = new Chart(routeCtx, { type: 'bar', data: { labels: [], datasets: [{ label:\
      \ 'Count', data: [], backgroundColor: [] }] }, options: opts }); } else console.error(\"\
      #requestsByRouteChart not found\");\n\n             // Requests by Status (Doughnut)\n\
      \             const statusCtx = document.getElementById('requestsByStatusChart')?.getContext('2d');\n\
      \             if (statusCtx) { const opts = JSON.parse(JSON.stringify(defaultCategoricalOptions));\
      \ opts.plugins.legend.position = 'right'; chartInstances.requestsByStatus =\
      \ new Chart(statusCtx, { type: 'doughnut', data: { labels: [], datasets: [{\
      \ label: 'Count', data: [], backgroundColor: [], borderWidth: 1, hoverOffset:\
      \ 8 }] }, options: opts }); } else console.error(\"#requestsByStatusChart not\
      \ found\");\n             console.log(\"Charts initialized.\");\n         }\n\
      \n        async function fetchData() {\n            if (statusIndicator && !statusIndicator.classList.contains('error'))\
      \ {\n                 statusIndicator.textContent = 'Fetching...'; statusIndicator.className\
      \ = 'status-indicator fetching';\n            }\n            console.debug(`[${new\
      \ Date().toLocaleTimeString()}] Fetching ${DASHBOARD_DATA_URL}`);\n\n      \
      \      try {\n                const response = await fetch(DASHBOARD_DATA_URL);\n\
      \                if (!response.ok) {\n                    let errorMsg = `Error\
      \ fetching dashboard data: ${response.status} ${response.statusText}`;\n   \
      \                 try { const errData = await response.json(); errorMsg += `\
      \ - ${errData.error || JSON.stringify(errData)}`; } catch (e) {}\n         \
      \           throw new Error(errorMsg);\n                }\n                const\
      \ data = await response.json();\n\n                if (data.error) { // Check\
      \ if backend reported an API fetch error\n                    if (lastKnownError\
      \ !== data.error) {\n                        console.error(\"Dashboard backend\
      \ reported API error:\", data.error);\n                        if (statusIndicator)\
      \ { statusIndicator.textContent = 'API Error'; statusIndicator.className = 'status-indicator\
      \ error'; }\n                        if (backendStatusSpan) { backendStatusSpan.textContent\
      \ = `API Error: ${data.error}`; backendStatusSpan.className = 'error'; }\n \
      \                       lastKnownError = data.error;\n                     \
      \   // clearCards(); // Optional: clear cards on backend error\n           \
      \         }\n                } else if (!data.latest_stats || Object.keys(data.latest_stats).length\
      \ === 0) { // Check for empty stats\n                     if (lastKnownError\
      \ !== \"Empty stats data\") {\n                        console.warn(\"Dashboard\
      \ backend returned empty 'latest_stats'.\");\n                        if (statusIndicator)\
      \ { statusIndicator.textContent = 'No Data'; statusIndicator.className = 'status-indicator\
      \ stale'; }\n                        const fetchTime = data.last_successful_fetch\
      \ ? new Date(data.last_successful_fetch).toLocaleString() : 'Never';\n     \
      \                   if (backendStatusSpan) { backendStatusSpan.textContent =\
      \ `No API stats received. Last fetch: ${fetchTime}`; backendStatusSpan.className\
      \ = 'error'; }\n                        lastKnownError = \"Empty stats data\"\
      ;\n                        clearCards();\n                        Object.values(chartInstances).forEach(chart\
      \ => updateChartData(chart)); // Clear charts\n                    }\n     \
      \           } else { // Success Case\n                    if (statusIndicator)\
      \ { statusIndicator.textContent = 'Live'; statusIndicator.className = 'status-indicator\
      \ live'; }\n                    const fetchTime = data.last_successful_fetch\
      \ ? new Date(data.last_successful_fetch).toLocaleString() : 'Never';\n     \
      \               if (backendStatusSpan) { backendStatusSpan.textContent = `Last\
      \ API fetch: ${fetchTime}`; backendStatusSpan.className = 'success'; }\n   \
      \                 updateDashboardUI(data);\n                    lastKnownError\
      \ = null;\n                }\n            } catch (error) { // Error fetching\
      \ from dashboard server itself\n                if (lastKnownError !== error.message)\
      \ {\n                    console.error(\"Error fetching or processing dashboard\
      \ data:\", error);\n                    if (statusIndicator) { statusIndicator.textContent\
      \ = 'Dashboard Error'; statusIndicator.className = 'status-indicator error';\
      \ }\n                    if (backendStatusSpan) { backendStatusSpan.textContent\
      \ = `Dashboard Fetch Error: ${error.message}`; backendStatusSpan.className =\
      \ 'error'; }\n                    lastKnownError = error.message;\n        \
      \            clearCards();\n                    Object.values(chartInstances).forEach(chart\
      \ => updateChartData(chart)); // Clear charts\n                 }\n        \
      \    }\n        }\n\n        function updateDashboardUI(data) {\n          \
      \   // Defend against incomplete data structures\n            if (!data || typeof\
      \ data !== 'object') { console.error(\"updateDashboardUI called with invalid\
      \ data:\", data); return; }\n            const stats = data.latest_stats ||\
      \ {};\n            const history = data.history || {};\n            const timeLabels\
      \ = history.time_labels || [];\n\n            // Update Cards\n            updateCardValue(cardValueElements.pendingMsgs,\
      \ stats.messages_pending);\n            updateCardValue(cardValueElements.processingMsgs,\
      \ stats.messages_processing);\n            updateCardValue(cardValueElements.failedMsgs,\
      \ stats.messages_failed);\n            updateCardValue(cardValueElements.processedMsgs,\
      \ stats.messages_processed);\n            updateCardValue(cardValueElements.totalRequests,\
      \ stats.requests_total);\n            // Access system stats safely\n      \
      \      const systemStats = stats.system || {};\n            updateCardValue(cardValueElements.processCpu,\
      \ systemStats.process_cpu_percent ?? null, formatPercentage);\n            updateCardValue(cardValueElements.processMem,\
      \ systemStats.process_memory_mb ?? null, formatMemory);\n            updateCardValue(cardValueElements.uptime,\
      \ stats.uptime_human, (val) => val || '--');\n\n            // Update Line Charts\
      \ (ensure history data exists)\n            const requestHistory = history.request_history\
      \ || [];\n            const messageStatusHistory = history.message_status ||\
      \ {};\n            const performanceHistory = history.performance || {};\n\n\
      \            updateChartData(chartInstances.requests, timeLabels, [ requestHistory\
      \ ]);\n            updateChartData(chartInstances.messageStatus, timeLabels,\
      \ [\n                messageStatusHistory.pending || [], messageStatusHistory.processing\
      \ || [],\n                messageStatusHistory.failed || [], messageStatusHistory.processed\
      \ || []\n            ]);\n            updateChartData(chartInstances.performance,\
      \ timeLabels, [\n                performanceHistory.cpu || [], performanceHistory.memory\
      \ || []\n            ]);\n\n            // Update Categorical Charts\n     \
      \       if (chartInstances.requestsByRoute) {\n                const routes\
      \ = stats.requests_by_route || {};\n                const routeLabels = Object.keys(routes).sort();\n\
      \                // Ensure routes[r] exists and is an object before using Object.values\n\
      \                const routeData = routeLabels.map(r => typeof routes[r] ===\
      \ 'object' && routes[r] !== null ? Object.values(routes[r]).reduce((s, c) =>\
      \ s + (Number(c) || 0), 0) : 0);\n                updateChartData(chartInstances.requestsByRoute,\
      \ routeLabels, [routeData]);\n            }\n            if (chartInstances.requestsByStatus)\
      \ {\n                const statuses = stats.requests_by_status || {};\n    \
      \            const statusLabels = Object.keys(statuses).sort((a, b) => Number(a)\
      \ - Number(b));\n                const statusData = statusLabels.map(s => statuses[s]\
      \ || 0);\n                updateChartData(chartInstances.requestsByStatus, statusLabels,\
      \ [statusData]);\n            }\n        }\n\n        document.addEventListener('DOMContentLoaded',\
      \ () => {\n            console.log(\"DOM Loaded. Initializing dashboard.\");\n\
      \            cacheDOMElements();\n            initializeCharts();\n        \
      \    clearCards();\n            fetchData(); // Initial fetch\n            if\
      \ (fetchDataIntervalId) clearInterval(fetchDataIntervalId);\n             //\
      \ NOTE: POLLING_INTERVAL_MS is available here because it was defined above\n\
      \            fetchDataIntervalId = setInterval(fetchData, POLLING_INTERVAL_MS);\n\
      \            console.log(`Polling data every ${POLLING_INTERVAL_MS / 1000}s.`);\n\
      \        });\n\n        // --- End Raw Block ---\n        {% endraw %}\n   \
      \ </script>\n</body>\n</html>\n\"\"\"\n\n\n# --- Flask Routes ---\n\n@app.route('/')\n\
      def serve_dashboard():\n    \"\"\"Serve the main dashboard HTML page.\"\"\"\n\
      \    logger.info(\"Serving dashboard HTML page.\")\n    try:\n        # Render\
      \ HTML, injecting Python config into JS template parts\n        return render_template_string(\n\
      \            HTML_CONTENT,\n            FETCH_INTERVAL_SECONDS=FETCH_INTERVAL_SECONDS,\n\
      \            MAX_CHART_HISTORY=MAX_CHART_HISTORY\n        )\n    except Exception\
      \ as e:\n        logger.error(f\"Error rendering dashboard template: {e}\",\
      \ exc_info=True)\n        return f\"<h1>Internal Server Error</h1><p>Failed\
      \ to render template: {e}</p>\", 500\n\n@app.route('/api/dashboard_data')\n\
      def get_dashboard_data():\n    \"\"\"Endpoint for frontend JS to fetch collected\
      \ data.\"\"\"\n    logger.debug(\"Request received for /api/dashboard_data\"\
      )\n    with data_lock:\n        try:\n            # Create snapshot, convert\
      \ deques to lists for JSON\n            data_to_send = {\n                \"\
      latest_stats\": app_state.get(\"latest_stats\", {}).copy(),\n              \
      \  \"history\": {\n                    \"time_labels\": list(app_state.get(\"\
      time_labels\", [])),\n                    \"request_history\": list(app_state.get(\"\
      request_history\", [])),\n                    \"message_status\": {k: list(v)\
      \ for k, v in app_state.get(\"message_status_history\", {}).items()},\n    \
      \                \"performance\": {k: list(v) for k, v in app_state.get(\"performance_history\"\
      , {}).items()}\n                },\n                \"last_successful_fetch\"\
      : app_state.get(\"last_successful_fetch\"),\n                \"error\": app_state.get(\"\
      last_error\") # Pass last known error\n            }\n        except Exception\
      \ as e:\n            logger.error(f\"Error preparing data for /api/dashboard_data:\
      \ {e}\", exc_info=True)\n            return jsonify({\"error\": \"Failed to\
      \ prepare data\", \"detail\": str(e)}), 500\n    return jsonify(data_to_send)\n\
      \n# --- Initialization ---\nif __name__ == '__main__':\n    # Optionally disable\
      \ warnings for insecure HTTPS requests made by this script\n    try:\n     \
      \   import urllib3\n        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\
      \        logger.warning(\"SSL certificate verification disabled for API requests\
      \ by dashboard. INSECURE FOR PRODUCTION.\")\n    except Exception as e: logger.warning(f\"\
      Could not disable urllib3 warnings: {e}\")\n\n    # Start the scheduler thread\n\
      \    scheduler_thread = threading.Thread(target=run_scheduler, name=\"SchedulerThread\"\
      , daemon=True)\n    scheduler_thread.start()\n\n    logger.info(f\"Starting\
      \ Dashboard server on http://0.0.0.0:{DASHBOARD_PORT}\")\n    logger.info(f\"\
      Fetching data from API ({API_BASE_URL}) every {FETCH_INTERVAL_SECONDS} seconds.\"\
      )\n\n    # Run Flask app (use a production server like Waitress/Gunicorn for\
      \ real deployment)\n    try:\n        # from waitress import serve\n       \
      \ # logger.info(\"Starting server with Waitress...\")\n        # serve(app,\
      \ host='0.0.0.0', port=DASHBOARD_PORT)\n        logger.info(\"Using Flask's\
      \ development server (use Waitress/Gunicorn for production).\")\n        app.run(host='0.0.0.0',\
      \ port=DASHBOARD_PORT, debug=False, use_reloader=False)\n    except KeyboardInterrupt:\n\
      \        logger.info(\"Dashboard server stopped.\")\n    except Exception as\
      \ e:\n        logger.critical(f\"Dashboard server failed: {e}\", exc_info=True)"
    tamanho: 0.04 MB
  webdocv1.py:
    caminho_completo: .\webdocv1.py
    classes: []
    functions:
    - docstring: Serves the main HTML documentation page.
      end_lineno: 975
      lineno: 972
      name: serve_documentation
    imports:
    - asname: null
      name: os
    - module: flask
      names:
      - Flask
      - Response
    numero_de_linhas: 982
    source_code: "# doc_server.py\nimport os\nfrom flask import Flask, Response\n\n\
      # --- Configuration ---\nDOC_SERVER_PORT = 8112\nAPI_BASE_URL = \"https://localhost:8777\"\
      \ # The actual base URL of your running API\n\n# --- Flask App ---\napp = Flask(__name__)\n\
      \n# --- HTML Content with Embedded CSS ---\n# Note: Using f-string for easy\
      \ embedding of API_BASE_URL\nHTML_CONTENT = f\"\"\"\n<!DOCTYPE html>\n<html\
      \ lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\"\
      \ content=\"width=device-width, initial-scale=1.0\">\n    <title>\U0001F680\
      \ Message Broker API Documentation</title>\n    <link rel=\"preconnect\" href=\"\
      https://fonts.googleapis.com\">\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\"\
      \ crossorigin>\n    <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap\"\
      \ rel=\"stylesheet\">\n    <style>\n        :root {{\n            --primary-color:\
      \ #6a11cb;\n            --secondary-color: #2575fc;\n            --card-bg:\
      \ rgba(255, 255, 255, 0.95);\n            --text-color: #333;\n            --heading-color:\
      \ #fff;\n            --code-bg: #f0f2f5;\n            --code-text: #333;\n \
      \           --shadow-light: rgba(0, 0, 0, 0.1);\n            --shadow-medium:\
      \ rgba(0, 0, 0, 0.15);\n            --border-radius: 8px;\n            --success-color:\
      \ #28a745;\n            --error-color: #dc3545;\n            --warning-color:\
      \ #ffc107;\n            --info-color: #17a2b8;\n        }}\n\n        * {{\n\
      \            margin: 0;\n            padding: 0;\n            box-sizing: border-box;\n\
      \        }}\n\n        body {{\n            font-family: 'Poppins', sans-serif;\n\
      \            line-height: 1.7;\n            color: var(--text-color);\n    \
      \        background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color)\
      \ 100%);\n            background-attachment: fixed;\n            padding: 20px;\n\
      \            font-size: 16px;\n        }}\n\n        .container {{\n       \
      \     max-width: 1000px;\n            margin: 20px auto;\n            background-color:\
      \ rgba(255, 255, 255, 0.85);\n            padding: 30px 40px;\n            border-radius:\
      \ var(--border-radius);\n            box-shadow: 0 10px 30px var(--shadow-medium);\n\
      \        }}\n\n        h1, h2, h3 {{\n            margin-bottom: 0.8em;\n  \
      \          color: var(--primary-color);\n            font-weight: 600;\n   \
      \     }}\n\n        h1 {{\n            font-size: 2.5em;\n            text-align:\
      \ center;\n            margin-bottom: 1em;\n            color: var(--secondary-color);\
      \ /* Different color for main title */\n            text-shadow: 1px 1px 2px\
      \ var(--shadow-light);\n        }}\n\n        h2 {{\n            font-size:\
      \ 1.8em;\n            border-bottom: 2px solid var(--secondary-color);\n   \
      \         padding-bottom: 0.3em;\n            margin-top: 1.8em;\n        }}\n\
      \n        h3 {{\n            font-size: 1.3em;\n            margin-top: 1.5em;\n\
      \            color: var(--primary-color);\n        }}\n\n        p {{\n    \
      \        margin-bottom: 1em;\n        }}\n\n        a {{\n            color:\
      \ var(--secondary-color);\n            text-decoration: none;\n        }}\n\n\
      \        a:hover {{\n            text-decoration: underline;\n        }}\n\n\
      \        .card {{\n            background-color: var(--card-bg);\n         \
      \   border-radius: var(--border-radius);\n            padding: 25px;\n     \
      \       margin-bottom: 25px;\n            box-shadow: 0 5px 15px var(--shadow-light);\n\
      \            border-left: 5px solid var(--primary-color);\n            transition:\
      \ transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;\n        }}\n\n \
      \       .card:hover {{\n            transform: translateY(-3px);\n         \
      \   box-shadow: 0 8px 20px var(--shadow-medium);\n        }}\n\n        .endpoint-header\
      \ {{\n            display: flex;\n            align-items: center;\n       \
      \     gap: 15px;\n            margin-bottom: 15px;\n            flex-wrap: wrap;\n\
      \        }}\n\n        .method {{\n            display: inline-block;\n    \
      \        padding: 5px 12px;\n            border-radius: 5px;\n            color:\
      \ #fff;\n            font-weight: 700;\n            font-size: 0.9em;\n    \
      \        text-transform: uppercase;\n        }}\n\n        .method-get {{ background-color:\
      \ #2575fc; }}\n        .method-post {{ background-color: #28a745; }}\n     \
      \   .method-delete {{ background-color: #dc3545; }}\n        .method-put {{\
      \ background-color: #fd7e14; }} /* Example if needed */\n        .method-patch\
      \ {{ background-color: #ffc107; }} /* Example if needed */\n\n        .endpoint-path\
      \ {{\n            font-family: 'Courier New', Courier, monospace;\n        \
      \    font-weight: 600;\n            font-size: 1.1em;\n            color: var(--primary-color);\n\
      \            word-break: break-all;\n            background-color: var(--code-bg);\n\
      \            padding: 3px 6px;\n            border-radius: 4px;\n        }}\n\
      \n        pre {{\n            background-color: var(--code-bg);\n          \
      \  color: var(--code-text);\n            padding: 15px;\n            border-radius:\
      \ var(--border-radius);\n            overflow-x: auto;\n            margin:\
      \ 15px 0;\n            font-size: 0.95em;\n            border: 1px solid #ddd;\n\
      \        }}\n\n        code {{\n            font-family: 'Courier New', Courier,\
      \ monospace;\n        }}\n\n        .details-section {{\n            margin-top:\
      \ 15px;\n            padding-left: 10px;\n            border-left: 3px solid\
      \ #eee;\n        }}\n\n        .details-section strong {{\n            display:\
      \ block;\n            margin-bottom: 5px;\n            color: var(--primary-color);\n\
      \        }}\n\n        .details-section ul {{\n            list-style: none;\n\
      \            padding-left: 0;\n        }}\n\n         .details-section ul li\
      \ {{\n            margin-bottom: 5px;\n            font-size: 0.95em;\n    \
      \     }}\n\n        .badge {{\n            display: inline-block;\n        \
      \    padding: 3px 8px;\n            border-radius: 4px;\n            font-size:\
      \ 0.85em;\n            font-weight: 600;\n            margin-left: 5px;\n  \
      \      }}\n\n        .badge-auth {{ background-color: var(--warning-color);\
      \ color: #333; }}\n        .badge-success {{ background-color: var(--success-color);\
      \ color: white; }}\n        .badge-error {{ background-color: var(--error-color);\
      \ color: white; }}\n        .badge-ratelimit {{ background-color: var(--info-color);\
      \ color: white; }}\n\n        /* Footer */\n        footer {{\n            text-align:\
      \ center;\n            margin-top: 40px;\n            padding-top: 20px;\n \
      \           border-top: 1px solid #ccc;\n            color: #555;\n        \
      \    font-size: 0.9em;\n        }}\n\n    </style>\n</head>\n<body>\n    <div\
      \ class=\"container\">\n        <h1>\U0001F680 Message Broker API Documentation</h1>\n\
      \n        <section id=\"introduction\">\n            <h2>\U0001F44B Introduction</h2>\n\
      \            <p>Welcome to the documentation for the Message Broker API V3 (Async/SQLite).\
      \ This API allows you to manage message queues and publish/consume messages\
      \ asynchronously.</p>\n            <p><strong>Base URL:</strong> <code class=\"\
      endpoint-path\">{API_BASE_URL}</code></p>\n            <p><strong>Authentication:</strong>\
      \ Most endpoints require authentication using JSON Web Tokens (JWT). Obtain\
      \ a token via the <code>/login</code> endpoint and include it in the <code>Authorization</code>\
      \ header of subsequent requests as <code>Bearer <your_access_token></code>.</p>\n\
      \            <p><strong>Content Type:</strong> All request bodies should be\
      \ JSON (<code>Content-Type: application/json</code>). Responses are also in\
      \ JSON format.</p>\n            <p><strong>Tools:</strong> You can interact\
      \ with this API using tools like <code>curl</code>, Postman, Insomnia, or programmatically\
      \ via HTTP clients in your preferred language.</p>\n        </section>\n\n \
      \       <section id=\"authentication\">\n            <h2>\U0001F511 Authentication</h2>\n\
      \n            <div class=\"card\">\n                <div class=\"endpoint-header\"\
      >\n                    <span class=\"method method-post\">POST</span>\n    \
      \                <span class=\"endpoint-path\">/login</span>\n             \
      \   </div>\n                <p>Authenticates a user and returns JWT access and\
      \ refresh tokens.</p>\n                <div class=\"details-section\">\n   \
      \                 <strong>Authentication:</strong> None required.\n        \
      \        </div>\n                <div class=\"details-section\">\n         \
      \           <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\"\
      >10 per minute</span>\n                </div>\n                 <div class=\"\
      details-section\">\n                    <strong>Request Body:</strong>\n   \
      \                 <pre><code>{{\n    \"username\": \"your_username\", // e.g.,\
      \ \"admin\"\n    \"password\": \"your_password\"  // e.g., \"admin\"\n}}</code></pre>\n\
      \                </div>\n                <div class=\"details-section\">\n \
      \                   <strong>Success Response (200 OK):</strong>\n          \
      \          <pre><code>{{\n    \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\
      ,\n    \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}}</code></pre>\n\
      \                </div>\n                <div class=\"details-section\">\n \
      \                   <strong>Error Responses:</strong>\n                    <ul>\n\
      \                        <li><span class=\"badge badge-error\">400</span> Bad\
      \ Request: Invalid payload format.</li>\n                        <li><span class=\"\
      badge badge-error\">401</span> Unauthorized: Invalid username or password.</li>\n\
      \                    </ul>\n                </div>\n            </div>\n\n \
      \           <div class=\"card\">\n                <div class=\"endpoint-header\"\
      >\n                    <span class=\"method method-post\">POST</span>\n    \
      \                <span class=\"endpoint-path\">/refresh</span>\n           \
      \     </div>\n                <p>Generates a new access token using a valid\
      \ refresh token.</p>\n                 <div class=\"details-section\">\n   \
      \                 <strong>Authentication:</strong> <span class=\"badge badge-auth\"\
      >JWT Refresh Token Required</span> (Provide refresh token in <code>Authorization:\
      \ Bearer <refresh_token></code> header).\n                </div>\n         \
      \        <div class=\"details-section\">\n                    <strong>Success\
      \ Response (200 OK):</strong>\n                    <pre><code>{{\n    \"access_token\"\
      : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\" // New access token\n}}</code></pre>\n\
      \                </div>\n                 <div class=\"details-section\">\n\
      \                    <strong>Error Responses:</strong>\n                   \
      \ <ul>\n                        <li><span class=\"badge badge-error\">401</span>\
      \ Unauthorized: Invalid or expired refresh token.</li>\n                   \
      \ </ul>\n                </div>\n            </div>\n        </section>\n\n\
      \        <section id=\"queues\">\n            <h2>\U0001F4E5 Queue Management</h2>\n\
      \n            <div class=\"card\">\n                <div class=\"endpoint-header\"\
      >\n                    <span class=\"method method-post\">POST</span>\n    \
      \                <span class=\"endpoint-path\">/queues</span>\n            \
      \    </div>\n                <p>Creates a new message queue.</p>\n         \
      \        <div class=\"details-section\">\n                    <strong>Authentication:</strong>\
      \ <span class=\"badge badge-auth\">JWT Access Token Required</span>\n      \
      \          </div>\n                <div class=\"details-section\">\n       \
      \             <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\"\
      >60 per minute</span>\n                </div>\n                 <div class=\"\
      details-section\">\n                    <strong>Request Body:</strong>\n   \
      \                 <pre><code>{{\n    \"name\": \"my-new-queue-name\" // String,\
      \ 1-255 chars, pattern: ^[a-zA-Z0-9_-]+$\n}}</code></pre>\n                </div>\n\
      \                <div class=\"details-section\">\n                    <strong>Success\
      \ Response (201 Created):</strong>\n                    <pre><code>{{\n    \"\
      msg\": \"Queue created\",\n    \"name\": \"my-new-queue-name\",\n    \"id\"\
      : 123 // Generated queue ID\n}}</code></pre>\n                </div>\n     \
      \            <div class=\"details-section\">\n                    <strong>Error\
      \ Responses:</strong>\n                    <ul>\n                        <li><span\
      \ class=\"badge badge-error\">400</span> Bad Request: Invalid payload (e.g.,\
      \ name format).</li>\n                        <li><span class=\"badge badge-error\"\
      >401</span> Unauthorized: Missing/Invalid JWT token.</li>\n                \
      \        <li><span class=\"badge badge-error\">409</span> Conflict: Queue name\
      \ already exists.</li>\n                        <li><span class=\"badge badge-error\"\
      >500</span> Internal Server Error: Database error.</li>\n                  \
      \  </ul>\n                </div>\n            </div>\n\n            <div class=\"\
      card\">\n                <div class=\"endpoint-header\">\n                 \
      \   <span class=\"method method-get\">GET</span>\n                    <span\
      \ class=\"endpoint-path\">/queues</span>\n                </div>\n         \
      \       <p>Lists all existing message queues.</p>\n                 <div class=\"\
      details-section\">\n                    <strong>Authentication:</strong> <span\
      \ class=\"badge badge-auth\">JWT Access Token Required</span>\n            \
      \    </div>\n                <div class=\"details-section\">\n             \
      \       <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\">100\
      \ per minute</span>\n                </div>\n                 <div class=\"\
      details-section\">\n                    <strong>Success Response (200 OK):</strong>\n\
      \                    <pre><code>[\n    {{\n        \"id\": 1,\n        \"name\"\
      : \"email-notifications\",\n        \"created_at\": \"2025-04-03T10:00:00Z\"\
      \n    }},\n    {{\n        \"id\": 2,\n        \"name\": \"image-processing\"\
      ,\n        \"created_at\": \"2025-04-03T11:30:00Z\"\n    }}\n    // ... more\
      \ queues\n]</code></pre>\n                </div>\n                 <div class=\"\
      details-section\">\n                    <strong>Error Responses:</strong>\n\
      \                    <ul>\n                         <li><span class=\"badge\
      \ badge-error\">401</span> Unauthorized: Missing/Invalid JWT token.</li>\n \
      \                        <li><span class=\"badge badge-error\">500</span> Internal\
      \ Server Error: Database error.</li>\n                    </ul>\n          \
      \      </div>\n            </div>\n\n            <div class=\"card\">\n    \
      \            <div class=\"endpoint-header\">\n                    <span class=\"\
      method method-get\">GET</span>\n                    <span class=\"endpoint-path\"\
      >/queues/{'{queue_name}'}</span>\n                </div>\n                <p>Retrieves\
      \ details for a specific queue, including the count of pending messages.</p>\n\
      \                 <div class=\"details-section\">\n                    <strong>Authentication:</strong>\
      \ <span class=\"badge badge-auth\">JWT Access Token Required</span>\n      \
      \          </div>\n                <div class=\"details-section\">\n       \
      \             <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\"\
      >100 per minute</span>\n                </div>\n                <div class=\"\
      details-section\">\n                    <strong>URL Parameters:</strong>\n \
      \                   <ul>\n                        <li><code>queue_name</code>\
      \ (string): The name of the queue to retrieve.</li>\n                    </ul>\n\
      \                </div>\n                 <div class=\"details-section\">\n\
      \                    <strong>Success Response (200 OK):</strong>\n         \
      \           <pre><code>{{\n    \"id\": 1,\n    \"name\": \"email-notifications\"\
      ,\n    \"created_at\": \"2025-04-03T10:00:00Z\",\n    \"pending_messages\":\
      \ 42\n}}</code></pre>\n                </div>\n                 <div class=\"\
      details-section\">\n                    <strong>Error Responses:</strong>\n\
      \                    <ul>\n                        <li><span class=\"badge badge-error\"\
      >401</span> Unauthorized: Missing/Invalid JWT token.</li>\n                \
      \        <li><span class=\"badge badge-error\">404</span> Not Found: The specified\
      \ queue name does not exist.</li>\n                        <li><span class=\"\
      badge badge-error\">500</span> Internal Server Error: Database error.</li>\n\
      \                    </ul>\n                </div>\n            </div>\n\n \
      \           <div class=\"card\">\n                <div class=\"endpoint-header\"\
      >\n                    <span class=\"method method-delete\">DELETE</span>\n\
      \                    <span class=\"endpoint-path\">/queues/{'{queue_name}'}</span>\n\
      \                </div>\n                <p>Deletes a specific queue and all\
      \ messages within it.</p>\n                 <div class=\"details-section\">\n\
      \                    <strong>Authentication:</strong> <span class=\"badge badge-auth\"\
      >JWT Access Token Required</span>\n                </div>\n                <div\
      \ class=\"details-section\">\n                    <strong>Rate Limit:</strong>\
      \ <span class=\"badge badge-ratelimit\">30 per minute</span>\n             \
      \   </div>\n                 <div class=\"details-section\">\n             \
      \       <strong>URL Parameters:</strong>\n                    <ul>\n       \
      \                 <li><code>queue_name</code> (string): The name of the queue\
      \ to delete.</li>\n                    </ul>\n                </div>\n     \
      \            <div class=\"details-section\">\n                    <strong>Success\
      \ Response (200 OK):</strong>\n                    <pre><code>{{\n    \"msg\"\
      : \"Queue 'queue-to-delete' deleted\"\n}}</code></pre>\n                </div>\n\
      \                 <div class=\"details-section\">\n                    <strong>Error\
      \ Responses:</strong>\n                    <ul>\n                        <li><span\
      \ class=\"badge badge-error\">401</span> Unauthorized: Missing/Invalid JWT token.</li>\n\
      \                        <li><span class=\"badge badge-error\">404</span> Not\
      \ Found: The specified queue name does not exist.</li>\n                   \
      \     <li><span class=\"badge badge-error\">500</span> Internal Server Error:\
      \ Database error.</li>\n                    </ul>\n                </div>\n\
      \            </div>\n        </section>\n\n        <section id=\"messages\"\
      >\n            <h2>✉️ Message Handling</h2>\n\n             <div class=\"card\"\
      >\n                <div class=\"endpoint-header\">\n                    <span\
      \ class=\"method method-post\">POST</span>\n                    <span class=\"\
      endpoint-path\">/queues/{'{queue_name}'}/messages</span>\n                </div>\n\
      \                <p>Publishes a new message to the specified queue.</p>\n  \
      \               <div class=\"details-section\">\n                    <strong>Authentication:</strong>\
      \ <span class=\"badge badge-auth\">JWT Access Token Required</span>\n      \
      \          </div>\n                <div class=\"details-section\">\n       \
      \             <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\"\
      >500 per minute</span>\n                </div>\n                <div class=\"\
      details-section\">\n                    <strong>URL Parameters:</strong>\n \
      \                   <ul>\n                        <li><code>queue_name</code>\
      \ (string): The name of the target queue.</li>\n                    </ul>\n\
      \                </div>\n                 <div class=\"details-section\">\n\
      \                    <strong>Request Body:</strong>\n                    <pre><code>{{\n\
      \    \"content\": {{ // Can be JSON object, string, or array\n        \"user_id\"\
      : 123,\n        \"task\": \"send_welcome_email\",\n        \"template\": \"\
      welcome_v1\"\n    }}\n}}</code></pre>\n                    <pre><code>{{\n \
      \   \"content\": \"Simple string message\"\n}}</code></pre>\n              \
      \      <pre><code>{{\n    \"content\": [\"item1\", \"item2\", 123]\n}}</code></pre>\n\
      \                </div>\n                <div class=\"details-section\">\n \
      \                   <strong>Success Response (201 Created):</strong>\n     \
      \               <pre><code>{{\n    \"msg\": \"Message published\",\n    \"message_id\"\
      : 5678 // Generated message ID\n}}</code></pre>\n                </div>\n  \
      \               <div class=\"details-section\">\n                    <strong>Error\
      \ Responses:</strong>\n                    <ul>\n                        <li><span\
      \ class=\"badge badge-error\">400</span> Bad Request: Invalid payload format.</li>\n\
      \                        <li><span class=\"badge badge-error\">401</span> Unauthorized:\
      \ Missing/Invalid JWT token.</li>\n                        <li><span class=\"\
      badge badge-error\">404</span> Not Found: The specified queue name does not\
      \ exist.</li>\n                        <li><span class=\"badge badge-error\"\
      >500</span> Internal Server Error: Database error.</li>\n                  \
      \  </ul>\n                </div>\n                 <div class=\"details-section\"\
      >\n                     <strong>Note:</strong> On success, an SSE event is published\
      \ to the queue's channel.\n                 </div>\n            </div>\n\n \
      \            <div class=\"card\">\n                <div class=\"endpoint-header\"\
      >\n                    <span class=\"method method-get\">GET</span>\n      \
      \              <span class=\"endpoint-path\">/queues/{'{queue_name}'}/messages</span>\n\
      \                </div>\n                <p>Consumes the oldest pending message\
      \ from the specified queue. Marks the message as 'processing'.</p>\n       \
      \          <div class=\"details-section\">\n                    <strong>Authentication:</strong>\
      \ <span class=\"badge badge-auth\">JWT Access Token Required</span>\n      \
      \          </div>\n                <div class=\"details-section\">\n       \
      \             <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\"\
      >200 per minute</span>\n                </div>\n                <div class=\"\
      details-section\">\n                    <strong>URL Parameters:</strong>\n \
      \                   <ul>\n                        <li><code>queue_name</code>\
      \ (string): The name of the queue to consume from.</li>\n                  \
      \  </ul>\n                </div>\n                 <div class=\"details-section\"\
      >\n                    <strong>Success Response (200 OK):</strong>\n       \
      \             <pre><code>{{\n    \"message_id\": 5678,\n    \"queue\": \"email-notifications\"\
      ,\n    \"content\": {{ // The original message content\n        \"user_id\"\
      : 123,\n        \"task\": \"send_welcome_email\",\n        \"template\": \"\
      welcome_v1\"\n    }},\n    \"status\": \"processing\",\n    \"retrieved_at\"\
      : \"2025-04-03T12:00:00Z\"\n}}</code></pre>\n                </div>\n      \
      \           <div class=\"details-section\">\n                    <strong>Success\
      \ Response (204 No Content):</strong>\n                    <ul>\n          \
      \               <li>Returned when there are no pending messages in the queue.\
      \ The response body is empty.</li>\n                    </ul>\n            \
      \     </div>\n                 <div class=\"details-section\">\n           \
      \         <strong>Error Responses:</strong>\n                    <ul>\n    \
      \                    <li><span class=\"badge badge-error\">401</span> Unauthorized:\
      \ Missing/Invalid JWT token.</li>\n                        <li><span class=\"\
      badge badge-error\">404</span> Not Found: The specified queue name does not\
      \ exist.</li>\n                        <li><span class=\"badge badge-error\"\
      >500</span> Internal Server Error: Database error during consumption.</li>\n\
      \                    </ul>\n                 </div>\n                  <div\
      \ class=\"details-section\">\n                     <strong>Important:</strong>\
      \ After successfully processing the message content received here, you <strong>must</strong>\
      \ call the ACK (<code>/messages/{'{message_id}'}/ack</code>) or NACK (<code>/messages/{'{message_id}'}/nack</code>)\
      \ endpoint. Failure to do so will leave the message in the 'processing' state\
      \ indefinitely.\n                 </div>\n            </div>\n\n           \
      \  <div class=\"card\">\n                <div class=\"endpoint-header\">\n \
      \                   <span class=\"method method-post\">POST</span>\n       \
      \             <span class=\"endpoint-path\">/messages/{'{message_id}'}/ack</span>\n\
      \                </div>\n                <p>✅ Acknowledges successful processing\
      \ of a message. Marks the message as 'processed'.</p>\n                 <div\
      \ class=\"details-section\">\n                    <strong>Authentication:</strong>\
      \ <span class=\"badge badge-auth\">JWT Access Token Required</span>\n      \
      \          </div>\n                <div class=\"details-section\">\n       \
      \             <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\"\
      >200 per minute</span>\n                </div>\n                 <div class=\"\
      details-section\">\n                    <strong>URL Parameters:</strong>\n \
      \                   <ul>\n                        <li><code>message_id</code>\
      \ (integer): The ID of the message to acknowledge.</li>\n                  \
      \  </ul>\n                </div>\n                <div class=\"details-section\"\
      >\n                    <strong>Request Body:</strong> None.\n              \
      \  </div>\n                 <div class=\"details-section\">\n              \
      \      <strong>Success Response (200 OK):</strong>\n                    <pre><code>{{\n\
      \    \"msg\": \"Message 5678 acknowledged\"\n}}</code></pre>\n             \
      \   </div>\n                 <div class=\"details-section\">\n             \
      \       <strong>Error Responses:</strong>\n                    <ul>\n      \
      \                  <li><span class=\"badge badge-error\">401</span> Unauthorized:\
      \ Missing/Invalid JWT token.</li>\n                        <li><span class=\"\
      badge badge-error\">403</span> Forbidden: You are not the consumer who retrieved\
      \ this message.</li>\n                        <li><span class=\"badge badge-error\"\
      >404</span> Not Found: The specified message ID does not exist.</li>\n     \
      \                   <li><span class=\"badge badge-error\">409</span> Conflict:\
      \ The message is not in the 'processing' state.</li>\n                     \
      \   <li><span class=\"badge badge-error\">500</span> Internal Server Error:\
      \ Database error.</li>\n                    </ul>\n                </div>\n\
      \                 <div class=\"details-section\">\n                     <strong>Note:</strong>\
      \ On success, an SSE event is published to the message's queue channel.\n  \
      \               </div>\n            </div>\n\n             <div class=\"card\"\
      >\n                <div class=\"endpoint-header\">\n                    <span\
      \ class=\"method method-post\">POST</span>\n                    <span class=\"\
      endpoint-path\">/messages/{'{message_id}'}/nack</span>\n                </div>\n\
      \                <p>❌ Negatively acknowledges a message, indicating processing\
      \ failed. Marks the message as 'failed'. (No automatic retry or DLQ implemented\
      \ in this version).</p>\n                 <div class=\"details-section\">\n\
      \                    <strong>Authentication:</strong> <span class=\"badge badge-auth\"\
      >JWT Access Token Required</span>\n                </div>\n                <div\
      \ class=\"details-section\">\n                    <strong>Rate Limit:</strong>\
      \ <span class=\"badge badge-ratelimit\">200 per minute</span>\n            \
      \    </div>\n                 <div class=\"details-section\">\n            \
      \        <strong>URL Parameters:</strong>\n                    <ul>\n      \
      \                  <li><code>message_id</code> (integer): The ID of the message\
      \ to NACK.</li>\n                    </ul>\n                </div>\n       \
      \          <div class=\"details-section\">\n                    <strong>Request\
      \ Body:</strong> None. (Optionally could accept a 'reason').\n             \
      \   </div>\n                 <div class=\"details-section\">\n             \
      \       <strong>Success Response (200 OK):</strong>\n                    <pre><code>{{\n\
      \    \"msg\": \"Message 5678 marked as failed (NACK)\"\n}}</code></pre>\n  \
      \              </div>\n                 <div class=\"details-section\">\n  \
      \                  <strong>Error Responses:</strong>\n                    <ul>\n\
      \                        <li><span class=\"badge badge-error\">401</span> Unauthorized:\
      \ Missing/Invalid JWT token.</li>\n                        <li><span class=\"\
      badge badge-error\">403</span> Forbidden: You are not the consumer who retrieved\
      \ this message.</li>\n                        <li><span class=\"badge badge-error\"\
      >404</span> Not Found: The specified message ID does not exist.</li>\n     \
      \                   <li><span class=\"badge badge-error\">409</span> Conflict:\
      \ The message is not in the 'processing' state.</li>\n                     \
      \   <li><span class=\"badge badge-error\">500</span> Internal Server Error:\
      \ Database error.</li>\n                    </ul>\n                </div>\n\
      \                 <div class=\"details-section\">\n                     <strong>Note:</strong>\
      \ On success, an SSE event is published to the message's queue channel.\n  \
      \               </div>\n            </div>\n        </section>\n\n        <section\
      \ id=\"stats\">\n            <h2>\U0001F4CA Statistics</h2>\n            <div\
      \ class=\"card\">\n                <div class=\"endpoint-header\">\n       \
      \             <span class=\"method method-get\">GET</span>\n               \
      \     <span class=\"endpoint-path\">/stats</span>\n                </div>\n\
      \                <p>Retrieves detailed statistics about the broker and the system\
      \ it's running on.</p>\n                <div class=\"details-section\">\n  \
      \                  <strong>Authentication:</strong> <span class=\"badge badge-auth\"\
      >JWT Access Token Required</span>\n                </div>\n                <div\
      \ class=\"details-section\">\n                    <strong>Rate Limit:</strong>\
      \ <span class=\"badge badge-ratelimit\">30 per minute</span>\n             \
      \   </div>\n                <div class=\"details-section\">\n              \
      \      <strong>Success Response (200 OK):</strong>\n                    <pre><code>{{\n\
      \    \"start_time\": \"2025-04-03T09:00:00Z\",\n    \"requests_total\": 1500,\n\
      \    \"requests_by_route\": {{\n        \"/queues\": {{ \"GET\": 500, \"POST\"\
      : 100 }},\n        \"/queues/<string:queue_name>/messages\": {{ \"GET\": 400,\
      \ \"POST\": 450 }},\n        // ... other routes\n    }},\n    \"requests_by_status\"\
      : {{\n        \"200\": 1200, \"201\": 100, \"204\": 50, \"404\": 100, \"401\"\
      : 50\n    }},\n    \"queues_total\": 5,\n    \"messages_total\": 10000,\n  \
      \  \"messages_pending\": 2000,\n    \"messages_processing\": 50,\n    \"messages_processed\"\
      : 7800,\n    \"messages_failed\": 150,\n    \"last_error\": null, // or \"DB\
      \ Stats Update Failed: 2025-04-03T13:00:00Z\"\n    \"system\": {{\n        \"\
      python_version\": \"3.10.x\",\n        \"platform\": \"Linux\", // or \"Windows\"\
      , \"Darwin\"\n        \"platform_release\": \"5.15.0-...\",\n        \"architecture\"\
      : \"x86_64\",\n        \"cpu_percent\": 15.5,\n        \"memory_total_gb\":\
      \ 15.6,\n        \"memory_available_gb\": 8.2,\n        \"memory_used_gb\":\
      \ 7.4,\n        \"memory_percent\": 47.4,\n        \"disk_usage\": {{\n    \
      \        \"/\": {{ \"total_gb\": 99.5, \"used_gb\": 40.2, \"free_gb\": 59.3,\
      \ \"percent\": 40.4 }}\n            // ... other mounted disks\n        }},\n\
      \        \"process_memory_mb\": 120.5,\n        \"process_cpu_percent\": 2.1\n\
      \    }},\n    \"broker_specific\": {{\n        \"db_engine\": \"sqlite (aiosqlite)\"\
      ,\n        \"auth_method\": \"jwt (access+refresh)\",\n        \"notification\"\
      : \"sse (redis)\",\n        \"rate_limit\": \"redis\"\n    }},\n    \"uptime_seconds\"\
      : 36000.5,\n    \"uptime_human\": \"10:00:00\"\n}}</code></pre>\n          \
      \      </div>\n                 <div class=\"details-section\">\n          \
      \          <strong>Error Responses:</strong>\n                    <ul>\n   \
      \                     <li><span class=\"badge badge-error\">401</span> Unauthorized:\
      \ Missing/Invalid JWT token.</li>\n                        <li><span class=\"\
      badge badge-error\">500</span> Internal Server Error: If stats collection fails\
      \ badly.</li>\n                    </ul>\n                </div>\n         \
      \   </div>\n        </section>\n\n         <section id=\"logs\">\n         \
      \   <h2>\U0001F4C4 Log Viewing</h2>\n             <p>These endpoints allow viewing\
      \ the JSON log files generated by the broker.</p>\n\n            <div class=\"\
      card\">\n                <div class=\"endpoint-header\">\n                 \
      \   <span class=\"method method-get\">GET</span>\n                    <span\
      \ class=\"endpoint-path\">/logs</span>\n                </div>\n           \
      \     <p>Lists the available JSON log files, sorted newest first.</p>\n    \
      \            <div class=\"details-section\">\n                    <strong>Authentication:</strong>\
      \ <span class=\"badge badge-auth\">JWT Access Token Required</span>\n      \
      \          </div>\n                <div class=\"details-section\">\n       \
      \             <strong>Rate Limit:</strong> <span class=\"badge badge-ratelimit\"\
      >10 per minute</span>\n                </div>\n                <div class=\"\
      details-section\">\n                    <strong>Success Response (200 OK):</strong>\n\
      \                    <pre><code>{{\n    \"log_files\": [\n        \"broker_log_20250403_140000_abcdef12.json\"\
      ,\n        \"broker_log_20250403_130000_fedcba98.json\"\n        // ... other\
      \ log files\n    ]\n}}</code></pre>\n                </div>\n              \
      \   <div class=\"details-section\">\n                    <strong>Error Responses:</strong>\n\
      \                    <ul>\n                        <li><span class=\"badge badge-error\"\
      >401</span> Unauthorized: Missing/Invalid JWT token.</li>\n                \
      \        <li><span class=\"badge badge-error\">500</span> Internal Server Error:\
      \ Error reading log directory.</li>\n                    </ul>\n           \
      \     </div>\n            </div>\n\n             <div class=\"card\">\n    \
      \            <div class=\"endpoint-header\">\n                    <span class=\"\
      method method-get\">GET</span>\n                    <span class=\"endpoint-path\"\
      >/logs/{'{filename}'}</span>\n                </div>\n                <p>Retrieves\
      \ the content of a specific log file.</p>\n                <div class=\"details-section\"\
      >\n                    <strong>Authentication:</strong> <span class=\"badge\
      \ badge-auth\">JWT Access Token Required</span>\n                </div>\n  \
      \              <div class=\"details-section\">\n                    <strong>Rate\
      \ Limit:</strong> <span class=\"badge badge-ratelimit\">60 per minute</span>\n\
      \                </div>\n                 <div class=\"details-section\">\n\
      \                    <strong>URL Parameters:</strong>\n                    <ul>\n\
      \                        <li><code>filename</code> (string): The exact name\
      \ of the JSON log file to retrieve (e.g., <code>broker_log_20250403_140000_abcdef12.json</code>).</li>\n\
      \                    </ul>\n                </div>\n                 <div class=\"\
      details-section\">\n                    <strong>Query Parameters (Optional):</strong>\n\
      \                    <ul>\n                        <li><code>start</code> (integer):\
      \ Line number to start reading from (1-based index).</li>\n                \
      \        <li><code>end</code> (integer): Line number to stop reading at (inclusive).</li>\n\
      \                        <li><code>tail</code> (integer): Retrieve only the\
      \ last N lines. (Takes precedence over start/end if provided).</li>\n      \
      \              </ul>\n                 </div>\n                 <div class=\"\
      details-section\">\n                    <strong>Success Response (200 OK):</strong>\
      \ Returns a JSON array, where each element is a parsed JSON log entry from a\
      \ line in the file.\n                    <pre><code>[\n    {{ // Log Entry 1\n\
      \        \"timestamp\": \"2025-04-03T14:00:01.123Z\",\n        \"level\": \"\
      INFO\",\n        \"name\": \"MessageBrokerV3\",\n        \"pid\": 12345,\n \
      \       \"thread\": \"MainThread\",\n        \"message\": \"\U0001F680 Initializing\
      \ Flask Application...\",\n        \"icon_type\": \"INFO\"\n    }},\n    {{\
      \ // Log Entry 2\n        \"timestamp\": \"2025-04-03T14:00:05.456Z\",\n   \
      \     \"level\": \"ERROR\",\n        \"name\": \"MessageBrokerV3\",\n      \
      \  \"pid\": 12345,\n        \"thread\": \"Thread-2\",\n        \"message\":\
      \ \"Database error consuming message from 'image-processing' (SQLite): database\
      \ is locked\",\n        \"icon_type\": \"DB\",\n        \"exception\": \"Traceback\
      \ (most recent call last):...\",\n        \"traceback\": [ \"...\" ] // Full\
      \ traceback array if exception occurred\n    }}\n    // ... more log entries\n\
      ]</code></pre>\n                 <p>If a line in the log file is not valid JSON,\
      \ it will be represented as:</p>\n                 <pre><code>{{\n    \"_error\"\
      : \"Invalid JSON\",\n    \"_line\": 15, // The line number where the error occurred\n\
      \    \"_raw\": \"This was not json {{ \"maybe\" }}\n}}\n</code></pre>\n    \
      \            </div>\n                 <div class=\"details-section\">\n    \
      \                <strong>Error Responses:</strong>\n                    <ul>\n\
      \                        <li><span class=\"badge badge-error\">400</span> Bad\
      \ Request: Invalid filename.</li>\n                        <li><span class=\"\
      badge badge-error\">401</span> Unauthorized: Missing/Invalid JWT token.</li>\n\
      \                        <li><span class=\"badge badge-error\">404</span> Not\
      \ Found: The specified log file does not exist.</li>\n                     \
      \   <li><span class=\"badge badge-error\">500</span> Internal Server Error:\
      \ Error reading the log file.</li>\n                    </ul>\n            \
      \    </div>\n            </div>\n        </section>\n\n         <section id=\"\
      graphql\">\n            <h2>\U0001F347 GraphQL API</h2>\n\n            <div\
      \ class=\"card\">\n                <div class=\"endpoint-header\">\n       \
      \             <span class=\"method method-post\">POST</span> / <span class=\"\
      method method-get\">GET</span>\n                    <span class=\"endpoint-path\"\
      >/graphql</span>\n                </div>\n                <p>Provides a GraphQL\
      \ endpoint for querying queues and messages.</p>\n                 <div class=\"\
      details-section\">\n                    <strong>Authentication:</strong> <span\
      \ class=\"badge badge-auth\">JWT Access Token Required</span>\n            \
      \    </div>\n                <div class=\"details-section\">\n             \
      \       <strong>Interface:</strong> Supports GET requests for introspection\
      \ and POST requests for queries/mutations (though only queries are defined here).\
      \ Accessing this endpoint in a browser typically shows the GraphiQL interface\
      \ for interactive exploration.\n                </div>\n                 <div\
      \ class=\"details-section\">\n                     <strong>Available Queries:</strong>\n\
      \                     <ul>\n                        <li><code>allQueues</code>:\
      \ Retrieves a list of all queues (supports pagination/sorting via Relay connections).</li>\n\
      \                        <li><code>queueByName(name: String!)</code>: Retrieves\
      \ a single queue by its exact name.</li>\n                        <li><code>messagesInQueue(queueName:\
      \ String!, status: String, limit: Int)</code>: Retrieves messages for a specific\
      \ queue, optionally filtering by status ('pending', 'processing', 'processed',\
      \ 'failed') and limiting the result count (default 100).</li>\n            \
      \         </ul>\n                 </div>\n                <div class=\"details-section\"\
      >\n                    <strong>Example GraphQL Query (POST Request Body):</strong>\n\
      \                    <pre><code>{{\n    \"query\": \\\"\\\"\\\"\n        query\
      \ {{\n          q1: queueByName(name: \"email-notifications\") {{\n        \
      \    id\n            name\n            createdAt\n          }}\n          pendingMessages:\
      \ messagesInQueue(queueName: \"image-processing\", status: \"pending\", limit:\
      \ 5) {{\n            edges {{\n              node {{\n                id\n \
      \               status\n                createdAt\n                content\n\
      \              }}\n            }}\n          }}\n        }}\n    \\\"\\\"\\\"\
      \n}}</code></pre>\n                </div>\n                <div class=\"details-section\"\
      >\n                    <strong>Success Response (200 OK):</strong> The structure\
      \ mirrors the GraphQL query.\n                    <pre><code>{{\n    \"data\"\
      : {{\n        \"q1\": {{\n            \"id\": \"UXVldWVPYmplY3Q6MQ==\", // Base64\
      \ encoded Relay ID\n            \"name\": \"email-notifications\",\n       \
      \     \"createdAt\": \"2025-04-03T10:00:00+00:00\"\n        }},\n        \"\
      pendingMessages\": {{\n             \"edges\": [\n                {{ \"node\"\
      : {{ \"id\": \"TWVzc2FnZU9iamVjdDo1...\", \"status\": \"pending\", ... }} }},\n\
      \                {{ \"node\": {{ \"id\": \"TWVzc2FnZU9iamVjdDo2...\", \"status\"\
      : \"pending\", ... }} }}\n             ]\n        }}\n    }}\n}}</code></pre>\n\
      \                </div>\n                 <div class=\"details-section\">\n\
      \                    <strong>Error Responses:</strong> GraphQL has its own error\
      \ reporting format within the JSON response, typically under an \"errors\" key.\
      \ HTTP status is usually 200 even if the query fails, unless there's an authentication\
      \ issue (401) or server error (500).\n                    <ul>\n           \
      \             <li><span class=\"badge badge-error\">401</span> Unauthorized:\
      \ Missing/Invalid JWT token.</li>\n                    </ul>\n             \
      \    </div>\n            </div>\n        </section>\n\n        <section id=\"\
      sse\">\n            <h2>\U0001F4E1 Server-Sent Events (SSE)</h2>\n\n       \
      \     <div class=\"card\">\n                 <div class=\"endpoint-header\"\
      >\n                    <span class=\"method method-get\">GET</span>\n      \
      \              <span class=\"endpoint-path\">/stream</span>\n              \
      \   </div>\n                 <p>Establishes a Server-Sent Events connection\
      \ to receive real-time notifications about message events.</p>\n           \
      \       <div class=\"details-section\">\n                    <strong>Authentication:</strong>\
      \ None required for the stream connection itself (consider adding JWT query\
      \ param auth if needed for specific use cases).\n                  </div>\n\
      \                  <div class=\"details-section\">\n                    <strong>How\
      \ it Works:</strong>\n                    <ul>\n                        <li>Clients\
      \ connect to this endpoint using the standard <code>EventSource</code> API in\
      \ JavaScript (or equivalent in other languages).</li>\n                    \
      \    <li>The server keeps this connection open and pushes events as they happen.</li>\n\
      \                        <li>Events are published by the server when:\n    \
      \                        <ul>\n                                <li>A new message\
      \ is published (event type: <code>message</code>, channel: <code>queue_name</code>).</li>\n\
      \                                <li>A message is acknowledged (event type:\
      \ <code>message</code>, channel: <code>queue_name</code>).</li>\n          \
      \                      <li>A message is NACKed (event type: <code>message</code>,\
      \ channel: <code>queue_name</code>).</li>\n                            </ul>\n\
      \                        </li>\n                        <li>The <code>channel</code>\
      \ parameter in the SSE URL (e.g., <code>/stream?channel=my-queue</code>) is\
      \ used by the <em>client</em> library (like the official `flask-sse` JS client)\
      \ to filter messages client-side if needed, but the Python backend currently\
      \ publishes events with the queue name embedded in the data and tagged with\
      \ the queue name as the channel type. You might need a specific client library\
      \ or custom JS to listen only to specific queue channels effectively based on\
      \ the pushed data or type.</li>\n                    </ul>\n               \
      \   </div>\n                  <div class=\"details-section\">\n            \
      \          <strong>Example JavaScript Client:</strong>\n                   \
      \   <pre><code>// Assuming you want events for the 'email-notifications' queue\n\
      const eventSource = new EventSource(\"{API_BASE_URL}/stream\"); // Connect to\
      \ the main stream\n\neventSource.onmessage = function(event) {{\n    console.log(\"\
      Raw message received:\", event.data);\n    try {{\n        const data = JSON.parse(event.data);\n\
      \n        // Check if the message is for the queue we care about\n        if\
      \ (data.queue === \"email-notifications\") {{\n            console.log(`Event\
      \ for email-notifications:`, data);\n            // Handle the event (e.g.,\
      \ update UI)\n            if (data.event === \"new_message\") {{\n         \
      \       console.log(`New message ${'{data.message_id}'} published.`);\n    \
      \        }} else if (data.event === \"message_acked\") {{\n                \
      \ console.log(`Message ${'{data.message_id}'} acknowledged.`);\n           \
      \ }} else if (data.event === \"message_nacked\") {{\n                 console.log(`Message\
      \ ${'{data.message_id}'} failed.`);\n            }}\n        }}\n    }} catch\
      \ (e) {{\n        console.error(\"Failed to parse SSE data:\", e);\n    }}\n\
      }};\n\neventSource.onerror = function(err) {{\n    console.error(\"EventSource\
      \ failed:\", err);\n    // Handle errors, maybe attempt reconnection\n}};\n\n\
      // To close the connection:\n// eventSource.close();\n</code></pre>\n      \
      \            </div>\n                  <div class=\"details-section\">\n   \
      \                 <strong>Event Data Format:</strong> The data field of each\
      \ SSE message is a JSON string like:\n                    <pre><code>{{\n  \
      \  \"queue\": \"queue_name\",      // Name of the queue the event pertains to\n\
      \    \"message_id\": 12345,        // ID of the relevant message\n    \"event\"\
      : \"new_message\"      // Type of event (\"new_message\", \"message_acked\"\
      , \"message_nacked\")\n}}</code></pre>\n                  </div>\n         \
      \   </div>\n        </section>\n\n        <footer>\n            Message Broker\
      \ API V3 Docs - Served by Flask\n        </footer>\n    </div>\n</body>\n</html>\n\
      \"\"\"\n\n@app.route('/')\ndef serve_documentation():\n    \"\"\"Serves the\
      \ main HTML documentation page.\"\"\"\n    # Use Response object for explicit\
      \ content type and status\n    return Response(HTML_CONTENT, mimetype='text/html',\
      \ status=200)\n\nif __name__ == '__main__':\n    print(f\" * Starting documentation\
      \ server on http://localhost:{DOC_SERVER_PORT}\")\n    # Use waitress or gunicorn\
      \ in production instead of Flask's development server\n    # For simplicity\
      \ here, we use the built-in server.\n    # Use host='0.0.0.0' to make it accessible\
      \ from other devices on the network\n    app.run(host='0.0.0.0', port=DOC_SERVER_PORT,\
      \ debug=False)"
    tamanho: 0.04 MB
.\certs_v3:
  cert.pem:
    caminho_completo: .\certs_v3\cert.pem
    numero_de_linhas: 21
    tamanho: 0.00 MB
  key_nopass.pem:
    caminho_completo: .\certs_v3\key_nopass.pem
    numero_de_linhas: 28
    tamanho: 0.00 MB
.\dash-templates: {}
.\databases:
  limpa-banco-.py:
    caminho_completo: .\databases\limpa-banco-.py
    classes: []
    functions:
    - docstring: "Limpa os dados das tabelas 'blockchain_blocos', 'transacao' e 'pool_mineracao'\n\
        no banco de dados SQLite especificado, mantendo apenas as duas primeiras linhas\
        \ de cada tabela.\nAs outras linhas serão completamente removidas.\nApós a\
        \ limpeza, executa VACUUM para reduzir o tamanho do arquivo DB.\n\nArgs:\n\
        \    db_path (str): Caminho para o arquivo do banco de dados SQLite."
      end_lineno: 57
      lineno: 4
      name: limpar_tabelas_blockchain_mantendo_duas_linhas
    imports:
    - asname: null
      name: sqlite3
    - asname: null
      name: os
    numero_de_linhas: 75
    source_code: "import sqlite3\nimport os\n\ndef limpar_tabelas_blockchain_mantendo_duas_linhas(db_path):\n\
      \    \"\"\"\n    Limpa os dados das tabelas 'blockchain_blocos', 'transacao'\
      \ e 'pool_mineracao'\n    no banco de dados SQLite especificado, mantendo apenas\
      \ as duas primeiras linhas de cada tabela.\n    As outras linhas serão completamente\
      \ removidas.\n    Após a limpeza, executa VACUUM para reduzir o tamanho do arquivo\
      \ DB.\n\n    Args:\n        db_path (str): Caminho para o arquivo do banco de\
      \ dados SQLite.\n    \"\"\"\n    conn = None  # Inicializa conn fora do bloco\
      \ try para usar no finally\n    try:\n        # Conecta ao banco de dados SQLite\n\
      \        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n\n\
      \        tabelas_para_limpar = ['blockchain_blocos', 'transacao', 'pool_mineracao']\n\
      \n        for tabela in tabelas_para_limpar:\n            # Conta o número de\
      \ linhas antes da limpeza\n            cursor.execute(f\"SELECT COUNT(*) FROM\
      \ {tabela}\")\n            linhas_antes = cursor.fetchone()[0]\n           \
      \ print(f\"Tabela '{tabela}': Linhas antes da limpeza: {linhas_antes}\")\n\n\
      \            # Deleta todos os dados da tabela, exceto as duas primeiras linhas\
      \ ordenadas por ID\n            cursor.execute(f\"\"\"\n                DELETE\
      \ FROM {tabela}\n                WHERE id NOT IN (SELECT id FROM {tabela} ORDER\
      \ BY id ASC LIMIT 2)\n            \"\"\")\n            print(f\"Dados da tabela\
      \ '{tabela}' limpos, mantendo as 2 primeiras linhas.\")\n\n            # Conta\
      \ o número de linhas após a limpeza\n            cursor.execute(f\"SELECT COUNT(*)\
      \ FROM {tabela}\")\n            linhas_depois = cursor.fetchone()[0]\n     \
      \       print(f\"Tabela '{tabela}': Linhas após a limpeza: {linhas_depois}\"\
      )\n\n        # Commita as alterações (IMPORTANTE: Commitar antes do VACUUM)\n\
      \        conn.commit()\n        print(\"Alterações commitadas.\")\n\n      \
      \  # Executa VACUUM para reduzir o tamanho do arquivo\n        cursor.execute(\"\
      VACUUM\")\n        conn.commit() # Commita o VACUUM também\n        print(\"\
      Comando VACUUM executado para reduzir o tamanho do arquivo.\")\n\n\n       \
      \ print(\"Operação de limpeza concluída (mantendo as duas primeiras linhas de\
      \ cada tabela e reduzindo o tamanho do DB).\")\n\n    except sqlite3.Error as\
      \ e:\n        print(f\"Erro ao limpar o banco de dados: {e}\")\n\n    finally:\n\
      \        if conn:\n            conn.close()\n\nif __name__ == \"__main__\":\n\
      \    db_file = 'blockchain.db' # Nome do arquivo do banco de dados na raiz\n\
      \    db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), db_file)\
      \ # Caminho completo para o db\n\n    if os.path.exists(db_path):\n        tamanho_inicial\
      \ = os.path.getsize(db_path) / (1024 * 1024) # Tamanho em MB\n        print(f\"\
      Tamanho inicial do banco de dados: {tamanho_inicial:.2f} MB\")\n        limpar_tabelas_blockchain_mantendo_duas_linhas(db_path)\n\
      \        tamanho_final = os.path.getsize(db_path) / (1024 * 1024) # Tamanho\
      \ em MB\n        print(f\"Tamanho final do banco de dados após limpeza e VACUUM:\
      \ {tamanho_final:.2f} MB\")\n        if tamanho_final < tamanho_inicial:\n \
      \           print(\"O tamanho do banco de dados foi reduzido com sucesso!\"\
      )\n        else:\n            print(\"O tamanho do banco de dados não foi reduzido\
      \ (ou a redução foi insignificante).\")\n\n    else:\n        print(f\"Banco\
      \ de dados '{db_path}' não encontrado na raiz do script.\")"
    tamanho: 0.00 MB
  message_broker_v3.db:
    caminho_completo: .\databases\message_broker_v3.db
    numero_de_linhas: -1
    sqlite_info:
      messages:
        columns:
        - !!python/tuple
          - id
          - INTEGER
        - !!python/tuple
          - content
          - TEXT
        - !!python/tuple
          - status
          - VARCHAR(20)
        - !!python/tuple
          - created_at
          - TIMESTAMP
        - !!python/tuple
          - updated_at
          - TIMESTAMP
        - !!python/tuple
          - queue_id
          - INT
        rows: []
      queues:
        columns:
        - !!python/tuple
          - id
          - INTEGER
        - !!python/tuple
          - name
          - VARCHAR(255)
        - !!python/tuple
          - created_at
          - TIMESTAMP
        - !!python/tuple
          - updated_at
          - TIMESTAMP
        rows: []
      sqlite_sequence:
        columns:
        - !!python/tuple
          - name
          - ''
        - !!python/tuple
          - seq
          - ''
        rows: []
    tamanho: 0.04 MB
  message_broker_v3.db-shm:
    caminho_completo: .\databases\message_broker_v3.db-shm
    numero_de_linhas: -1
    tamanho: 0.03 MB
  message_broker_v3.db-wal:
    caminho_completo: .\databases\message_broker_v3.db-wal
    numero_de_linhas: 0
    tamanho: 0.00 MB
.\documenta-projeto:
  doc_projeto_message_broker_replika_ai_v1_20250403_114342.md:
    caminho_completo: .\documenta-projeto\doc_projeto_message_broker_replika_ai_v1_20250403_114342.md
    numero_de_linhas: 167
    tamanho: 0.01 MB
.\logs_v3:
  broker_log_20250403_023313_f153a3a3.json:
    caminho_completo: .\logs_v3\broker_log_20250403_023313_f153a3a3.json
    json_info:
      numero_de_linhas: 150298
      tamanho: 50.88 MB
    numero_de_linhas: 150298
    tamanho: 50.88 MB
  broker_log_20250403_194354_99a2dd0d.json:
    caminho_completo: .\logs_v3\broker_log_20250403_194354_99a2dd0d.json
    json_info:
      numero_de_linhas: 5115
      tamanho: 1.73 MB
    numero_de_linhas: 5115
    tamanho: 1.73 MB
  broker_log_20250403_194623_9a40d26b.json:
    caminho_completo: .\logs_v3\broker_log_20250403_194623_9a40d26b.json
    json_info:
      numero_de_linhas: 76
      tamanho: 0.03 MB
    numero_de_linhas: 76
    tamanho: 0.03 MB
  broker_log_20250403_194729_8ada6f1f.json:
    caminho_completo: .\logs_v3\broker_log_20250403_194729_8ada6f1f.json
    json_info:
      numero_de_linhas: 46
      tamanho: 0.01 MB
    numero_de_linhas: 46
    tamanho: 0.01 MB
  broker_log_20250403_194813_99adfef1.json:
    caminho_completo: .\logs_v3\broker_log_20250403_194813_99adfef1.json
    json_info:
      numero_de_linhas: 61
      tamanho: 0.02 MB
    numero_de_linhas: 61
    tamanho: 0.02 MB
  broker_log_20250403_194950_a5f043aa.json:
    caminho_completo: .\logs_v3\broker_log_20250403_194950_a5f043aa.json
    json_info:
      numero_de_linhas: 46
      tamanho: 0.01 MB
    numero_de_linhas: 46
    tamanho: 0.01 MB
  broker_log_20250407_221659_9e3fe276.json:
    caminho_completo: .\logs_v3\broker_log_20250407_221659_9e3fe276.json
    json_info:
      numero_de_linhas: 111
      tamanho: 0.04 MB
    numero_de_linhas: 111
    tamanho: 0.04 MB
  broker_log_20250407_222757_92bf0f6c.json:
    caminho_completo: .\logs_v3\broker_log_20250407_222757_92bf0f6c.json
    json_info:
      numero_de_linhas: 33904
      tamanho: 11.45 MB
    numero_de_linhas: 33904
    tamanho: 11.45 MB
  broker_log_20250407_223937_39d99091.json:
    caminho_completo: .\logs_v3\broker_log_20250407_223937_39d99091.json
    json_info:
      numero_de_linhas: 31287
      tamanho: 10.58 MB
    numero_de_linhas: 31287
    tamanho: 10.58 MB
  broker_log_20250407_224802_7dc0aa81.json:
    caminho_completo: .\logs_v3\broker_log_20250407_224802_7dc0aa81.json
    json_info:
      numero_de_linhas: 43927
      tamanho: 14.83 MB
    numero_de_linhas: 43927
    tamanho: 14.83 MB
  broker_log_20250407_225313_9737b429.json:
    caminho_completo: .\logs_v3\broker_log_20250407_225313_9737b429.json
    json_info:
      numero_de_linhas: 74
      tamanho: 0.03 MB
    numero_de_linhas: 74
    tamanho: 0.03 MB
  broker_log_20250407_225839_0f7f854a.json:
    caminho_completo: .\logs_v3\broker_log_20250407_225839_0f7f854a.json
    json_info:
      numero_de_linhas: 101
      tamanho: 0.04 MB
    numero_de_linhas: 101
    tamanho: 0.04 MB
  broker_log_20250407_230233_dabccf22.json:
    caminho_completo: .\logs_v3\broker_log_20250407_230233_dabccf22.json
    json_info:
      numero_de_linhas: 68
      tamanho: 0.02 MB
    numero_de_linhas: 68
    tamanho: 0.02 MB
  broker_log_20250407_230346_a6ec4d22.json:
    caminho_completo: .\logs_v3\broker_log_20250407_230346_a6ec4d22.json
    json_info:
      numero_de_linhas: 493
      tamanho: 0.18 MB
    numero_de_linhas: 493
    tamanho: 0.18 MB
  broker_log_20250407_230455_111c0fbe.json:
    caminho_completo: .\logs_v3\broker_log_20250407_230455_111c0fbe.json
    json_info:
      numero_de_linhas: 3
      tamanho: 0.00 MB
    numero_de_linhas: 3
    tamanho: 0.00 MB
  broker_log_20250407_230541_d5d59adb.json:
    caminho_completo: .\logs_v3\broker_log_20250407_230541_d5d59adb.json
    json_info:
      numero_de_linhas: 3
      tamanho: 0.00 MB
    numero_de_linhas: 3
    tamanho: 0.00 MB
  broker_log_20250407_230631_297230ed.json:
    caminho_completo: .\logs_v3\broker_log_20250407_230631_297230ed.json
    json_info:
      numero_de_linhas: 38
      tamanho: 0.01 MB
    numero_de_linhas: 38
    tamanho: 0.01 MB
  broker_log_20250407_231124_d55459a4.json:
    caminho_completo: .\logs_v3\broker_log_20250407_231124_d55459a4.json
    json_info:
      numero_de_linhas: 39
      tamanho: 0.01 MB
    numero_de_linhas: 39
    tamanho: 0.01 MB
  broker_log_20250407_231132_7a68829d.json:
    caminho_completo: .\logs_v3\broker_log_20250407_231132_7a68829d.json
    json_info:
      numero_de_linhas: 66
      tamanho: 0.02 MB
    numero_de_linhas: 66
    tamanho: 0.02 MB
  broker_log_20250407_231158_fcb58719.json:
    caminho_completo: .\logs_v3\broker_log_20250407_231158_fcb58719.json
    json_info:
      numero_de_linhas: 38
      tamanho: 0.01 MB
    numero_de_linhas: 38
    tamanho: 0.01 MB
  broker_log_20250407_231222_f17d5a05.json:
    caminho_completo: .\logs_v3\broker_log_20250407_231222_f17d5a05.json
    json_info:
      numero_de_linhas: 54
      tamanho: 0.02 MB
    numero_de_linhas: 54
    tamanho: 0.02 MB
  broker_log_20250407_231405_4f12aafb.json:
    caminho_completo: .\logs_v3\broker_log_20250407_231405_4f12aafb.json
    json_info:
      numero_de_linhas: 83
      tamanho: 0.03 MB
    numero_de_linhas: 83
    tamanho: 0.03 MB
  broker_log_20250407_231541_ce5b9e30.json:
    caminho_completo: .\logs_v3\broker_log_20250407_231541_ce5b9e30.json
    json_info:
      numero_de_linhas: 71
      tamanho: 0.03 MB
    numero_de_linhas: 71
    tamanho: 0.03 MB
  broker_log_20250407_231719_45fa7ef1.json:
    caminho_completo: .\logs_v3\broker_log_20250407_231719_45fa7ef1.json
    json_info:
      numero_de_linhas: 98
      tamanho: 0.03 MB
    numero_de_linhas: 98
    tamanho: 0.03 MB
  broker_log_20250407_232356_18e0a157.json:
    caminho_completo: .\logs_v3\broker_log_20250407_232356_18e0a157.json
    json_info:
      numero_de_linhas: 101
      tamanho: 0.04 MB
    numero_de_linhas: 101
    tamanho: 0.04 MB
  broker_log_20250407_232804_57b59550.json:
    caminho_completo: .\logs_v3\broker_log_20250407_232804_57b59550.json
    json_info:
      numero_de_linhas: 122
      tamanho: 0.05 MB
    numero_de_linhas: 122
    tamanho: 0.05 MB
  broker_log_20250407_233057_4c3485a8.json:
    caminho_completo: .\logs_v3\broker_log_20250407_233057_4c3485a8.json
    json_info:
      numero_de_linhas: 212
      tamanho: 0.07 MB
    numero_de_linhas: 212
    tamanho: 0.07 MB
  broker_log_20250407_233441_5051f4c7.json:
    caminho_completo: .\logs_v3\broker_log_20250407_233441_5051f4c7.json
    json_info:
      numero_de_linhas: 101916
      tamanho: 33.28 MB
    numero_de_linhas: 101916
    tamanho: 33.28 MB
  broker_log_20250408_002747_61d981dc.json:
    caminho_completo: .\logs_v3\broker_log_20250408_002747_61d981dc.json
    json_info:
      numero_de_linhas: 33
      tamanho: 0.01 MB
    numero_de_linhas: 33
    tamanho: 0.01 MB
  broker_log_20250408_003836_99711a32.json:
    caminho_completo: .\logs_v3\broker_log_20250408_003836_99711a32.json
    json_info:
      numero_de_linhas: 36
      tamanho: 0.01 MB
    numero_de_linhas: 36
    tamanho: 0.01 MB
.\test-json-data-collector-validation:
  collected_data_minha-fila-teste-stress_20250407_230641_39095436.json:
    caminho_completo: .\test-json-data-collector-validation\collected_data_minha-fila-teste-stress_20250407_230641_39095436.json
    json_info:
      numero_de_linhas: 1
      tamanho: 0.00 MB
    numero_de_linhas: 1
    tamanho: 0.00 MB
  collected_data_minha-fila-teste-stress_20250407_231207_a7bc0b8a.json:
    caminho_completo: .\test-json-data-collector-validation\collected_data_minha-fila-teste-stress_20250407_231207_a7bc0b8a.json
    json_info:
      numero_de_linhas: 1
      tamanho: 0.00 MB
    numero_de_linhas: 1
    tamanho: 0.00 MB
.\test-json-data-collector-validation_batched:
  collected_batch_minha-fila-teste-stress_20250407_233814_264018_e03802ad.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233814_264018_e03802ad.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233814_410415_26c8c3fd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233814_410415_26c8c3fd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233814_651095_18db75f4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233814_651095_18db75f4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233814_809004_93a6dcf5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233814_809004_93a6dcf5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233814_940840_12c41786.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233814_940840_12c41786.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233815_072177_d436ea6e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233815_072177_d436ea6e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233815_208507_ef9c3241.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233815_208507_ef9c3241.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233815_370447_ff3cac28.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233815_370447_ff3cac28.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233815_563524_88e99366.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233815_563524_88e99366.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233815_726454_5594771d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233815_726454_5594771d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233816_040790_9e8e611a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233816_040790_9e8e611a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233816_181159_f105a13e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233816_181159_f105a13e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233816_330545_b7439102.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233816_330545_b7439102.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233816_486490_a6c2906a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233816_486490_a6c2906a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233816_623332_d950f857.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233816_623332_d950f857.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233816_758642_5de655ed.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233816_758642_5de655ed.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233816_915077_ac649cea.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233816_915077_ac649cea.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233817_153589_2553f721.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233817_153589_2553f721.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233817_295969_467c8484.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233817_295969_467c8484.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233817_551717_c65b4ba3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233817_551717_c65b4ba3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233817_698110_add1220c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233817_698110_add1220c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233817_855059_c0f0edec.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233817_855059_c0f0edec.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233818_018509_6877040f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233818_018509_6877040f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233818_161872_fee05f05.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233818_161872_fee05f05.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233818_317792_0d9ab028.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233818_317792_0d9ab028.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233818_461152_46783226.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233818_461152_46783226.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233818_609065_f16d2545.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233818_609065_f16d2545.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233818_818081_1e536fb5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233818_818081_1e536fb5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233818_967466_b2e2aa73.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233818_967466_b2e2aa73.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233819_100283_86f72d76.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233819_100283_86f72d76.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233819_235622_6b37f2db.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233819_235622_6b37f2db.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233819_373986_55c25aea.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233819_373986_55c25aea.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233819_530413_6af55c8c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233819_530413_6af55c8c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233819_704439_b09cc9b3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233819_704439_b09cc9b3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233820_006787_1aca322b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233820_006787_1aca322b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233820_263482_e103803c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233820_263482_e103803c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233820_400838_fbef7973.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233820_400838_fbef7973.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233820_542728_7d0afa19.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233820_542728_7d0afa19.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233820_681089_c6d3fe76.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233820_681089_c6d3fe76.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233820_815418_e34023c9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233820_815418_e34023c9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233820_951258_9404f602.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233820_951258_9404f602.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233821_087128_dfbaa92e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233821_087128_dfbaa92e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233821_219449_5af1e805.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233821_219449_5af1e805.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233821_356306_c48174b0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233821_356306_c48174b0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233821_486149_fdc7e1dd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233821_486149_fdc7e1dd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233821_680255_c5206026.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233821_680255_c5206026.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233821_912985_def0269e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233821_912985_def0269e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233822_280500_03bb77a3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233822_280500_03bb77a3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233822_506473_3cfb6b84.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233822_506473_3cfb6b84.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233822_654860_2c1267bf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233822_654860_2c1267bf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233822_810783_abab7362.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233822_810783_abab7362.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233822_994868_9fcc2372.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233822_994868_9fcc2372.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233823_165385_e9b39835.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233823_165385_e9b39835.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233823_329309_11fd39e1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233823_329309_11fd39e1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233823_456097_0f8c51c4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233823_456097_0f8c51c4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233823_585896_57d1db6e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233823_585896_57d1db6e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233823_751870_294e7785.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233823_751870_294e7785.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233823_882680_9ff4ab8d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233823_882680_9ff4ab8d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233824_008957_fce8f60a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233824_008957_fce8f60a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233824_154365_4362b683.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233824_154365_4362b683.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233824_299195_d3a06c55.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233824_299195_d3a06c55.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233824_443067_8b13446a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233824_443067_8b13446a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233824_595961_1be74e07.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233824_595961_1be74e07.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233824_771986_1ef7dc98.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233824_771986_1ef7dc98.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233825_005571_2ce1f70d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233825_005571_2ce1f70d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233825_138906_0816985b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233825_138906_0816985b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233825_283287_f78582f8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233825_283287_f78582f8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233825_498997_f2ff4966.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233825_498997_f2ff4966.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233825_738717_3892e46e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233825_738717_3892e46e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233825_904798_aeaff62a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233825_904798_aeaff62a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233826_165545_ca18533a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233826_165545_ca18533a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233826_369104_f808a279.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233826_369104_f808a279.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233826_518056_ccbf559b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233826_518056_ccbf559b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233826_672043_1dccbc76.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233826_672043_1dccbc76.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233826_831561_337d87e7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233826_831561_337d87e7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233826_983032_00351ac9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233826_983032_00351ac9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233827_128449_60a36fa2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233827_128449_60a36fa2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233827_278891_020bf5c9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233827_278891_020bf5c9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233827_416281_641f1aef.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233827_416281_641f1aef.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233827_581761_4e9ade4f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233827_581761_4e9ade4f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233827_837423_04dba1d7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233827_837423_04dba1d7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233827_986858_2dfeb2c0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233827_986858_2dfeb2c0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233828_130793_537d9c8c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233828_130793_537d9c8c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233828_269172_1432d059.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233828_269172_1432d059.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233828_404563_c2936120.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233828_404563_c2936120.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233828_554993_4fec857c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233828_554993_4fec857c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233828_712438_2bd0b00e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233828_712438_2bd0b00e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233828_864868_ac7031a6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233828_864868_ac7031a6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233829_041837_69cc7fe0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233829_041837_69cc7fe0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233829_297126_2b3ca495.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233829_297126_2b3ca495.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233829_435475_44b27bb1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233829_435475_44b27bb1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233829_573825_542b3db6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233829_573825_542b3db6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233829_704139_5e0c0c28.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233829_704139_5e0c0c28.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233829_852046_b173b23c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233829_852046_b173b23c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233830_017049_f73965a5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233830_017049_f73965a5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233830_213703_012bf405.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233830_213703_012bf405.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233830_453540_fa496af8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233830_453540_fa496af8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233830_731576_871d225e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233830_731576_871d225e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233831_040443_01d8f502.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233831_040443_01d8f502.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233831_487221_f90e250c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233831_487221_f90e250c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233831_728675_8dcb5a1a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233831_728675_8dcb5a1a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233832_055975_3fc8f36a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233832_055975_3fc8f36a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233832_247170_f11ebd35.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233832_247170_f11ebd35.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233832_400699_67c59fc2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233832_400699_67c59fc2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233832_547647_8549eae4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233832_547647_8549eae4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233832_771292_95c72fae.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233832_771292_95c72fae.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233832_926748_e0e71d86.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233832_926748_e0e71d86.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233833_164268_3bf66852.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233833_164268_3bf66852.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233833_294644_f7668c9a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233833_294644_f7668c9a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233833_418928_b491f898.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233833_418928_b491f898.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233833_548292_1f4ae594.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233833_548292_1f4ae594.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233833_680095_6c742c89.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233833_680095_6c742c89.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233833_812424_673e2c59.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233833_812424_673e2c59.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233833_941230_d1455276.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233833_941230_d1455276.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233834_070034_246b623e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233834_070034_246b623e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233834_318211_fa1d38c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233834_318211_fa1d38c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233834_454046_d5635b06.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233834_454046_d5635b06.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233834_590870_d14e5687.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233834_590870_d14e5687.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233834_723752_0cfc70fb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233834_723752_0cfc70fb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233834_854077_7b51fc5a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233834_854077_7b51fc5a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233834_986387_488eb37f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233834_986387_488eb37f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233835_130265_8271239b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233835_130265_8271239b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233835_292268_edf3f761.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233835_292268_edf3f761.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233835_427081_ee00950f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233835_427081_ee00950f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233835_554391_13cc7851.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233835_554391_13cc7851.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233835_684713_1624673e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233835_684713_1624673e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233835_815542_40a63eda.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233835_815542_40a63eda.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233836_039130_055aa5e3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233836_039130_055aa5e3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233836_166440_43bf5377.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233836_166440_43bf5377.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233836_415305_8ae89523.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233836_415305_8ae89523.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233836_627504_6da26590.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233836_627504_6da26590.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233836_798489_85569d8f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233836_798489_85569d8f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233836_926815_f2529923.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233836_926815_f2529923.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233837_063695_3cdcf3ac.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233837_063695_3cdcf3ac.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233837_196991_07dcc97c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233837_196991_07dcc97c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233837_344384_6255a99e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233837_344384_6255a99e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233837_568433_74207fc5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233837_568433_74207fc5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233837_698753_f5bf96aa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233837_698753_f5bf96aa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233837_831062_92d730ae.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233837_831062_92d730ae.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233837_962891_39a9fb59.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233837_962891_39a9fb59.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233838_101746_36fdad26.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233838_101746_36fdad26.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233838_258629_5a943670.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233838_258629_5a943670.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233838_493169_2299c735.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233838_493169_2299c735.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233838_626977_98d31482.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233838_626977_98d31482.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233838_753288_81590343.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233838_753288_81590343.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233838_883579_ba1f14fc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233838_883579_ba1f14fc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233839_011394_5ca9ea46.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233839_011394_5ca9ea46.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233839_180862_e79b2dd2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233839_180862_e79b2dd2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233839_345340_a1a7b8df.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233839_345340_a1a7b8df.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233839_513334_91720a30.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233839_513334_91720a30.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233839_641642_321c988f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233839_641642_321c988f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233839_773963_e615c6ef.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233839_773963_e615c6ef.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233839_906785_595606aa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233839_906785_595606aa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233840_037121_68c5f577.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233840_037121_68c5f577.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233840_169427_c01f935d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233840_169427_c01f935d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233840_301278_806a19e3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233840_301278_806a19e3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233840_555984_9fcb2d17.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233840_555984_9fcb2d17.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233840_683316_a6e1cd5e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233840_683316_a6e1cd5e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233840_808610_e38981f9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233840_808610_e38981f9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233840_940426_35c1aa7c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233840_940426_35c1aa7c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233841_072750_4913381e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233841_072750_4913381e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233841_207068_351d3748.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233841_207068_351d3748.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233841_481525_2c76df99.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233841_481525_2c76df99.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233841_706353_3d153758.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233841_706353_3d153758.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233841_839206_29645e9c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233841_839206_29645e9c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233841_968541_14429200.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233841_968541_14429200.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233842_111438_f73c7c20.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233842_111438_f73c7c20.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233842_238256_2450beb0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233842_238256_2450beb0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233842_366080_19befa5b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233842_366080_19befa5b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233842_499391_4fafc926.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233842_499391_4fafc926.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233842_640288_79c4f869.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233842_640288_79c4f869.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233842_768098_8cf6edc3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233842_768098_8cf6edc3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233842_893919_563de8cf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233842_893919_563de8cf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233843_023263_e17a0056.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233843_023263_e17a0056.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233843_157560_433d1213.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233843_157560_433d1213.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233843_285398_541ff310.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233843_285398_541ff310.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233843_410696_f4070f91.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233843_410696_f4070f91.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233843_563125_35f9e884.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233843_563125_35f9e884.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233843_790114_59dc38ca.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233843_790114_59dc38ca.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233843_956489_63915dbe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233843_956489_63915dbe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233844_172045_80371735.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233844_172045_80371735.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233844_300364_9a2ba1ff.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233844_300364_9a2ba1ff.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233844_456314_6a2d1bbb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233844_456314_6a2d1bbb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233844_611242_9034a042.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233844_611242_9034a042.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233844_743061_e80e923a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233844_743061_e80e923a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233844_873387_58ee3dc8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233844_873387_58ee3dc8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233845_003696_3f60145f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233845_003696_3f60145f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233845_136526_d75c9d6b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233845_136526_d75c9d6b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233845_263842_ca1d917c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233845_263842_ca1d917c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233845_396167_609cf9e2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233845_396167_609cf9e2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233845_662058_8d77e658.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233845_662058_8d77e658.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233845_985821_6a2e306f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233845_985821_6a2e306f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233846_174007_e0bd192c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233846_174007_e0bd192c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233846_813471_2eb412f3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233846_813471_2eb412f3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233847_033808_29008130.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233847_033808_29008130.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233847_336426_cb35599b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233847_336426_cb35599b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233847_548615_9068fba5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233847_548615_9068fba5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233847_713106_2128d702.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233847_713106_2128d702.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233847_841929_2d00edfe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233847_841929_2d00edfe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233847_976294_c11b4d51.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233847_976294_c11b4d51.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233848_124214_873c0b31.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233848_124214_873c0b31.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233848_251512_4fe14555.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233848_251512_4fe14555.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233848_481602_40aa80cb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233848_481602_40aa80cb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233848_609409_200b8e1b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233848_609409_200b8e1b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233848_738244_316caad0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233848_738244_316caad0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233848_880610_f66ee78d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233848_880610_f66ee78d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233849_114617_d6216e5e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233849_114617_d6216e5e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233849_247445_cbb44bcb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233849_247445_cbb44bcb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233849_386292_4d312fb2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233849_386292_4d312fb2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233849_515620_6d37b461.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233849_515620_6d37b461.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233849_671027_a4a30627.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233849_671027_a4a30627.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233849_814374_31f73c7a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233849_814374_31f73c7a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233849_939167_cf7c4831.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233849_939167_cf7c4831.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233850_064958_42c83c21.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233850_064958_42c83c21.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233850_216352_925f5a35.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233850_216352_925f5a35.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233850_348660_aeb2efe5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233850_348660_aeb2efe5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233850_480956_dbc2cca4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233850_480956_dbc2cca4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233850_607755_11bb06a5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233850_607755_11bb06a5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233850_735583_48938991.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233850_735583_48938991.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233850_879486_f41f739c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233850_879486_f41f739c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233851_014298_f74653a2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233851_014298_f74653a2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233851_155686_e1b035b8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233851_155686_e1b035b8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233851_293554_40e07fb9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233851_293554_40e07fb9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233851_430867_773b5de1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233851_430867_773b5de1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233851_823115_935519c7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233851_823115_935519c7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233852_247371_24e73615.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233852_247371_24e73615.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233852_530469_4bab68e8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233852_530469_4bab68e8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233852_898444_55bf24fa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233852_898444_55bf24fa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233853_243814_ccebb8de.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233853_243814_ccebb8de.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233853_463622_2d7a4cb9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233853_463622_2d7a4cb9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233853_751471_77a5c475.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233853_751471_77a5c475.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233853_912489_01fcfd0c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233853_912489_01fcfd0c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233854_047347_1df3b020.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233854_047347_1df3b020.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233854_189222_8ed1c25f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233854_189222_8ed1c25f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233854_424777_0659c1b3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233854_424777_0659c1b3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233854_549079_c82ef541.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233854_549079_c82ef541.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233854_674391_e156d848.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233854_674391_e156d848.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233854_802685_08665e45.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233854_802685_08665e45.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233854_928588_75aa78a6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233854_928588_75aa78a6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233855_062429_a7b011c6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233855_062429_a7b011c6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233855_210808_dca5b2a3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233855_210808_dca5b2a3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233855_364766_d9b9fd70.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233855_364766_d9b9fd70.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233855_525715_35ecc2dd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233855_525715_35ecc2dd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233855_697700_e28826c7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233855_697700_e28826c7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233855_832038_0b78e56f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233855_832038_0b78e56f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233856_072690_20465294.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233856_072690_20465294.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233856_204000_61711e1b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233856_204000_61711e1b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233856_355439_024709b1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233856_355439_024709b1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233856_733882_674a9c9c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233856_733882_674a9c9c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233856_984314_4fe067a4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233856_984314_4fe067a4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233857_210655_193dc9a8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233857_210655_193dc9a8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233857_448646_c3856cb2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233857_448646_c3856cb2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233857_808488_2d875623.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233857_808488_2d875623.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233858_075582_3ee64ac6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233858_075582_3ee64ac6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233858_331137_a4f5639d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233858_331137_a4f5639d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233858_530899_54bc6e93.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233858_530899_54bc6e93.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233858_670796_633ba5be.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233858_670796_633ba5be.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233858_813698_7cc7711b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233858_813698_7cc7711b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233858_956105_fbd6cfc5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233858_956105_fbd6cfc5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233859_100488_801b0abb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233859_100488_801b0abb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233859_433314_be0a4b46.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233859_433314_be0a4b46.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233859_846310_290fa1cc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233859_846310_290fa1cc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233900_092738_865fa38c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233900_092738_865fa38c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233900_235124_2ce1681e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233900_235124_2ce1681e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233900_393086_7f97fc35.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233900_393086_7f97fc35.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233900_566098_30c1f6b8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233900_566098_30c1f6b8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233900_720049_47c88822.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233900_720049_47c88822.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233900_860445_2433fb3b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233900_860445_2433fb3b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233901_108064_4dbdb142.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233901_108064_4dbdb142.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233901_255972_dede4adc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233901_255972_dede4adc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233901_407889_efa68c5c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233901_407889_efa68c5c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233901_558787_52fc98ab.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233901_558787_52fc98ab.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233901_710679_35a9f59d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233901_710679_35a9f59d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233901_836463_2a2a93d2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233901_836463_2a2a93d2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233901_977828_080b7578.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233901_977828_080b7578.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233902_107127_e66477e9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233902_107127_e66477e9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233902_230410_b34be550.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233902_230410_b34be550.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233902_470023_990b84c6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233902_470023_990b84c6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233902_627986_0525bb94.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233902_627986_0525bb94.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233902_777885_ad1918fe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233902_777885_ad1918fe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233902_930779_03b74d03.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233902_930779_03b74d03.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233903_075180_b5a36427.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233903_075180_b5a36427.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233903_221575_d50ae56b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233903_221575_d50ae56b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233903_367956_2215d4be.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233903_367956_2215d4be.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233903_513354_39b288c6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233903_513354_39b288c6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233903_673821_4556ca33.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233903_673821_4556ca33.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233903_808142_52a47590.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233903_808142_52a47590.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233903_938978_dcc4db4a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233903_938978_dcc4db4a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233904_177613_6d5e7efe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233904_177613_6d5e7efe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233904_341605_30eff7a8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233904_341605_30eff7a8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233904_549328_26f31bf7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233904_549328_26f31bf7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233904_780127_cfd2f57b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233904_780127_cfd2f57b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233904_924979_8dba4d47.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233904_924979_8dba4d47.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233905_151498_1c85e552.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233905_151498_1c85e552.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233905_284839_402b1030.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233905_284839_402b1030.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233905_415157_def5b696.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233905_415157_def5b696.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233905_543489_e99c4a75.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233905_543489_e99c4a75.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233905_678830_5a46f0f5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233905_678830_5a46f0f5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233905_822223_50fcb8e8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233905_822223_50fcb8e8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233905_954030_995bb5b5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233905_954030_995bb5b5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233906_083812_43eaea96.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233906_083812_43eaea96.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233906_217627_29104631.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233906_217627_29104631.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233906_456771_60bbcb56.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233906_456771_60bbcb56.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233906_584079_af97681d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233906_584079_af97681d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233906_725983_a0cf99a7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233906_725983_a0cf99a7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233906_861332_433775f6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233906_861332_433775f6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233906_989113_e74364e7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233906_989113_e74364e7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233907_117410_f3e2b2f0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233907_117410_f3e2b2f0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233907_247231_153c3eb2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233907_247231_153c3eb2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233907_392625_5ddf85f6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233907_392625_5ddf85f6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233907_526944_f00014fb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233907_526944_f00014fb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233907_652757_63b5c739.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233907_652757_63b5c739.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233907_797629_0bc980a2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233907_797629_0bc980a2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233907_925938_fe3159b4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233907_925938_fe3159b4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233908_054744_c4bcc33b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233908_054744_c4bcc33b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233908_191578_021ebaef.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233908_191578_021ebaef.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233908_327942_9d5ffc1e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233908_327942_9d5ffc1e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233908_467300_4abc8615.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233908_467300_4abc8615.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233908_595618_2867859b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233908_595618_2867859b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233908_727922_b44ffe07.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233908_727922_b44ffe07.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233908_889407_7b118876.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233908_889407_7b118876.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233909_117498_c4d8a717.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233909_117498_c4d8a717.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233909_248309_c4598861.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233909_248309_c4598861.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233909_476664_49d6353b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233909_476664_49d6353b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233909_654207_2688608b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233909_654207_2688608b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233909_826713_a4d00e80.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233909_826713_a4d00e80.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233909_954243_5c787def.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233909_954243_5c787def.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233910_098607_1883e216.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233910_098607_1883e216.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233910_249486_b1cb9225.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233910_249486_b1cb9225.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233910_497659_f30a6f17.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233910_497659_f30a6f17.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233910_717738_c2bedf60.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233910_717738_c2bedf60.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233910_871706_a61b7c2d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233910_871706_a61b7c2d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_000109_2242f480.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_000109_2242f480.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_128390_bfd645fc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_128390_bfd645fc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_255188_d479413c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_255188_d479413c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_397011_96f90bdf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_397011_96f90bdf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_529317_37f79bb6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_529317_37f79bb6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_653619_dcf1b123.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_653619_dcf1b123.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_784949_d14c5ba7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_784949_d14c5ba7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233911_940363_d1fb6844.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233911_940363_d1fb6844.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233912_074739_3ff8c651.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233912_074739_3ff8c651.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233912_212560_fa851be7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233912_212560_fa851be7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233912_340833_ae0fb805.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233912_340833_ae0fb805.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233912_474681_28ed2a9f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233912_474681_28ed2a9f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233912_607981_02c95f66.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233912_607981_02c95f66.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233912_742817_e0c49cbe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233912_742817_e0c49cbe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233912_888234_875dacbf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233912_888234_875dacbf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233913_022146_bdb8907c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233913_022146_bdb8907c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233913_239181_dcaa5632.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233913_239181_dcaa5632.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233913_374526_c7eba56b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233913_374526_c7eba56b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233913_501810_eb0751c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233913_501810_eb0751c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233913_631115_cbb667e0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233913_631115_cbb667e0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233913_763026_f39efe98.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233913_763026_f39efe98.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233913_907911_08fceda7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233913_907911_08fceda7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233914_040761_cecfe10f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233914_040761_cecfe10f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233914_170656_c9db8347.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233914_170656_c9db8347.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233914_364888_ceaa8d44.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233914_364888_ceaa8d44.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233914_570011_59b56230.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233914_570011_59b56230.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233914_746546_e44d3a7b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233914_746546_e44d3a7b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233914_877381_7cad1152.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233914_877381_7cad1152.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233915_021803_e50d1ebd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233915_021803_e50d1ebd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233915_150098_684abbda.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233915_150098_684abbda.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233915_276911_a187655f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233915_276911_a187655f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233915_401195_b2dd5775.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233915_401195_b2dd5775.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233915_550558_92a80f0d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233915_550558_92a80f0d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233915_780514_00ec9154.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233915_780514_00ec9154.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233915_912338_0a309bcc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233915_912338_0a309bcc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233916_058218_500810fd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233916_058218_500810fd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233916_277742_e75811ee.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233916_277742_e75811ee.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233916_419088_d2dc8f5f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233916_419088_d2dc8f5f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233916_555400_330b479c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233916_555400_330b479c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233916_678694_9beb2d88.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233916_678694_9beb2d88.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233916_811536_e932d765.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233916_811536_e932d765.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233916_945878_73106269.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233916_945878_73106269.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_084262_5600158a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_084262_5600158a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_212541_833482d1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_212541_833482d1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_340845_e7c6cefe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_340845_e7c6cefe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_470666_6af78ec5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_470666_6af78ec5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_598450_262c7636.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_598450_262c7636.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_726745_e3359c41.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_726745_e3359c41.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_849535_8292a2d5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_849535_8292a2d5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233917_988876_95ab1e25.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233917_988876_95ab1e25.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233918_127763_2b932b14.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233918_127763_2b932b14.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233918_252076_2e1d4bdb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233918_252076_2e1d4bdb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233918_398441_139ae945.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233918_398441_139ae945.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233918_530257_18d62042.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233918_530257_18d62042.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233918_663567_96883198.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233918_663567_96883198.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233918_791389_8c188938.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233918_791389_8c188938.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233918_921705_c496f797.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233918_921705_c496f797.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233919_066615_ddff5dc3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233919_066615_ddff5dc3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233919_194534_58d2141c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233919_194534_58d2141c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233919_361063_f3385ac5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233919_361063_f3385ac5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233919_563711_b5a35345.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233919_563711_b5a35345.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233919_754921_de6d74c0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233919_754921_de6d74c0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233919_960939_3d3510b8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233919_960939_3d3510b8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233920_137394_15bc10a8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233920_137394_15bc10a8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233920_264208_1d80ce1b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233920_264208_1d80ce1b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233920_392013_16e0f9f2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233920_392013_16e0f9f2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233920_523822_d1a81c91.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233920_523822_d1a81c91.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233920_649096_a0fcfac0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233920_649096_a0fcfac0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233920_777883_bd84867f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233920_777883_bd84867f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233920_914199_b0188507.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233920_914199_b0188507.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233921_155227_d6090edf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233921_155227_d6090edf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233921_287098_5623126a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233921_287098_5623126a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233921_445573_272fa45d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233921_445573_272fa45d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233921_588973_0b766948.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233921_588973_0b766948.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233921_724830_042485fb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233921_724830_042485fb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233921_868783_defd33c8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233921_868783_defd33c8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233922_097504_5e9ac551.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233922_097504_5e9ac551.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233922_234367_5442d162.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233922_234367_5442d162.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233922_370189_14a591ab.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233922_370189_14a591ab.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233922_498470_b045fad2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233922_498470_b045fad2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233922_625787_8ae7a316.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233922_625787_8ae7a316.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233922_762672_4f080d7d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233922_762672_4f080d7d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233922_905261_8647349f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233922_905261_8647349f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_030516_5f8dff90.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_030516_5f8dff90.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_177966_4f8d161c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_177966_4f8d161c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_306815_2f11f6a2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_306815_2f11f6a2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_435139_86ec8281.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_435139_86ec8281.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_563528_d5f723d8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_563528_d5f723d8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_693360_708f90d8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_693360_708f90d8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_823705_c5ec9c38.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_823705_c5ec9c38.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233923_948487_0f4f997a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233923_948487_0f4f997a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233924_077298_3ca0c686.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233924_077298_3ca0c686.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233924_232281_41f55541.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233924_232281_41f55541.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233924_429467_eec4d7cd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233924_429467_eec4d7cd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233924_604047_28afa2f8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233924_604047_28afa2f8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233924_770539_daabfcb8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233924_770539_daabfcb8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233924_897994_8be9720d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233924_897994_8be9720d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233925_029436_7da3ec32.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233925_029436_7da3ec32.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233925_158756_ca409886.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233925_158756_ca409886.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233925_325762_1f852596.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233925_325762_1f852596.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233925_480309_b53cd95e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233925_480309_b53cd95e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233925_629289_5049f75c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233925_629289_5049f75c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233925_941720_16d571c0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233925_941720_16d571c0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233926_112829_49333633.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233926_112829_49333633.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233926_394186_1cf29c09.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233926_394186_1cf29c09.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233926_539100_77d7c966.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233926_539100_77d7c966.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233926_676080_febe7459.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233926_676080_febe7459.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233926_827038_63a8d83e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233926_827038_63a8d83e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233926_968915_6fe375a4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233926_968915_6fe375a4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233927_128401_dba5869d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233927_128401_dba5869d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233927_281887_8f728a31.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233927_281887_8f728a31.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233927_426241_b0203ea5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233927_426241_b0203ea5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233927_568630_662949fc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233927_568630_662949fc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233927_721057_4048e3ee.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233927_721057_4048e3ee.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233927_864472_798710af.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233927_864472_798710af.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_004356_d6bb331a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_004356_d6bb331a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_150235_895837eb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_150235_895837eb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_297846_61e7546c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_297846_61e7546c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_434150_840b473a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_434150_840b473a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_562962_01f5a190.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_562962_01f5a190.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_691278_cdcc9cbc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_691278_cdcc9cbc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_819078_a45b12e0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_819078_a45b12e0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233928_948443_c134e6c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233928_948443_c134e6c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233929_234173_9e184099.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233929_234173_9e184099.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233929_469099_ad158966.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233929_469099_ad158966.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233929_692394_d755fa28.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233929_692394_d755fa28.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233929_854334_4c33ce27.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233929_854334_4c33ce27.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233930_009246_53685ce9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233930_009246_53685ce9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233930_156724_461069ac.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233930_156724_461069ac.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233930_307650_585a0350.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233930_307650_585a0350.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233930_470570_b377fafc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233930_470570_b377fafc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233930_613721_673fd2f6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233930_613721_673fd2f6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233930_754562_f773a476.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233930_754562_f773a476.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233930_879371_1104a2b9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233930_879371_1104a2b9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233931_006185_758e8c93.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233931_006185_758e8c93.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233931_132483_48d89028.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233931_132483_48d89028.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233931_265812_374babef.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233931_265812_374babef.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233931_426373_571b8731.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233931_426373_571b8731.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233931_567321_97747c73.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233931_567321_97747c73.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233931_788504_f349d890.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233931_788504_f349d890.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233931_922355_d9c7fb52.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233931_922355_d9c7fb52.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233932_053800_8176659a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233932_053800_8176659a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233932_185098_019ace62.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233932_185098_019ace62.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233932_327517_66e9922d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233932_327517_66e9922d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233932_509139_f9e08776.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233932_509139_f9e08776.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233932_657532_c6e86858.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233932_657532_c6e86858.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233932_788382_30f047c2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233932_788382_30f047c2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233932_918680_06139fe5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233932_918680_06139fe5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233933_044993_a0ba2590.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233933_044993_a0ba2590.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233933_174350_f448116b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233933_174350_f448116b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233933_313186_1c54d5a5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233933_313186_1c54d5a5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233933_466091_1246237b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233933_466091_1246237b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233933_595928_2f2866ff.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233933_595928_2f2866ff.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233933_727710_cb3cfef9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233933_727710_cb3cfef9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233933_974831_58140362.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233933_974831_58140362.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233934_106178_dccc7157.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233934_106178_dccc7157.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233934_232613_b161705f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233934_232613_b161705f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233934_493623_f591622d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233934_493623_f591622d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233934_746923_7e612f02.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233934_746923_7e612f02.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233934_872721_92cc04fa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233934_872721_92cc04fa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233934_998505_3e832f64.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233934_998505_3e832f64.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233935_127811_238480dd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233935_127811_238480dd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233935_254112_9c80ebef.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233935_254112_9c80ebef.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233935_388464_af366d60.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233935_388464_af366d60.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233935_544398_d44a1f4d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233935_544398_d44a1f4d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233935_671785_0cc342bc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233935_671785_0cc342bc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233935_799072_8007e9cd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233935_799072_8007e9cd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233935_929448_f3b7bd63.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233935_929448_f3b7bd63.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233936_062262_fb0ed001.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233936_062262_fb0ed001.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233936_190541_ef49c6ec.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233936_190541_ef49c6ec.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233936_325461_165da281.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233936_325461_165da281.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233936_463423_42df5741.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233936_463423_42df5741.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233936_607775_28e5cc00.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233936_607775_28e5cc00.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233936_750109_67f0c762.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233936_750109_67f0c762.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233936_977585_f085c0b3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233936_977585_f085c0b3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233937_102394_f34521ce.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233937_102394_f34521ce.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233937_229162_a19c997c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233937_229162_a19c997c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233937_463741_faab3c05.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233937_463741_faab3c05.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233937_622300_0b0fc719.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233937_622300_0b0fc719.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233937_750205_d95756de.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233937_750205_d95756de.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233937_876530_101c87f3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233937_876530_101c87f3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_003378_8a42df76.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_003378_8a42df76.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_133687_a79e660f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_133687_a79e660f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_265021_8a0430d0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_265021_8a0430d0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_397858_3520391b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_397858_3520391b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_530263_0fd6f3f8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_530263_0fd6f3f8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_693695_924786bd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_693695_924786bd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_822534_9f266f89.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_822534_9f266f89.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233938_953923_feffc78c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233938_953923_feffc78c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233939_084309_e94f462c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233939_084309_e94f462c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233939_217156_dfb03eae.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233939_217156_dfb03eae.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233939_425353_bb62db76.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233939_425353_bb62db76.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233939_647244_60ba7908.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233939_647244_60ba7908.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233939_803186_21999cfa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233939_803186_21999cfa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233939_932048_4eaaf8d4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233939_932048_4eaaf8d4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233940_063385_59426497.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233940_063385_59426497.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233940_197805_2e27b996.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233940_197805_2e27b996.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233940_327626_4d0bd938.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233940_327626_4d0bd938.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233940_455098_1ff54733.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233940_455098_1ff54733.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233940_596956_6b001caf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233940_596956_6b001caf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233940_749460_f6f588f1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233940_749460_f6f588f1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233940_875899_27d9195d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233940_875899_27d9195d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_003686_d3549203.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_003686_d3549203.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_134489_dd06a625.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_134489_dd06a625.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_263844_617cfe6d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_263844_617cfe6d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_398659_d2f0e6e3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_398659_d2f0e6e3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_527451_fdf83ff5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_527451_fdf83ff5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_668894_6f38e474.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_668894_6f38e474.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_801228_280f6a59.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_801228_280f6a59.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233941_938065_713c31b0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233941_938065_713c31b0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233942_076890_e0f1f652.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233942_076890_e0f1f652.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233942_294372_8bb6e207.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233942_294372_8bb6e207.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233942_421252_768d4900.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233942_421252_768d4900.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233942_550058_c054887e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233942_550058_c054887e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233942_693473_8ed309be.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233942_693473_8ed309be.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233942_832913_ccdce84f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233942_832913_ccdce84f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233942_978903_7197f475.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233942_978903_7197f475.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233943_139323_11d8ecd0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233943_139323_11d8ecd0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233943_265663_e87a6fd2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233943_265663_e87a6fd2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233943_395038_bc74fac6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233943_395038_bc74fac6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233943_526867_adb05198.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233943_526867_adb05198.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233943_666715_7bd727e2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233943_666715_7bd727e2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233943_801556_4888ef3e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233943_801556_4888ef3e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233943_928864_7e7e3015.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233943_928864_7e7e3015.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233944_057191_e549db4f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233944_057191_e549db4f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233944_192006_51e39640.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233944_192006_51e39640.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233944_361079_8903c605.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233944_361079_8903c605.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233944_546716_3be5fa19.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233944_546716_3be5fa19.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233944_764632_85c74b79.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233944_764632_85c74b79.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233944_896143_23add706.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233944_896143_23add706.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_035523_eec9adf5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_035523_eec9adf5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_170357_f4486e73.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_170357_f4486e73.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_297298_14bda595.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_297298_14bda595.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_429234_bee4713c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_429234_bee4713c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_558557_e0efae9b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_558557_e0efae9b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_684853_04e93818.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_684853_04e93818.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_832871_445392bd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_832871_445392bd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233945_963171_dda2c0a6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233945_963171_dda2c0a6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233946_216861_cd237980.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233946_216861_cd237980.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233946_350777_37bc82e1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233946_350777_37bc82e1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233946_476589_abcd51d2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233946_476589_abcd51d2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233946_605195_a8826682.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233946_605195_a8826682.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233946_739118_7d286a99.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233946_739118_7d286a99.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233947_027211_e6a21d46.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233947_027211_e6a21d46.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233947_164558_3c008897.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233947_164558_3c008897.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233947_295891_c3b306e3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233947_295891_c3b306e3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233947_436725_00745da7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233947_436725_00745da7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233947_660689_431e6d4c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233947_660689_431e6d4c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233947_803651_d5e2d1b6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233947_803651_d5e2d1b6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233947_938961_027f617d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233947_938961_027f617d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233948_068300_7a2b00d2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233948_068300_7a2b00d2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233948_205149_f676db87.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233948_205149_f676db87.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233948_332955_c18fbdfd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233948_332955_c18fbdfd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233948_470808_37900c9c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233948_470808_37900c9c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233948_596605_a163fd57.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233948_596605_a163fd57.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233948_728408_c909f929.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233948_728408_c909f929.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233948_884349_8e73a1c5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233948_884349_8e73a1c5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233949_010637_6aa9fc15.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233949_010637_6aa9fc15.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233949_141462_c8d37baa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233949_141462_c8d37baa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233949_315490_5609e210.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233949_315490_5609e210.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233949_527686_58505b13.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233949_527686_58505b13.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233949_828106_c2e80ae3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233949_828106_c2e80ae3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_008130_75ecd379.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_008130_75ecd379.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_131944_bc8eaaea.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_131944_bc8eaaea.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_257728_0b03eea6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_257728_0b03eea6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_396581_1de9009c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_396581_1de9009c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_529408_aed52976.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_529408_aed52976.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_663242_64901f31.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_663242_64901f31.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_788046_5c13540e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_788046_5c13540e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233950_931962_9da5c3d8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233950_931962_9da5c3d8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_064275_ec59432d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_064275_ec59432d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_192587_c2cb24a2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_192587_c2cb24a2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_324433_14308490.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_324433_14308490.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_455754_c064f6b3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_455754_c064f6b3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_591580_34a6116d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_591580_34a6116d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_717360_ead57e9b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_717360_ead57e9b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_846685_5e63e215.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_846685_5e63e215.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233951_991612_e2eae182.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233951_991612_e2eae182.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233952_122931_0e00a1bf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233952_122931_0e00a1bf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233952_253722_975489bb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233952_253722_975489bb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233952_378496_9fdb8312.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233952_378496_9fdb8312.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233952_508771_55412848.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233952_508771_55412848.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233952_638564_8b679a7f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233952_638564_8b679a7f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233952_977861_0f317ab0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233952_977861_0f317ab0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233953_108163_6f2bd2f1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233953_108163_6f2bd2f1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233953_232513_a0c785e1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233953_232513_a0c785e1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233953_362840_8fc78632.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233953_362840_8fc78632.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233953_514251_b38a713a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233953_514251_b38a713a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233953_663119_ac4f0987.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233953_663119_ac4f0987.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233953_792424_e55006fd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233953_792424_e55006fd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233953_918236_83be6d78.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233953_918236_83be6d78.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233954_062126_c6731143.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233954_062126_c6731143.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233954_188921_556922d6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233954_188921_556922d6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233954_358978_6fb2d942.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233954_358978_6fb2d942.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233954_774680_e56143cc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233954_774680_e56143cc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233954_905995_9aad2243.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233954_905995_9aad2243.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_046589_48d52392.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_046589_48d52392.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_174996_30a21551.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_174996_30a21551.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_298787_11e60a3c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_298787_11e60a3c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_431152_a237caaf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_431152_a237caaf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_560611_73c3e645.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_560611_73c3e645.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_688508_fbd6a8e1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_688508_fbd6a8e1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_822372_5fd4d7e8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_822372_5fd4d7e8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233955_951205_2f925413.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233955_951205_2f925413.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233956_096170_ade2bab3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233956_096170_ade2bab3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233956_227485_8322eaea.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233956_227485_8322eaea.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233956_371415_ceebd4f0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233956_371415_ceebd4f0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233956_514465_174895e7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233956_514465_174895e7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233956_671902_8b8efdb3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233956_671902_8b8efdb3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233956_821309_f8de40e3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233956_821309_f8de40e3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233957_071151_0d1f7a5a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233957_071151_0d1f7a5a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233957_219093_3ce1c87f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233957_219093_3ce1c87f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233957_359111_0ad86fa5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233957_359111_0ad86fa5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233957_510512_a86f405e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233957_510512_a86f405e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233957_648386_bfe884d3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233957_648386_bfe884d3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233957_800815_1d628822.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233957_800815_1d628822.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233957_944816_47a71cd2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233957_944816_47a71cd2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233958_124117_8c0a57fa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233958_124117_8c0a57fa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233958_454100_bb99f643.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233958_454100_bb99f643.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233958_605554_58e55af3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233958_605554_58e55af3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233958_765962_3ca197be.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233958_765962_3ca197be.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233958_910832_e4e2198e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233958_910832_e4e2198e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233959_057330_d87f1ad7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233959_057330_d87f1ad7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233959_220363_d82c0b3f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233959_220363_d82c0b3f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233959_418583_96b56dc9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233959_418583_96b56dc9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233959_628270_7dd5df37.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233959_628270_7dd5df37.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233959_796292_f0142041.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233959_796292_f0142041.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_233959_925699_779ff79d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_233959_925699_779ff79d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234000_062065_57bf3b64.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234000_062065_57bf3b64.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234000_222586_dad01ece.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234000_222586_dad01ece.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234000_368941_4ac76044.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234000_368941_4ac76044.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234000_516828_2d341f01.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234000_516828_2d341f01.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234000_671952_d1aa4b6f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234000_671952_d1aa4b6f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234000_814860_7c34093f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234000_814860_7c34093f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234000_963361_96686b83.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234000_963361_96686b83.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234001_122273_45e9c776.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234001_122273_45e9c776.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234001_257641_aa05a6bb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234001_257641_aa05a6bb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234001_391975_10ac82ba.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234001_391975_10ac82ba.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234001_525304_12c94331.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234001_525304_12c94331.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234001_652150_96da3efa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234001_652150_96da3efa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234001_777935_ad72ae17.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234001_777935_ad72ae17.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234001_916774_3270511c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234001_916774_3270511c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_048581_1af8d85f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_048581_1af8d85f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_200533_2974d8b0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_200533_2974d8b0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_329313_5bf8b0c1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_329313_5bf8b0c1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_460631_eb6f06b9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_460631_eb6f06b9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_584461_41126009.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_584461_41126009.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_717769_c4bd5b46.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_717769_c4bd5b46.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_843626_f3f66df0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_843626_f3f66df0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234002_973066_4643edf8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234002_973066_4643edf8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234003_106511_f1d13b09.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234003_106511_f1d13b09.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234003_261545_9a06b189.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234003_261545_9a06b189.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234003_393962_8a0f2f48.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234003_393962_8a0f2f48.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234003_530773_8981fc55.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234003_530773_8981fc55.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234003_753882_f1f5fe63.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234003_753882_f1f5fe63.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234003_885193_c6e7d4e1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234003_885193_c6e7d4e1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234004_015521_3a928c56.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234004_015521_3a928c56.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234004_145485_c5847b7c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234004_145485_c5847b7c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234004_308557_c8645ee0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234004_308557_c8645ee0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234004_495915_1037f540.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234004_495915_1037f540.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234004_679495_c07b008d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234004_679495_c07b008d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234004_823909_2a78ef25.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234004_823909_2a78ef25.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234004_950236_bb7f77f8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234004_950236_bb7f77f8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234005_078655_d35fe32f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234005_078655_d35fe32f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234005_229059_3edbba89.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234005_229059_3edbba89.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234005_380549_5a4e1cd9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234005_380549_5a4e1cd9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234005_513876_b4cef4ea.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234005_513876_b4cef4ea.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234005_646201_1eb372ed.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234005_646201_1eb372ed.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234005_776008_9eee1665.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234005_776008_9eee1665.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234005_901292_f31e917b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234005_901292_f31e917b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_038600_4e02a47b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_038600_4e02a47b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_166374_a2c136d1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_166374_a2c136d1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_314258_52b3f93f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_314258_52b3f93f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_461631_caa6a004.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_461631_caa6a004.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_598561_9d705b6a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_598561_9d705b6a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_727888_784a1c54.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_727888_784a1c54.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_856198_e446b996.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_856198_e446b996.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234006_984511_2ba9e6e4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234006_984511_2ba9e6e4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234007_193573_866e110e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234007_193573_866e110e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234007_383542_e09ce9aa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234007_383542_e09ce9aa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234007_521372_6371a1a4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234007_521372_6371a1a4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234007_655180_bbf7ee81.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234007_655180_bbf7ee81.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234007_782505_cb765da4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234007_782505_cb765da4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234007_912817_11f578eb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234007_912817_11f578eb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234008_038600_265e469c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234008_038600_265e469c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234008_171923_ed5f0511.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234008_171923_ed5f0511.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234008_308249_2ee13e82.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234008_308249_2ee13e82.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234008_458157_49a6d817.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234008_458157_49a6d817.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234008_587505_c3fd6029.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234008_587505_c3fd6029.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234008_729327_9efaa7ce.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234008_729327_9efaa7ce.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234008_947396_f97ff968.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234008_947396_f97ff968.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234009_080246_0fbf2360.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234009_080246_0fbf2360.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234009_209056_aa558d56.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234009_209056_aa558d56.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234009_414245_205da434.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234009_414245_205da434.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234009_625454_2aae1169.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234009_625454_2aae1169.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_053811_bbee304b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_053811_bbee304b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_192650_be4970fb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_192650_be4970fb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_328959_10ef49ce.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_328959_10ef49ce.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_473886_684e2e65.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_473886_684e2e65.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_598669_7cac0a98.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_598669_7cac0a98.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_725978_fda0426d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_725978_fda0426d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_850280_e8f5c1a1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_850280_e8f5c1a1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234010_979053_311ccc76.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234010_979053_311ccc76.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234011_137950_30f3d89a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234011_137950_30f3d89a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234011_344952_0c3af21f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234011_344952_0c3af21f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234011_540454_af2500cc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234011_540454_af2500cc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234011_674806_cc33e87d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234011_674806_cc33e87d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234011_816661_f63dafef.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234011_816661_f63dafef.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234011_970547_28c44bd3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234011_970547_28c44bd3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234012_125444_d4dc998c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234012_125444_d4dc998c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234012_257283_7ff70eae.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234012_257283_7ff70eae.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234012_415201_ed57ad80.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234012_415201_ed57ad80.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234012_616815_0f9b36fc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234012_616815_0f9b36fc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234012_854005_de42927d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234012_854005_de42927d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234013_031992_9a803401.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234013_031992_9a803401.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234013_190428_0fb7c894.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234013_190428_0fb7c894.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234013_360936_f6e563a6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234013_360936_f6e563a6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234013_547971_ab0108a4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234013_547971_ab0108a4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234013_676806_8a3bcdb3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234013_676806_8a3bcdb3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234013_832758_6513b4cc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234013_832758_6513b4cc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234013_981628_68c91d8f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234013_981628_68c91d8f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234014_138001_2bbdd1f3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234014_138001_2bbdd1f3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234014_373079_20a3c5ba.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234014_373079_20a3c5ba.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234014_566128_ceb66d88.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234014_566128_ceb66d88.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234014_712500_db5233e5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234014_712500_db5233e5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234014_867417_0ccff35e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234014_867417_0ccff35e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234015_002256_7d35c456.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234015_002256_7d35c456.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234015_157650_a6838094.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234015_157650_a6838094.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234015_394343_798a8244.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234015_394343_798a8244.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234015_603479_e6259e8d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234015_603479_e6259e8d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234015_759377_3d776e05.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234015_759377_3d776e05.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234015_894237_c5b931e9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234015_894237_c5b931e9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_023059_08f4a263.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_023059_08f4a263.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_148828_57b019dc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_148828_57b019dc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_278138_f62b7adb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_278138_f62b7adb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_414475_739601f3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_414475_739601f3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_564365_2582e17f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_564365_2582e17f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_695678_1bc5b759.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_695678_1bc5b759.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_856602_78751186.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_856602_78751186.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234016_989423_ba02acf2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234016_989423_ba02acf2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234017_383654_058066b5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234017_383654_058066b5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234017_577733_4ea1ea72.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234017_577733_4ea1ea72.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234017_791414_cd7a3a82.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234017_791414_cd7a3a82.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234017_999073_2c0a3495.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234017_999073_2c0a3495.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234018_281126_a35c5d83.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234018_281126_a35c5d83.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234018_512388_6b881500.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234018_512388_6b881500.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234018_716059_447c1343.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234018_716059_447c1343.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234018_927180_ea835e04.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234018_927180_ea835e04.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234019_062008_a215d835.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234019_062008_a215d835.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234019_216901_e4e2e1ef.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234019_216901_e4e2e1ef.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234019_662625_1f04fcdd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234019_662625_1f04fcdd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234019_820116_2ac1ac9e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234019_820116_2ac1ac9e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234019_988575_f6020e32.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234019_988575_f6020e32.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234020_147544_f2ab9cbf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234020_147544_f2ab9cbf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234020_607893_74731d05.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234020_607893_74731d05.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234020_863717_6e941d1d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234020_863717_6e941d1d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234021_016649_722481f2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234021_016649_722481f2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234021_165057_9b1c81b0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234021_165057_9b1c81b0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234021_339131_6c5f0af0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234021_339131_6c5f0af0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234021_754778_5a125c9a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234021_754778_5a125c9a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234022_137966_7e1639e6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234022_137966_7e1639e6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234022_272345_0c2ee966.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234022_272345_0c2ee966.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234022_411176_592a609e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234022_411176_592a609e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234022_547530_5dcd128f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234022_547530_5dcd128f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234022_678365_9f7325ba.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234022_678365_9f7325ba.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234022_833295_d6ae7858.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234022_833295_d6ae7858.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234022_962602_ae0f3c86.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234022_962602_ae0f3c86.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234023_106990_1b993216.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234023_106990_1b993216.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234023_237817_2c741a8f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234023_237817_2c741a8f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234023_371168_b5b35d4b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234023_371168_b5b35d4b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234023_636871_8903ea3d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234023_636871_8903ea3d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234023_804403_1b58a36c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234023_804403_1b58a36c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234023_982447_5cda076d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234023_982447_5cda076d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234024_129360_b70bc7c6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234024_129360_b70bc7c6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234024_258707_75b0e15a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234024_258707_75b0e15a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234024_394588_57049408.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234024_394588_57049408.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234024_534462_4d80eb6d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234024_534462_4d80eb6d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234024_681373_d12008c0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234024_681373_d12008c0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234024_992210_00fca35a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234024_992210_00fca35a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234025_150174_ad4c67b1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234025_150174_ad4c67b1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234025_324262_076e5c4f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234025_324262_076e5c4f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234025_513358_3b5c3845.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234025_513358_3b5c3845.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234025_716108_97a1b274.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234025_716108_97a1b274.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234026_008037_034ea72f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234026_008037_034ea72f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234026_225718_6feb407f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234026_225718_6feb407f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234026_407297_918c0ca9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234026_407297_918c0ca9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234026_586901_f6911382.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234026_586901_f6911382.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234026_759985_eebcd207.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234026_759985_eebcd207.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234026_955129_50550ba9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234026_955129_50550ba9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234027_123185_0c7dc545.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234027_123185_0c7dc545.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234027_310312_460ec88a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234027_310312_460ec88a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234027_472294_a6b2542a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234027_472294_a6b2542a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234027_750641_a0325a1d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234027_750641_a0325a1d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234027_921710_710092c7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234027_921710_710092c7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234028_090196_9c664880.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234028_090196_9c664880.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234028_244169_e6768a5f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234028_244169_e6768a5f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234028_395115_69debe1a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234028_395115_69debe1a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234028_533999_a179379f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234028_533999_a179379f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234028_670871_9976dbe2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234028_670871_9976dbe2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234028_827820_7483020a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234028_827820_7483020a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234028_995819_89da1e39.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234028_995819_89da1e39.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234029_246006_1a8f2e05.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234029_246006_1a8f2e05.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234029_402479_9817542f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234029_402479_9817542f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234029_551850_2cbd0423.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234029_551850_2cbd0423.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234029_702812_23d00163.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234029_702812_23d00163.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234029_862771_77a71110.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234029_862771_77a71110.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234030_048388_80f698b8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234030_048388_80f698b8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234030_304997_da4e7fb9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234030_304997_da4e7fb9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234030_471992_dfd670e2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234030_471992_dfd670e2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234030_661067_82e83acd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234030_661067_82e83acd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234030_932358_5256e6e8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234030_932358_5256e6e8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234031_123031_ab2e0782.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234031_123031_ab2e0782.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234031_283977_714de44d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234031_283977_714de44d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234031_450438_c8c3c5c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234031_450438_c8c3c5c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234031_600846_14e5b29a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234031_600846_14e5b29a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234031_747221_04ef4ec2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234031_747221_04ef4ec2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234031_900606_38b2294c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234031_900606_38b2294c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234032_076129_c826c5b6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234032_076129_c826c5b6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234032_229072_972d5aa0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234032_229072_972d5aa0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234032_385537_347dcad8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234032_385537_347dcad8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234032_643327_f50a2638.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234032_643327_f50a2638.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234032_780131_b92420c0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234032_780131_b92420c0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234032_913971_8daa6e8d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234032_913971_8daa6e8d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234033_068396_74823456.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234033_068396_74823456.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234033_210268_738b0941.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234033_210268_738b0941.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234033_378769_3d915aa6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234033_378769_3d915aa6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234033_541755_6fc6eacb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234033_541755_6fc6eacb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234033_684657_d97ba95a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234033_684657_d97ba95a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234033_829068_658f1b44.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234033_829068_658f1b44.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234033_979492_6b561fcd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234033_979492_6b561fcd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234034_245309_ffe3d9c6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234034_245309_ffe3d9c6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234034_461999_db0c7339.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234034_461999_db0c7339.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234034_600393_1651138c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234034_600393_1651138c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234034_746274_1f6780b2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234034_746274_1f6780b2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234034_892194_8275102e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234034_892194_8275102e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234035_037092_5d8130b9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234035_037092_5d8130b9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234035_218711_ec3b9d85.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234035_218711_ec3b9d85.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234035_366106_c87484c0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234035_366106_c87484c0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234035_540633_ececc1ab.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234035_540633_ececc1ab.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234035_775660_ad53e869.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234035_775660_ad53e869.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234036_054457_5397750b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234036_054457_5397750b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234036_232513_6e1fa99c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234036_232513_6e1fa99c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234036_386943_dc7c06f5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234036_386943_dc7c06f5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234036_544413_485dd0ce.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234036_544413_485dd0ce.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234036_690792_a2b3a041.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234036_690792_a2b3a041.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234036_843733_8316c112.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234036_843733_8316c112.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234037_005168_afe644a5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234037_005168_afe644a5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234037_166603_6a5b6371.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234037_166603_6a5b6371.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234037_326607_a67a931b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234037_326607_a67a931b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234037_483544_d1ec55da.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234037_483544_d1ec55da.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234037_797982_ebc2770f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234037_797982_ebc2770f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234037_957935_e98625eb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234037_957935_e98625eb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234038_102840_f98ec7cb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234038_102840_f98ec7cb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234038_271326_42af86cf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234038_271326_42af86cf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234038_405192_5582a3f3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234038_405192_5582a3f3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234038_567171_01e8014a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234038_567171_01e8014a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234038_730164_595e43ab.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234038_730164_595e43ab.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234038_875052_24b407c2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234038_875052_24b407c2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234039_021968_1ccb1ec8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234039_021968_1ccb1ec8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234039_333992_6a0bd870.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234039_333992_6a0bd870.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234039_491946_0a7edb59.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234039_491946_0a7edb59.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234039_625766_522c733d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234039_625766_522c733d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234039_766625_87c525a0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234039_766625_87c525a0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234039_913567_e85d5611.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234039_913567_e85d5611.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234040_060427_322073cc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234040_060427_322073cc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234040_210362_8a003d0e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234040_210362_8a003d0e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234040_392984_d7bf83d1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234040_392984_d7bf83d1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234040_525812_2185f986.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234040_525812_2185f986.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234040_656133_17cdc3bd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234040_656133_17cdc3bd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234040_896757_56479bfd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234040_896757_56479bfd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234041_126270_f5eb7508.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234041_126270_f5eb7508.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234041_348964_18b8ecb2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234041_348964_18b8ecb2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234041_497347_b7b4bf3f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234041_497347_b7b4bf3f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234041_647266_ea28b6c1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234041_647266_ea28b6c1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234041_818686_d74196aa.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234041_818686_d74196aa.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234041_953012_4e0d006d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234041_953012_4e0d006d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234042_088827_08ead248.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234042_088827_08ead248.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234042_234234_647f51f1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234042_234234_647f51f1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234042_573175_9b60f418.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234042_573175_9b60f418.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234042_719546_5714f3f1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234042_719546_5714f3f1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234042_860920_a66e5015.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234042_860920_a66e5015.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234043_010845_e5fd1b84.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234043_010845_e5fd1b84.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234043_197364_0279e7c4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234043_197364_0279e7c4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234043_385412_28f67ad9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234043_385412_28f67ad9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234043_526780_0d97b6a5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234043_526780_0d97b6a5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234043_727345_33c4af0a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234043_727345_33c4af0a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234043_869175_f54c3beb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234043_869175_f54c3beb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234044_007551_ceb35f52.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234044_007551_ceb35f52.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234044_339465_d7d69a27.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234044_339465_d7d69a27.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234044_498414_09986edb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234044_498414_09986edb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234044_638782_20e0f956.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234044_638782_20e0f956.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234044_781169_fe1ad029.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234044_781169_fe1ad029.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234044_933133_2efd7992.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234044_933133_2efd7992.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234045_079014_5a39571c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234045_079014_5a39571c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234045_266052_2750ee89.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234045_266052_2750ee89.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234045_434086_a596c1cf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234045_434086_a596c1cf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234045_573940_3c88b59c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234045_573940_3c88b59c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234045_838146_fdf05e1c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234045_838146_fdf05e1c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234045_976508_cd4d95a1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234045_976508_cd4d95a1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234046_176053_b20b9201.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234046_176053_b20b9201.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234046_446209_a33656ba.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234046_446209_a33656ba.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234046_593097_ae98d341.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234046_593097_ae98d341.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234046_730443_5dffa99f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234046_730443_5dffa99f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234046_918434_a2bdb3a1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234046_918434_a2bdb3a1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234047_056779_4bdae40d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234047_056779_4bdae40d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234047_197123_549a1ce9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234047_197123_549a1ce9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234047_343001_1be3d4ec.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234047_343001_1be3d4ec.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234047_648346_01574ba9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234047_648346_01574ba9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234047_842853_3a5853e5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234047_842853_3a5853e5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234047_995399_e7bb8e89.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234047_995399_e7bb8e89.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234048_137742_eabde6f0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234048_137742_eabde6f0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234048_282114_9861ce63.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234048_282114_9861ce63.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234048_428489_541132a8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234048_428489_541132a8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234048_591949_f0214a55.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234048_591949_f0214a55.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234048_799556_bb38ab6d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234048_799556_bb38ab6d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234048_935961_2006b1b0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234048_935961_2006b1b0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234049_210700_188dbed5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234049_210700_188dbed5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234049_361635_ed5fa050.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234049_361635_ed5fa050.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234049_506523_08f3befc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234049_506523_08f3befc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234049_737209_11fa7680.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234049_737209_11fa7680.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234049_874090_afc27385.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234049_874090_afc27385.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234050_013011_2ed6159f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234050_013011_2ed6159f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234050_150363_48379e2f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234050_150363_48379e2f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234050_294329_8d6094fe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234050_294329_8d6094fe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234050_441256_9bccadbe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234050_441256_9bccadbe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234050_625260_ab00ca30.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234050_625260_ab00ca30.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234050_788240_43241912.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234050_788240_43241912.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234050_926138_93394372.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234050_926138_93394372.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234051_091256_324eaae0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234051_091256_324eaae0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234051_252710_067d76bf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234051_252710_067d76bf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234051_457263_5b943449.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234051_457263_5b943449.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234051_625705_99fac83a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234051_625705_99fac83a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234051_994078_16a41ef6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234051_994078_16a41ef6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234052_131405_f254f97a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234052_131405_f254f97a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234052_274302_28b9ac34.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234052_274302_28b9ac34.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234052_461279_8ef6513c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234052_461279_8ef6513c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234052_605151_b1cc8c16.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234052_605151_b1cc8c16.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234052_762785_7390c4f6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234052_762785_7390c4f6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234052_899107_4cab79be.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234052_899107_4cab79be.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234053_042009_ea8abbc8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234053_042009_ea8abbc8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234053_264129_ef8fd496.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234053_264129_ef8fd496.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234053_418670_12adf661.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234053_418670_12adf661.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234053_730200_41ddf947.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234053_730200_41ddf947.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234053_889165_6a1b1646.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234053_889165_6a1b1646.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234054_045658_0391a1bf.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234054_045658_0391a1bf.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234054_264338_9e2e69e2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234054_264338_9e2e69e2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234054_431375_e8e93c0d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234054_431375_e8e93c0d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234054_574266_728a3911.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234054_574266_728a3911.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234054_719137_4a5c7bbb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234054_719137_4a5c7bbb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234054_861136_22601806.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234054_861136_22601806.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234055_181510_f4d8529b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234055_181510_f4d8529b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234055_354472_11e74601.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234055_354472_11e74601.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234055_503879_fe9772c8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234055_503879_fe9772c8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234055_645252_18159be8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234055_645252_18159be8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234055_785097_fcbf777f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234055_785097_fcbf777f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234055_980137_b0061fff.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234055_980137_b0061fff.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234056_142610_b5707848.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234056_142610_b5707848.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234056_299994_552a5e00.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234056_299994_552a5e00.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234056_479482_1eb79233.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234056_479482_1eb79233.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234056_684545_9b2af905.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234056_684545_9b2af905.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234057_131674_a7af7ad2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234057_131674_a7af7ad2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234057_307218_99814229.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234057_307218_99814229.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234057_457614_d07ae8bb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234057_457614_d07ae8bb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234057_610045_b7f45531.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234057_610045_b7f45531.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234057_804587_1fd5f4d9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234057_804587_1fd5f4d9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234057_957497_528d1dfc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234057_957497_528d1dfc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234058_108992_f64b9dbc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234058_108992_f64b9dbc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234058_277992_83ca6a79.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234058_277992_83ca6a79.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234058_426488_b7378399.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234058_426488_b7378399.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234058_582955_20e4f3bb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234058_582955_20e4f3bb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234058_815249_4996ec45.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234058_815249_4996ec45.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234058_985225_8343707a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234058_985225_8343707a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234059_281570_f0765d9b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234059_281570_f0765d9b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234059_512858_601d32ed.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234059_512858_601d32ed.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234059_677392_2d355ab0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234059_677392_2d355ab0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234059_868436_07abada5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234059_868436_07abada5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234100_060482_e643e0c6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234100_060482_e643e0c6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234100_251119_4a555ec2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234100_251119_4a555ec2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234100_437674_e1a4a1c8.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234100_437674_e1a4a1c8.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234100_757194_5d76640e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234100_757194_5d76640e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234100_921675_6210ff5a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234100_921675_6210ff5a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234101_530163_701d8dff.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234101_530163_701d8dff.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234101_855507_300de953.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234101_855507_300de953.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234102_033585_5869bb26.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234102_033585_5869bb26.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234102_210136_deb239fd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234102_210136_deb239fd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234102_375636_ee7be4e5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234102_375636_ee7be4e5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234102_621753_99999960.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234102_621753_99999960.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234102_766200_27fa2a25.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234102_766200_27fa2a25.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234102_966845_5eed25f0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234102_966845_5eed25f0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234103_131387_e6f254b5.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234103_131387_e6f254b5.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234103_274301_e499c3c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234103_274301_e499c3c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234103_417866_9e5db31c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234103_417866_9e5db31c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234103_582927_268b481d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234103_582927_268b481d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234103_747987_a1696e49.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234103_747987_a1696e49.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234103_924547_6170d5d2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234103_924547_6170d5d2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234104_093598_bded7641.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234104_093598_bded7641.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234104_272419_10a1d7f7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234104_272419_10a1d7f7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234104_493794_1b5f1452.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234104_493794_1b5f1452.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234104_822443_57fcf914.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234104_822443_57fcf914.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234105_024644_cd47e201.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234105_024644_cd47e201.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234105_250349_92bc3fb3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234105_250349_92bc3fb3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234105_408292_c0ff317b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234105_408292_c0ff317b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234105_544635_8010273d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234105_544635_8010273d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234105_706087_66e86f11.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234105_706087_66e86f11.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234105_832858_32e683c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234105_832858_32e683c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234105_970684_4f3c8c93.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234105_970684_4f3c8c93.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234106_124121_16c8d826.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234106_124121_16c8d826.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234106_282567_2973a6a9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234106_282567_2973a6a9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234106_527242_50b0ac15.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234106_527242_50b0ac15.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234106_673620_b3b97f8c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234106_673620_b3b97f8c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234106_805458_7c50a9ab.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234106_805458_7c50a9ab.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234106_958836_b9a18d33.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234106_958836_b9a18d33.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234107_086654_9b52fb6f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234107_086654_9b52fb6f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234107_242068_31fb07f6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234107_242068_31fb07f6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234107_397479_81a19d98.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234107_397479_81a19d98.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234107_534346_fc69273c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234107_534346_fc69273c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234107_710286_0943a117.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234107_710286_0943a117.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234107_947757_08e72cc0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234107_947757_08e72cc0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234108_075076_a6e27ae3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234108_075076_a6e27ae3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234108_229994_36cb49f4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234108_229994_36cb49f4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234108_362355_cb6d7a0e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234108_362355_cb6d7a0e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234108_512727_d0114c0b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234108_512727_d0114c0b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234108_656608_70913cdb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234108_656608_70913cdb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234108_780895_5010eb32.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234108_780895_5010eb32.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234108_929291_e53ec6d6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234108_929291_e53ec6d6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234109_164175_7021c558.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234109_164175_7021c558.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234109_346350_f8d04ed6.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234109_346350_f8d04ed6.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234109_577238_04bc6f06.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234109_577238_04bc6f06.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234109_806023_19b68d6f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234109_806023_19b68d6f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234109_948368_6f49f306.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234109_948368_6f49f306.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234110_070639_a11cdcbe.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234110_070639_a11cdcbe.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234110_218532_32f45dda.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234110_218532_32f45dda.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234110_365960_2a94965f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234110_365960_2a94965f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234110_508315_b02d293c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234110_508315_b02d293c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234110_743900_71d05892.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234110_743900_71d05892.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234110_876726_6a3e1096.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234110_876726_6a3e1096.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234111_017599_c7cf1c57.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234111_017599_c7cf1c57.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234111_144912_9723d260.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234111_144912_9723d260.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234111_298307_cf035645.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234111_298307_cf035645.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234111_455763_67c6ab82.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234111_455763_67c6ab82.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234111_588591_6cc4d9f9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234111_588591_6cc4d9f9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234111_720916_53e8bfe4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234111_720916_53e8bfe4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234111_889866_463e47c9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234111_889866_463e47c9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234112_176331_4883868b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234112_176331_4883868b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234112_431030_40724d31.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234112_431030_40724d31.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234112_562341_10c499bc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234112_562341_10c499bc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234112_703294_716a36c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234112_703294_716a36c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234112_862169_136ab01f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234112_862169_136ab01f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234113_014097_6610090f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234113_014097_6610090f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234113_237059_5565473a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234113_237059_5565473a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234113_364349_37d230f3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234113_364349_37d230f3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234113_512272_69c6b743.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234113_512272_69c6b743.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234113_636067_6a97fe2d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234113_636067_6a97fe2d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234113_777953_1234dfb1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234113_777953_1234dfb1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_010598_3f30e562.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_010598_3f30e562.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_132909_941a8c3e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_132909_941a8c3e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_273304_838f4825.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_273304_838f4825.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_416209_82d3d033.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_416209_82d3d033.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_550553_1e127048.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_550553_1e127048.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_678354_208171ab.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_678354_208171ab.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_802129_dec4588a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_802129_dec4588a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234114_926442_d9777868.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234114_926442_d9777868.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234115_072328_e14ae601.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234115_072328_e14ae601.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234115_212676_f562318e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234115_212676_f562318e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234115_444270_37922064.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234115_444270_37922064.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234115_583619_e5b48c4e.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234115_583619_e5b48c4e.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234115_709914_6aad81a9.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234115_709914_6aad81a9.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234115_850771_f0e4e9c3.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234115_850771_f0e4e9c3.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234115_998654_7fecdd32.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234115_998654_7fecdd32.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234116_143016_4fad4548.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234116_143016_4fad4548.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234116_281358_3fd3bd78.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234116_281358_3fd3bd78.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234116_440779_111a82bb.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234116_440779_111a82bb.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234116_617298_a13e3226.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234116_617298_a13e3226.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234116_745614_b489ca03.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234116_745614_b489ca03.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_010845_c1124253.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_010845_c1124253.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_138159_71348e1d.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_138159_71348e1d.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_272992_5bcf9423.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_272992_5bcf9423.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_397793_c897aac1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_397793_c897aac1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_548739_abb907c7.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_548739_abb907c7.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_693140_7d3afc2f.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_693140_7d3afc2f.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_816438_d7f3ff6b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_816438_d7f3ff6b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234117_950793_9786d2bd.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234117_950793_9786d2bd.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234118_084642_1cf1fbfc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234118_084642_1cf1fbfc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234118_272649_ed4ece17.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234118_272649_ed4ece17.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234118_545832_183c4011.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234118_545832_183c4011.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234118_668585_6b07e096.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234118_668585_6b07e096.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234118_799902_56177bc1.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234118_799902_56177bc1.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234118_922686_f928f4c0.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234118_922686_f928f4c0.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_038430_dba7d68c.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_038430_dba7d68c.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_160222_047451c4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_160222_047451c4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_273441_b606790b.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_273441_b606790b.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_385671_ea67d121.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_385671_ea67d121.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_498885_72883b48.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_498885_72883b48.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_627739_3ffffecc.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_627739_3ffffecc.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_739467_9382fa2a.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_739467_9382fa2a.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_848678_d3508425.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_848678_d3508425.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234119_957891_66b96453.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234119_957891_66b96453.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234120_068116_633e6df2.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234120_068116_633e6df2.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
  collected_batch_minha-fila-teste-stress_20250407_234120_184836_9bc2ade4.json:
    caminho_completo: .\test-json-data-collector-validation_batched\collected_batch_minha-fila-teste-stress_20250407_234120_184836_9bc2ade4.json
    json_info:
      numero_de_linhas: 12
      tamanho: 0.00 MB
    numero_de_linhas: 12
    tamanho: 0.00 MB
